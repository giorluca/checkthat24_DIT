{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Appeal_to_Hypocrisy_precision', 0.23529411764705882),\n",
       "  ('Appeal_to_Hypocrisy_recall', 0.17699115044247787),\n",
       "  ('Appeal_to_Hypocrisy_f1-score', 0.20202020202020202),\n",
       "  ('Appeal_to_Hypocrisy_support', 113.0)],\n",
       " [('Obfuscation-Vagueness-Confusion_precision', 0.07692307692307693),\n",
       "  ('Obfuscation-Vagueness-Confusion_recall', 0.030303030303030304),\n",
       "  ('Obfuscation-Vagueness-Confusion_f1-score', 0.043478260869565216),\n",
       "  ('Obfuscation-Vagueness-Confusion_support', 99.0)],\n",
       " [('Doubt_precision', 0.20867768595041322),\n",
       "  ('Doubt_recall', 0.14831130690161526),\n",
       "  ('Doubt_f1-score', 0.17339055793991417),\n",
       "  ('Doubt_support', 681.0)],\n",
       " [('Causal_Oversimplification_precision', 0.038461538461538464),\n",
       "  ('Causal_Oversimplification_recall', 0.0125),\n",
       "  ('Causal_Oversimplification_f1-score', 0.01886792452830189),\n",
       "  ('Causal_Oversimplification_support', 160)],\n",
       " [('Straw_Man_precision', 0.06451612903225806),\n",
       "  ('Straw_Man_recall', 0.029850746268656716),\n",
       "  ('Straw_Man_f1-score', 0.04081632653061224),\n",
       "  ('Straw_Man_support', 67)],\n",
       " [('Exaggeration-Minimisation_precision', 0.02512562814070352),\n",
       "  ('Exaggeration-Minimisation_recall', 0.03546099290780142),\n",
       "  ('Exaggeration-Minimisation_f1-score', 0.029411764705882353),\n",
       "  ('Exaggeration-Minimisation_support', 141.0)],\n",
       " [('Flag_Waving_precision', 0.012195121951219513),\n",
       "  ('Flag_Waving_recall', 0.01098901098901099),\n",
       "  ('Flag_Waving_f1-score', 0.0115606936416185),\n",
       "  ('Flag_Waving_support', 91)],\n",
       " [('False_Dilemma-No_Choice_precision', 0.041666666666666664),\n",
       "  ('False_Dilemma-No_Choice_recall', 0.021052631578947368),\n",
       "  ('False_Dilemma-No_Choice_f1-score', 0.02797202797202797),\n",
       "  ('False_Dilemma-No_Choice_support', 95)],\n",
       " [('Loaded_Language_precision', 0.05546218487394958),\n",
       "  ('Loaded_Language_recall', 0.10945273631840796),\n",
       "  ('Loaded_Language_f1-score', 0.07361963190184048),\n",
       "  ('Loaded_Language_support', 603.0)],\n",
       " [('Appeal_to_Time_precision', 0.1111111111111111),\n",
       "  ('Appeal_to_Time_recall', 0.03389830508474576),\n",
       "  ('Appeal_to_Time_f1-score', 0.05194805194805195),\n",
       "  ('Appeal_to_Time_support', 59.0)],\n",
       " [('Appeal_to_Values_precision', 0.25301204819277107),\n",
       "  ('Appeal_to_Values_recall', 0.12138728323699421),\n",
       "  ('Appeal_to_Values_f1-score', 0.1640625),\n",
       "  ('Appeal_to_Values_support', 173)],\n",
       " [('Consequential_Oversimplification_precision', 0.35555555555555557),\n",
       "  ('Consequential_Oversimplification_recall', 0.21052631578947367),\n",
       "  ('Consequential_Oversimplification_f1-score', 0.2644628099173553),\n",
       "  ('Consequential_Oversimplification_support', 76)],\n",
       " [('Guilt_by_Association_precision', 0.01818181818181818),\n",
       "  ('Guilt_by_Association_recall', 0.008620689655172414),\n",
       "  ('Guilt_by_Association_f1-score', 0.011695906432748537),\n",
       "  ('Guilt_by_Association_support', 116.0)],\n",
       " [('Questioning_the_Reputation_precision', 0.20673076923076922),\n",
       "  ('Questioning_the_Reputation_recall', 0.14576271186440679),\n",
       "  ('Questioning_the_Reputation_f1-score', 0.17097415506958252),\n",
       "  ('Questioning_the_Reputation_support', 295.0)],\n",
       " [('Appeal_to_Fear-Prejudice_precision', 0.0658682634730539),\n",
       "  ('Appeal_to_Fear-Prejudice_recall', 0.03873239436619718),\n",
       "  ('Appeal_to_Fear-Prejudice_f1-score', 0.04878048780487805),\n",
       "  ('Appeal_to_Fear-Prejudice_support', 284)],\n",
       " [('Conversation_Killer_precision', 0.33636363636363636),\n",
       "  ('Conversation_Killer_recall', 0.3425925925925926),\n",
       "  ('Conversation_Killer_f1-score', 0.3394495412844037),\n",
       "  ('Conversation_Killer_support', 108.0)],\n",
       " [('Slogans_precision', 0.3048780487804878),\n",
       "  ('Slogans_recall', 0.23148148148148148),\n",
       "  ('Slogans_f1-score', 0.26315789473684215),\n",
       "  ('Slogans_support', 108)],\n",
       " [('Appeal_to_Popularity_precision', 0.20930232558139536),\n",
       "  ('Appeal_to_Popularity_recall', 0.072),\n",
       "  ('Appeal_to_Popularity_f1-score', 0.10714285714285714),\n",
       "  ('Appeal_to_Popularity_support', 125)],\n",
       " [('Whataboutism_precision', 0.09090909090909091),\n",
       "  ('Whataboutism_recall', 0.034482758620689655),\n",
       "  ('Whataboutism_f1-score', 0.05),\n",
       "  ('Whataboutism_support', 29)],\n",
       " [('Appeal_to_Authority_precision', 0.10810810810810811),\n",
       "  ('Appeal_to_Authority_recall', 0.049079754601226995),\n",
       "  ('Appeal_to_Authority_f1-score', 0.06751054852320676),\n",
       "  ('Appeal_to_Authority_support', 163)],\n",
       " [('Repetition_precision', 0.007142857142857143),\n",
       "  ('Repetition_recall', 0.014925373134328358),\n",
       "  ('Repetition_f1-score', 0.00966183574879227),\n",
       "  ('Repetition_support', 67.0)],\n",
       " [('Red_Herring_precision', 0),\n",
       "  ('Red_Herring_recall', 0),\n",
       "  ('Red_Herring_f1-score', 0),\n",
       "  ('Red_Herring_support', 39)],\n",
       " [('Name_Calling-Labeling_precision', 0.1923497267759563),\n",
       "  ('Name_Calling-Labeling_recall', 0.2337317397078353),\n",
       "  ('Name_Calling-Labeling_f1-score', 0.21103117505995203),\n",
       "  ('Name_Calling-Labeling_support', 753.0)]]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "path = '/home/lgiordano/LUCA/checkthat_GITHUB/models/M2/'\n",
    "results = []\n",
    "for subdir in os.listdir(path):\n",
    "    res = json.load(open(path + subdir + '/results.json'))\n",
    "    metrics = list(res.items())[1:5]\n",
    "    results.append(metrics)\n",
    "\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                persuasion_technique  precision    recall        f1  n_samples\n",
      "0                Appeal_to_Hypocrisy   0.235294  0.176991  0.202020        113\n",
      "1    Obfuscation-Vagueness-Confusion   0.076923  0.030303  0.043478         99\n",
      "2                              Doubt   0.208678  0.148311  0.173391        681\n",
      "3          Causal_Oversimplification   0.038462  0.012500  0.018868        160\n",
      "4                          Straw_Man   0.064516  0.029851  0.040816         67\n",
      "5          Exaggeration-Minimisation   0.025126  0.035461  0.029412        141\n",
      "6                        Flag_Waving   0.012195  0.010989  0.011561         91\n",
      "7            False_Dilemma-No_Choice   0.041667  0.021053  0.027972         95\n",
      "8                    Loaded_Language   0.055462  0.109453  0.073620        603\n",
      "9                     Appeal_to_Time   0.111111  0.033898  0.051948         59\n",
      "10                  Appeal_to_Values   0.253012  0.121387  0.164062        173\n",
      "11  Consequential_Oversimplification   0.355556  0.210526  0.264463         76\n",
      "12              Guilt_by_Association   0.018182  0.008621  0.011696        116\n",
      "13        Questioning_the_Reputation   0.206731  0.145763  0.170974        295\n",
      "14          Appeal_to_Fear-Prejudice   0.065868  0.038732  0.048780        284\n",
      "15               Conversation_Killer   0.336364  0.342593  0.339450        108\n",
      "16                           Slogans   0.304878  0.231481  0.263158        108\n",
      "17              Appeal_to_Popularity   0.209302  0.072000  0.107143        125\n",
      "18                      Whataboutism   0.090909  0.034483  0.050000         29\n",
      "19               Appeal_to_Authority   0.108108  0.049080  0.067511        163\n",
      "20                        Repetition   0.007143  0.014925  0.009662         67\n",
      "21                       Red_Herring   0.000000  0.000000  0.000000         39\n",
      "22             Name_Calling-Labeling   0.192350  0.233732  0.211031        753\n"
     ]
    }
   ],
   "source": [
    "# Define the column names\n",
    "columns = ['persuasion_technique', 'precision', 'recall', 'f1', 'n_samples']\n",
    "\n",
    "# Initialize an empty list to store the transformed data\n",
    "transformed_data = []\n",
    "\n",
    "# Iterate through the original data and transform it\n",
    "for sublist in results:\n",
    "    technique_data = {}\n",
    "    for item in sublist:\n",
    "        key, value = item\n",
    "        if '_precision' in key:\n",
    "            technique = key.split('_precision')[0]\n",
    "            metric = 'precision'\n",
    "        elif '_recall' in key:\n",
    "            technique = key.split('_recall')[0]\n",
    "            metric = 'recall'\n",
    "        elif '_f1-score' in key:\n",
    "            technique = key.split('_f1-score')[0]\n",
    "            metric = 'f1-score'\n",
    "        elif '_support' in key:\n",
    "            technique = key.split('_support')[0]\n",
    "            metric = 'support'\n",
    "        if technique not in technique_data:\n",
    "            technique_data[technique] = {}\n",
    "        technique_data[technique][metric] = value\n",
    "    for technique, metrics in technique_data.items():\n",
    "        transformed_data.append([technique, metrics.get('precision', None), metrics.get('recall', None), metrics.get('f1-score', None), int(metrics.get('support', None))])\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(transformed_data, columns=columns)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/home/lgiordano/LUCA/checkthat_GITHUB/misc/results.tsv', sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
