{"results": [{"micro_f1": 0.7570458989991948, "Appeal_to_Fear-Prejudice_precision": 0.0546448087431694, "Appeal_to_Fear-Prejudice_recall": 0.029069767441860465, "Appeal_to_Fear-Prejudice_f1-score": 0.03795066413662239, "Appeal_to_Fear-Prejudice_support": 344.0, "micro avg_precision": 0.0546448087431694, "micro avg_recall": 0.029069767441860465, "micro avg_f1-score": 0.03795066413662239, "micro avg_support": 344.0, "macro avg_precision": 0.0546448087431694, "macro avg_recall": 0.029069767441860465, "macro avg_f1-score": 0.03795066413662239, "macro avg_support": 344.0, "weighted avg_precision": 0.0546448087431694, "weighted avg_recall": 0.029069767441860465, "weighted avg_f1-score": 0.03795066413662239, "weighted avg_support": 344.0, "O_support": 5769, "B-Appeal_to_Fear-Prejudice_support": 183, "I-Appeal_to_Fear-Prejudice_support": 2741, "epoch": 0}, {"micro_f1": 0.7670539514551938, "Appeal_to_Fear-Prejudice_precision": 0.08743169398907104, "Appeal_to_Fear-Prejudice_recall": 0.05, "Appeal_to_Fear-Prejudice_f1-score": 0.0636182902584493, "Appeal_to_Fear-Prejudice_support": 320.0, "micro avg_precision": 0.08743169398907104, "micro avg_recall": 0.05, "micro avg_f1-score": 0.0636182902584493, "micro avg_support": 320.0, "macro avg_precision": 0.08743169398907104, "macro avg_recall": 0.05, "macro avg_f1-score": 0.0636182902584493, "macro avg_support": 320.0, "weighted avg_precision": 0.08743169398907104, "weighted avg_recall": 0.05, "weighted avg_f1-score": 0.0636182902584493, "weighted avg_support": 320.0, "O_support": 5769, "B-Appeal_to_Fear-Prejudice_support": 183, "I-Appeal_to_Fear-Prejudice_support": 2741, "epoch": 1}, {"micro_f1": 0.7797078108823191, "Appeal_to_Fear-Prejudice_precision": 0.1912568306010929, "Appeal_to_Fear-Prejudice_recall": 0.09803921568627451, "Appeal_to_Fear-Prejudice_f1-score": 0.12962962962962962, "Appeal_to_Fear-Prejudice_support": 357.0, "micro avg_precision": 0.1912568306010929, "micro avg_recall": 0.09803921568627451, "micro avg_f1-score": 0.12962962962962962, "micro avg_support": 357.0, "macro avg_precision": 0.1912568306010929, "macro avg_recall": 0.09803921568627451, "macro avg_f1-score": 0.12962962962962962, "macro avg_support": 357.0, "weighted avg_precision": 0.19125683060109291, "weighted avg_recall": 0.09803921568627451, "weighted avg_f1-score": 0.12962962962962962, "weighted avg_support": 357.0, "O_support": 5769, "B-Appeal_to_Fear-Prejudice_support": 183, "I-Appeal_to_Fear-Prejudice_support": 2741, "epoch": 2}, {"micro_f1": 0.7640630392269642, "Appeal_to_Fear-Prejudice_precision": 0.16939890710382513, "Appeal_to_Fear-Prejudice_recall": 0.09748427672955975, "Appeal_to_Fear-Prejudice_f1-score": 0.12375249500998003, "Appeal_to_Fear-Prejudice_support": 318.0, "micro avg_precision": 0.16939890710382513, "micro avg_recall": 0.09748427672955975, "micro avg_f1-score": 0.12375249500998003, "micro avg_support": 318.0, "macro avg_precision": 0.16939890710382513, "macro avg_recall": 0.09748427672955975, "macro avg_f1-score": 0.12375249500998003, "macro avg_support": 318.0, "weighted avg_precision": 0.16939890710382513, "weighted avg_recall": 0.09748427672955975, "weighted avg_f1-score": 0.12375249500998003, "weighted avg_support": 318.0, "O_support": 5769, "B-Appeal_to_Fear-Prejudice_support": 183, "I-Appeal_to_Fear-Prejudice_support": 2741, "epoch": 3}], "best_epoch": 3, "train_data_path": "./data/formatted/train_sentences_ls.json"}