{"results": [{"micro_f1": 0.7520325203252033, "Appeal_to_Hypocrisy_precision": 0.2426470588235294, "Appeal_to_Hypocrisy_recall": 0.10679611650485436, "Appeal_to_Hypocrisy_f1-score": 0.148314606741573, "Appeal_to_Hypocrisy_support": 309.0, "micro avg_precision": 0.2426470588235294, "micro avg_recall": 0.10679611650485436, "micro avg_f1-score": 0.148314606741573, "micro avg_support": 309.0, "macro avg_precision": 0.2426470588235294, "macro avg_recall": 0.10679611650485436, "macro avg_f1-score": 0.148314606741573, "macro avg_support": 309.0, "weighted avg_precision": 0.24264705882352944, "weighted avg_recall": 0.10679611650485436, "weighted avg_f1-score": 0.148314606741573, "weighted avg_support": 309.0, "O_support": 2397, "B-Appeal_to_Hypocrisy_support": 136, "I-Appeal_to_Hypocrisy_support": 2879, "epoch": 0}, {"micro_f1": 0.7560975609756099, "Appeal_to_Hypocrisy_precision": 0.22058823529411764, "Appeal_to_Hypocrisy_recall": 0.11320754716981132, "Appeal_to_Hypocrisy_f1-score": 0.14962593516209477, "Appeal_to_Hypocrisy_support": 265.0, "micro avg_precision": 0.22058823529411764, "micro avg_recall": 0.11320754716981132, "micro avg_f1-score": 0.14962593516209477, "micro avg_support": 265.0, "macro avg_precision": 0.22058823529411764, "macro avg_recall": 0.11320754716981132, "macro avg_f1-score": 0.14962593516209477, "macro avg_support": 265.0, "weighted avg_precision": 0.22058823529411764, "weighted avg_recall": 0.11320754716981132, "weighted avg_f1-score": 0.14962593516209477, "weighted avg_support": 265.0, "O_support": 2397, "B-Appeal_to_Hypocrisy_support": 136, "I-Appeal_to_Hypocrisy_support": 2879, "epoch": 1}, {"micro_f1": 0.7392830746489283, "Appeal_to_Hypocrisy_precision": 0.25735294117647056, "Appeal_to_Hypocrisy_recall": 0.15283842794759825, "Appeal_to_Hypocrisy_f1-score": 0.1917808219178082, "Appeal_to_Hypocrisy_support": 229.0, "micro avg_precision": 0.25735294117647056, "micro avg_recall": 0.15283842794759825, "micro avg_f1-score": 0.1917808219178082, "micro avg_support": 229.0, "macro avg_precision": 0.25735294117647056, "macro avg_recall": 0.15283842794759825, "macro avg_f1-score": 0.1917808219178082, "macro avg_support": 229.0, "weighted avg_precision": 0.25735294117647056, "weighted avg_recall": 0.15283842794759825, "weighted avg_f1-score": 0.1917808219178082, "weighted avg_support": 229.0, "O_support": 2397, "B-Appeal_to_Hypocrisy_support": 136, "I-Appeal_to_Hypocrisy_support": 2879, "epoch": 2}, {"micro_f1": 0.753880266075388, "Appeal_to_Hypocrisy_precision": 0.19117647058823528, "Appeal_to_Hypocrisy_recall": 0.12682926829268293, "Appeal_to_Hypocrisy_f1-score": 0.15249266862170088, "Appeal_to_Hypocrisy_support": 205.0, "micro avg_precision": 0.19117647058823528, "micro avg_recall": 0.12682926829268293, "micro avg_f1-score": 0.15249266862170088, "micro avg_support": 205.0, "macro avg_precision": 0.19117647058823528, "macro avg_recall": 0.12682926829268293, "macro avg_f1-score": 0.15249266862170088, "macro avg_support": 205.0, "weighted avg_precision": 0.19117647058823528, "weighted avg_recall": 0.12682926829268293, "weighted avg_f1-score": 0.15249266862170088, "weighted avg_support": 205.0, "O_support": 2397, "B-Appeal_to_Hypocrisy_support": 136, "I-Appeal_to_Hypocrisy_support": 2879, "epoch": 3}], "best_epoch": 3, "train_data_path": "./data/formatted/train_sentences_ls.json"}