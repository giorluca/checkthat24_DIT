[?7l

Training model no. 0 of 23 for (0, 'Appeal_to_Authority') persuasion technique...
{'micro_f1': 0.5772184300341296, 'precision': 0.5772184300341296, 'Appeal_to_Authority_precision': 0.0, 'Appeal_to_Authority_recall': 0.0, 'Appeal_to_Authority_f1-score': 0.0, 'Appeal_to_Authority_support': 32.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 32.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 32.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 32.0, 'O_support': 2643, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 0}
{'results': [{'micro_f1': 0.5772184300341296, 'precision': 0.5772184300341296, 'Appeal_to_Authority_precision': 0.0, 'Appeal_to_Authority_recall': 0.0, 'Appeal_to_Authority_f1-score': 0.0, 'Appeal_to_Authority_support': 32.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 32.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 32.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 32.0, 'O_support': 2643, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 0}]}
{'micro_f1': 0.7408276450511946, 'precision': 0.7408276450511946, 'Appeal_to_Authority_precision': 0.05982905982905983, 'Appeal_to_Authority_recall': 0.03317535545023697, 'Appeal_to_Authority_f1-score': 0.0426829268292683, 'Appeal_to_Authority_support': 211.0, 'micro avg_precision': 0.05982905982905983, 'micro avg_recall': 0.03317535545023697, 'micro avg_f1-score': 0.0426829268292683, 'micro avg_support': 211.0, 'macro avg_precision': 0.05982905982905983, 'macro avg_recall': 0.03317535545023697, 'macro avg_f1-score': 0.0426829268292683, 'macro avg_support': 211.0, 'weighted avg_precision': 0.05982905982905984, 'weighted avg_recall': 0.03317535545023697, 'weighted avg_f1-score': 0.0426829268292683, 'weighted avg_support': 211.0, 'O_support': 2643, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 1}
{'results': [{'micro_f1': 0.5772184300341296, 'precision': 0.5772184300341296, 'Appeal_to_Authority_precision': 0.0, 'Appeal_to_Authority_recall': 0.0, 'Appeal_to_Authority_f1-score': 0.0, 'Appeal_to_Authority_support': 32.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 32.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 32.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 32.0, 'O_support': 2643, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 0}, {'micro_f1': 0.7408276450511946, 'precision': 0.7408276450511946, 'Appeal_to_Authority_precision': 0.05982905982905983, 'Appeal_to_Authority_recall': 0.03317535545023697, 'Appeal_to_Authority_f1-score': 0.0426829268292683, 'Appeal_to_Authority_support': 211.0, 'micro avg_precision': 0.05982905982905983, 'micro avg_recall': 0.03317535545023697, 'micro avg_f1-score': 0.0426829268292683, 'micro avg_support': 211.0, 'macro avg_precision': 0.05982905982905983, 'macro avg_recall': 0.03317535545023697, 'macro avg_f1-score': 0.0426829268292683, 'macro avg_support': 211.0, 'weighted avg_precision': 0.05982905982905984, 'weighted avg_recall': 0.03317535545023697, 'weighted avg_f1-score': 0.0426829268292683, 'weighted avg_support': 211.0, 'O_support': 2643, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 1}]}
Best model updated: current epoch macro f1 = 0.0426829268292683
{'micro_f1': 0.7610921501706485, 'precision': 0.7610921501706485, 'Appeal_to_Authority_precision': 0.09401709401709402, 'Appeal_to_Authority_recall': 0.0658682634730539, 'Appeal_to_Authority_f1-score': 0.07746478873239436, 'Appeal_to_Authority_support': 167.0, 'micro avg_precision': 0.09401709401709402, 'micro avg_recall': 0.0658682634730539, 'micro avg_f1-score': 0.07746478873239436, 'micro avg_support': 167.0, 'macro avg_precision': 0.09401709401709402, 'macro avg_recall': 0.0658682634730539, 'macro avg_f1-score': 0.07746478873239436, 'macro avg_support': 167.0, 'weighted avg_precision': 0.09401709401709402, 'weighted avg_recall': 0.0658682634730539, 'weighted avg_f1-score': 0.07746478873239436, 'weighted avg_support': 167.0, 'O_support': 2643, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 2}
{'results': [{'micro_f1': 0.5772184300341296, 'precision': 0.5772184300341296, 'Appeal_to_Authority_precision': 0.0, 'Appeal_to_Authority_recall': 0.0, 'Appeal_to_Authority_f1-score': 0.0, 'Appeal_to_Authority_support': 32.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 32.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 32.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 32.0, 'O_support': 2643, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 0}, {'micro_f1': 0.7408276450511946, 'precision': 0.7408276450511946, 'Appeal_to_Authority_precision': 0.05982905982905983, 'Appeal_to_Authority_recall': 0.03317535545023697, 'Appeal_to_Authority_f1-score': 0.0426829268292683, 'Appeal_to_Authority_support': 211.0, 'micro avg_precision': 0.05982905982905983, 'micro avg_recall': 0.03317535545023697, 'micro avg_f1-score': 0.0426829268292683, 'micro avg_support': 211.0, 'macro avg_precision': 0.05982905982905983, 'macro avg_recall': 0.03317535545023697, 'macro avg_f1-score': 0.0426829268292683, 'macro avg_support': 211.0, 'weighted avg_precision': 0.05982905982905984, 'weighted avg_recall': 0.03317535545023697, 'weighted avg_f1-score': 0.0426829268292683, 'weighted avg_support': 211.0, 'O_support': 2643, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 1}, {'micro_f1': 0.7610921501706485, 'precision': 0.7610921501706485, 'Appeal_to_Authority_precision': 0.09401709401709402, 'Appeal_to_Authority_recall': 0.0658682634730539, 'Appeal_to_Authority_f1-score': 0.07746478873239436, 'Appeal_to_Authority_support': 167.0, 'micro avg_precision': 0.09401709401709402, 'micro avg_recall': 0.0658682634730539, 'micro avg_f1-score': 0.07746478873239436, 'micro avg_support': 167.0, 'macro avg_precision': 0.09401709401709402, 'macro avg_recall': 0.0658682634730539, 'macro avg_f1-score': 0.07746478873239436, 'macro avg_support': 167.0, 'weighted avg_precision': 0.09401709401709402, 'weighted avg_recall': 0.0658682634730539, 'weighted avg_f1-score': 0.07746478873239436, 'weighted avg_support': 167.0, 'O_support': 2643, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 2}]}
Best model updated: current epoch macro f1 = 0.07746478873239436
{'micro_f1': 0.7753839590443686, 'precision': 0.7753839590443686, 'Appeal_to_Authority_precision': 0.1623931623931624, 'Appeal_to_Authority_recall': 0.09047619047619047, 'Appeal_to_Authority_f1-score': 0.11620795107033641, 'Appeal_to_Authority_support': 210.0, 'micro avg_precision': 0.1623931623931624, 'micro avg_recall': 0.09047619047619047, 'micro avg_f1-score': 0.11620795107033641, 'micro avg_support': 210.0, 'macro avg_precision': 0.1623931623931624, 'macro avg_recall': 0.09047619047619047, 'macro avg_f1-score': 0.11620795107033641, 'macro avg_support': 210.0, 'weighted avg_precision': 0.1623931623931624, 'weighted avg_recall': 0.09047619047619047, 'weighted avg_f1-score': 0.11620795107033641, 'weighted avg_support': 210.0, 'O_support': 2643, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 3}
{'results': [{'micro_f1': 0.5772184300341296, 'precision': 0.5772184300341296, 'Appeal_to_Authority_precision': 0.0, 'Appeal_to_Authority_recall': 0.0, 'Appeal_to_Authority_f1-score': 0.0, 'Appeal_to_Authority_support': 32.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 32.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 32.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 32.0, 'O_support': 2643, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 0}, {'micro_f1': 0.7408276450511946, 'precision': 0.7408276450511946, 'Appeal_to_Authority_precision': 0.05982905982905983, 'Appeal_to_Authority_recall': 0.03317535545023697, 'Appeal_to_Authority_f1-score': 0.0426829268292683, 'Appeal_to_Authority_support': 211.0, 'micro avg_precision': 0.05982905982905983, 'micro avg_recall': 0.03317535545023697, 'micro avg_f1-score': 0.0426829268292683, 'micro avg_support': 211.0, 'macro avg_precision': 0.05982905982905983, 'macro avg_recall': 0.03317535545023697, 'macro avg_f1-score': 0.0426829268292683, 'macro avg_support': 211.0, 'weighted avg_precision': 0.05982905982905984, 'weighted avg_recall': 0.03317535545023697, 'weighted avg_f1-score': 0.0426829268292683, 'weighted avg_support': 211.0, 'O_support': 2643, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 1}, {'micro_f1': 0.7610921501706485, 'precision': 0.7610921501706485, 'Appeal_to_Authority_precision': 0.09401709401709402, 'Appeal_to_Authority_recall': 0.0658682634730539, 'Appeal_to_Authority_f1-score': 0.07746478873239436, 'Appeal_to_Authority_support': 167.0, 'micro avg_precision': 0.09401709401709402, 'micro avg_recall': 0.0658682634730539, 'micro avg_f1-score': 0.07746478873239436, 'micro avg_support': 167.0, 'macro avg_precision': 0.09401709401709402, 'macro avg_recall': 0.0658682634730539, 'macro avg_f1-score': 0.07746478873239436, 'macro avg_support': 167.0, 'weighted avg_precision': 0.09401709401709402, 'weighted avg_recall': 0.0658682634730539, 'weighted avg_f1-score': 0.07746478873239436, 'weighted avg_support': 167.0, 'O_support': 2643, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 2}, {'micro_f1': 0.7753839590443686, 'precision': 0.7753839590443686, 'Appeal_to_Authority_precision': 0.1623931623931624, 'Appeal_to_Authority_recall': 0.09047619047619047, 'Appeal_to_Authority_f1-score': 0.11620795107033641, 'Appeal_to_Authority_support': 210.0, 'micro avg_precision': 0.1623931623931624, 'micro avg_recall': 0.09047619047619047, 'micro avg_f1-score': 0.11620795107033641, 'micro avg_support': 210.0, 'macro avg_precision': 0.1623931623931624, 'macro avg_recall': 0.09047619047619047, 'macro avg_f1-score': 0.11620795107033641, 'macro avg_support': 210.0, 'weighted avg_precision': 0.1623931623931624, 'weighted avg_recall': 0.09047619047619047, 'weighted avg_f1-score': 0.11620795107033641, 'weighted avg_support': 210.0, 'O_support': 2643, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 3}]}
Best model updated: current epoch macro f1 = 0.11620795107033641
{'micro_f1': 0.7901023890784983, 'precision': 0.7901023890784983, 'Appeal_to_Authority_precision': 0.20512820512820512, 'Appeal_to_Authority_recall': 0.15, 'Appeal_to_Authority_f1-score': 0.1732851985559567, 'Appeal_to_Authority_support': 160.0, 'micro avg_precision': 0.20512820512820512, 'micro avg_recall': 0.15, 'micro avg_f1-score': 0.1732851985559567, 'micro avg_support': 160.0, 'macro avg_precision': 0.20512820512820512, 'macro avg_recall': 0.15, 'macro avg_f1-score': 0.1732851985559567, 'macro avg_support': 160.0, 'weighted avg_precision': 0.20512820512820512, 'weighted avg_recall': 0.15, 'weighted avg_f1-score': 0.1732851985559567, 'weighted avg_support': 160.0, 'O_support': 2643, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 4}
{'results': [{'micro_f1': 0.5772184300341296, 'precision': 0.5772184300341296, 'Appeal_to_Authority_precision': 0.0, 'Appeal_to_Authority_recall': 0.0, 'Appeal_to_Authority_f1-score': 0.0, 'Appeal_to_Authority_support': 32.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 32.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 32.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 32.0, 'O_support': 2643, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 0}, {'micro_f1': 0.7408276450511946, 'precision': 0.7408276450511946, 'Appeal_to_Authority_precision': 0.05982905982905983, 'Appeal_to_Authority_recall': 0.03317535545023697, 'Appeal_to_Authority_f1-score': 0.0426829268292683, 'Appeal_to_Authority_support': 211.0, 'micro avg_precision': 0.05982905982905983, 'micro avg_recall': 0.03317535545023697, 'micro avg_f1-score': 0.0426829268292683, 'micro avg_support': 211.0, 'macro avg_precision': 0.05982905982905983, 'macro avg_recall': 0.03317535545023697, 'macro avg_f1-score': 0.0426829268292683, 'macro avg_support': 211.0, 'weighted avg_precision': 0.05982905982905984, 'weighted avg_recall': 0.03317535545023697, 'weighted avg_f1-score': 0.0426829268292683, 'weighted avg_support': 211.0, 'O_support': 2643, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 1}, {'micro_f1': 0.7610921501706485, 'precision': 0.7610921501706485, 'Appeal_to_Authority_precision': 0.09401709401709402, 'Appeal_to_Authority_recall': 0.0658682634730539, 'Appeal_to_Authority_f1-score': 0.07746478873239436, 'Appeal_to_Authority_support': 167.0, 'micro avg_precision': 0.09401709401709402, 'micro avg_recall': 0.0658682634730539, 'micro avg_f1-score': 0.07746478873239436, 'micro avg_support': 167.0, 'macro avg_precision': 0.09401709401709402, 'macro avg_recall': 0.0658682634730539, 'macro avg_f1-score': 0.07746478873239436, 'macro avg_support': 167.0, 'weighted avg_precision': 0.09401709401709402, 'weighted avg_recall': 0.0658682634730539, 'weighted avg_f1-score': 0.07746478873239436, 'weighted avg_support': 167.0, 'O_support': 2643, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 2}, {'micro_f1': 0.7753839590443686, 'precision': 0.7753839590443686, 'Appeal_to_Authority_precision': 0.1623931623931624, 'Appeal_to_Authority_recall': 0.09047619047619047, 'Appeal_to_Authority_f1-score': 0.11620795107033641, 'Appeal_to_Authority_support': 210.0, 'micro avg_precision': 0.1623931623931624, 'micro avg_recall': 0.09047619047619047, 'micro avg_f1-score': 0.11620795107033641, 'micro avg_support': 210.0, 'macro avg_precision': 0.1623931623931624, 'macro avg_recall': 0.09047619047619047, 'macro avg_f1-score': 0.11620795107033641, 'macro avg_support': 210.0, 'weighted avg_precision': 0.1623931623931624, 'weighted avg_recall': 0.09047619047619047, 'weighted avg_f1-score': 0.11620795107033641, 'weighted avg_support': 210.0, 'O_support': 2643, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 3}, {'micro_f1': 0.7901023890784983, 'precision': 0.7901023890784983, 'Appeal_to_Authority_precision': 0.20512820512820512, 'Appeal_to_Authority_recall': 0.15, 'Appeal_to_Authority_f1-score': 0.1732851985559567, 'Appeal_to_Authority_support': 160.0, 'micro avg_precision': 0.20512820512820512, 'micro avg_recall': 0.15, 'micro avg_f1-score': 0.1732851985559567, 'micro avg_support': 160.0, 'macro avg_precision': 0.20512820512820512, 'macro avg_recall': 0.15, 'macro avg_f1-score': 0.1732851985559567, 'macro avg_support': 160.0, 'weighted avg_precision': 0.20512820512820512, 'weighted avg_recall': 0.15, 'weighted avg_f1-score': 0.1732851985559567, 'weighted avg_support': 160.0, 'O_support': 2643, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 4}]}
Best model updated: current epoch macro f1 = 0.1732851985559567
{'micro_f1': 0.7928754266211605, 'precision': 0.7928754266211604, 'Appeal_to_Authority_precision': 0.20512820512820512, 'Appeal_to_Authority_recall': 0.14285714285714285, 'Appeal_to_Authority_f1-score': 0.16842105263157894, 'Appeal_to_Authority_support': 168.0, 'micro avg_precision': 0.20512820512820512, 'micro avg_recall': 0.14285714285714285, 'micro avg_f1-score': 0.16842105263157894, 'micro avg_support': 168.0, 'macro avg_precision': 0.20512820512820512, 'macro avg_recall': 0.14285714285714285, 'macro avg_f1-score': 0.16842105263157894, 'macro avg_support': 168.0, 'weighted avg_precision': 0.20512820512820512, 'weighted avg_recall': 0.14285714285714285, 'weighted avg_f1-score': 0.16842105263157894, 'weighted avg_support': 168.0, 'O_support': 2643, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 5}
{'results': [{'micro_f1': 0.5772184300341296, 'precision': 0.5772184300341296, 'Appeal_to_Authority_precision': 0.0, 'Appeal_to_Authority_recall': 0.0, 'Appeal_to_Authority_f1-score': 0.0, 'Appeal_to_Authority_support': 32.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 32.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 32.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 32.0, 'O_support': 2643, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 0}, {'micro_f1': 0.7408276450511946, 'precision': 0.7408276450511946, 'Appeal_to_Authority_precision': 0.05982905982905983, 'Appeal_to_Authority_recall': 0.03317535545023697, 'Appeal_to_Authority_f1-score': 0.0426829268292683, 'Appeal_to_Authority_support': 211.0, 'micro avg_precision': 0.05982905982905983, 'micro avg_recall': 0.03317535545023697, 'micro avg_f1-score': 0.0426829268292683, 'micro avg_support': 211.0, 'macro avg_precision': 0.05982905982905983, 'macro avg_recall': 0.03317535545023697, 'macro avg_f1-score': 0.0426829268292683, 'macro avg_support': 211.0, 'weighted avg_precision': 0.05982905982905984, 'weighted avg_recall': 0.03317535545023697, 'weighted avg_f1-score': 0.0426829268292683, 'weighted avg_support': 211.0, 'O_support': 2643, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 1}, {'micro_f1': 0.7610921501706485, 'precision': 0.7610921501706485, 'Appeal_to_Authority_precision': 0.09401709401709402, 'Appeal_to_Authority_recall': 0.0658682634730539, 'Appeal_to_Authority_f1-score': 0.07746478873239436, 'Appeal_to_Authority_support': 167.0, 'micro avg_precision': 0.09401709401709402, 'micro avg_recall': 0.0658682634730539, 'micro avg_f1-score': 0.07746478873239436, 'micro avg_support': 167.0, 'macro avg_precision': 0.09401709401709402, 'macro avg_recall': 0.0658682634730539, 'macro avg_f1-score': 0.07746478873239436, 'macro avg_support': 167.0, 'weighted avg_precision': 0.09401709401709402, 'weighted avg_recall': 0.0658682634730539, 'weighted avg_f1-score': 0.07746478873239436, 'weighted avg_support': 167.0, 'O_support': 2643, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 2}, {'micro_f1': 0.7753839590443686, 'precision': 0.7753839590443686, 'Appeal_to_Authority_precision': 0.1623931623931624, 'Appeal_to_Authority_recall': 0.09047619047619047, 'Appeal_to_Authority_f1-score': 0.11620795107033641, 'Appeal_to_Authority_support': 210.0, 'micro avg_precision': 0.1623931623931624, 'micro avg_recall': 0.09047619047619047, 'micro avg_f1-score': 0.11620795107033641, 'micro avg_support': 210.0, 'macro avg_precision': 0.1623931623931624, 'macro avg_recall': 0.09047619047619047, 'macro avg_f1-score': 0.11620795107033641, 'macro avg_support': 210.0, 'weighted avg_precision': 0.1623931623931624, 'weighted avg_recall': 0.09047619047619047, 'weighted avg_f1-score': 0.11620795107033641, 'weighted avg_support': 210.0, 'O_support': 2643, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 3}, {'micro_f1': 0.7901023890784983, 'precision': 0.7901023890784983, 'Appeal_to_Authority_precision': 0.20512820512820512, 'Appeal_to_Authority_recall': 0.15, 'Appeal_to_Authority_f1-score': 0.1732851985559567, 'Appeal_to_Authority_support': 160.0, 'micro avg_precision': 0.20512820512820512, 'micro avg_recall': 0.15, 'micro avg_f1-score': 0.1732851985559567, 'micro avg_support': 160.0, 'macro avg_precision': 0.20512820512820512, 'macro avg_recall': 0.15, 'macro avg_f1-score': 0.1732851985559567, 'macro avg_support': 160.0, 'weighted avg_precision': 0.20512820512820512, 'weighted avg_recall': 0.15, 'weighted avg_f1-score': 0.1732851985559567, 'weighted avg_support': 160.0, 'O_support': 2643, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 4}, {'micro_f1': 0.7928754266211605, 'precision': 0.7928754266211604, 'Appeal_to_Authority_precision': 0.20512820512820512, 'Appeal_to_Authority_recall': 0.14285714285714285, 'Appeal_to_Authority_f1-score': 0.16842105263157894, 'Appeal_to_Authority_support': 168.0, 'micro avg_precision': 0.20512820512820512, 'micro avg_recall': 0.14285714285714285, 'micro avg_f1-score': 0.16842105263157894, 'micro avg_support': 168.0, 'macro avg_precision': 0.20512820512820512, 'macro avg_recall': 0.14285714285714285, 'macro avg_f1-score': 0.16842105263157894, 'macro avg_support': 168.0, 'weighted avg_precision': 0.20512820512820512, 'weighted avg_recall': 0.14285714285714285, 'weighted avg_f1-score': 0.16842105263157894, 'weighted avg_support': 168.0, 'O_support': 2643, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 5}]}
{'micro_f1': 0.8026877133105802, 'precision': 0.8026877133105802, 'Appeal_to_Authority_precision': 0.2222222222222222, 'Appeal_to_Authority_recall': 0.14606741573033707, 'Appeal_to_Authority_f1-score': 0.17627118644067793, 'Appeal_to_Authority_support': 178.0, 'micro avg_precision': 0.2222222222222222, 'micro avg_recall': 0.14606741573033707, 'micro avg_f1-score': 0.17627118644067793, 'micro avg_support': 178.0, 'macro avg_precision': 0.2222222222222222, 'macro avg_recall': 0.14606741573033707, 'macro avg_f1-score': 0.17627118644067793, 'macro avg_support': 178.0, 'weighted avg_precision': 0.22222222222222218, 'weighted avg_recall': 0.14606741573033707, 'weighted avg_f1-score': 0.17627118644067793, 'weighted avg_support': 178.0, 'O_support': 2643, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 6}
{'results': [{'micro_f1': 0.5772184300341296, 'precision': 0.5772184300341296, 'Appeal_to_Authority_precision': 0.0, 'Appeal_to_Authority_recall': 0.0, 'Appeal_to_Authority_f1-score': 0.0, 'Appeal_to_Authority_support': 32.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 32.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 32.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 32.0, 'O_support': 2643, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 0}, {'micro_f1': 0.7408276450511946, 'precision': 0.7408276450511946, 'Appeal_to_Authority_precision': 0.05982905982905983, 'Appeal_to_Authority_recall': 0.03317535545023697, 'Appeal_to_Authority_f1-score': 0.0426829268292683, 'Appeal_to_Authority_support': 211.0, 'micro avg_precision': 0.05982905982905983, 'micro avg_recall': 0.03317535545023697, 'micro avg_f1-score': 0.0426829268292683, 'micro avg_support': 211.0, 'macro avg_precision': 0.05982905982905983, 'macro avg_recall': 0.03317535545023697, 'macro avg_f1-score': 0.0426829268292683, 'macro avg_support': 211.0, 'weighted avg_precision': 0.05982905982905984, 'weighted avg_recall': 0.03317535545023697, 'weighted avg_f1-score': 0.0426829268292683, 'weighted avg_support': 211.0, 'O_support': 2643, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 1}, {'micro_f1': 0.7610921501706485, 'precision': 0.7610921501706485, 'Appeal_to_Authority_precision': 0.09401709401709402, 'Appeal_to_Authority_recall': 0.0658682634730539, 'Appeal_to_Authority_f1-score': 0.07746478873239436, 'Appeal_to_Authority_support': 167.0, 'micro avg_precision': 0.09401709401709402, 'micro avg_recall': 0.0658682634730539, 'micro avg_f1-score': 0.07746478873239436, 'micro avg_support': 167.0, 'macro avg_precision': 0.09401709401709402, 'macro avg_recall': 0.0658682634730539, 'macro avg_f1-score': 0.07746478873239436, 'macro avg_support': 167.0, 'weighted avg_precision': 0.09401709401709402, 'weighted avg_recall': 0.0658682634730539, 'weighted avg_f1-score': 0.07746478873239436, 'weighted avg_support': 167.0, 'O_support': 2643, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 2}, {'micro_f1': 0.7753839590443686, 'precision': 0.7753839590443686, 'Appeal_to_Authority_precision': 0.1623931623931624, 'Appeal_to_Authority_recall': 0.09047619047619047, 'Appeal_to_Authority_f1-score': 0.11620795107033641, 'Appeal_to_Authority_support': 210.0, 'micro avg_precision': 0.1623931623931624, 'micro avg_recall': 0.09047619047619047, 'micro avg_f1-score': 0.11620795107033641, 'micro avg_support': 210.0, 'macro avg_precision': 0.1623931623931624, 'macro avg_recall': 0.09047619047619047, 'macro avg_f1-score': 0.11620795107033641, 'macro avg_support': 210.0, 'weighted avg_precision': 0.1623931623931624, 'weighted avg_recall': 0.09047619047619047, 'weighted avg_f1-score': 0.11620795107033641, 'weighted avg_support': 210.0, 'O_support': 2643, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 3}, {'micro_f1': 0.7901023890784983, 'precision': 0.7901023890784983, 'Appeal_to_Authority_precision': 0.20512820512820512, 'Appeal_to_Authority_recall': 0.15, 'Appeal_to_Authority_f1-score': 0.1732851985559567, 'Appeal_to_Authority_support': 160.0, 'micro avg_precision': 0.20512820512820512, 'micro avg_recall': 0.15, 'micro avg_f1-score': 0.1732851985559567, 'micro avg_support': 160.0, 'macro avg_precision': 0.20512820512820512, 'macro avg_recall': 0.15, 'macro avg_f1-score': 0.1732851985559567, 'macro avg_support': 160.0, 'weighted avg_precision': 0.20512820512820512, 'weighted avg_recall': 0.15, 'weighted avg_f1-score': 0.1732851985559567, 'weighted avg_support': 160.0, 'O_support': 2643, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 4}, {'micro_f1': 0.7928754266211605, 'precision': 0.7928754266211604, 'Appeal_to_Authority_precision': 0.20512820512820512, 'Appeal_to_Authority_recall': 0.14285714285714285, 'Appeal_to_Authority_f1-score': 0.16842105263157894, 'Appeal_to_Authority_support': 168.0, 'micro avg_precision': 0.20512820512820512, 'micro avg_recall': 0.14285714285714285, 'micro avg_f1-score': 0.16842105263157894, 'micro avg_support': 168.0, 'macro avg_precision': 0.20512820512820512, 'macro avg_recall': 0.14285714285714285, 'macro avg_f1-score': 0.16842105263157894, 'macro avg_support': 168.0, 'weighted avg_precision': 0.20512820512820512, 'weighted avg_recall': 0.14285714285714285, 'weighted avg_f1-score': 0.16842105263157894, 'weighted avg_support': 168.0, 'O_support': 2643, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 5}, {'micro_f1': 0.8026877133105802, 'precision': 0.8026877133105802, 'Appeal_to_Authority_precision': 0.2222222222222222, 'Appeal_to_Authority_recall': 0.14606741573033707, 'Appeal_to_Authority_f1-score': 0.17627118644067793, 'Appeal_to_Authority_support': 178.0, 'micro avg_precision': 0.2222222222222222, 'micro avg_recall': 0.14606741573033707, 'micro avg_f1-score': 0.17627118644067793, 'micro avg_support': 178.0, 'macro avg_precision': 0.2222222222222222, 'macro avg_recall': 0.14606741573033707, 'macro avg_f1-score': 0.17627118644067793, 'macro avg_support': 178.0, 'weighted avg_precision': 0.22222222222222218, 'weighted avg_recall': 0.14606741573033707, 'weighted avg_f1-score': 0.17627118644067793, 'weighted avg_support': 178.0, 'O_support': 2643, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 6}]}
Best model updated: current epoch macro f1 = 0.17627118644067793
{'micro_f1': 0.7604522184300341, 'precision': 0.7604522184300341, 'Appeal_to_Authority_precision': 0.1452991452991453, 'Appeal_to_Authority_recall': 0.10059171597633136, 'Appeal_to_Authority_f1-score': 0.11888111888111888, 'Appeal_to_Authority_support': 169.0, 'micro avg_precision': 0.1452991452991453, 'micro avg_recall': 0.10059171597633136, 'micro avg_f1-score': 0.11888111888111888, 'micro avg_support': 169.0, 'macro avg_precision': 0.1452991452991453, 'macro avg_recall': 0.10059171597633136, 'macro avg_f1-score': 0.11888111888111888, 'macro avg_support': 169.0, 'weighted avg_precision': 0.1452991452991453, 'weighted avg_recall': 0.10059171597633136, 'weighted avg_f1-score': 0.11888111888111888, 'weighted avg_support': 169.0, 'O_support': 2643, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 7}
{'results': [{'micro_f1': 0.5772184300341296, 'precision': 0.5772184300341296, 'Appeal_to_Authority_precision': 0.0, 'Appeal_to_Authority_recall': 0.0, 'Appeal_to_Authority_f1-score': 0.0, 'Appeal_to_Authority_support': 32.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 32.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 32.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 32.0, 'O_support': 2643, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 0}, {'micro_f1': 0.7408276450511946, 'precision': 0.7408276450511946, 'Appeal_to_Authority_precision': 0.05982905982905983, 'Appeal_to_Authority_recall': 0.03317535545023697, 'Appeal_to_Authority_f1-score': 0.0426829268292683, 'Appeal_to_Authority_support': 211.0, 'micro avg_precision': 0.05982905982905983, 'micro avg_recall': 0.03317535545023697, 'micro avg_f1-score': 0.0426829268292683, 'micro avg_support': 211.0, 'macro avg_precision': 0.05982905982905983, 'macro avg_recall': 0.03317535545023697, 'macro avg_f1-score': 0.0426829268292683, 'macro avg_support': 211.0, 'weighted avg_precision': 0.05982905982905984, 'weighted avg_recall': 0.03317535545023697, 'weighted avg_f1-score': 0.0426829268292683, 'weighted avg_support': 211.0, 'O_support': 2643, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 1}, {'micro_f1': 0.7610921501706485, 'precision': 0.7610921501706485, 'Appeal_to_Authority_precision': 0.09401709401709402, 'Appeal_to_Authority_recall': 0.0658682634730539, 'Appeal_to_Authority_f1-score': 0.07746478873239436, 'Appeal_to_Authority_support': 167.0, 'micro avg_precision': 0.09401709401709402, 'micro avg_recall': 0.0658682634730539, 'micro avg_f1-score': 0.07746478873239436, 'micro avg_support': 167.0, 'macro avg_precision': 0.09401709401709402, 'macro avg_recall': 0.0658682634730539, 'macro avg_f1-score': 0.07746478873239436, 'macro avg_support': 167.0, 'weighted avg_precision': 0.09401709401709402, 'weighted avg_recall': 0.0658682634730539, 'weighted avg_f1-score': 0.07746478873239436, 'weighted avg_support': 167.0, 'O_support': 2643, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 2}, {'micro_f1': 0.7753839590443686, 'precision': 0.7753839590443686, 'Appeal_to_Authority_precision': 0.1623931623931624, 'Appeal_to_Authority_recall': 0.09047619047619047, 'Appeal_to_Authority_f1-score': 0.11620795107033641, 'Appeal_to_Authority_support': 210.0, 'micro avg_precision': 0.1623931623931624, 'micro avg_recall': 0.09047619047619047, 'micro avg_f1-score': 0.11620795107033641, 'micro avg_support': 210.0, 'macro avg_precision': 0.1623931623931624, 'macro avg_recall': 0.09047619047619047, 'macro avg_f1-score': 0.11620795107033641, 'macro avg_support': 210.0, 'weighted avg_precision': 0.1623931623931624, 'weighted avg_recall': 0.09047619047619047, 'weighted avg_f1-score': 0.11620795107033641, 'weighted avg_support': 210.0, 'O_support': 2643, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 3}, {'micro_f1': 0.7901023890784983, 'precision': 0.7901023890784983, 'Appeal_to_Authority_precision': 0.20512820512820512, 'Appeal_to_Authority_recall': 0.15, 'Appeal_to_Authority_f1-score': 0.1732851985559567, 'Appeal_to_Authority_support': 160.0, 'micro avg_precision': 0.20512820512820512, 'micro avg_recall': 0.15, 'micro avg_f1-score': 0.1732851985559567, 'micro avg_support': 160.0, 'macro avg_precision': 0.20512820512820512, 'macro avg_recall': 0.15, 'macro avg_f1-score': 0.1732851985559567, 'macro avg_support': 160.0, 'weighted avg_precision': 0.20512820512820512, 'weighted avg_recall': 0.15, 'weighted avg_f1-score': 0.1732851985559567, 'weighted avg_support': 160.0, 'O_support': 2643, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 4}, {'micro_f1': 0.7928754266211605, 'precision': 0.7928754266211604, 'Appeal_to_Authority_precision': 0.20512820512820512, 'Appeal_to_Authority_recall': 0.14285714285714285, 'Appeal_to_Authority_f1-score': 0.16842105263157894, 'Appeal_to_Authority_support': 168.0, 'micro avg_precision': 0.20512820512820512, 'micro avg_recall': 0.14285714285714285, 'micro avg_f1-score': 0.16842105263157894, 'micro avg_support': 168.0, 'macro avg_precision': 0.20512820512820512, 'macro avg_recall': 0.14285714285714285, 'macro avg_f1-score': 0.16842105263157894, 'macro avg_support': 168.0, 'weighted avg_precision': 0.20512820512820512, 'weighted avg_recall': 0.14285714285714285, 'weighted avg_f1-score': 0.16842105263157894, 'weighted avg_support': 168.0, 'O_support': 2643, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 5}, {'micro_f1': 0.8026877133105802, 'precision': 0.8026877133105802, 'Appeal_to_Authority_precision': 0.2222222222222222, 'Appeal_to_Authority_recall': 0.14606741573033707, 'Appeal_to_Authority_f1-score': 0.17627118644067793, 'Appeal_to_Authority_support': 178.0, 'micro avg_precision': 0.2222222222222222, 'micro avg_recall': 0.14606741573033707, 'micro avg_f1-score': 0.17627118644067793, 'micro avg_support': 178.0, 'macro avg_precision': 0.2222222222222222, 'macro avg_recall': 0.14606741573033707, 'macro avg_f1-score': 0.17627118644067793, 'macro avg_support': 178.0, 'weighted avg_precision': 0.22222222222222218, 'weighted avg_recall': 0.14606741573033707, 'weighted avg_f1-score': 0.17627118644067793, 'weighted avg_support': 178.0, 'O_support': 2643, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 6}, {'micro_f1': 0.7604522184300341, 'precision': 0.7604522184300341, 'Appeal_to_Authority_precision': 0.1452991452991453, 'Appeal_to_Authority_recall': 0.10059171597633136, 'Appeal_to_Authority_f1-score': 0.11888111888111888, 'Appeal_to_Authority_support': 169.0, 'micro avg_precision': 0.1452991452991453, 'micro avg_recall': 0.10059171597633136, 'micro avg_f1-score': 0.11888111888111888, 'micro avg_support': 169.0, 'macro avg_precision': 0.1452991452991453, 'macro avg_recall': 0.10059171597633136, 'macro avg_f1-score': 0.11888111888111888, 'macro avg_support': 169.0, 'weighted avg_precision': 0.1452991452991453, 'weighted avg_recall': 0.10059171597633136, 'weighted avg_f1-score': 0.11888111888111888, 'weighted avg_support': 169.0, 'O_support': 2643, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 7}]}
{'micro_f1': 0.76919795221843, 'precision': 0.76919795221843, 'Appeal_to_Authority_precision': 0.21367521367521367, 'Appeal_to_Authority_recall': 0.12953367875647667, 'Appeal_to_Authority_f1-score': 0.16129032258064516, 'Appeal_to_Authority_support': 193.0, 'micro avg_precision': 0.21367521367521367, 'micro avg_recall': 0.12953367875647667, 'micro avg_f1-score': 0.16129032258064516, 'micro avg_support': 193.0, 'macro avg_precision': 0.21367521367521367, 'macro avg_recall': 0.12953367875647667, 'macro avg_f1-score': 0.16129032258064516, 'macro avg_support': 193.0, 'weighted avg_precision': 0.21367521367521367, 'weighted avg_recall': 0.12953367875647667, 'weighted avg_f1-score': 0.16129032258064516, 'weighted avg_support': 193.0, 'O_support': 2643, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 8}
{'results': [{'micro_f1': 0.5772184300341296, 'precision': 0.5772184300341296, 'Appeal_to_Authority_precision': 0.0, 'Appeal_to_Authority_recall': 0.0, 'Appeal_to_Authority_f1-score': 0.0, 'Appeal_to_Authority_support': 32.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 32.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 32.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 32.0, 'O_support': 2643, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 0}, {'micro_f1': 0.7408276450511946, 'precision': 0.7408276450511946, 'Appeal_to_Authority_precision': 0.05982905982905983, 'Appeal_to_Authority_recall': 0.03317535545023697, 'Appeal_to_Authority_f1-score': 0.0426829268292683, 'Appeal_to_Authority_support': 211.0, 'micro avg_precision': 0.05982905982905983, 'micro avg_recall': 0.03317535545023697, 'micro avg_f1-score': 0.0426829268292683, 'micro avg_support': 211.0, 'macro avg_precision': 0.05982905982905983, 'macro avg_recall': 0.03317535545023697, 'macro avg_f1-score': 0.0426829268292683, 'macro avg_support': 211.0, 'weighted avg_precision': 0.05982905982905984, 'weighted avg_recall': 0.03317535545023697, 'weighted avg_f1-score': 0.0426829268292683, 'weighted avg_support': 211.0, 'O_support': 2643, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 1}, {'micro_f1': 0.7610921501706485, 'precision': 0.7610921501706485, 'Appeal_to_Authority_precision': 0.09401709401709402, 'Appeal_to_Authority_recall': 0.0658682634730539, 'Appeal_to_Authority_f1-score': 0.07746478873239436, 'Appeal_to_Authority_support': 167.0, 'micro avg_precision': 0.09401709401709402, 'micro avg_recall': 0.0658682634730539, 'micro avg_f1-score': 0.07746478873239436, 'micro avg_support': 167.0, 'macro avg_precision': 0.09401709401709402, 'macro avg_recall': 0.0658682634730539, 'macro avg_f1-score': 0.07746478873239436, 'macro avg_support': 167.0, 'weighted avg_precision': 0.09401709401709402, 'weighted avg_recall': 0.0658682634730539, 'weighted avg_f1-score': 0.07746478873239436, 'weighted avg_support': 167.0, 'O_support': 2643, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 2}, {'micro_f1': 0.7753839590443686, 'precision': 0.7753839590443686, 'Appeal_to_Authority_precision': 0.1623931623931624, 'Appeal_to_Authority_recall': 0.09047619047619047, 'Appeal_to_Authority_f1-score': 0.11620795107033641, 'Appeal_to_Authority_support': 210.0, 'micro avg_precision': 0.1623931623931624, 'micro avg_recall': 0.09047619047619047, 'micro avg_f1-score': 0.11620795107033641, 'micro avg_support': 210.0, 'macro avg_precision': 0.1623931623931624, 'macro avg_recall': 0.09047619047619047, 'macro avg_f1-score': 0.11620795107033641, 'macro avg_support': 210.0, 'weighted avg_precision': 0.1623931623931624, 'weighted avg_recall': 0.09047619047619047, 'weighted avg_f1-score': 0.11620795107033641, 'weighted avg_support': 210.0, 'O_support': 2643, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 3}, {'micro_f1': 0.7901023890784983, 'precision': 0.7901023890784983, 'Appeal_to_Authority_precision': 0.20512820512820512, 'Appeal_to_Authority_recall': 0.15, 'Appeal_to_Authority_f1-score': 0.1732851985559567, 'Appeal_to_Authority_support': 160.0, 'micro avg_precision': 0.20512820512820512, 'micro avg_recall': 0.15, 'micro avg_f1-score': 0.1732851985559567, 'micro avg_support': 160.0, 'macro avg_precision': 0.20512820512820512, 'macro avg_recall': 0.15, 'macro avg_f1-score': 0.1732851985559567, 'macro avg_support': 160.0, 'weighted avg_precision': 0.20512820512820512, 'weighted avg_recall': 0.15, 'weighted avg_f1-score': 0.1732851985559567, 'weighted avg_support': 160.0, 'O_support': 2643, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 4}, {'micro_f1': 0.7928754266211605, 'precision': 0.7928754266211604, 'Appeal_to_Authority_precision': 0.20512820512820512, 'Appeal_to_Authority_recall': 0.14285714285714285, 'Appeal_to_Authority_f1-score': 0.16842105263157894, 'Appeal_to_Authority_support': 168.0, 'micro avg_precision': 0.20512820512820512, 'micro avg_recall': 0.14285714285714285, 'micro avg_f1-score': 0.16842105263157894, 'micro avg_support': 168.0, 'macro avg_precision': 0.20512820512820512, 'macro avg_recall': 0.14285714285714285, 'macro avg_f1-score': 0.16842105263157894, 'macro avg_support': 168.0, 'weighted avg_precision': 0.20512820512820512, 'weighted avg_recall': 0.14285714285714285, 'weighted avg_f1-score': 0.16842105263157894, 'weighted avg_support': 168.0, 'O_support': 2643, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 5}, {'micro_f1': 0.8026877133105802, 'precision': 0.8026877133105802, 'Appeal_to_Authority_precision': 0.2222222222222222, 'Appeal_to_Authority_recall': 0.14606741573033707, 'Appeal_to_Authority_f1-score': 0.17627118644067793, 'Appeal_to_Authority_support': 178.0, 'micro avg_precision': 0.2222222222222222, 'micro avg_recall': 0.14606741573033707, 'micro avg_f1-score': 0.17627118644067793, 'micro avg_support': 178.0, 'macro avg_precision': 0.2222222222222222, 'macro avg_recall': 0.14606741573033707, 'macro avg_f1-score': 0.17627118644067793, 'macro avg_support': 178.0, 'weighted avg_precision': 0.22222222222222218, 'weighted avg_recall': 0.14606741573033707, 'weighted avg_f1-score': 0.17627118644067793, 'weighted avg_support': 178.0, 'O_support': 2643, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 6}, {'micro_f1': 0.7604522184300341, 'precision': 0.7604522184300341, 'Appeal_to_Authority_precision': 0.1452991452991453, 'Appeal_to_Authority_recall': 0.10059171597633136, 'Appeal_to_Authority_f1-score': 0.11888111888111888, 'Appeal_to_Authority_support': 169.0, 'micro avg_precision': 0.1452991452991453, 'micro avg_recall': 0.10059171597633136, 'micro avg_f1-score': 0.11888111888111888, 'micro avg_support': 169.0, 'macro avg_precision': 0.1452991452991453, 'macro avg_recall': 0.10059171597633136, 'macro avg_f1-score': 0.11888111888111888, 'macro avg_support': 169.0, 'weighted avg_precision': 0.1452991452991453, 'weighted avg_recall': 0.10059171597633136, 'weighted avg_f1-score': 0.11888111888111888, 'weighted avg_support': 169.0, 'O_support': 2643, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 7}, {'micro_f1': 0.76919795221843, 'precision': 0.76919795221843, 'Appeal_to_Authority_precision': 0.21367521367521367, 'Appeal_to_Authority_recall': 0.12953367875647667, 'Appeal_to_Authority_f1-score': 0.16129032258064516, 'Appeal_to_Authority_support': 193.0, 'micro avg_precision': 0.21367521367521367, 'micro avg_recall': 0.12953367875647667, 'micro avg_f1-score': 0.16129032258064516, 'micro avg_support': 193.0, 'macro avg_precision': 0.21367521367521367, 'macro avg_recall': 0.12953367875647667, 'macro avg_f1-score': 0.16129032258064516, 'macro avg_support': 193.0, 'weighted avg_precision': 0.21367521367521367, 'weighted avg_recall': 0.12953367875647667, 'weighted avg_f1-score': 0.16129032258064516, 'weighted avg_support': 193.0, 'O_support': 2643, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 8}]}
Early stopping triggered.
Saving model to directory: ./models/M2/2024-05-14-06-51-04_aug_ts0.9/mdeberta-v3-base_0_ME10_target=Appeal_to_Authority_SUBSAMPLED_2024-05-14-06-51-04
Training model no. 1 of 23 for (1, 'Appeal_to_Popularity') persuasion technique...
{'micro_f1': 0.7260411440040141, 'precision': 0.7260411440040141, 'Appeal_to_Popularity_precision': 0.0, 'Appeal_to_Popularity_recall': 0.0, 'Appeal_to_Popularity_f1-score': 0.0, 'Appeal_to_Popularity_support': 64.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 64.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 64.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 64.0, 'O_support': 1325, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 0}
{'results': [{'micro_f1': 0.7260411440040141, 'precision': 0.7260411440040141, 'Appeal_to_Popularity_precision': 0.0, 'Appeal_to_Popularity_recall': 0.0, 'Appeal_to_Popularity_f1-score': 0.0, 'Appeal_to_Popularity_support': 64.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 64.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 64.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 64.0, 'O_support': 1325, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 0}]}
{'micro_f1': 0.7165077772202709, 'precision': 0.7165077772202709, 'Appeal_to_Popularity_precision': 0.0, 'Appeal_to_Popularity_recall': 0.0, 'Appeal_to_Popularity_f1-score': 0.0, 'Appeal_to_Popularity_support': 38.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 38.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 38.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 38.0, 'O_support': 1325, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 1}
{'results': [{'micro_f1': 0.7260411440040141, 'precision': 0.7260411440040141, 'Appeal_to_Popularity_precision': 0.0, 'Appeal_to_Popularity_recall': 0.0, 'Appeal_to_Popularity_f1-score': 0.0, 'Appeal_to_Popularity_support': 64.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 64.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 64.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 64.0, 'O_support': 1325, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 0}, {'micro_f1': 0.7165077772202709, 'precision': 0.7165077772202709, 'Appeal_to_Popularity_precision': 0.0, 'Appeal_to_Popularity_recall': 0.0, 'Appeal_to_Popularity_f1-score': 0.0, 'Appeal_to_Popularity_support': 38.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 38.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 38.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 38.0, 'O_support': 1325, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 1}]}
Early stopping triggered.
Saving model to directory: ./models/M2/2024-05-14-06-51-04_aug_ts0.9/mdeberta-v3-base_1_ME10_target=Appeal_to_Popularity_SUBSAMPLED_2024-05-14-06-51-04
Training model no. 2 of 23 for (2, 'Appeal_to_Values') persuasion technique...
{'micro_f1': 0.6520474379055717, 'precision': 0.6520474379055717, 'Appeal_to_Values_precision': 0.0, 'Appeal_to_Values_recall': 0.0, 'Appeal_to_Values_f1-score': 0.0, 'Appeal_to_Values_support': 149.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 149.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 149.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 149.0, 'O_support': 2662, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'epoch': 0}
{'results': [{'micro_f1': 0.6520474379055717, 'precision': 0.6520474379055717, 'Appeal_to_Values_precision': 0.0, 'Appeal_to_Values_recall': 0.0, 'Appeal_to_Values_f1-score': 0.0, 'Appeal_to_Values_support': 149.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 149.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 149.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 149.0, 'O_support': 2662, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'epoch': 0}]}
{'micro_f1': 0.6956813604833296, 'precision': 0.6956813604833296, 'Appeal_to_Values_precision': 0.0, 'Appeal_to_Values_recall': 0.0, 'Appeal_to_Values_f1-score': 0.0, 'Appeal_to_Values_support': 161.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 161.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 161.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 161.0, 'O_support': 2662, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'epoch': 1}
{'results': [{'micro_f1': 0.6520474379055717, 'precision': 0.6520474379055717, 'Appeal_to_Values_precision': 0.0, 'Appeal_to_Values_recall': 0.0, 'Appeal_to_Values_f1-score': 0.0, 'Appeal_to_Values_support': 149.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 149.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 149.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 149.0, 'O_support': 2662, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'epoch': 0}, {'micro_f1': 0.6956813604833296, 'precision': 0.6956813604833296, 'Appeal_to_Values_precision': 0.0, 'Appeal_to_Values_recall': 0.0, 'Appeal_to_Values_f1-score': 0.0, 'Appeal_to_Values_support': 161.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 161.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 161.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 161.0, 'O_support': 2662, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'epoch': 1}]}
Early stopping triggered.
Saving model to directory: ./models/M2/2024-05-14-06-51-04_aug_ts0.9/mdeberta-v3-base_2_ME10_target=Appeal_to_Values_SUBSAMPLED_2024-05-14-06-51-04
Training model no. 3 of 23 for (3, 'Appeal_to_Fear-Prejudice') persuasion technique...
{'micro_f1': 0.7169395100429582, 'precision': 0.7169395100429583, 'Appeal_to_Fear-Prejudice_precision': 0.00546448087431694, 'Appeal_to_Fear-Prejudice_recall': 0.010526315789473684, 'Appeal_to_Fear-Prejudice_f1-score': 0.007194244604316546, 'Appeal_to_Fear-Prejudice_support': 95.0, 'micro avg_precision': 0.00546448087431694, 'micro avg_recall': 0.010526315789473684, 'micro avg_f1-score': 0.007194244604316546, 'micro avg_support': 95.0, 'macro avg_precision': 0.00546448087431694, 'macro avg_recall': 0.010526315789473684, 'macro avg_f1-score': 0.007194244604316546, 'macro avg_support': 95.0, 'weighted avg_precision': 0.00546448087431694, 'weighted avg_recall': 0.010526315789473684, 'weighted avg_f1-score': 0.007194244604316546, 'weighted avg_support': 95.0, 'O_support': 5689, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'epoch': 0}
{'results': [{'micro_f1': 0.7169395100429582, 'precision': 0.7169395100429583, 'Appeal_to_Fear-Prejudice_precision': 0.00546448087431694, 'Appeal_to_Fear-Prejudice_recall': 0.010526315789473684, 'Appeal_to_Fear-Prejudice_f1-score': 0.007194244604316546, 'Appeal_to_Fear-Prejudice_support': 95.0, 'micro avg_precision': 0.00546448087431694, 'micro avg_recall': 0.010526315789473684, 'micro avg_f1-score': 0.007194244604316546, 'micro avg_support': 95.0, 'macro avg_precision': 0.00546448087431694, 'macro avg_recall': 0.010526315789473684, 'macro avg_f1-score': 0.007194244604316546, 'macro avg_support': 95.0, 'weighted avg_precision': 0.00546448087431694, 'weighted avg_recall': 0.010526315789473684, 'weighted avg_f1-score': 0.007194244604316546, 'weighted avg_support': 95.0, 'O_support': 5689, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'epoch': 0}]}
Best model updated: current epoch macro f1 = 0.007194244604316546
{'micro_f1': 0.7964704516428655, 'precision': 0.7964704516428655, 'Appeal_to_Fear-Prejudice_precision': 0.00546448087431694, 'Appeal_to_Fear-Prejudice_recall': 0.005050505050505051, 'Appeal_to_Fear-Prejudice_f1-score': 0.005249343832020997, 'Appeal_to_Fear-Prejudice_support': 198.0, 'micro avg_precision': 0.00546448087431694, 'micro avg_recall': 0.005050505050505051, 'micro avg_f1-score': 0.005249343832020997, 'micro avg_support': 198.0, 'macro avg_precision': 0.00546448087431694, 'macro avg_recall': 0.005050505050505051, 'macro avg_f1-score': 0.005249343832020997, 'macro avg_support': 198.0, 'weighted avg_precision': 0.005464480874316941, 'weighted avg_recall': 0.005050505050505051, 'weighted avg_f1-score': 0.005249343832020997, 'weighted avg_support': 198.0, 'O_support': 5689, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'epoch': 1}
{'results': [{'micro_f1': 0.7169395100429582, 'precision': 0.7169395100429583, 'Appeal_to_Fear-Prejudice_precision': 0.00546448087431694, 'Appeal_to_Fear-Prejudice_recall': 0.010526315789473684, 'Appeal_to_Fear-Prejudice_f1-score': 0.007194244604316546, 'Appeal_to_Fear-Prejudice_support': 95.0, 'micro avg_precision': 0.00546448087431694, 'micro avg_recall': 0.010526315789473684, 'micro avg_f1-score': 0.007194244604316546, 'micro avg_support': 95.0, 'macro avg_precision': 0.00546448087431694, 'macro avg_recall': 0.010526315789473684, 'macro avg_f1-score': 0.007194244604316546, 'macro avg_support': 95.0, 'weighted avg_precision': 0.00546448087431694, 'weighted avg_recall': 0.010526315789473684, 'weighted avg_f1-score': 0.007194244604316546, 'weighted avg_support': 95.0, 'O_support': 5689, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'epoch': 0}, {'micro_f1': 0.7964704516428655, 'precision': 0.7964704516428655, 'Appeal_to_Fear-Prejudice_precision': 0.00546448087431694, 'Appeal_to_Fear-Prejudice_recall': 0.005050505050505051, 'Appeal_to_Fear-Prejudice_f1-score': 0.005249343832020997, 'Appeal_to_Fear-Prejudice_support': 198.0, 'micro avg_precision': 0.00546448087431694, 'micro avg_recall': 0.005050505050505051, 'micro avg_f1-score': 0.005249343832020997, 'micro avg_support': 198.0, 'macro avg_precision': 0.00546448087431694, 'macro avg_recall': 0.005050505050505051, 'macro avg_f1-score': 0.005249343832020997, 'macro avg_support': 198.0, 'weighted avg_precision': 0.005464480874316941, 'weighted avg_recall': 0.005050505050505051, 'weighted avg_f1-score': 0.005249343832020997, 'weighted avg_support': 198.0, 'O_support': 5689, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'epoch': 1}]}
{'micro_f1': 0.7719725995588064, 'precision': 0.7719725995588065, 'Appeal_to_Fear-Prejudice_precision': 0.01639344262295082, 'Appeal_to_Fear-Prejudice_recall': 0.02040816326530612, 'Appeal_to_Fear-Prejudice_f1-score': 0.01818181818181818, 'Appeal_to_Fear-Prejudice_support': 147.0, 'micro avg_precision': 0.01639344262295082, 'micro avg_recall': 0.02040816326530612, 'micro avg_f1-score': 0.01818181818181818, 'micro avg_support': 147.0, 'macro avg_precision': 0.01639344262295082, 'macro avg_recall': 0.02040816326530612, 'macro avg_f1-score': 0.01818181818181818, 'macro avg_support': 147.0, 'weighted avg_precision': 0.01639344262295082, 'weighted avg_recall': 0.02040816326530612, 'weighted avg_f1-score': 0.01818181818181818, 'weighted avg_support': 147.0, 'O_support': 5689, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'epoch': 2}
{'results': [{'micro_f1': 0.7169395100429582, 'precision': 0.7169395100429583, 'Appeal_to_Fear-Prejudice_precision': 0.00546448087431694, 'Appeal_to_Fear-Prejudice_recall': 0.010526315789473684, 'Appeal_to_Fear-Prejudice_f1-score': 0.007194244604316546, 'Appeal_to_Fear-Prejudice_support': 95.0, 'micro avg_precision': 0.00546448087431694, 'micro avg_recall': 0.010526315789473684, 'micro avg_f1-score': 0.007194244604316546, 'micro avg_support': 95.0, 'macro avg_precision': 0.00546448087431694, 'macro avg_recall': 0.010526315789473684, 'macro avg_f1-score': 0.007194244604316546, 'macro avg_support': 95.0, 'weighted avg_precision': 0.00546448087431694, 'weighted avg_recall': 0.010526315789473684, 'weighted avg_f1-score': 0.007194244604316546, 'weighted avg_support': 95.0, 'O_support': 5689, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'epoch': 0}, {'micro_f1': 0.7964704516428655, 'precision': 0.7964704516428655, 'Appeal_to_Fear-Prejudice_precision': 0.00546448087431694, 'Appeal_to_Fear-Prejudice_recall': 0.005050505050505051, 'Appeal_to_Fear-Prejudice_f1-score': 0.005249343832020997, 'Appeal_to_Fear-Prejudice_support': 198.0, 'micro avg_precision': 0.00546448087431694, 'micro avg_recall': 0.005050505050505051, 'micro avg_f1-score': 0.005249343832020997, 'micro avg_support': 198.0, 'macro avg_precision': 0.00546448087431694, 'macro avg_recall': 0.005050505050505051, 'macro avg_f1-score': 0.005249343832020997, 'macro avg_support': 198.0, 'weighted avg_precision': 0.005464480874316941, 'weighted avg_recall': 0.005050505050505051, 'weighted avg_f1-score': 0.005249343832020997, 'weighted avg_support': 198.0, 'O_support': 5689, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'epoch': 1}, {'micro_f1': 0.7719725995588064, 'precision': 0.7719725995588065, 'Appeal_to_Fear-Prejudice_precision': 0.01639344262295082, 'Appeal_to_Fear-Prejudice_recall': 0.02040816326530612, 'Appeal_to_Fear-Prejudice_f1-score': 0.01818181818181818, 'Appeal_to_Fear-Prejudice_support': 147.0, 'micro avg_precision': 0.01639344262295082, 'micro avg_recall': 0.02040816326530612, 'micro avg_f1-score': 0.01818181818181818, 'micro avg_support': 147.0, 'macro avg_precision': 0.01639344262295082, 'macro avg_recall': 0.02040816326530612, 'macro avg_f1-score': 0.01818181818181818, 'macro avg_support': 147.0, 'weighted avg_precision': 0.01639344262295082, 'weighted avg_recall': 0.02040816326530612, 'weighted avg_f1-score': 0.01818181818181818, 'weighted avg_support': 147.0, 'O_support': 5689, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'epoch': 2}]}
Best model updated: current epoch macro f1 = 0.01818181818181818
{'micro_f1': 0.8047138047138047, 'precision': 0.8047138047138047, 'Appeal_to_Fear-Prejudice_precision': 0.09289617486338798, 'Appeal_to_Fear-Prejudice_recall': 0.08173076923076923, 'Appeal_to_Fear-Prejudice_f1-score': 0.08695652173913043, 'Appeal_to_Fear-Prejudice_support': 208.0, 'micro avg_precision': 0.09289617486338798, 'micro avg_recall': 0.08173076923076923, 'micro avg_f1-score': 0.08695652173913043, 'micro avg_support': 208.0, 'macro avg_precision': 0.09289617486338798, 'macro avg_recall': 0.08173076923076923, 'macro avg_f1-score': 0.08695652173913043, 'macro avg_support': 208.0, 'weighted avg_precision': 0.09289617486338798, 'weighted avg_recall': 0.08173076923076923, 'weighted avg_f1-score': 0.08695652173913043, 'weighted avg_support': 208.0, 'O_support': 5689, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'epoch': 3}
{'results': [{'micro_f1': 0.7169395100429582, 'precision': 0.7169395100429583, 'Appeal_to_Fear-Prejudice_precision': 0.00546448087431694, 'Appeal_to_Fear-Prejudice_recall': 0.010526315789473684, 'Appeal_to_Fear-Prejudice_f1-score': 0.007194244604316546, 'Appeal_to_Fear-Prejudice_support': 95.0, 'micro avg_precision': 0.00546448087431694, 'micro avg_recall': 0.010526315789473684, 'micro avg_f1-score': 0.007194244604316546, 'micro avg_support': 95.0, 'macro avg_precision': 0.00546448087431694, 'macro avg_recall': 0.010526315789473684, 'macro avg_f1-score': 0.007194244604316546, 'macro avg_support': 95.0, 'weighted avg_precision': 0.00546448087431694, 'weighted avg_recall': 0.010526315789473684, 'weighted avg_f1-score': 0.007194244604316546, 'weighted avg_support': 95.0, 'O_support': 5689, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'epoch': 0}, {'micro_f1': 0.7964704516428655, 'precision': 0.7964704516428655, 'Appeal_to_Fear-Prejudice_precision': 0.00546448087431694, 'Appeal_to_Fear-Prejudice_recall': 0.005050505050505051, 'Appeal_to_Fear-Prejudice_f1-score': 0.005249343832020997, 'Appeal_to_Fear-Prejudice_support': 198.0, 'micro avg_precision': 0.00546448087431694, 'micro avg_recall': 0.005050505050505051, 'micro avg_f1-score': 0.005249343832020997, 'micro avg_support': 198.0, 'macro avg_precision': 0.00546448087431694, 'macro avg_recall': 0.005050505050505051, 'macro avg_f1-score': 0.005249343832020997, 'macro avg_support': 198.0, 'weighted avg_precision': 0.005464480874316941, 'weighted avg_recall': 0.005050505050505051, 'weighted avg_f1-score': 0.005249343832020997, 'weighted avg_support': 198.0, 'O_support': 5689, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'epoch': 1}, {'micro_f1': 0.7719725995588064, 'precision': 0.7719725995588065, 'Appeal_to_Fear-Prejudice_precision': 0.01639344262295082, 'Appeal_to_Fear-Prejudice_recall': 0.02040816326530612, 'Appeal_to_Fear-Prejudice_f1-score': 0.01818181818181818, 'Appeal_to_Fear-Prejudice_support': 147.0, 'micro avg_precision': 0.01639344262295082, 'micro avg_recall': 0.02040816326530612, 'micro avg_f1-score': 0.01818181818181818, 'micro avg_support': 147.0, 'macro avg_precision': 0.01639344262295082, 'macro avg_recall': 0.02040816326530612, 'macro avg_f1-score': 0.01818181818181818, 'macro avg_support': 147.0, 'weighted avg_precision': 0.01639344262295082, 'weighted avg_recall': 0.02040816326530612, 'weighted avg_f1-score': 0.01818181818181818, 'weighted avg_support': 147.0, 'O_support': 5689, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'epoch': 2}, {'micro_f1': 0.8047138047138047, 'precision': 0.8047138047138047, 'Appeal_to_Fear-Prejudice_precision': 0.09289617486338798, 'Appeal_to_Fear-Prejudice_recall': 0.08173076923076923, 'Appeal_to_Fear-Prejudice_f1-score': 0.08695652173913043, 'Appeal_to_Fear-Prejudice_support': 208.0, 'micro avg_precision': 0.09289617486338798, 'micro avg_recall': 0.08173076923076923, 'micro avg_f1-score': 0.08695652173913043, 'micro avg_support': 208.0, 'macro avg_precision': 0.09289617486338798, 'macro avg_recall': 0.08173076923076923, 'macro avg_f1-score': 0.08695652173913043, 'macro avg_support': 208.0, 'weighted avg_precision': 0.09289617486338798, 'weighted avg_recall': 0.08173076923076923, 'weighted avg_f1-score': 0.08695652173913043, 'weighted avg_support': 208.0, 'O_support': 5689, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'epoch': 3}]}
Best model updated: current epoch macro f1 = 0.08695652173913043
{'micro_f1': 0.8182979217461976, 'precision': 0.8182979217461976, 'Appeal_to_Fear-Prejudice_precision': 0.2185792349726776, 'Appeal_to_Fear-Prejudice_recall': 0.14814814814814814, 'Appeal_to_Fear-Prejudice_f1-score': 0.17660044150110374, 'Appeal_to_Fear-Prejudice_support': 270.0, 'micro avg_precision': 0.2185792349726776, 'micro avg_recall': 0.14814814814814814, 'micro avg_f1-score': 0.17660044150110374, 'micro avg_support': 270.0, 'macro avg_precision': 0.2185792349726776, 'macro avg_recall': 0.14814814814814814, 'macro avg_f1-score': 0.17660044150110374, 'macro avg_support': 270.0, 'weighted avg_precision': 0.2185792349726776, 'weighted avg_recall': 0.14814814814814814, 'weighted avg_f1-score': 0.17660044150110374, 'weighted avg_support': 270.0, 'O_support': 5689, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'epoch': 4}
{'results': [{'micro_f1': 0.7169395100429582, 'precision': 0.7169395100429583, 'Appeal_to_Fear-Prejudice_precision': 0.00546448087431694, 'Appeal_to_Fear-Prejudice_recall': 0.010526315789473684, 'Appeal_to_Fear-Prejudice_f1-score': 0.007194244604316546, 'Appeal_to_Fear-Prejudice_support': 95.0, 'micro avg_precision': 0.00546448087431694, 'micro avg_recall': 0.010526315789473684, 'micro avg_f1-score': 0.007194244604316546, 'micro avg_support': 95.0, 'macro avg_precision': 0.00546448087431694, 'macro avg_recall': 0.010526315789473684, 'macro avg_f1-score': 0.007194244604316546, 'macro avg_support': 95.0, 'weighted avg_precision': 0.00546448087431694, 'weighted avg_recall': 0.010526315789473684, 'weighted avg_f1-score': 0.007194244604316546, 'weighted avg_support': 95.0, 'O_support': 5689, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'epoch': 0}, {'micro_f1': 0.7964704516428655, 'precision': 0.7964704516428655, 'Appeal_to_Fear-Prejudice_precision': 0.00546448087431694, 'Appeal_to_Fear-Prejudice_recall': 0.005050505050505051, 'Appeal_to_Fear-Prejudice_f1-score': 0.005249343832020997, 'Appeal_to_Fear-Prejudice_support': 198.0, 'micro avg_precision': 0.00546448087431694, 'micro avg_recall': 0.005050505050505051, 'micro avg_f1-score': 0.005249343832020997, 'micro avg_support': 198.0, 'macro avg_precision': 0.00546448087431694, 'macro avg_recall': 0.005050505050505051, 'macro avg_f1-score': 0.005249343832020997, 'macro avg_support': 198.0, 'weighted avg_precision': 0.005464480874316941, 'weighted avg_recall': 0.005050505050505051, 'weighted avg_f1-score': 0.005249343832020997, 'weighted avg_support': 198.0, 'O_support': 5689, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'epoch': 1}, {'micro_f1': 0.7719725995588064, 'precision': 0.7719725995588065, 'Appeal_to_Fear-Prejudice_precision': 0.01639344262295082, 'Appeal_to_Fear-Prejudice_recall': 0.02040816326530612, 'Appeal_to_Fear-Prejudice_f1-score': 0.01818181818181818, 'Appeal_to_Fear-Prejudice_support': 147.0, 'micro avg_precision': 0.01639344262295082, 'micro avg_recall': 0.02040816326530612, 'micro avg_f1-score': 0.01818181818181818, 'micro avg_support': 147.0, 'macro avg_precision': 0.01639344262295082, 'macro avg_recall': 0.02040816326530612, 'macro avg_f1-score': 0.01818181818181818, 'macro avg_support': 147.0, 'weighted avg_precision': 0.01639344262295082, 'weighted avg_recall': 0.02040816326530612, 'weighted avg_f1-score': 0.01818181818181818, 'weighted avg_support': 147.0, 'O_support': 5689, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'epoch': 2}, {'micro_f1': 0.8047138047138047, 'precision': 0.8047138047138047, 'Appeal_to_Fear-Prejudice_precision': 0.09289617486338798, 'Appeal_to_Fear-Prejudice_recall': 0.08173076923076923, 'Appeal_to_Fear-Prejudice_f1-score': 0.08695652173913043, 'Appeal_to_Fear-Prejudice_support': 208.0, 'micro avg_precision': 0.09289617486338798, 'micro avg_recall': 0.08173076923076923, 'micro avg_f1-score': 0.08695652173913043, 'micro avg_support': 208.0, 'macro avg_precision': 0.09289617486338798, 'macro avg_recall': 0.08173076923076923, 'macro avg_f1-score': 0.08695652173913043, 'macro avg_support': 208.0, 'weighted avg_precision': 0.09289617486338798, 'weighted avg_recall': 0.08173076923076923, 'weighted avg_f1-score': 0.08695652173913043, 'weighted avg_support': 208.0, 'O_support': 5689, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'epoch': 3}, {'micro_f1': 0.8182979217461976, 'precision': 0.8182979217461976, 'Appeal_to_Fear-Prejudice_precision': 0.2185792349726776, 'Appeal_to_Fear-Prejudice_recall': 0.14814814814814814, 'Appeal_to_Fear-Prejudice_f1-score': 0.17660044150110374, 'Appeal_to_Fear-Prejudice_support': 270.0, 'micro avg_precision': 0.2185792349726776, 'micro avg_recall': 0.14814814814814814, 'micro avg_f1-score': 0.17660044150110374, 'micro avg_support': 270.0, 'macro avg_precision': 0.2185792349726776, 'macro avg_recall': 0.14814814814814814, 'macro avg_f1-score': 0.17660044150110374, 'macro avg_support': 270.0, 'weighted avg_precision': 0.2185792349726776, 'weighted avg_recall': 0.14814814814814814, 'weighted avg_f1-score': 0.17660044150110374, 'weighted avg_support': 270.0, 'O_support': 5689, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'epoch': 4}]}
Best model updated: current epoch macro f1 = 0.17660044150110374
{'micro_f1': 0.8340880065017996, 'precision': 0.8340880065017996, 'Appeal_to_Fear-Prejudice_precision': 0.24043715846994534, 'Appeal_to_Fear-Prejudice_recall': 0.2037037037037037, 'Appeal_to_Fear-Prejudice_f1-score': 0.22055137844611528, 'Appeal_to_Fear-Prejudice_support': 216.0, 'micro avg_precision': 0.24043715846994534, 'micro avg_recall': 0.2037037037037037, 'micro avg_f1-score': 0.22055137844611528, 'micro avg_support': 216.0, 'macro avg_precision': 0.24043715846994534, 'macro avg_recall': 0.2037037037037037, 'macro avg_f1-score': 0.22055137844611528, 'macro avg_support': 216.0, 'weighted avg_precision': 0.24043715846994537, 'weighted avg_recall': 0.2037037037037037, 'weighted avg_f1-score': 0.22055137844611525, 'weighted avg_support': 216.0, 'O_support': 5689, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'epoch': 5}
{'results': [{'micro_f1': 0.7169395100429582, 'precision': 0.7169395100429583, 'Appeal_to_Fear-Prejudice_precision': 0.00546448087431694, 'Appeal_to_Fear-Prejudice_recall': 0.010526315789473684, 'Appeal_to_Fear-Prejudice_f1-score': 0.007194244604316546, 'Appeal_to_Fear-Prejudice_support': 95.0, 'micro avg_precision': 0.00546448087431694, 'micro avg_recall': 0.010526315789473684, 'micro avg_f1-score': 0.007194244604316546, 'micro avg_support': 95.0, 'macro avg_precision': 0.00546448087431694, 'macro avg_recall': 0.010526315789473684, 'macro avg_f1-score': 0.007194244604316546, 'macro avg_support': 95.0, 'weighted avg_precision': 0.00546448087431694, 'weighted avg_recall': 0.010526315789473684, 'weighted avg_f1-score': 0.007194244604316546, 'weighted avg_support': 95.0, 'O_support': 5689, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'epoch': 0}, {'micro_f1': 0.7964704516428655, 'precision': 0.7964704516428655, 'Appeal_to_Fear-Prejudice_precision': 0.00546448087431694, 'Appeal_to_Fear-Prejudice_recall': 0.005050505050505051, 'Appeal_to_Fear-Prejudice_f1-score': 0.005249343832020997, 'Appeal_to_Fear-Prejudice_support': 198.0, 'micro avg_precision': 0.00546448087431694, 'micro avg_recall': 0.005050505050505051, 'micro avg_f1-score': 0.005249343832020997, 'micro avg_support': 198.0, 'macro avg_precision': 0.00546448087431694, 'macro avg_recall': 0.005050505050505051, 'macro avg_f1-score': 0.005249343832020997, 'macro avg_support': 198.0, 'weighted avg_precision': 0.005464480874316941, 'weighted avg_recall': 0.005050505050505051, 'weighted avg_f1-score': 0.005249343832020997, 'weighted avg_support': 198.0, 'O_support': 5689, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'epoch': 1}, {'micro_f1': 0.7719725995588064, 'precision': 0.7719725995588065, 'Appeal_to_Fear-Prejudice_precision': 0.01639344262295082, 'Appeal_to_Fear-Prejudice_recall': 0.02040816326530612, 'Appeal_to_Fear-Prejudice_f1-score': 0.01818181818181818, 'Appeal_to_Fear-Prejudice_support': 147.0, 'micro avg_precision': 0.01639344262295082, 'micro avg_recall': 0.02040816326530612, 'micro avg_f1-score': 0.01818181818181818, 'micro avg_support': 147.0, 'macro avg_precision': 0.01639344262295082, 'macro avg_recall': 0.02040816326530612, 'macro avg_f1-score': 0.01818181818181818, 'macro avg_support': 147.0, 'weighted avg_precision': 0.01639344262295082, 'weighted avg_recall': 0.02040816326530612, 'weighted avg_f1-score': 0.01818181818181818, 'weighted avg_support': 147.0, 'O_support': 5689, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'epoch': 2}, {'micro_f1': 0.8047138047138047, 'precision': 0.8047138047138047, 'Appeal_to_Fear-Prejudice_precision': 0.09289617486338798, 'Appeal_to_Fear-Prejudice_recall': 0.08173076923076923, 'Appeal_to_Fear-Prejudice_f1-score': 0.08695652173913043, 'Appeal_to_Fear-Prejudice_support': 208.0, 'micro avg_precision': 0.09289617486338798, 'micro avg_recall': 0.08173076923076923, 'micro avg_f1-score': 0.08695652173913043, 'micro avg_support': 208.0, 'macro avg_precision': 0.09289617486338798, 'macro avg_recall': 0.08173076923076923, 'macro avg_f1-score': 0.08695652173913043, 'macro avg_support': 208.0, 'weighted avg_precision': 0.09289617486338798, 'weighted avg_recall': 0.08173076923076923, 'weighted avg_f1-score': 0.08695652173913043, 'weighted avg_support': 208.0, 'O_support': 5689, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'epoch': 3}, {'micro_f1': 0.8182979217461976, 'precision': 0.8182979217461976, 'Appeal_to_Fear-Prejudice_precision': 0.2185792349726776, 'Appeal_to_Fear-Prejudice_recall': 0.14814814814814814, 'Appeal_to_Fear-Prejudice_f1-score': 0.17660044150110374, 'Appeal_to_Fear-Prejudice_support': 270.0, 'micro avg_precision': 0.2185792349726776, 'micro avg_recall': 0.14814814814814814, 'micro avg_f1-score': 0.17660044150110374, 'micro avg_support': 270.0, 'macro avg_precision': 0.2185792349726776, 'macro avg_recall': 0.14814814814814814, 'macro avg_f1-score': 0.17660044150110374, 'macro avg_support': 270.0, 'weighted avg_precision': 0.2185792349726776, 'weighted avg_recall': 0.14814814814814814, 'weighted avg_f1-score': 0.17660044150110374, 'weighted avg_support': 270.0, 'O_support': 5689, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'epoch': 4}, {'micro_f1': 0.8340880065017996, 'precision': 0.8340880065017996, 'Appeal_to_Fear-Prejudice_precision': 0.24043715846994534, 'Appeal_to_Fear-Prejudice_recall': 0.2037037037037037, 'Appeal_to_Fear-Prejudice_f1-score': 0.22055137844611528, 'Appeal_to_Fear-Prejudice_support': 216.0, 'micro avg_precision': 0.24043715846994534, 'micro avg_recall': 0.2037037037037037, 'micro avg_f1-score': 0.22055137844611528, 'micro avg_support': 216.0, 'macro avg_precision': 0.24043715846994534, 'macro avg_recall': 0.2037037037037037, 'macro avg_f1-score': 0.22055137844611528, 'macro avg_support': 216.0, 'weighted avg_precision': 0.24043715846994537, 'weighted avg_recall': 0.2037037037037037, 'weighted avg_f1-score': 0.22055137844611525, 'weighted avg_support': 216.0, 'O_support': 5689, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'epoch': 5}]}
Best model updated: current epoch macro f1 = 0.22055137844611528
{'micro_f1': 0.8105189829327759, 'precision': 0.810518982932776, 'Appeal_to_Fear-Prejudice_precision': 0.16939890710382513, 'Appeal_to_Fear-Prejudice_recall': 0.15196078431372548, 'Appeal_to_Fear-Prejudice_f1-score': 0.16020671834625322, 'Appeal_to_Fear-Prejudice_support': 204.0, 'micro avg_precision': 0.16939890710382513, 'micro avg_recall': 0.15196078431372548, 'micro avg_f1-score': 0.16020671834625322, 'micro avg_support': 204.0, 'macro avg_precision': 0.16939890710382513, 'macro avg_recall': 0.15196078431372548, 'macro avg_f1-score': 0.16020671834625322, 'macro avg_support': 204.0, 'weighted avg_precision': 0.16939890710382513, 'weighted avg_recall': 0.15196078431372548, 'weighted avg_f1-score': 0.16020671834625325, 'weighted avg_support': 204.0, 'O_support': 5689, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'epoch': 6}
{'results': [{'micro_f1': 0.7169395100429582, 'precision': 0.7169395100429583, 'Appeal_to_Fear-Prejudice_precision': 0.00546448087431694, 'Appeal_to_Fear-Prejudice_recall': 0.010526315789473684, 'Appeal_to_Fear-Prejudice_f1-score': 0.007194244604316546, 'Appeal_to_Fear-Prejudice_support': 95.0, 'micro avg_precision': 0.00546448087431694, 'micro avg_recall': 0.010526315789473684, 'micro avg_f1-score': 0.007194244604316546, 'micro avg_support': 95.0, 'macro avg_precision': 0.00546448087431694, 'macro avg_recall': 0.010526315789473684, 'macro avg_f1-score': 0.007194244604316546, 'macro avg_support': 95.0, 'weighted avg_precision': 0.00546448087431694, 'weighted avg_recall': 0.010526315789473684, 'weighted avg_f1-score': 0.007194244604316546, 'weighted avg_support': 95.0, 'O_support': 5689, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'epoch': 0}, {'micro_f1': 0.7964704516428655, 'precision': 0.7964704516428655, 'Appeal_to_Fear-Prejudice_precision': 0.00546448087431694, 'Appeal_to_Fear-Prejudice_recall': 0.005050505050505051, 'Appeal_to_Fear-Prejudice_f1-score': 0.005249343832020997, 'Appeal_to_Fear-Prejudice_support': 198.0, 'micro avg_precision': 0.00546448087431694, 'micro avg_recall': 0.005050505050505051, 'micro avg_f1-score': 0.005249343832020997, 'micro avg_support': 198.0, 'macro avg_precision': 0.00546448087431694, 'macro avg_recall': 0.005050505050505051, 'macro avg_f1-score': 0.005249343832020997, 'macro avg_support': 198.0, 'weighted avg_precision': 0.005464480874316941, 'weighted avg_recall': 0.005050505050505051, 'weighted avg_f1-score': 0.005249343832020997, 'weighted avg_support': 198.0, 'O_support': 5689, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'epoch': 1}, {'micro_f1': 0.7719725995588064, 'precision': 0.7719725995588065, 'Appeal_to_Fear-Prejudice_precision': 0.01639344262295082, 'Appeal_to_Fear-Prejudice_recall': 0.02040816326530612, 'Appeal_to_Fear-Prejudice_f1-score': 0.01818181818181818, 'Appeal_to_Fear-Prejudice_support': 147.0, 'micro avg_precision': 0.01639344262295082, 'micro avg_recall': 0.02040816326530612, 'micro avg_f1-score': 0.01818181818181818, 'micro avg_support': 147.0, 'macro avg_precision': 0.01639344262295082, 'macro avg_recall': 0.02040816326530612, 'macro avg_f1-score': 0.01818181818181818, 'macro avg_support': 147.0, 'weighted avg_precision': 0.01639344262295082, 'weighted avg_recall': 0.02040816326530612, 'weighted avg_f1-score': 0.01818181818181818, 'weighted avg_support': 147.0, 'O_support': 5689, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'epoch': 2}, {'micro_f1': 0.8047138047138047, 'precision': 0.8047138047138047, 'Appeal_to_Fear-Prejudice_precision': 0.09289617486338798, 'Appeal_to_Fear-Prejudice_recall': 0.08173076923076923, 'Appeal_to_Fear-Prejudice_f1-score': 0.08695652173913043, 'Appeal_to_Fear-Prejudice_support': 208.0, 'micro avg_precision': 0.09289617486338798, 'micro avg_recall': 0.08173076923076923, 'micro avg_f1-score': 0.08695652173913043, 'micro avg_support': 208.0, 'macro avg_precision': 0.09289617486338798, 'macro avg_recall': 0.08173076923076923, 'macro avg_f1-score': 0.08695652173913043, 'macro avg_support': 208.0, 'weighted avg_precision': 0.09289617486338798, 'weighted avg_recall': 0.08173076923076923, 'weighted avg_f1-score': 0.08695652173913043, 'weighted avg_support': 208.0, 'O_support': 5689, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'epoch': 3}, {'micro_f1': 0.8182979217461976, 'precision': 0.8182979217461976, 'Appeal_to_Fear-Prejudice_precision': 0.2185792349726776, 'Appeal_to_Fear-Prejudice_recall': 0.14814814814814814, 'Appeal_to_Fear-Prejudice_f1-score': 0.17660044150110374, 'Appeal_to_Fear-Prejudice_support': 270.0, 'micro avg_precision': 0.2185792349726776, 'micro avg_recall': 0.14814814814814814, 'micro avg_f1-score': 0.17660044150110374, 'micro avg_support': 270.0, 'macro avg_precision': 0.2185792349726776, 'macro avg_recall': 0.14814814814814814, 'macro avg_f1-score': 0.17660044150110374, 'macro avg_support': 270.0, 'weighted avg_precision': 0.2185792349726776, 'weighted avg_recall': 0.14814814814814814, 'weighted avg_f1-score': 0.17660044150110374, 'weighted avg_support': 270.0, 'O_support': 5689, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'epoch': 4}, {'micro_f1': 0.8340880065017996, 'precision': 0.8340880065017996, 'Appeal_to_Fear-Prejudice_precision': 0.24043715846994534, 'Appeal_to_Fear-Prejudice_recall': 0.2037037037037037, 'Appeal_to_Fear-Prejudice_f1-score': 0.22055137844611528, 'Appeal_to_Fear-Prejudice_support': 216.0, 'micro avg_precision': 0.24043715846994534, 'micro avg_recall': 0.2037037037037037, 'micro avg_f1-score': 0.22055137844611528, 'micro avg_support': 216.0, 'macro avg_precision': 0.24043715846994534, 'macro avg_recall': 0.2037037037037037, 'macro avg_f1-score': 0.22055137844611528, 'macro avg_support': 216.0, 'weighted avg_precision': 0.24043715846994537, 'weighted avg_recall': 0.2037037037037037, 'weighted avg_f1-score': 0.22055137844611525, 'weighted avg_support': 216.0, 'O_support': 5689, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'epoch': 5}, {'micro_f1': 0.8105189829327759, 'precision': 0.810518982932776, 'Appeal_to_Fear-Prejudice_precision': 0.16939890710382513, 'Appeal_to_Fear-Prejudice_recall': 0.15196078431372548, 'Appeal_to_Fear-Prejudice_f1-score': 0.16020671834625322, 'Appeal_to_Fear-Prejudice_support': 204.0, 'micro avg_precision': 0.16939890710382513, 'micro avg_recall': 0.15196078431372548, 'micro avg_f1-score': 0.16020671834625322, 'micro avg_support': 204.0, 'macro avg_precision': 0.16939890710382513, 'macro avg_recall': 0.15196078431372548, 'macro avg_f1-score': 0.16020671834625322, 'macro avg_support': 204.0, 'weighted avg_precision': 0.16939890710382513, 'weighted avg_recall': 0.15196078431372548, 'weighted avg_f1-score': 0.16020671834625325, 'weighted avg_support': 204.0, 'O_support': 5689, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'epoch': 6}]}
{'micro_f1': 0.8207360965981656, 'precision': 0.8207360965981656, 'Appeal_to_Fear-Prejudice_precision': 0.21311475409836064, 'Appeal_to_Fear-Prejudice_recall': 0.203125, 'Appeal_to_Fear-Prejudice_f1-score': 0.20799999999999996, 'Appeal_to_Fear-Prejudice_support': 192.0, 'micro avg_precision': 0.21311475409836064, 'micro avg_recall': 0.203125, 'micro avg_f1-score': 0.20799999999999996, 'micro avg_support': 192.0, 'macro avg_precision': 0.21311475409836064, 'macro avg_recall': 0.203125, 'macro avg_f1-score': 0.20799999999999996, 'macro avg_support': 192.0, 'weighted avg_precision': 0.21311475409836064, 'weighted avg_recall': 0.203125, 'weighted avg_f1-score': 0.20799999999999996, 'weighted avg_support': 192.0, 'O_support': 5689, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'epoch': 7}
{'results': [{'micro_f1': 0.7169395100429582, 'precision': 0.7169395100429583, 'Appeal_to_Fear-Prejudice_precision': 0.00546448087431694, 'Appeal_to_Fear-Prejudice_recall': 0.010526315789473684, 'Appeal_to_Fear-Prejudice_f1-score': 0.007194244604316546, 'Appeal_to_Fear-Prejudice_support': 95.0, 'micro avg_precision': 0.00546448087431694, 'micro avg_recall': 0.010526315789473684, 'micro avg_f1-score': 0.007194244604316546, 'micro avg_support': 95.0, 'macro avg_precision': 0.00546448087431694, 'macro avg_recall': 0.010526315789473684, 'macro avg_f1-score': 0.007194244604316546, 'macro avg_support': 95.0, 'weighted avg_precision': 0.00546448087431694, 'weighted avg_recall': 0.010526315789473684, 'weighted avg_f1-score': 0.007194244604316546, 'weighted avg_support': 95.0, 'O_support': 5689, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'epoch': 0}, {'micro_f1': 0.7964704516428655, 'precision': 0.7964704516428655, 'Appeal_to_Fear-Prejudice_precision': 0.00546448087431694, 'Appeal_to_Fear-Prejudice_recall': 0.005050505050505051, 'Appeal_to_Fear-Prejudice_f1-score': 0.005249343832020997, 'Appeal_to_Fear-Prejudice_support': 198.0, 'micro avg_precision': 0.00546448087431694, 'micro avg_recall': 0.005050505050505051, 'micro avg_f1-score': 0.005249343832020997, 'micro avg_support': 198.0, 'macro avg_precision': 0.00546448087431694, 'macro avg_recall': 0.005050505050505051, 'macro avg_f1-score': 0.005249343832020997, 'macro avg_support': 198.0, 'weighted avg_precision': 0.005464480874316941, 'weighted avg_recall': 0.005050505050505051, 'weighted avg_f1-score': 0.005249343832020997, 'weighted avg_support': 198.0, 'O_support': 5689, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'epoch': 1}, {'micro_f1': 0.7719725995588064, 'precision': 0.7719725995588065, 'Appeal_to_Fear-Prejudice_precision': 0.01639344262295082, 'Appeal_to_Fear-Prejudice_recall': 0.02040816326530612, 'Appeal_to_Fear-Prejudice_f1-score': 0.01818181818181818, 'Appeal_to_Fear-Prejudice_support': 147.0, 'micro avg_precision': 0.01639344262295082, 'micro avg_recall': 0.02040816326530612, 'micro avg_f1-score': 0.01818181818181818, 'micro avg_support': 147.0, 'macro avg_precision': 0.01639344262295082, 'macro avg_recall': 0.02040816326530612, 'macro avg_f1-score': 0.01818181818181818, 'macro avg_support': 147.0, 'weighted avg_precision': 0.01639344262295082, 'weighted avg_recall': 0.02040816326530612, 'weighted avg_f1-score': 0.01818181818181818, 'weighted avg_support': 147.0, 'O_support': 5689, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'epoch': 2}, {'micro_f1': 0.8047138047138047, 'precision': 0.8047138047138047, 'Appeal_to_Fear-Prejudice_precision': 0.09289617486338798, 'Appeal_to_Fear-Prejudice_recall': 0.08173076923076923, 'Appeal_to_Fear-Prejudice_f1-score': 0.08695652173913043, 'Appeal_to_Fear-Prejudice_support': 208.0, 'micro avg_precision': 0.09289617486338798, 'micro avg_recall': 0.08173076923076923, 'micro avg_f1-score': 0.08695652173913043, 'micro avg_support': 208.0, 'macro avg_precision': 0.09289617486338798, 'macro avg_recall': 0.08173076923076923, 'macro avg_f1-score': 0.08695652173913043, 'macro avg_support': 208.0, 'weighted avg_precision': 0.09289617486338798, 'weighted avg_recall': 0.08173076923076923, 'weighted avg_f1-score': 0.08695652173913043, 'weighted avg_support': 208.0, 'O_support': 5689, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'epoch': 3}, {'micro_f1': 0.8182979217461976, 'precision': 0.8182979217461976, 'Appeal_to_Fear-Prejudice_precision': 0.2185792349726776, 'Appeal_to_Fear-Prejudice_recall': 0.14814814814814814, 'Appeal_to_Fear-Prejudice_f1-score': 0.17660044150110374, 'Appeal_to_Fear-Prejudice_support': 270.0, 'micro avg_precision': 0.2185792349726776, 'micro avg_recall': 0.14814814814814814, 'micro avg_f1-score': 0.17660044150110374, 'micro avg_support': 270.0, 'macro avg_precision': 0.2185792349726776, 'macro avg_recall': 0.14814814814814814, 'macro avg_f1-score': 0.17660044150110374, 'macro avg_support': 270.0, 'weighted avg_precision': 0.2185792349726776, 'weighted avg_recall': 0.14814814814814814, 'weighted avg_f1-score': 0.17660044150110374, 'weighted avg_support': 270.0, 'O_support': 5689, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'epoch': 4}, {'micro_f1': 0.8340880065017996, 'precision': 0.8340880065017996, 'Appeal_to_Fear-Prejudice_precision': 0.24043715846994534, 'Appeal_to_Fear-Prejudice_recall': 0.2037037037037037, 'Appeal_to_Fear-Prejudice_f1-score': 0.22055137844611528, 'Appeal_to_Fear-Prejudice_support': 216.0, 'micro avg_precision': 0.24043715846994534, 'micro avg_recall': 0.2037037037037037, 'micro avg_f1-score': 0.22055137844611528, 'micro avg_support': 216.0, 'macro avg_precision': 0.24043715846994534, 'macro avg_recall': 0.2037037037037037, 'macro avg_f1-score': 0.22055137844611528, 'macro avg_support': 216.0, 'weighted avg_precision': 0.24043715846994537, 'weighted avg_recall': 0.2037037037037037, 'weighted avg_f1-score': 0.22055137844611525, 'weighted avg_support': 216.0, 'O_support': 5689, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'epoch': 5}, {'micro_f1': 0.8105189829327759, 'precision': 0.810518982932776, 'Appeal_to_Fear-Prejudice_precision': 0.16939890710382513, 'Appeal_to_Fear-Prejudice_recall': 0.15196078431372548, 'Appeal_to_Fear-Prejudice_f1-score': 0.16020671834625322, 'Appeal_to_Fear-Prejudice_support': 204.0, 'micro avg_precision': 0.16939890710382513, 'micro avg_recall': 0.15196078431372548, 'micro avg_f1-score': 0.16020671834625322, 'micro avg_support': 204.0, 'macro avg_precision': 0.16939890710382513, 'macro avg_recall': 0.15196078431372548, 'macro avg_f1-score': 0.16020671834625322, 'macro avg_support': 204.0, 'weighted avg_precision': 0.16939890710382513, 'weighted avg_recall': 0.15196078431372548, 'weighted avg_f1-score': 0.16020671834625325, 'weighted avg_support': 204.0, 'O_support': 5689, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'epoch': 6}, {'micro_f1': 0.8207360965981656, 'precision': 0.8207360965981656, 'Appeal_to_Fear-Prejudice_precision': 0.21311475409836064, 'Appeal_to_Fear-Prejudice_recall': 0.203125, 'Appeal_to_Fear-Prejudice_f1-score': 0.20799999999999996, 'Appeal_to_Fear-Prejudice_support': 192.0, 'micro avg_precision': 0.21311475409836064, 'micro avg_recall': 0.203125, 'micro avg_f1-score': 0.20799999999999996, 'micro avg_support': 192.0, 'macro avg_precision': 0.21311475409836064, 'macro avg_recall': 0.203125, 'macro avg_f1-score': 0.20799999999999996, 'macro avg_support': 192.0, 'weighted avg_precision': 0.21311475409836064, 'weighted avg_recall': 0.203125, 'weighted avg_f1-score': 0.20799999999999996, 'weighted avg_support': 192.0, 'O_support': 5689, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'epoch': 7}]}
Early stopping triggered.
Saving model to directory: ./models/M2/2024-05-14-06-51-04_aug_ts0.9/mdeberta-v3-base_3_ME10_target=Appeal_to_Fear-Prejudice_SUBSAMPLED_2024-05-14-06-51-04
Training model no. 4 of 23 for (4, 'Flag_Waving') persuasion technique...
{'micro_f1': 0.8000528960592436, 'precision': 0.8000528960592436, 'Flag_Waving_precision': 0.02197802197802198, 'Flag_Waving_recall': 0.022727272727272728, 'Flag_Waving_f1-score': 0.0223463687150838, 'Flag_Waving_support': 88.0, 'micro avg_precision': 0.02197802197802198, 'micro avg_recall': 0.022727272727272728, 'micro avg_f1-score': 0.0223463687150838, 'micro avg_support': 88.0, 'macro avg_precision': 0.02197802197802198, 'macro avg_recall': 0.022727272727272728, 'macro avg_f1-score': 0.0223463687150838, 'macro avg_support': 88.0, 'weighted avg_precision': 0.02197802197802198, 'weighted avg_recall': 0.022727272727272728, 'weighted avg_f1-score': 0.0223463687150838, 'weighted avg_support': 88.0, 'O_support': 2641, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'epoch': 0}
{'results': [{'micro_f1': 0.8000528960592436, 'precision': 0.8000528960592436, 'Flag_Waving_precision': 0.02197802197802198, 'Flag_Waving_recall': 0.022727272727272728, 'Flag_Waving_f1-score': 0.0223463687150838, 'Flag_Waving_support': 88.0, 'micro avg_precision': 0.02197802197802198, 'micro avg_recall': 0.022727272727272728, 'micro avg_f1-score': 0.0223463687150838, 'micro avg_support': 88.0, 'macro avg_precision': 0.02197802197802198, 'macro avg_recall': 0.022727272727272728, 'macro avg_f1-score': 0.0223463687150838, 'macro avg_support': 88.0, 'weighted avg_precision': 0.02197802197802198, 'weighted avg_recall': 0.022727272727272728, 'weighted avg_f1-score': 0.0223463687150838, 'weighted avg_support': 88.0, 'O_support': 2641, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'epoch': 0}]}
Best model updated: current epoch macro f1 = 0.0223463687150838
{'micro_f1': 0.7791589526580269, 'precision': 0.7791589526580269, 'Flag_Waving_precision': 0.03296703296703297, 'Flag_Waving_recall': 0.03896103896103896, 'Flag_Waving_f1-score': 0.03571428571428571, 'Flag_Waving_support': 77.0, 'micro avg_precision': 0.03296703296703297, 'micro avg_recall': 0.03896103896103896, 'micro avg_f1-score': 0.03571428571428571, 'micro avg_support': 77.0, 'macro avg_precision': 0.03296703296703297, 'macro avg_recall': 0.03896103896103896, 'macro avg_f1-score': 0.03571428571428571, 'macro avg_support': 77.0, 'weighted avg_precision': 0.03296703296703297, 'weighted avg_recall': 0.03896103896103896, 'weighted avg_f1-score': 0.03571428571428571, 'weighted avg_support': 77.0, 'O_support': 2641, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'epoch': 1}
{'results': [{'micro_f1': 0.8000528960592436, 'precision': 0.8000528960592436, 'Flag_Waving_precision': 0.02197802197802198, 'Flag_Waving_recall': 0.022727272727272728, 'Flag_Waving_f1-score': 0.0223463687150838, 'Flag_Waving_support': 88.0, 'micro avg_precision': 0.02197802197802198, 'micro avg_recall': 0.022727272727272728, 'micro avg_f1-score': 0.0223463687150838, 'micro avg_support': 88.0, 'macro avg_precision': 0.02197802197802198, 'macro avg_recall': 0.022727272727272728, 'macro avg_f1-score': 0.0223463687150838, 'macro avg_support': 88.0, 'weighted avg_precision': 0.02197802197802198, 'weighted avg_recall': 0.022727272727272728, 'weighted avg_f1-score': 0.0223463687150838, 'weighted avg_support': 88.0, 'O_support': 2641, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'epoch': 0}, {'micro_f1': 0.7791589526580269, 'precision': 0.7791589526580269, 'Flag_Waving_precision': 0.03296703296703297, 'Flag_Waving_recall': 0.03896103896103896, 'Flag_Waving_f1-score': 0.03571428571428571, 'Flag_Waving_support': 77.0, 'micro avg_precision': 0.03296703296703297, 'micro avg_recall': 0.03896103896103896, 'micro avg_f1-score': 0.03571428571428571, 'micro avg_support': 77.0, 'macro avg_precision': 0.03296703296703297, 'macro avg_recall': 0.03896103896103896, 'macro avg_f1-score': 0.03571428571428571, 'macro avg_support': 77.0, 'weighted avg_precision': 0.03296703296703297, 'weighted avg_recall': 0.03896103896103896, 'weighted avg_f1-score': 0.03571428571428571, 'weighted avg_support': 77.0, 'O_support': 2641, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'epoch': 1}]}
Best model updated: current epoch macro f1 = 0.03571428571428571
{'micro_f1': 0.8206823591642423, 'precision': 0.8206823591642423, 'Flag_Waving_precision': 0.1978021978021978, 'Flag_Waving_recall': 0.1935483870967742, 'Flag_Waving_f1-score': 0.19565217391304346, 'Flag_Waving_support': 93.0, 'micro avg_precision': 0.1978021978021978, 'micro avg_recall': 0.1935483870967742, 'micro avg_f1-score': 0.19565217391304346, 'micro avg_support': 93.0, 'macro avg_precision': 0.1978021978021978, 'macro avg_recall': 0.1935483870967742, 'macro avg_f1-score': 0.19565217391304346, 'macro avg_support': 93.0, 'weighted avg_precision': 0.1978021978021978, 'weighted avg_recall': 0.1935483870967742, 'weighted avg_f1-score': 0.1956521739130435, 'weighted avg_support': 93.0, 'O_support': 2641, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'epoch': 2}
{'results': [{'micro_f1': 0.8000528960592436, 'precision': 0.8000528960592436, 'Flag_Waving_precision': 0.02197802197802198, 'Flag_Waving_recall': 0.022727272727272728, 'Flag_Waving_f1-score': 0.0223463687150838, 'Flag_Waving_support': 88.0, 'micro avg_precision': 0.02197802197802198, 'micro avg_recall': 0.022727272727272728, 'micro avg_f1-score': 0.0223463687150838, 'micro avg_support': 88.0, 'macro avg_precision': 0.02197802197802198, 'macro avg_recall': 0.022727272727272728, 'macro avg_f1-score': 0.0223463687150838, 'macro avg_support': 88.0, 'weighted avg_precision': 0.02197802197802198, 'weighted avg_recall': 0.022727272727272728, 'weighted avg_f1-score': 0.0223463687150838, 'weighted avg_support': 88.0, 'O_support': 2641, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'epoch': 0}, {'micro_f1': 0.7791589526580269, 'precision': 0.7791589526580269, 'Flag_Waving_precision': 0.03296703296703297, 'Flag_Waving_recall': 0.03896103896103896, 'Flag_Waving_f1-score': 0.03571428571428571, 'Flag_Waving_support': 77.0, 'micro avg_precision': 0.03296703296703297, 'micro avg_recall': 0.03896103896103896, 'micro avg_f1-score': 0.03571428571428571, 'micro avg_support': 77.0, 'macro avg_precision': 0.03296703296703297, 'macro avg_recall': 0.03896103896103896, 'macro avg_f1-score': 0.03571428571428571, 'macro avg_support': 77.0, 'weighted avg_precision': 0.03296703296703297, 'weighted avg_recall': 0.03896103896103896, 'weighted avg_f1-score': 0.03571428571428571, 'weighted avg_support': 77.0, 'O_support': 2641, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'epoch': 1}, {'micro_f1': 0.8206823591642423, 'precision': 0.8206823591642423, 'Flag_Waving_precision': 0.1978021978021978, 'Flag_Waving_recall': 0.1935483870967742, 'Flag_Waving_f1-score': 0.19565217391304346, 'Flag_Waving_support': 93.0, 'micro avg_precision': 0.1978021978021978, 'micro avg_recall': 0.1935483870967742, 'micro avg_f1-score': 0.19565217391304346, 'micro avg_support': 93.0, 'macro avg_precision': 0.1978021978021978, 'macro avg_recall': 0.1935483870967742, 'macro avg_f1-score': 0.19565217391304346, 'macro avg_support': 93.0, 'weighted avg_precision': 0.1978021978021978, 'weighted avg_recall': 0.1935483870967742, 'weighted avg_f1-score': 0.1956521739130435, 'weighted avg_support': 93.0, 'O_support': 2641, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'epoch': 2}]}
Best model updated: current epoch macro f1 = 0.19565217391304346
{'micro_f1': 0.825707484792383, 'precision': 0.825707484792383, 'Flag_Waving_precision': 0.21978021978021978, 'Flag_Waving_recall': 0.1941747572815534, 'Flag_Waving_f1-score': 0.20618556701030924, 'Flag_Waving_support': 103.0, 'micro avg_precision': 0.21978021978021978, 'micro avg_recall': 0.1941747572815534, 'micro avg_f1-score': 0.20618556701030924, 'micro avg_support': 103.0, 'macro avg_precision': 0.21978021978021978, 'macro avg_recall': 0.1941747572815534, 'macro avg_f1-score': 0.20618556701030924, 'macro avg_support': 103.0, 'weighted avg_precision': 0.2197802197802198, 'weighted avg_recall': 0.1941747572815534, 'weighted avg_f1-score': 0.20618556701030924, 'weighted avg_support': 103.0, 'O_support': 2641, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'epoch': 3}
{'results': [{'micro_f1': 0.8000528960592436, 'precision': 0.8000528960592436, 'Flag_Waving_precision': 0.02197802197802198, 'Flag_Waving_recall': 0.022727272727272728, 'Flag_Waving_f1-score': 0.0223463687150838, 'Flag_Waving_support': 88.0, 'micro avg_precision': 0.02197802197802198, 'micro avg_recall': 0.022727272727272728, 'micro avg_f1-score': 0.0223463687150838, 'micro avg_support': 88.0, 'macro avg_precision': 0.02197802197802198, 'macro avg_recall': 0.022727272727272728, 'macro avg_f1-score': 0.0223463687150838, 'macro avg_support': 88.0, 'weighted avg_precision': 0.02197802197802198, 'weighted avg_recall': 0.022727272727272728, 'weighted avg_f1-score': 0.0223463687150838, 'weighted avg_support': 88.0, 'O_support': 2641, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'epoch': 0}, {'micro_f1': 0.7791589526580269, 'precision': 0.7791589526580269, 'Flag_Waving_precision': 0.03296703296703297, 'Flag_Waving_recall': 0.03896103896103896, 'Flag_Waving_f1-score': 0.03571428571428571, 'Flag_Waving_support': 77.0, 'micro avg_precision': 0.03296703296703297, 'micro avg_recall': 0.03896103896103896, 'micro avg_f1-score': 0.03571428571428571, 'micro avg_support': 77.0, 'macro avg_precision': 0.03296703296703297, 'macro avg_recall': 0.03896103896103896, 'macro avg_f1-score': 0.03571428571428571, 'macro avg_support': 77.0, 'weighted avg_precision': 0.03296703296703297, 'weighted avg_recall': 0.03896103896103896, 'weighted avg_f1-score': 0.03571428571428571, 'weighted avg_support': 77.0, 'O_support': 2641, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'epoch': 1}, {'micro_f1': 0.8206823591642423, 'precision': 0.8206823591642423, 'Flag_Waving_precision': 0.1978021978021978, 'Flag_Waving_recall': 0.1935483870967742, 'Flag_Waving_f1-score': 0.19565217391304346, 'Flag_Waving_support': 93.0, 'micro avg_precision': 0.1978021978021978, 'micro avg_recall': 0.1935483870967742, 'micro avg_f1-score': 0.19565217391304346, 'micro avg_support': 93.0, 'macro avg_precision': 0.1978021978021978, 'macro avg_recall': 0.1935483870967742, 'macro avg_f1-score': 0.19565217391304346, 'macro avg_support': 93.0, 'weighted avg_precision': 0.1978021978021978, 'weighted avg_recall': 0.1935483870967742, 'weighted avg_f1-score': 0.1956521739130435, 'weighted avg_support': 93.0, 'O_support': 2641, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'epoch': 2}, {'micro_f1': 0.825707484792383, 'precision': 0.825707484792383, 'Flag_Waving_precision': 0.21978021978021978, 'Flag_Waving_recall': 0.1941747572815534, 'Flag_Waving_f1-score': 0.20618556701030924, 'Flag_Waving_support': 103.0, 'micro avg_precision': 0.21978021978021978, 'micro avg_recall': 0.1941747572815534, 'micro avg_f1-score': 0.20618556701030924, 'micro avg_support': 103.0, 'macro avg_precision': 0.21978021978021978, 'macro avg_recall': 0.1941747572815534, 'macro avg_f1-score': 0.20618556701030924, 'macro avg_support': 103.0, 'weighted avg_precision': 0.2197802197802198, 'weighted avg_recall': 0.1941747572815534, 'weighted avg_f1-score': 0.20618556701030924, 'weighted avg_support': 103.0, 'O_support': 2641, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'epoch': 3}]}
Best model updated: current epoch macro f1 = 0.20618556701030924
{'micro_f1': 0.8500396720444326, 'precision': 0.8500396720444326, 'Flag_Waving_precision': 0.3076923076923077, 'Flag_Waving_recall': 0.25, 'Flag_Waving_f1-score': 0.27586206896551724, 'Flag_Waving_support': 112.0, 'micro avg_precision': 0.3076923076923077, 'micro avg_recall': 0.25, 'micro avg_f1-score': 0.27586206896551724, 'micro avg_support': 112.0, 'macro avg_precision': 0.3076923076923077, 'macro avg_recall': 0.25, 'macro avg_f1-score': 0.27586206896551724, 'macro avg_support': 112.0, 'weighted avg_precision': 0.30769230769230776, 'weighted avg_recall': 0.25, 'weighted avg_f1-score': 0.27586206896551724, 'weighted avg_support': 112.0, 'O_support': 2641, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'epoch': 4}
{'results': [{'micro_f1': 0.8000528960592436, 'precision': 0.8000528960592436, 'Flag_Waving_precision': 0.02197802197802198, 'Flag_Waving_recall': 0.022727272727272728, 'Flag_Waving_f1-score': 0.0223463687150838, 'Flag_Waving_support': 88.0, 'micro avg_precision': 0.02197802197802198, 'micro avg_recall': 0.022727272727272728, 'micro avg_f1-score': 0.0223463687150838, 'micro avg_support': 88.0, 'macro avg_precision': 0.02197802197802198, 'macro avg_recall': 0.022727272727272728, 'macro avg_f1-score': 0.0223463687150838, 'macro avg_support': 88.0, 'weighted avg_precision': 0.02197802197802198, 'weighted avg_recall': 0.022727272727272728, 'weighted avg_f1-score': 0.0223463687150838, 'weighted avg_support': 88.0, 'O_support': 2641, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'epoch': 0}, {'micro_f1': 0.7791589526580269, 'precision': 0.7791589526580269, 'Flag_Waving_precision': 0.03296703296703297, 'Flag_Waving_recall': 0.03896103896103896, 'Flag_Waving_f1-score': 0.03571428571428571, 'Flag_Waving_support': 77.0, 'micro avg_precision': 0.03296703296703297, 'micro avg_recall': 0.03896103896103896, 'micro avg_f1-score': 0.03571428571428571, 'micro avg_support': 77.0, 'macro avg_precision': 0.03296703296703297, 'macro avg_recall': 0.03896103896103896, 'macro avg_f1-score': 0.03571428571428571, 'macro avg_support': 77.0, 'weighted avg_precision': 0.03296703296703297, 'weighted avg_recall': 0.03896103896103896, 'weighted avg_f1-score': 0.03571428571428571, 'weighted avg_support': 77.0, 'O_support': 2641, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'epoch': 1}, {'micro_f1': 0.8206823591642423, 'precision': 0.8206823591642423, 'Flag_Waving_precision': 0.1978021978021978, 'Flag_Waving_recall': 0.1935483870967742, 'Flag_Waving_f1-score': 0.19565217391304346, 'Flag_Waving_support': 93.0, 'micro avg_precision': 0.1978021978021978, 'micro avg_recall': 0.1935483870967742, 'micro avg_f1-score': 0.19565217391304346, 'micro avg_support': 93.0, 'macro avg_precision': 0.1978021978021978, 'macro avg_recall': 0.1935483870967742, 'macro avg_f1-score': 0.19565217391304346, 'macro avg_support': 93.0, 'weighted avg_precision': 0.1978021978021978, 'weighted avg_recall': 0.1935483870967742, 'weighted avg_f1-score': 0.1956521739130435, 'weighted avg_support': 93.0, 'O_support': 2641, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'epoch': 2}, {'micro_f1': 0.825707484792383, 'precision': 0.825707484792383, 'Flag_Waving_precision': 0.21978021978021978, 'Flag_Waving_recall': 0.1941747572815534, 'Flag_Waving_f1-score': 0.20618556701030924, 'Flag_Waving_support': 103.0, 'micro avg_precision': 0.21978021978021978, 'micro avg_recall': 0.1941747572815534, 'micro avg_f1-score': 0.20618556701030924, 'micro avg_support': 103.0, 'macro avg_precision': 0.21978021978021978, 'macro avg_recall': 0.1941747572815534, 'macro avg_f1-score': 0.20618556701030924, 'macro avg_support': 103.0, 'weighted avg_precision': 0.2197802197802198, 'weighted avg_recall': 0.1941747572815534, 'weighted avg_f1-score': 0.20618556701030924, 'weighted avg_support': 103.0, 'O_support': 2641, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'epoch': 3}, {'micro_f1': 0.8500396720444326, 'precision': 0.8500396720444326, 'Flag_Waving_precision': 0.3076923076923077, 'Flag_Waving_recall': 0.25, 'Flag_Waving_f1-score': 0.27586206896551724, 'Flag_Waving_support': 112.0, 'micro avg_precision': 0.3076923076923077, 'micro avg_recall': 0.25, 'micro avg_f1-score': 0.27586206896551724, 'micro avg_support': 112.0, 'macro avg_precision': 0.3076923076923077, 'macro avg_recall': 0.25, 'macro avg_f1-score': 0.27586206896551724, 'macro avg_support': 112.0, 'weighted avg_precision': 0.30769230769230776, 'weighted avg_recall': 0.25, 'weighted avg_f1-score': 0.27586206896551724, 'weighted avg_support': 112.0, 'O_support': 2641, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'epoch': 4}]}
Best model updated: current epoch macro f1 = 0.27586206896551724
{'micro_f1': 0.8458079873049458, 'precision': 0.8458079873049458, 'Flag_Waving_precision': 0.31868131868131866, 'Flag_Waving_recall': 0.28431372549019607, 'Flag_Waving_f1-score': 0.30051813471502586, 'Flag_Waving_support': 102.0, 'micro avg_precision': 0.31868131868131866, 'micro avg_recall': 0.28431372549019607, 'micro avg_f1-score': 0.30051813471502586, 'micro avg_support': 102.0, 'macro avg_precision': 0.31868131868131866, 'macro avg_recall': 0.28431372549019607, 'macro avg_f1-score': 0.30051813471502586, 'macro avg_support': 102.0, 'weighted avg_precision': 0.31868131868131866, 'weighted avg_recall': 0.28431372549019607, 'weighted avg_f1-score': 0.30051813471502586, 'weighted avg_support': 102.0, 'O_support': 2641, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'epoch': 5}
{'results': [{'micro_f1': 0.8000528960592436, 'precision': 0.8000528960592436, 'Flag_Waving_precision': 0.02197802197802198, 'Flag_Waving_recall': 0.022727272727272728, 'Flag_Waving_f1-score': 0.0223463687150838, 'Flag_Waving_support': 88.0, 'micro avg_precision': 0.02197802197802198, 'micro avg_recall': 0.022727272727272728, 'micro avg_f1-score': 0.0223463687150838, 'micro avg_support': 88.0, 'macro avg_precision': 0.02197802197802198, 'macro avg_recall': 0.022727272727272728, 'macro avg_f1-score': 0.0223463687150838, 'macro avg_support': 88.0, 'weighted avg_precision': 0.02197802197802198, 'weighted avg_recall': 0.022727272727272728, 'weighted avg_f1-score': 0.0223463687150838, 'weighted avg_support': 88.0, 'O_support': 2641, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'epoch': 0}, {'micro_f1': 0.7791589526580269, 'precision': 0.7791589526580269, 'Flag_Waving_precision': 0.03296703296703297, 'Flag_Waving_recall': 0.03896103896103896, 'Flag_Waving_f1-score': 0.03571428571428571, 'Flag_Waving_support': 77.0, 'micro avg_precision': 0.03296703296703297, 'micro avg_recall': 0.03896103896103896, 'micro avg_f1-score': 0.03571428571428571, 'micro avg_support': 77.0, 'macro avg_precision': 0.03296703296703297, 'macro avg_recall': 0.03896103896103896, 'macro avg_f1-score': 0.03571428571428571, 'macro avg_support': 77.0, 'weighted avg_precision': 0.03296703296703297, 'weighted avg_recall': 0.03896103896103896, 'weighted avg_f1-score': 0.03571428571428571, 'weighted avg_support': 77.0, 'O_support': 2641, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'epoch': 1}, {'micro_f1': 0.8206823591642423, 'precision': 0.8206823591642423, 'Flag_Waving_precision': 0.1978021978021978, 'Flag_Waving_recall': 0.1935483870967742, 'Flag_Waving_f1-score': 0.19565217391304346, 'Flag_Waving_support': 93.0, 'micro avg_precision': 0.1978021978021978, 'micro avg_recall': 0.1935483870967742, 'micro avg_f1-score': 0.19565217391304346, 'micro avg_support': 93.0, 'macro avg_precision': 0.1978021978021978, 'macro avg_recall': 0.1935483870967742, 'macro avg_f1-score': 0.19565217391304346, 'macro avg_support': 93.0, 'weighted avg_precision': 0.1978021978021978, 'weighted avg_recall': 0.1935483870967742, 'weighted avg_f1-score': 0.1956521739130435, 'weighted avg_support': 93.0, 'O_support': 2641, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'epoch': 2}, {'micro_f1': 0.825707484792383, 'precision': 0.825707484792383, 'Flag_Waving_precision': 0.21978021978021978, 'Flag_Waving_recall': 0.1941747572815534, 'Flag_Waving_f1-score': 0.20618556701030924, 'Flag_Waving_support': 103.0, 'micro avg_precision': 0.21978021978021978, 'micro avg_recall': 0.1941747572815534, 'micro avg_f1-score': 0.20618556701030924, 'micro avg_support': 103.0, 'macro avg_precision': 0.21978021978021978, 'macro avg_recall': 0.1941747572815534, 'macro avg_f1-score': 0.20618556701030924, 'macro avg_support': 103.0, 'weighted avg_precision': 0.2197802197802198, 'weighted avg_recall': 0.1941747572815534, 'weighted avg_f1-score': 0.20618556701030924, 'weighted avg_support': 103.0, 'O_support': 2641, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'epoch': 3}, {'micro_f1': 0.8500396720444326, 'precision': 0.8500396720444326, 'Flag_Waving_precision': 0.3076923076923077, 'Flag_Waving_recall': 0.25, 'Flag_Waving_f1-score': 0.27586206896551724, 'Flag_Waving_support': 112.0, 'micro avg_precision': 0.3076923076923077, 'micro avg_recall': 0.25, 'micro avg_f1-score': 0.27586206896551724, 'micro avg_support': 112.0, 'macro avg_precision': 0.3076923076923077, 'macro avg_recall': 0.25, 'macro avg_f1-score': 0.27586206896551724, 'macro avg_support': 112.0, 'weighted avg_precision': 0.30769230769230776, 'weighted avg_recall': 0.25, 'weighted avg_f1-score': 0.27586206896551724, 'weighted avg_support': 112.0, 'O_support': 2641, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'epoch': 4}, {'micro_f1': 0.8458079873049458, 'precision': 0.8458079873049458, 'Flag_Waving_precision': 0.31868131868131866, 'Flag_Waving_recall': 0.28431372549019607, 'Flag_Waving_f1-score': 0.30051813471502586, 'Flag_Waving_support': 102.0, 'micro avg_precision': 0.31868131868131866, 'micro avg_recall': 0.28431372549019607, 'micro avg_f1-score': 0.30051813471502586, 'micro avg_support': 102.0, 'macro avg_precision': 0.31868131868131866, 'macro avg_recall': 0.28431372549019607, 'macro avg_f1-score': 0.30051813471502586, 'macro avg_support': 102.0, 'weighted avg_precision': 0.31868131868131866, 'weighted avg_recall': 0.28431372549019607, 'weighted avg_f1-score': 0.30051813471502586, 'weighted avg_support': 102.0, 'O_support': 2641, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'epoch': 5}]}
Best model updated: current epoch macro f1 = 0.30051813471502586
{'micro_f1': 0.8397249404919334, 'precision': 0.8397249404919334, 'Flag_Waving_precision': 0.3956043956043956, 'Flag_Waving_recall': 0.35294117647058826, 'Flag_Waving_f1-score': 0.37305699481865284, 'Flag_Waving_support': 102.0, 'micro avg_precision': 0.3956043956043956, 'micro avg_recall': 0.35294117647058826, 'micro avg_f1-score': 0.37305699481865284, 'micro avg_support': 102.0, 'macro avg_precision': 0.3956043956043956, 'macro avg_recall': 0.35294117647058826, 'macro avg_f1-score': 0.37305699481865284, 'macro avg_support': 102.0, 'weighted avg_precision': 0.3956043956043956, 'weighted avg_recall': 0.35294117647058826, 'weighted avg_f1-score': 0.37305699481865284, 'weighted avg_support': 102.0, 'O_support': 2641, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'epoch': 6}
{'results': [{'micro_f1': 0.8000528960592436, 'precision': 0.8000528960592436, 'Flag_Waving_precision': 0.02197802197802198, 'Flag_Waving_recall': 0.022727272727272728, 'Flag_Waving_f1-score': 0.0223463687150838, 'Flag_Waving_support': 88.0, 'micro avg_precision': 0.02197802197802198, 'micro avg_recall': 0.022727272727272728, 'micro avg_f1-score': 0.0223463687150838, 'micro avg_support': 88.0, 'macro avg_precision': 0.02197802197802198, 'macro avg_recall': 0.022727272727272728, 'macro avg_f1-score': 0.0223463687150838, 'macro avg_support': 88.0, 'weighted avg_precision': 0.02197802197802198, 'weighted avg_recall': 0.022727272727272728, 'weighted avg_f1-score': 0.0223463687150838, 'weighted avg_support': 88.0, 'O_support': 2641, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'epoch': 0}, {'micro_f1': 0.7791589526580269, 'precision': 0.7791589526580269, 'Flag_Waving_precision': 0.03296703296703297, 'Flag_Waving_recall': 0.03896103896103896, 'Flag_Waving_f1-score': 0.03571428571428571, 'Flag_Waving_support': 77.0, 'micro avg_precision': 0.03296703296703297, 'micro avg_recall': 0.03896103896103896, 'micro avg_f1-score': 0.03571428571428571, 'micro avg_support': 77.0, 'macro avg_precision': 0.03296703296703297, 'macro avg_recall': 0.03896103896103896, 'macro avg_f1-score': 0.03571428571428571, 'macro avg_support': 77.0, 'weighted avg_precision': 0.03296703296703297, 'weighted avg_recall': 0.03896103896103896, 'weighted avg_f1-score': 0.03571428571428571, 'weighted avg_support': 77.0, 'O_support': 2641, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'epoch': 1}, {'micro_f1': 0.8206823591642423, 'precision': 0.8206823591642423, 'Flag_Waving_precision': 0.1978021978021978, 'Flag_Waving_recall': 0.1935483870967742, 'Flag_Waving_f1-score': 0.19565217391304346, 'Flag_Waving_support': 93.0, 'micro avg_precision': 0.1978021978021978, 'micro avg_recall': 0.1935483870967742, 'micro avg_f1-score': 0.19565217391304346, 'micro avg_support': 93.0, 'macro avg_precision': 0.1978021978021978, 'macro avg_recall': 0.1935483870967742, 'macro avg_f1-score': 0.19565217391304346, 'macro avg_support': 93.0, 'weighted avg_precision': 0.1978021978021978, 'weighted avg_recall': 0.1935483870967742, 'weighted avg_f1-score': 0.1956521739130435, 'weighted avg_support': 93.0, 'O_support': 2641, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'epoch': 2}, {'micro_f1': 0.825707484792383, 'precision': 0.825707484792383, 'Flag_Waving_precision': 0.21978021978021978, 'Flag_Waving_recall': 0.1941747572815534, 'Flag_Waving_f1-score': 0.20618556701030924, 'Flag_Waving_support': 103.0, 'micro avg_precision': 0.21978021978021978, 'micro avg_recall': 0.1941747572815534, 'micro avg_f1-score': 0.20618556701030924, 'micro avg_support': 103.0, 'macro avg_precision': 0.21978021978021978, 'macro avg_recall': 0.1941747572815534, 'macro avg_f1-score': 0.20618556701030924, 'macro avg_support': 103.0, 'weighted avg_precision': 0.2197802197802198, 'weighted avg_recall': 0.1941747572815534, 'weighted avg_f1-score': 0.20618556701030924, 'weighted avg_support': 103.0, 'O_support': 2641, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'epoch': 3}, {'micro_f1': 0.8500396720444326, 'precision': 0.8500396720444326, 'Flag_Waving_precision': 0.3076923076923077, 'Flag_Waving_recall': 0.25, 'Flag_Waving_f1-score': 0.27586206896551724, 'Flag_Waving_support': 112.0, 'micro avg_precision': 0.3076923076923077, 'micro avg_recall': 0.25, 'micro avg_f1-score': 0.27586206896551724, 'micro avg_support': 112.0, 'macro avg_precision': 0.3076923076923077, 'macro avg_recall': 0.25, 'macro avg_f1-score': 0.27586206896551724, 'macro avg_support': 112.0, 'weighted avg_precision': 0.30769230769230776, 'weighted avg_recall': 0.25, 'weighted avg_f1-score': 0.27586206896551724, 'weighted avg_support': 112.0, 'O_support': 2641, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'epoch': 4}, {'micro_f1': 0.8458079873049458, 'precision': 0.8458079873049458, 'Flag_Waving_precision': 0.31868131868131866, 'Flag_Waving_recall': 0.28431372549019607, 'Flag_Waving_f1-score': 0.30051813471502586, 'Flag_Waving_support': 102.0, 'micro avg_precision': 0.31868131868131866, 'micro avg_recall': 0.28431372549019607, 'micro avg_f1-score': 0.30051813471502586, 'micro avg_support': 102.0, 'macro avg_precision': 0.31868131868131866, 'macro avg_recall': 0.28431372549019607, 'macro avg_f1-score': 0.30051813471502586, 'macro avg_support': 102.0, 'weighted avg_precision': 0.31868131868131866, 'weighted avg_recall': 0.28431372549019607, 'weighted avg_f1-score': 0.30051813471502586, 'weighted avg_support': 102.0, 'O_support': 2641, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'epoch': 5}, {'micro_f1': 0.8397249404919334, 'precision': 0.8397249404919334, 'Flag_Waving_precision': 0.3956043956043956, 'Flag_Waving_recall': 0.35294117647058826, 'Flag_Waving_f1-score': 0.37305699481865284, 'Flag_Waving_support': 102.0, 'micro avg_precision': 0.3956043956043956, 'micro avg_recall': 0.35294117647058826, 'micro avg_f1-score': 0.37305699481865284, 'micro avg_support': 102.0, 'macro avg_precision': 0.3956043956043956, 'macro avg_recall': 0.35294117647058826, 'macro avg_f1-score': 0.37305699481865284, 'macro avg_support': 102.0, 'weighted avg_precision': 0.3956043956043956, 'weighted avg_recall': 0.35294117647058826, 'weighted avg_f1-score': 0.37305699481865284, 'weighted avg_support': 102.0, 'O_support': 2641, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'epoch': 6}]}
Best model updated: current epoch macro f1 = 0.37305699481865284
{'micro_f1': 0.85294895530283, 'precision': 0.85294895530283, 'Flag_Waving_precision': 0.4175824175824176, 'Flag_Waving_recall': 0.3275862068965517, 'Flag_Waving_f1-score': 0.3671497584541063, 'Flag_Waving_support': 116.0, 'micro avg_precision': 0.4175824175824176, 'micro avg_recall': 0.3275862068965517, 'micro avg_f1-score': 0.3671497584541063, 'micro avg_support': 116.0, 'macro avg_precision': 0.4175824175824176, 'macro avg_recall': 0.3275862068965517, 'macro avg_f1-score': 0.3671497584541063, 'macro avg_support': 116.0, 'weighted avg_precision': 0.41758241758241754, 'weighted avg_recall': 0.3275862068965517, 'weighted avg_f1-score': 0.3671497584541063, 'weighted avg_support': 116.0, 'O_support': 2641, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'epoch': 7}
{'results': [{'micro_f1': 0.8000528960592436, 'precision': 0.8000528960592436, 'Flag_Waving_precision': 0.02197802197802198, 'Flag_Waving_recall': 0.022727272727272728, 'Flag_Waving_f1-score': 0.0223463687150838, 'Flag_Waving_support': 88.0, 'micro avg_precision': 0.02197802197802198, 'micro avg_recall': 0.022727272727272728, 'micro avg_f1-score': 0.0223463687150838, 'micro avg_support': 88.0, 'macro avg_precision': 0.02197802197802198, 'macro avg_recall': 0.022727272727272728, 'macro avg_f1-score': 0.0223463687150838, 'macro avg_support': 88.0, 'weighted avg_precision': 0.02197802197802198, 'weighted avg_recall': 0.022727272727272728, 'weighted avg_f1-score': 0.0223463687150838, 'weighted avg_support': 88.0, 'O_support': 2641, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'epoch': 0}, {'micro_f1': 0.7791589526580269, 'precision': 0.7791589526580269, 'Flag_Waving_precision': 0.03296703296703297, 'Flag_Waving_recall': 0.03896103896103896, 'Flag_Waving_f1-score': 0.03571428571428571, 'Flag_Waving_support': 77.0, 'micro avg_precision': 0.03296703296703297, 'micro avg_recall': 0.03896103896103896, 'micro avg_f1-score': 0.03571428571428571, 'micro avg_support': 77.0, 'macro avg_precision': 0.03296703296703297, 'macro avg_recall': 0.03896103896103896, 'macro avg_f1-score': 0.03571428571428571, 'macro avg_support': 77.0, 'weighted avg_precision': 0.03296703296703297, 'weighted avg_recall': 0.03896103896103896, 'weighted avg_f1-score': 0.03571428571428571, 'weighted avg_support': 77.0, 'O_support': 2641, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'epoch': 1}, {'micro_f1': 0.8206823591642423, 'precision': 0.8206823591642423, 'Flag_Waving_precision': 0.1978021978021978, 'Flag_Waving_recall': 0.1935483870967742, 'Flag_Waving_f1-score': 0.19565217391304346, 'Flag_Waving_support': 93.0, 'micro avg_precision': 0.1978021978021978, 'micro avg_recall': 0.1935483870967742, 'micro avg_f1-score': 0.19565217391304346, 'micro avg_support': 93.0, 'macro avg_precision': 0.1978021978021978, 'macro avg_recall': 0.1935483870967742, 'macro avg_f1-score': 0.19565217391304346, 'macro avg_support': 93.0, 'weighted avg_precision': 0.1978021978021978, 'weighted avg_recall': 0.1935483870967742, 'weighted avg_f1-score': 0.1956521739130435, 'weighted avg_support': 93.0, 'O_support': 2641, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'epoch': 2}, {'micro_f1': 0.825707484792383, 'precision': 0.825707484792383, 'Flag_Waving_precision': 0.21978021978021978, 'Flag_Waving_recall': 0.1941747572815534, 'Flag_Waving_f1-score': 0.20618556701030924, 'Flag_Waving_support': 103.0, 'micro avg_precision': 0.21978021978021978, 'micro avg_recall': 0.1941747572815534, 'micro avg_f1-score': 0.20618556701030924, 'micro avg_support': 103.0, 'macro avg_precision': 0.21978021978021978, 'macro avg_recall': 0.1941747572815534, 'macro avg_f1-score': 0.20618556701030924, 'macro avg_support': 103.0, 'weighted avg_precision': 0.2197802197802198, 'weighted avg_recall': 0.1941747572815534, 'weighted avg_f1-score': 0.20618556701030924, 'weighted avg_support': 103.0, 'O_support': 2641, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'epoch': 3}, {'micro_f1': 0.8500396720444326, 'precision': 0.8500396720444326, 'Flag_Waving_precision': 0.3076923076923077, 'Flag_Waving_recall': 0.25, 'Flag_Waving_f1-score': 0.27586206896551724, 'Flag_Waving_support': 112.0, 'micro avg_precision': 0.3076923076923077, 'micro avg_recall': 0.25, 'micro avg_f1-score': 0.27586206896551724, 'micro avg_support': 112.0, 'macro avg_precision': 0.3076923076923077, 'macro avg_recall': 0.25, 'macro avg_f1-score': 0.27586206896551724, 'macro avg_support': 112.0, 'weighted avg_precision': 0.30769230769230776, 'weighted avg_recall': 0.25, 'weighted avg_f1-score': 0.27586206896551724, 'weighted avg_support': 112.0, 'O_support': 2641, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'epoch': 4}, {'micro_f1': 0.8458079873049458, 'precision': 0.8458079873049458, 'Flag_Waving_precision': 0.31868131868131866, 'Flag_Waving_recall': 0.28431372549019607, 'Flag_Waving_f1-score': 0.30051813471502586, 'Flag_Waving_support': 102.0, 'micro avg_precision': 0.31868131868131866, 'micro avg_recall': 0.28431372549019607, 'micro avg_f1-score': 0.30051813471502586, 'micro avg_support': 102.0, 'macro avg_precision': 0.31868131868131866, 'macro avg_recall': 0.28431372549019607, 'macro avg_f1-score': 0.30051813471502586, 'macro avg_support': 102.0, 'weighted avg_precision': 0.31868131868131866, 'weighted avg_recall': 0.28431372549019607, 'weighted avg_f1-score': 0.30051813471502586, 'weighted avg_support': 102.0, 'O_support': 2641, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'epoch': 5}, {'micro_f1': 0.8397249404919334, 'precision': 0.8397249404919334, 'Flag_Waving_precision': 0.3956043956043956, 'Flag_Waving_recall': 0.35294117647058826, 'Flag_Waving_f1-score': 0.37305699481865284, 'Flag_Waving_support': 102.0, 'micro avg_precision': 0.3956043956043956, 'micro avg_recall': 0.35294117647058826, 'micro avg_f1-score': 0.37305699481865284, 'micro avg_support': 102.0, 'macro avg_precision': 0.3956043956043956, 'macro avg_recall': 0.35294117647058826, 'macro avg_f1-score': 0.37305699481865284, 'macro avg_support': 102.0, 'weighted avg_precision': 0.3956043956043956, 'weighted avg_recall': 0.35294117647058826, 'weighted avg_f1-score': 0.37305699481865284, 'weighted avg_support': 102.0, 'O_support': 2641, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'epoch': 6}, {'micro_f1': 0.85294895530283, 'precision': 0.85294895530283, 'Flag_Waving_precision': 0.4175824175824176, 'Flag_Waving_recall': 0.3275862068965517, 'Flag_Waving_f1-score': 0.3671497584541063, 'Flag_Waving_support': 116.0, 'micro avg_precision': 0.4175824175824176, 'micro avg_recall': 0.3275862068965517, 'micro avg_f1-score': 0.3671497584541063, 'micro avg_support': 116.0, 'macro avg_precision': 0.4175824175824176, 'macro avg_recall': 0.3275862068965517, 'macro avg_f1-score': 0.3671497584541063, 'macro avg_support': 116.0, 'weighted avg_precision': 0.41758241758241754, 'weighted avg_recall': 0.3275862068965517, 'weighted avg_f1-score': 0.3671497584541063, 'weighted avg_support': 116.0, 'O_support': 2641, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'epoch': 7}]}
{'micro_f1': 0.8315260513091774, 'precision': 0.8315260513091774, 'Flag_Waving_precision': 0.3626373626373626, 'Flag_Waving_recall': 0.336734693877551, 'Flag_Waving_f1-score': 0.3492063492063492, 'Flag_Waving_support': 98.0, 'micro avg_precision': 0.3626373626373626, 'micro avg_recall': 0.336734693877551, 'micro avg_f1-score': 0.3492063492063492, 'micro avg_support': 98.0, 'macro avg_precision': 0.3626373626373626, 'macro avg_recall': 0.336734693877551, 'macro avg_f1-score': 0.3492063492063492, 'macro avg_support': 98.0, 'weighted avg_precision': 0.3626373626373627, 'weighted avg_recall': 0.336734693877551, 'weighted avg_f1-score': 0.3492063492063492, 'weighted avg_support': 98.0, 'O_support': 2641, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'epoch': 8}
{'results': [{'micro_f1': 0.8000528960592436, 'precision': 0.8000528960592436, 'Flag_Waving_precision': 0.02197802197802198, 'Flag_Waving_recall': 0.022727272727272728, 'Flag_Waving_f1-score': 0.0223463687150838, 'Flag_Waving_support': 88.0, 'micro avg_precision': 0.02197802197802198, 'micro avg_recall': 0.022727272727272728, 'micro avg_f1-score': 0.0223463687150838, 'micro avg_support': 88.0, 'macro avg_precision': 0.02197802197802198, 'macro avg_recall': 0.022727272727272728, 'macro avg_f1-score': 0.0223463687150838, 'macro avg_support': 88.0, 'weighted avg_precision': 0.02197802197802198, 'weighted avg_recall': 0.022727272727272728, 'weighted avg_f1-score': 0.0223463687150838, 'weighted avg_support': 88.0, 'O_support': 2641, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'epoch': 0}, {'micro_f1': 0.7791589526580269, 'precision': 0.7791589526580269, 'Flag_Waving_precision': 0.03296703296703297, 'Flag_Waving_recall': 0.03896103896103896, 'Flag_Waving_f1-score': 0.03571428571428571, 'Flag_Waving_support': 77.0, 'micro avg_precision': 0.03296703296703297, 'micro avg_recall': 0.03896103896103896, 'micro avg_f1-score': 0.03571428571428571, 'micro avg_support': 77.0, 'macro avg_precision': 0.03296703296703297, 'macro avg_recall': 0.03896103896103896, 'macro avg_f1-score': 0.03571428571428571, 'macro avg_support': 77.0, 'weighted avg_precision': 0.03296703296703297, 'weighted avg_recall': 0.03896103896103896, 'weighted avg_f1-score': 0.03571428571428571, 'weighted avg_support': 77.0, 'O_support': 2641, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'epoch': 1}, {'micro_f1': 0.8206823591642423, 'precision': 0.8206823591642423, 'Flag_Waving_precision': 0.1978021978021978, 'Flag_Waving_recall': 0.1935483870967742, 'Flag_Waving_f1-score': 0.19565217391304346, 'Flag_Waving_support': 93.0, 'micro avg_precision': 0.1978021978021978, 'micro avg_recall': 0.1935483870967742, 'micro avg_f1-score': 0.19565217391304346, 'micro avg_support': 93.0, 'macro avg_precision': 0.1978021978021978, 'macro avg_recall': 0.1935483870967742, 'macro avg_f1-score': 0.19565217391304346, 'macro avg_support': 93.0, 'weighted avg_precision': 0.1978021978021978, 'weighted avg_recall': 0.1935483870967742, 'weighted avg_f1-score': 0.1956521739130435, 'weighted avg_support': 93.0, 'O_support': 2641, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'epoch': 2}, {'micro_f1': 0.825707484792383, 'precision': 0.825707484792383, 'Flag_Waving_precision': 0.21978021978021978, 'Flag_Waving_recall': 0.1941747572815534, 'Flag_Waving_f1-score': 0.20618556701030924, 'Flag_Waving_support': 103.0, 'micro avg_precision': 0.21978021978021978, 'micro avg_recall': 0.1941747572815534, 'micro avg_f1-score': 0.20618556701030924, 'micro avg_support': 103.0, 'macro avg_precision': 0.21978021978021978, 'macro avg_recall': 0.1941747572815534, 'macro avg_f1-score': 0.20618556701030924, 'macro avg_support': 103.0, 'weighted avg_precision': 0.2197802197802198, 'weighted avg_recall': 0.1941747572815534, 'weighted avg_f1-score': 0.20618556701030924, 'weighted avg_support': 103.0, 'O_support': 2641, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'epoch': 3}, {'micro_f1': 0.8500396720444326, 'precision': 0.8500396720444326, 'Flag_Waving_precision': 0.3076923076923077, 'Flag_Waving_recall': 0.25, 'Flag_Waving_f1-score': 0.27586206896551724, 'Flag_Waving_support': 112.0, 'micro avg_precision': 0.3076923076923077, 'micro avg_recall': 0.25, 'micro avg_f1-score': 0.27586206896551724, 'micro avg_support': 112.0, 'macro avg_precision': 0.3076923076923077, 'macro avg_recall': 0.25, 'macro avg_f1-score': 0.27586206896551724, 'macro avg_support': 112.0, 'weighted avg_precision': 0.30769230769230776, 'weighted avg_recall': 0.25, 'weighted avg_f1-score': 0.27586206896551724, 'weighted avg_support': 112.0, 'O_support': 2641, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'epoch': 4}, {'micro_f1': 0.8458079873049458, 'precision': 0.8458079873049458, 'Flag_Waving_precision': 0.31868131868131866, 'Flag_Waving_recall': 0.28431372549019607, 'Flag_Waving_f1-score': 0.30051813471502586, 'Flag_Waving_support': 102.0, 'micro avg_precision': 0.31868131868131866, 'micro avg_recall': 0.28431372549019607, 'micro avg_f1-score': 0.30051813471502586, 'micro avg_support': 102.0, 'macro avg_precision': 0.31868131868131866, 'macro avg_recall': 0.28431372549019607, 'macro avg_f1-score': 0.30051813471502586, 'macro avg_support': 102.0, 'weighted avg_precision': 0.31868131868131866, 'weighted avg_recall': 0.28431372549019607, 'weighted avg_f1-score': 0.30051813471502586, 'weighted avg_support': 102.0, 'O_support': 2641, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'epoch': 5}, {'micro_f1': 0.8397249404919334, 'precision': 0.8397249404919334, 'Flag_Waving_precision': 0.3956043956043956, 'Flag_Waving_recall': 0.35294117647058826, 'Flag_Waving_f1-score': 0.37305699481865284, 'Flag_Waving_support': 102.0, 'micro avg_precision': 0.3956043956043956, 'micro avg_recall': 0.35294117647058826, 'micro avg_f1-score': 0.37305699481865284, 'micro avg_support': 102.0, 'macro avg_precision': 0.3956043956043956, 'macro avg_recall': 0.35294117647058826, 'macro avg_f1-score': 0.37305699481865284, 'macro avg_support': 102.0, 'weighted avg_precision': 0.3956043956043956, 'weighted avg_recall': 0.35294117647058826, 'weighted avg_f1-score': 0.37305699481865284, 'weighted avg_support': 102.0, 'O_support': 2641, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'epoch': 6}, {'micro_f1': 0.85294895530283, 'precision': 0.85294895530283, 'Flag_Waving_precision': 0.4175824175824176, 'Flag_Waving_recall': 0.3275862068965517, 'Flag_Waving_f1-score': 0.3671497584541063, 'Flag_Waving_support': 116.0, 'micro avg_precision': 0.4175824175824176, 'micro avg_recall': 0.3275862068965517, 'micro avg_f1-score': 0.3671497584541063, 'micro avg_support': 116.0, 'macro avg_precision': 0.4175824175824176, 'macro avg_recall': 0.3275862068965517, 'macro avg_f1-score': 0.3671497584541063, 'macro avg_support': 116.0, 'weighted avg_precision': 0.41758241758241754, 'weighted avg_recall': 0.3275862068965517, 'weighted avg_f1-score': 0.3671497584541063, 'weighted avg_support': 116.0, 'O_support': 2641, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'epoch': 7}, {'micro_f1': 0.8315260513091774, 'precision': 0.8315260513091774, 'Flag_Waving_precision': 0.3626373626373626, 'Flag_Waving_recall': 0.336734693877551, 'Flag_Waving_f1-score': 0.3492063492063492, 'Flag_Waving_support': 98.0, 'micro avg_precision': 0.3626373626373626, 'micro avg_recall': 0.336734693877551, 'micro avg_f1-score': 0.3492063492063492, 'micro avg_support': 98.0, 'macro avg_precision': 0.3626373626373626, 'macro avg_recall': 0.336734693877551, 'macro avg_f1-score': 0.3492063492063492, 'macro avg_support': 98.0, 'weighted avg_precision': 0.3626373626373627, 'weighted avg_recall': 0.336734693877551, 'weighted avg_f1-score': 0.3492063492063492, 'weighted avg_support': 98.0, 'O_support': 2641, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'epoch': 8}]}
Early stopping triggered.
Saving model to directory: ./models/M2/2024-05-14-06-51-04_aug_ts0.9/mdeberta-v3-base_4_ME10_target=Flag_Waving_SUBSAMPLED_2024-05-14-06-51-04
Training model no. 5 of 23 for (5, 'Causal_Oversimplification') persuasion technique...
{'micro_f1': 0.4852263486039577, 'precision': 0.4852263486039577, 'Causal_Oversimplification_precision': 0.0, 'Causal_Oversimplification_recall': 0.0, 'Causal_Oversimplification_f1-score': 0.0, 'Causal_Oversimplification_support': 25.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 25.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 25.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 25.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1715, 'epoch': 0}
{'results': [{'micro_f1': 0.4852263486039577, 'precision': 0.4852263486039577, 'Causal_Oversimplification_precision': 0.0, 'Causal_Oversimplification_recall': 0.0, 'Causal_Oversimplification_f1-score': 0.0, 'Causal_Oversimplification_support': 25.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 25.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 25.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 25.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1715, 'epoch': 0}]}
{'micro_f1': 0.6890756302521008, 'precision': 0.6890756302521008, 'Causal_Oversimplification_precision': 0.11363636363636363, 'Causal_Oversimplification_recall': 0.08849557522123894, 'Causal_Oversimplification_f1-score': 0.09950248756218906, 'Causal_Oversimplification_support': 113.0, 'micro avg_precision': 0.11363636363636363, 'micro avg_recall': 0.08849557522123894, 'micro avg_f1-score': 0.09950248756218906, 'micro avg_support': 113.0, 'macro avg_precision': 0.11363636363636363, 'macro avg_recall': 0.08849557522123894, 'macro avg_f1-score': 0.09950248756218906, 'macro avg_support': 113.0, 'weighted avg_precision': 0.11363636363636363, 'weighted avg_recall': 0.08849557522123894, 'weighted avg_f1-score': 0.09950248756218906, 'weighted avg_support': 113.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1715, 'epoch': 1}
{'results': [{'micro_f1': 0.4852263486039577, 'precision': 0.4852263486039577, 'Causal_Oversimplification_precision': 0.0, 'Causal_Oversimplification_recall': 0.0, 'Causal_Oversimplification_f1-score': 0.0, 'Causal_Oversimplification_support': 25.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 25.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 25.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 25.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1715, 'epoch': 0}, {'micro_f1': 0.6890756302521008, 'precision': 0.6890756302521008, 'Causal_Oversimplification_precision': 0.11363636363636363, 'Causal_Oversimplification_recall': 0.08849557522123894, 'Causal_Oversimplification_f1-score': 0.09950248756218906, 'Causal_Oversimplification_support': 113.0, 'micro avg_precision': 0.11363636363636363, 'micro avg_recall': 0.08849557522123894, 'micro avg_f1-score': 0.09950248756218906, 'micro avg_support': 113.0, 'macro avg_precision': 0.11363636363636363, 'macro avg_recall': 0.08849557522123894, 'macro avg_f1-score': 0.09950248756218906, 'macro avg_support': 113.0, 'weighted avg_precision': 0.11363636363636363, 'weighted avg_recall': 0.08849557522123894, 'weighted avg_f1-score': 0.09950248756218906, 'weighted avg_support': 113.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1715, 'epoch': 1}]}
Best model updated: current epoch macro f1 = 0.09950248756218906
{'micro_f1': 0.6383843860124695, 'precision': 0.6383843860124695, 'Causal_Oversimplification_precision': 0.07954545454545454, 'Causal_Oversimplification_recall': 0.07608695652173914, 'Causal_Oversimplification_f1-score': 0.07777777777777779, 'Causal_Oversimplification_support': 92.0, 'micro avg_precision': 0.07954545454545454, 'micro avg_recall': 0.07608695652173914, 'micro avg_f1-score': 0.07777777777777779, 'micro avg_support': 92.0, 'macro avg_precision': 0.07954545454545454, 'macro avg_recall': 0.07608695652173914, 'macro avg_f1-score': 0.07777777777777779, 'macro avg_support': 92.0, 'weighted avg_precision': 0.07954545454545454, 'weighted avg_recall': 0.07608695652173914, 'weighted avg_f1-score': 0.07777777777777779, 'weighted avg_support': 92.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1715, 'epoch': 2}
{'results': [{'micro_f1': 0.4852263486039577, 'precision': 0.4852263486039577, 'Causal_Oversimplification_precision': 0.0, 'Causal_Oversimplification_recall': 0.0, 'Causal_Oversimplification_f1-score': 0.0, 'Causal_Oversimplification_support': 25.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 25.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 25.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 25.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1715, 'epoch': 0}, {'micro_f1': 0.6890756302521008, 'precision': 0.6890756302521008, 'Causal_Oversimplification_precision': 0.11363636363636363, 'Causal_Oversimplification_recall': 0.08849557522123894, 'Causal_Oversimplification_f1-score': 0.09950248756218906, 'Causal_Oversimplification_support': 113.0, 'micro avg_precision': 0.11363636363636363, 'micro avg_recall': 0.08849557522123894, 'micro avg_f1-score': 0.09950248756218906, 'micro avg_support': 113.0, 'macro avg_precision': 0.11363636363636363, 'macro avg_recall': 0.08849557522123894, 'macro avg_f1-score': 0.09950248756218906, 'macro avg_support': 113.0, 'weighted avg_precision': 0.11363636363636363, 'weighted avg_recall': 0.08849557522123894, 'weighted avg_f1-score': 0.09950248756218906, 'weighted avg_support': 113.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1715, 'epoch': 1}, {'micro_f1': 0.6383843860124695, 'precision': 0.6383843860124695, 'Causal_Oversimplification_precision': 0.07954545454545454, 'Causal_Oversimplification_recall': 0.07608695652173914, 'Causal_Oversimplification_f1-score': 0.07777777777777779, 'Causal_Oversimplification_support': 92.0, 'micro avg_precision': 0.07954545454545454, 'micro avg_recall': 0.07608695652173914, 'micro avg_f1-score': 0.07777777777777779, 'micro avg_support': 92.0, 'macro avg_precision': 0.07954545454545454, 'macro avg_recall': 0.07608695652173914, 'macro avg_f1-score': 0.07777777777777779, 'macro avg_support': 92.0, 'weighted avg_precision': 0.07954545454545454, 'weighted avg_recall': 0.07608695652173914, 'weighted avg_f1-score': 0.07777777777777779, 'weighted avg_support': 92.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1715, 'epoch': 2}]}
{'micro_f1': 0.8040119273515858, 'precision': 0.8040119273515858, 'Causal_Oversimplification_precision': 0.32954545454545453, 'Causal_Oversimplification_recall': 0.26126126126126126, 'Causal_Oversimplification_f1-score': 0.2914572864321608, 'Causal_Oversimplification_support': 111.0, 'micro avg_precision': 0.32954545454545453, 'micro avg_recall': 0.26126126126126126, 'micro avg_f1-score': 0.2914572864321608, 'micro avg_support': 111.0, 'macro avg_precision': 0.32954545454545453, 'macro avg_recall': 0.26126126126126126, 'macro avg_f1-score': 0.2914572864321608, 'macro avg_support': 111.0, 'weighted avg_precision': 0.32954545454545453, 'weighted avg_recall': 0.26126126126126126, 'weighted avg_f1-score': 0.2914572864321608, 'weighted avg_support': 111.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1715, 'epoch': 3}
{'results': [{'micro_f1': 0.4852263486039577, 'precision': 0.4852263486039577, 'Causal_Oversimplification_precision': 0.0, 'Causal_Oversimplification_recall': 0.0, 'Causal_Oversimplification_f1-score': 0.0, 'Causal_Oversimplification_support': 25.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 25.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 25.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 25.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1715, 'epoch': 0}, {'micro_f1': 0.6890756302521008, 'precision': 0.6890756302521008, 'Causal_Oversimplification_precision': 0.11363636363636363, 'Causal_Oversimplification_recall': 0.08849557522123894, 'Causal_Oversimplification_f1-score': 0.09950248756218906, 'Causal_Oversimplification_support': 113.0, 'micro avg_precision': 0.11363636363636363, 'micro avg_recall': 0.08849557522123894, 'micro avg_f1-score': 0.09950248756218906, 'micro avg_support': 113.0, 'macro avg_precision': 0.11363636363636363, 'macro avg_recall': 0.08849557522123894, 'macro avg_f1-score': 0.09950248756218906, 'macro avg_support': 113.0, 'weighted avg_precision': 0.11363636363636363, 'weighted avg_recall': 0.08849557522123894, 'weighted avg_f1-score': 0.09950248756218906, 'weighted avg_support': 113.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1715, 'epoch': 1}, {'micro_f1': 0.6383843860124695, 'precision': 0.6383843860124695, 'Causal_Oversimplification_precision': 0.07954545454545454, 'Causal_Oversimplification_recall': 0.07608695652173914, 'Causal_Oversimplification_f1-score': 0.07777777777777779, 'Causal_Oversimplification_support': 92.0, 'micro avg_precision': 0.07954545454545454, 'micro avg_recall': 0.07608695652173914, 'micro avg_f1-score': 0.07777777777777779, 'micro avg_support': 92.0, 'macro avg_precision': 0.07954545454545454, 'macro avg_recall': 0.07608695652173914, 'macro avg_f1-score': 0.07777777777777779, 'macro avg_support': 92.0, 'weighted avg_precision': 0.07954545454545454, 'weighted avg_recall': 0.07608695652173914, 'weighted avg_f1-score': 0.07777777777777779, 'weighted avg_support': 92.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1715, 'epoch': 2}, {'micro_f1': 0.8040119273515858, 'precision': 0.8040119273515858, 'Causal_Oversimplification_precision': 0.32954545454545453, 'Causal_Oversimplification_recall': 0.26126126126126126, 'Causal_Oversimplification_f1-score': 0.2914572864321608, 'Causal_Oversimplification_support': 111.0, 'micro avg_precision': 0.32954545454545453, 'micro avg_recall': 0.26126126126126126, 'micro avg_f1-score': 0.2914572864321608, 'micro avg_support': 111.0, 'macro avg_precision': 0.32954545454545453, 'macro avg_recall': 0.26126126126126126, 'macro avg_f1-score': 0.2914572864321608, 'macro avg_support': 111.0, 'weighted avg_precision': 0.32954545454545453, 'weighted avg_recall': 0.26126126126126126, 'weighted avg_f1-score': 0.2914572864321608, 'weighted avg_support': 111.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1715, 'epoch': 3}]}
Best model updated: current epoch macro f1 = 0.2914572864321608
{'micro_f1': 0.6595283274600162, 'precision': 0.6595283274600162, 'Causal_Oversimplification_precision': 0.13636363636363635, 'Causal_Oversimplification_recall': 0.13636363636363635, 'Causal_Oversimplification_f1-score': 0.13636363636363635, 'Causal_Oversimplification_support': 88.0, 'micro avg_precision': 0.13636363636363635, 'micro avg_recall': 0.13636363636363635, 'micro avg_f1-score': 0.13636363636363635, 'micro avg_support': 88.0, 'macro avg_precision': 0.13636363636363635, 'macro avg_recall': 0.13636363636363635, 'macro avg_f1-score': 0.13636363636363635, 'macro avg_support': 88.0, 'weighted avg_precision': 0.13636363636363635, 'weighted avg_recall': 0.13636363636363635, 'weighted avg_f1-score': 0.13636363636363635, 'weighted avg_support': 88.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1715, 'epoch': 4}
{'results': [{'micro_f1': 0.4852263486039577, 'precision': 0.4852263486039577, 'Causal_Oversimplification_precision': 0.0, 'Causal_Oversimplification_recall': 0.0, 'Causal_Oversimplification_f1-score': 0.0, 'Causal_Oversimplification_support': 25.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 25.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 25.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 25.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1715, 'epoch': 0}, {'micro_f1': 0.6890756302521008, 'precision': 0.6890756302521008, 'Causal_Oversimplification_precision': 0.11363636363636363, 'Causal_Oversimplification_recall': 0.08849557522123894, 'Causal_Oversimplification_f1-score': 0.09950248756218906, 'Causal_Oversimplification_support': 113.0, 'micro avg_precision': 0.11363636363636363, 'micro avg_recall': 0.08849557522123894, 'micro avg_f1-score': 0.09950248756218906, 'micro avg_support': 113.0, 'macro avg_precision': 0.11363636363636363, 'macro avg_recall': 0.08849557522123894, 'macro avg_f1-score': 0.09950248756218906, 'macro avg_support': 113.0, 'weighted avg_precision': 0.11363636363636363, 'weighted avg_recall': 0.08849557522123894, 'weighted avg_f1-score': 0.09950248756218906, 'weighted avg_support': 113.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1715, 'epoch': 1}, {'micro_f1': 0.6383843860124695, 'precision': 0.6383843860124695, 'Causal_Oversimplification_precision': 0.07954545454545454, 'Causal_Oversimplification_recall': 0.07608695652173914, 'Causal_Oversimplification_f1-score': 0.07777777777777779, 'Causal_Oversimplification_support': 92.0, 'micro avg_precision': 0.07954545454545454, 'micro avg_recall': 0.07608695652173914, 'micro avg_f1-score': 0.07777777777777779, 'micro avg_support': 92.0, 'macro avg_precision': 0.07954545454545454, 'macro avg_recall': 0.07608695652173914, 'macro avg_f1-score': 0.07777777777777779, 'macro avg_support': 92.0, 'weighted avg_precision': 0.07954545454545454, 'weighted avg_recall': 0.07608695652173914, 'weighted avg_f1-score': 0.07777777777777779, 'weighted avg_support': 92.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1715, 'epoch': 2}, {'micro_f1': 0.8040119273515858, 'precision': 0.8040119273515858, 'Causal_Oversimplification_precision': 0.32954545454545453, 'Causal_Oversimplification_recall': 0.26126126126126126, 'Causal_Oversimplification_f1-score': 0.2914572864321608, 'Causal_Oversimplification_support': 111.0, 'micro avg_precision': 0.32954545454545453, 'micro avg_recall': 0.26126126126126126, 'micro avg_f1-score': 0.2914572864321608, 'micro avg_support': 111.0, 'macro avg_precision': 0.32954545454545453, 'macro avg_recall': 0.26126126126126126, 'macro avg_f1-score': 0.2914572864321608, 'macro avg_support': 111.0, 'weighted avg_precision': 0.32954545454545453, 'weighted avg_recall': 0.26126126126126126, 'weighted avg_f1-score': 0.2914572864321608, 'weighted avg_support': 111.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1715, 'epoch': 3}, {'micro_f1': 0.6595283274600162, 'precision': 0.6595283274600162, 'Causal_Oversimplification_precision': 0.13636363636363635, 'Causal_Oversimplification_recall': 0.13636363636363635, 'Causal_Oversimplification_f1-score': 0.13636363636363635, 'Causal_Oversimplification_support': 88.0, 'micro avg_precision': 0.13636363636363635, 'micro avg_recall': 0.13636363636363635, 'micro avg_f1-score': 0.13636363636363635, 'micro avg_support': 88.0, 'macro avg_precision': 0.13636363636363635, 'macro avg_recall': 0.13636363636363635, 'macro avg_f1-score': 0.13636363636363635, 'macro avg_support': 88.0, 'weighted avg_precision': 0.13636363636363635, 'weighted avg_recall': 0.13636363636363635, 'weighted avg_f1-score': 0.13636363636363635, 'weighted avg_support': 88.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1715, 'epoch': 4}]}
{'micro_f1': 0.74573055028463, 'precision': 0.74573055028463, 'Causal_Oversimplification_precision': 0.20454545454545456, 'Causal_Oversimplification_recall': 0.1836734693877551, 'Causal_Oversimplification_f1-score': 0.1935483870967742, 'Causal_Oversimplification_support': 98.0, 'micro avg_precision': 0.20454545454545456, 'micro avg_recall': 0.1836734693877551, 'micro avg_f1-score': 0.1935483870967742, 'micro avg_support': 98.0, 'macro avg_precision': 0.20454545454545456, 'macro avg_recall': 0.1836734693877551, 'macro avg_f1-score': 0.1935483870967742, 'macro avg_support': 98.0, 'weighted avg_precision': 0.20454545454545456, 'weighted avg_recall': 0.1836734693877551, 'weighted avg_f1-score': 0.19354838709677422, 'weighted avg_support': 98.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1715, 'epoch': 5}
{'results': [{'micro_f1': 0.4852263486039577, 'precision': 0.4852263486039577, 'Causal_Oversimplification_precision': 0.0, 'Causal_Oversimplification_recall': 0.0, 'Causal_Oversimplification_f1-score': 0.0, 'Causal_Oversimplification_support': 25.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 25.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 25.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 25.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1715, 'epoch': 0}, {'micro_f1': 0.6890756302521008, 'precision': 0.6890756302521008, 'Causal_Oversimplification_precision': 0.11363636363636363, 'Causal_Oversimplification_recall': 0.08849557522123894, 'Causal_Oversimplification_f1-score': 0.09950248756218906, 'Causal_Oversimplification_support': 113.0, 'micro avg_precision': 0.11363636363636363, 'micro avg_recall': 0.08849557522123894, 'micro avg_f1-score': 0.09950248756218906, 'micro avg_support': 113.0, 'macro avg_precision': 0.11363636363636363, 'macro avg_recall': 0.08849557522123894, 'macro avg_f1-score': 0.09950248756218906, 'macro avg_support': 113.0, 'weighted avg_precision': 0.11363636363636363, 'weighted avg_recall': 0.08849557522123894, 'weighted avg_f1-score': 0.09950248756218906, 'weighted avg_support': 113.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1715, 'epoch': 1}, {'micro_f1': 0.6383843860124695, 'precision': 0.6383843860124695, 'Causal_Oversimplification_precision': 0.07954545454545454, 'Causal_Oversimplification_recall': 0.07608695652173914, 'Causal_Oversimplification_f1-score': 0.07777777777777779, 'Causal_Oversimplification_support': 92.0, 'micro avg_precision': 0.07954545454545454, 'micro avg_recall': 0.07608695652173914, 'micro avg_f1-score': 0.07777777777777779, 'micro avg_support': 92.0, 'macro avg_precision': 0.07954545454545454, 'macro avg_recall': 0.07608695652173914, 'macro avg_f1-score': 0.07777777777777779, 'macro avg_support': 92.0, 'weighted avg_precision': 0.07954545454545454, 'weighted avg_recall': 0.07608695652173914, 'weighted avg_f1-score': 0.07777777777777779, 'weighted avg_support': 92.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1715, 'epoch': 2}, {'micro_f1': 0.8040119273515858, 'precision': 0.8040119273515858, 'Causal_Oversimplification_precision': 0.32954545454545453, 'Causal_Oversimplification_recall': 0.26126126126126126, 'Causal_Oversimplification_f1-score': 0.2914572864321608, 'Causal_Oversimplification_support': 111.0, 'micro avg_precision': 0.32954545454545453, 'micro avg_recall': 0.26126126126126126, 'micro avg_f1-score': 0.2914572864321608, 'micro avg_support': 111.0, 'macro avg_precision': 0.32954545454545453, 'macro avg_recall': 0.26126126126126126, 'macro avg_f1-score': 0.2914572864321608, 'macro avg_support': 111.0, 'weighted avg_precision': 0.32954545454545453, 'weighted avg_recall': 0.26126126126126126, 'weighted avg_f1-score': 0.2914572864321608, 'weighted avg_support': 111.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1715, 'epoch': 3}, {'micro_f1': 0.6595283274600162, 'precision': 0.6595283274600162, 'Causal_Oversimplification_precision': 0.13636363636363635, 'Causal_Oversimplification_recall': 0.13636363636363635, 'Causal_Oversimplification_f1-score': 0.13636363636363635, 'Causal_Oversimplification_support': 88.0, 'micro avg_precision': 0.13636363636363635, 'micro avg_recall': 0.13636363636363635, 'micro avg_f1-score': 0.13636363636363635, 'micro avg_support': 88.0, 'macro avg_precision': 0.13636363636363635, 'macro avg_recall': 0.13636363636363635, 'macro avg_f1-score': 0.13636363636363635, 'macro avg_support': 88.0, 'weighted avg_precision': 0.13636363636363635, 'weighted avg_recall': 0.13636363636363635, 'weighted avg_f1-score': 0.13636363636363635, 'weighted avg_support': 88.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1715, 'epoch': 4}, {'micro_f1': 0.74573055028463, 'precision': 0.74573055028463, 'Causal_Oversimplification_precision': 0.20454545454545456, 'Causal_Oversimplification_recall': 0.1836734693877551, 'Causal_Oversimplification_f1-score': 0.1935483870967742, 'Causal_Oversimplification_support': 98.0, 'micro avg_precision': 0.20454545454545456, 'micro avg_recall': 0.1836734693877551, 'micro avg_f1-score': 0.1935483870967742, 'micro avg_support': 98.0, 'macro avg_precision': 0.20454545454545456, 'macro avg_recall': 0.1836734693877551, 'macro avg_f1-score': 0.1935483870967742, 'macro avg_support': 98.0, 'weighted avg_precision': 0.20454545454545456, 'weighted avg_recall': 0.1836734693877551, 'weighted avg_f1-score': 0.19354838709677422, 'weighted avg_support': 98.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1715, 'epoch': 5}]}
Early stopping triggered.
Saving model to directory: ./models/M2/2024-05-14-06-51-04_aug_ts0.9/mdeberta-v3-base_5_ME10_target=Causal_Oversimplification_SUBSAMPLED_2024-05-14-06-51-04
Training model no. 6 of 23 for (6, 'False_Dilemma-No_Choice') persuasion technique...
{'micro_f1': 0.749708963911525, 'precision': 0.7497089639115251, 'False_Dilemma-No_Choice_precision': 0.0, 'False_Dilemma-No_Choice_recall': 0.0, 'False_Dilemma-No_Choice_f1-score': 0.0, 'False_Dilemma-No_Choice_support': 110.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 110.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 110.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 110.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 2008, 'epoch': 0}
{'results': [{'micro_f1': 0.749708963911525, 'precision': 0.7497089639115251, 'False_Dilemma-No_Choice_precision': 0.0, 'False_Dilemma-No_Choice_recall': 0.0, 'False_Dilemma-No_Choice_f1-score': 0.0, 'False_Dilemma-No_Choice_support': 110.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 110.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 110.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 110.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 2008, 'epoch': 0}]}
{'micro_f1': 0.8306169965075669, 'precision': 0.8306169965075669, 'False_Dilemma-No_Choice_precision': 0.11904761904761904, 'False_Dilemma-No_Choice_recall': 0.0847457627118644, 'False_Dilemma-No_Choice_f1-score': 0.09900990099009901, 'False_Dilemma-No_Choice_support': 118.0, 'micro avg_precision': 0.11904761904761904, 'micro avg_recall': 0.0847457627118644, 'micro avg_f1-score': 0.09900990099009901, 'micro avg_support': 118.0, 'macro avg_precision': 0.11904761904761904, 'macro avg_recall': 0.0847457627118644, 'macro avg_f1-score': 0.09900990099009901, 'macro avg_support': 118.0, 'weighted avg_precision': 0.11904761904761904, 'weighted avg_recall': 0.0847457627118644, 'weighted avg_f1-score': 0.099009900990099, 'weighted avg_support': 118.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 2008, 'epoch': 1}
{'results': [{'micro_f1': 0.749708963911525, 'precision': 0.7497089639115251, 'False_Dilemma-No_Choice_precision': 0.0, 'False_Dilemma-No_Choice_recall': 0.0, 'False_Dilemma-No_Choice_f1-score': 0.0, 'False_Dilemma-No_Choice_support': 110.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 110.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 110.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 110.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 2008, 'epoch': 0}, {'micro_f1': 0.8306169965075669, 'precision': 0.8306169965075669, 'False_Dilemma-No_Choice_precision': 0.11904761904761904, 'False_Dilemma-No_Choice_recall': 0.0847457627118644, 'False_Dilemma-No_Choice_f1-score': 0.09900990099009901, 'False_Dilemma-No_Choice_support': 118.0, 'micro avg_precision': 0.11904761904761904, 'micro avg_recall': 0.0847457627118644, 'micro avg_f1-score': 0.09900990099009901, 'micro avg_support': 118.0, 'macro avg_precision': 0.11904761904761904, 'macro avg_recall': 0.0847457627118644, 'macro avg_f1-score': 0.09900990099009901, 'macro avg_support': 118.0, 'weighted avg_precision': 0.11904761904761904, 'weighted avg_recall': 0.0847457627118644, 'weighted avg_f1-score': 0.099009900990099, 'weighted avg_support': 118.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 2008, 'epoch': 1}]}
Best model updated: current epoch macro f1 = 0.09900990099009901
{'micro_f1': 0.8320721769499417, 'precision': 0.8320721769499418, 'False_Dilemma-No_Choice_precision': 0.16666666666666666, 'False_Dilemma-No_Choice_recall': 0.13592233009708737, 'False_Dilemma-No_Choice_f1-score': 0.1497326203208556, 'False_Dilemma-No_Choice_support': 103.0, 'micro avg_precision': 0.16666666666666666, 'micro avg_recall': 0.13592233009708737, 'micro avg_f1-score': 0.1497326203208556, 'micro avg_support': 103.0, 'macro avg_precision': 0.16666666666666666, 'macro avg_recall': 0.13592233009708737, 'macro avg_f1-score': 0.1497326203208556, 'macro avg_support': 103.0, 'weighted avg_precision': 0.16666666666666666, 'weighted avg_recall': 0.13592233009708737, 'weighted avg_f1-score': 0.1497326203208556, 'weighted avg_support': 103.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 2008, 'epoch': 2}
{'results': [{'micro_f1': 0.749708963911525, 'precision': 0.7497089639115251, 'False_Dilemma-No_Choice_precision': 0.0, 'False_Dilemma-No_Choice_recall': 0.0, 'False_Dilemma-No_Choice_f1-score': 0.0, 'False_Dilemma-No_Choice_support': 110.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 110.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 110.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 110.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 2008, 'epoch': 0}, {'micro_f1': 0.8306169965075669, 'precision': 0.8306169965075669, 'False_Dilemma-No_Choice_precision': 0.11904761904761904, 'False_Dilemma-No_Choice_recall': 0.0847457627118644, 'False_Dilemma-No_Choice_f1-score': 0.09900990099009901, 'False_Dilemma-No_Choice_support': 118.0, 'micro avg_precision': 0.11904761904761904, 'micro avg_recall': 0.0847457627118644, 'micro avg_f1-score': 0.09900990099009901, 'micro avg_support': 118.0, 'macro avg_precision': 0.11904761904761904, 'macro avg_recall': 0.0847457627118644, 'macro avg_f1-score': 0.09900990099009901, 'macro avg_support': 118.0, 'weighted avg_precision': 0.11904761904761904, 'weighted avg_recall': 0.0847457627118644, 'weighted avg_f1-score': 0.099009900990099, 'weighted avg_support': 118.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 2008, 'epoch': 1}, {'micro_f1': 0.8320721769499417, 'precision': 0.8320721769499418, 'False_Dilemma-No_Choice_precision': 0.16666666666666666, 'False_Dilemma-No_Choice_recall': 0.13592233009708737, 'False_Dilemma-No_Choice_f1-score': 0.1497326203208556, 'False_Dilemma-No_Choice_support': 103.0, 'micro avg_precision': 0.16666666666666666, 'micro avg_recall': 0.13592233009708737, 'micro avg_f1-score': 0.1497326203208556, 'micro avg_support': 103.0, 'macro avg_precision': 0.16666666666666666, 'macro avg_recall': 0.13592233009708737, 'macro avg_f1-score': 0.1497326203208556, 'macro avg_support': 103.0, 'weighted avg_precision': 0.16666666666666666, 'weighted avg_recall': 0.13592233009708737, 'weighted avg_f1-score': 0.1497326203208556, 'weighted avg_support': 103.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 2008, 'epoch': 2}]}
Best model updated: current epoch macro f1 = 0.1497326203208556
{'micro_f1': 0.8533178114086146, 'precision': 0.8533178114086146, 'False_Dilemma-No_Choice_precision': 0.21428571428571427, 'False_Dilemma-No_Choice_recall': 0.16363636363636364, 'False_Dilemma-No_Choice_f1-score': 0.18556701030927836, 'False_Dilemma-No_Choice_support': 110.0, 'micro avg_precision': 0.21428571428571427, 'micro avg_recall': 0.16363636363636364, 'micro avg_f1-score': 0.18556701030927836, 'micro avg_support': 110.0, 'macro avg_precision': 0.21428571428571427, 'macro avg_recall': 0.16363636363636364, 'macro avg_f1-score': 0.18556701030927836, 'macro avg_support': 110.0, 'weighted avg_precision': 0.21428571428571427, 'weighted avg_recall': 0.16363636363636364, 'weighted avg_f1-score': 0.18556701030927836, 'weighted avg_support': 110.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 2008, 'epoch': 3}
{'results': [{'micro_f1': 0.749708963911525, 'precision': 0.7497089639115251, 'False_Dilemma-No_Choice_precision': 0.0, 'False_Dilemma-No_Choice_recall': 0.0, 'False_Dilemma-No_Choice_f1-score': 0.0, 'False_Dilemma-No_Choice_support': 110.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 110.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 110.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 110.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 2008, 'epoch': 0}, {'micro_f1': 0.8306169965075669, 'precision': 0.8306169965075669, 'False_Dilemma-No_Choice_precision': 0.11904761904761904, 'False_Dilemma-No_Choice_recall': 0.0847457627118644, 'False_Dilemma-No_Choice_f1-score': 0.09900990099009901, 'False_Dilemma-No_Choice_support': 118.0, 'micro avg_precision': 0.11904761904761904, 'micro avg_recall': 0.0847457627118644, 'micro avg_f1-score': 0.09900990099009901, 'micro avg_support': 118.0, 'macro avg_precision': 0.11904761904761904, 'macro avg_recall': 0.0847457627118644, 'macro avg_f1-score': 0.09900990099009901, 'macro avg_support': 118.0, 'weighted avg_precision': 0.11904761904761904, 'weighted avg_recall': 0.0847457627118644, 'weighted avg_f1-score': 0.099009900990099, 'weighted avg_support': 118.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 2008, 'epoch': 1}, {'micro_f1': 0.8320721769499417, 'precision': 0.8320721769499418, 'False_Dilemma-No_Choice_precision': 0.16666666666666666, 'False_Dilemma-No_Choice_recall': 0.13592233009708737, 'False_Dilemma-No_Choice_f1-score': 0.1497326203208556, 'False_Dilemma-No_Choice_support': 103.0, 'micro avg_precision': 0.16666666666666666, 'micro avg_recall': 0.13592233009708737, 'micro avg_f1-score': 0.1497326203208556, 'micro avg_support': 103.0, 'macro avg_precision': 0.16666666666666666, 'macro avg_recall': 0.13592233009708737, 'macro avg_f1-score': 0.1497326203208556, 'macro avg_support': 103.0, 'weighted avg_precision': 0.16666666666666666, 'weighted avg_recall': 0.13592233009708737, 'weighted avg_f1-score': 0.1497326203208556, 'weighted avg_support': 103.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 2008, 'epoch': 2}, {'micro_f1': 0.8533178114086146, 'precision': 0.8533178114086146, 'False_Dilemma-No_Choice_precision': 0.21428571428571427, 'False_Dilemma-No_Choice_recall': 0.16363636363636364, 'False_Dilemma-No_Choice_f1-score': 0.18556701030927836, 'False_Dilemma-No_Choice_support': 110.0, 'micro avg_precision': 0.21428571428571427, 'micro avg_recall': 0.16363636363636364, 'micro avg_f1-score': 0.18556701030927836, 'micro avg_support': 110.0, 'macro avg_precision': 0.21428571428571427, 'macro avg_recall': 0.16363636363636364, 'macro avg_f1-score': 0.18556701030927836, 'macro avg_support': 110.0, 'weighted avg_precision': 0.21428571428571427, 'weighted avg_recall': 0.16363636363636364, 'weighted avg_f1-score': 0.18556701030927836, 'weighted avg_support': 110.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 2008, 'epoch': 3}]}
Best model updated: current epoch macro f1 = 0.18556701030927836
{'micro_f1': 0.8655413271245634, 'precision': 0.8655413271245634, 'False_Dilemma-No_Choice_precision': 0.2619047619047619, 'False_Dilemma-No_Choice_recall': 0.23655913978494625, 'False_Dilemma-No_Choice_f1-score': 0.24858757062146894, 'False_Dilemma-No_Choice_support': 93.0, 'micro avg_precision': 0.2619047619047619, 'micro avg_recall': 0.23655913978494625, 'micro avg_f1-score': 0.24858757062146894, 'micro avg_support': 93.0, 'macro avg_precision': 0.2619047619047619, 'macro avg_recall': 0.23655913978494625, 'macro avg_f1-score': 0.24858757062146894, 'macro avg_support': 93.0, 'weighted avg_precision': 0.2619047619047619, 'weighted avg_recall': 0.23655913978494625, 'weighted avg_f1-score': 0.24858757062146894, 'weighted avg_support': 93.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 2008, 'epoch': 4}
{'results': [{'micro_f1': 0.749708963911525, 'precision': 0.7497089639115251, 'False_Dilemma-No_Choice_precision': 0.0, 'False_Dilemma-No_Choice_recall': 0.0, 'False_Dilemma-No_Choice_f1-score': 0.0, 'False_Dilemma-No_Choice_support': 110.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 110.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 110.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 110.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 2008, 'epoch': 0}, {'micro_f1': 0.8306169965075669, 'precision': 0.8306169965075669, 'False_Dilemma-No_Choice_precision': 0.11904761904761904, 'False_Dilemma-No_Choice_recall': 0.0847457627118644, 'False_Dilemma-No_Choice_f1-score': 0.09900990099009901, 'False_Dilemma-No_Choice_support': 118.0, 'micro avg_precision': 0.11904761904761904, 'micro avg_recall': 0.0847457627118644, 'micro avg_f1-score': 0.09900990099009901, 'micro avg_support': 118.0, 'macro avg_precision': 0.11904761904761904, 'macro avg_recall': 0.0847457627118644, 'macro avg_f1-score': 0.09900990099009901, 'macro avg_support': 118.0, 'weighted avg_precision': 0.11904761904761904, 'weighted avg_recall': 0.0847457627118644, 'weighted avg_f1-score': 0.099009900990099, 'weighted avg_support': 118.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 2008, 'epoch': 1}, {'micro_f1': 0.8320721769499417, 'precision': 0.8320721769499418, 'False_Dilemma-No_Choice_precision': 0.16666666666666666, 'False_Dilemma-No_Choice_recall': 0.13592233009708737, 'False_Dilemma-No_Choice_f1-score': 0.1497326203208556, 'False_Dilemma-No_Choice_support': 103.0, 'micro avg_precision': 0.16666666666666666, 'micro avg_recall': 0.13592233009708737, 'micro avg_f1-score': 0.1497326203208556, 'micro avg_support': 103.0, 'macro avg_precision': 0.16666666666666666, 'macro avg_recall': 0.13592233009708737, 'macro avg_f1-score': 0.1497326203208556, 'macro avg_support': 103.0, 'weighted avg_precision': 0.16666666666666666, 'weighted avg_recall': 0.13592233009708737, 'weighted avg_f1-score': 0.1497326203208556, 'weighted avg_support': 103.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 2008, 'epoch': 2}, {'micro_f1': 0.8533178114086146, 'precision': 0.8533178114086146, 'False_Dilemma-No_Choice_precision': 0.21428571428571427, 'False_Dilemma-No_Choice_recall': 0.16363636363636364, 'False_Dilemma-No_Choice_f1-score': 0.18556701030927836, 'False_Dilemma-No_Choice_support': 110.0, 'micro avg_precision': 0.21428571428571427, 'micro avg_recall': 0.16363636363636364, 'micro avg_f1-score': 0.18556701030927836, 'micro avg_support': 110.0, 'macro avg_precision': 0.21428571428571427, 'macro avg_recall': 0.16363636363636364, 'macro avg_f1-score': 0.18556701030927836, 'macro avg_support': 110.0, 'weighted avg_precision': 0.21428571428571427, 'weighted avg_recall': 0.16363636363636364, 'weighted avg_f1-score': 0.18556701030927836, 'weighted avg_support': 110.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 2008, 'epoch': 3}, {'micro_f1': 0.8655413271245634, 'precision': 0.8655413271245634, 'False_Dilemma-No_Choice_precision': 0.2619047619047619, 'False_Dilemma-No_Choice_recall': 0.23655913978494625, 'False_Dilemma-No_Choice_f1-score': 0.24858757062146894, 'False_Dilemma-No_Choice_support': 93.0, 'micro avg_precision': 0.2619047619047619, 'micro avg_recall': 0.23655913978494625, 'micro avg_f1-score': 0.24858757062146894, 'micro avg_support': 93.0, 'macro avg_precision': 0.2619047619047619, 'macro avg_recall': 0.23655913978494625, 'macro avg_f1-score': 0.24858757062146894, 'macro avg_support': 93.0, 'weighted avg_precision': 0.2619047619047619, 'weighted avg_recall': 0.23655913978494625, 'weighted avg_f1-score': 0.24858757062146894, 'weighted avg_support': 93.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 2008, 'epoch': 4}]}
Best model updated: current epoch macro f1 = 0.24858757062146894
{'micro_f1': 0.8105355064027938, 'precision': 0.8105355064027939, 'False_Dilemma-No_Choice_precision': 0.40476190476190477, 'False_Dilemma-No_Choice_recall': 0.29310344827586204, 'False_Dilemma-No_Choice_f1-score': 0.34, 'False_Dilemma-No_Choice_support': 116.0, 'micro avg_precision': 0.40476190476190477, 'micro avg_recall': 0.29310344827586204, 'micro avg_f1-score': 0.34, 'micro avg_support': 116.0, 'macro avg_precision': 0.40476190476190477, 'macro avg_recall': 0.29310344827586204, 'macro avg_f1-score': 0.34, 'macro avg_support': 116.0, 'weighted avg_precision': 0.40476190476190477, 'weighted avg_recall': 0.29310344827586204, 'weighted avg_f1-score': 0.34, 'weighted avg_support': 116.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 2008, 'epoch': 5}
{'results': [{'micro_f1': 0.749708963911525, 'precision': 0.7497089639115251, 'False_Dilemma-No_Choice_precision': 0.0, 'False_Dilemma-No_Choice_recall': 0.0, 'False_Dilemma-No_Choice_f1-score': 0.0, 'False_Dilemma-No_Choice_support': 110.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 110.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 110.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 110.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 2008, 'epoch': 0}, {'micro_f1': 0.8306169965075669, 'precision': 0.8306169965075669, 'False_Dilemma-No_Choice_precision': 0.11904761904761904, 'False_Dilemma-No_Choice_recall': 0.0847457627118644, 'False_Dilemma-No_Choice_f1-score': 0.09900990099009901, 'False_Dilemma-No_Choice_support': 118.0, 'micro avg_precision': 0.11904761904761904, 'micro avg_recall': 0.0847457627118644, 'micro avg_f1-score': 0.09900990099009901, 'micro avg_support': 118.0, 'macro avg_precision': 0.11904761904761904, 'macro avg_recall': 0.0847457627118644, 'macro avg_f1-score': 0.09900990099009901, 'macro avg_support': 118.0, 'weighted avg_precision': 0.11904761904761904, 'weighted avg_recall': 0.0847457627118644, 'weighted avg_f1-score': 0.099009900990099, 'weighted avg_support': 118.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 2008, 'epoch': 1}, {'micro_f1': 0.8320721769499417, 'precision': 0.8320721769499418, 'False_Dilemma-No_Choice_precision': 0.16666666666666666, 'False_Dilemma-No_Choice_recall': 0.13592233009708737, 'False_Dilemma-No_Choice_f1-score': 0.1497326203208556, 'False_Dilemma-No_Choice_support': 103.0, 'micro avg_precision': 0.16666666666666666, 'micro avg_recall': 0.13592233009708737, 'micro avg_f1-score': 0.1497326203208556, 'micro avg_support': 103.0, 'macro avg_precision': 0.16666666666666666, 'macro avg_recall': 0.13592233009708737, 'macro avg_f1-score': 0.1497326203208556, 'macro avg_support': 103.0, 'weighted avg_precision': 0.16666666666666666, 'weighted avg_recall': 0.13592233009708737, 'weighted avg_f1-score': 0.1497326203208556, 'weighted avg_support': 103.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 2008, 'epoch': 2}, {'micro_f1': 0.8533178114086146, 'precision': 0.8533178114086146, 'False_Dilemma-No_Choice_precision': 0.21428571428571427, 'False_Dilemma-No_Choice_recall': 0.16363636363636364, 'False_Dilemma-No_Choice_f1-score': 0.18556701030927836, 'False_Dilemma-No_Choice_support': 110.0, 'micro avg_precision': 0.21428571428571427, 'micro avg_recall': 0.16363636363636364, 'micro avg_f1-score': 0.18556701030927836, 'micro avg_support': 110.0, 'macro avg_precision': 0.21428571428571427, 'macro avg_recall': 0.16363636363636364, 'macro avg_f1-score': 0.18556701030927836, 'macro avg_support': 110.0, 'weighted avg_precision': 0.21428571428571427, 'weighted avg_recall': 0.16363636363636364, 'weighted avg_f1-score': 0.18556701030927836, 'weighted avg_support': 110.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 2008, 'epoch': 3}, {'micro_f1': 0.8655413271245634, 'precision': 0.8655413271245634, 'False_Dilemma-No_Choice_precision': 0.2619047619047619, 'False_Dilemma-No_Choice_recall': 0.23655913978494625, 'False_Dilemma-No_Choice_f1-score': 0.24858757062146894, 'False_Dilemma-No_Choice_support': 93.0, 'micro avg_precision': 0.2619047619047619, 'micro avg_recall': 0.23655913978494625, 'micro avg_f1-score': 0.24858757062146894, 'micro avg_support': 93.0, 'macro avg_precision': 0.2619047619047619, 'macro avg_recall': 0.23655913978494625, 'macro avg_f1-score': 0.24858757062146894, 'macro avg_support': 93.0, 'weighted avg_precision': 0.2619047619047619, 'weighted avg_recall': 0.23655913978494625, 'weighted avg_f1-score': 0.24858757062146894, 'weighted avg_support': 93.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 2008, 'epoch': 4}, {'micro_f1': 0.8105355064027938, 'precision': 0.8105355064027939, 'False_Dilemma-No_Choice_precision': 0.40476190476190477, 'False_Dilemma-No_Choice_recall': 0.29310344827586204, 'False_Dilemma-No_Choice_f1-score': 0.34, 'False_Dilemma-No_Choice_support': 116.0, 'micro avg_precision': 0.40476190476190477, 'micro avg_recall': 0.29310344827586204, 'micro avg_f1-score': 0.34, 'micro avg_support': 116.0, 'macro avg_precision': 0.40476190476190477, 'macro avg_recall': 0.29310344827586204, 'macro avg_f1-score': 0.34, 'macro avg_support': 116.0, 'weighted avg_precision': 0.40476190476190477, 'weighted avg_recall': 0.29310344827586204, 'weighted avg_f1-score': 0.34, 'weighted avg_support': 116.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 2008, 'epoch': 5}]}
Best model updated: current epoch macro f1 = 0.34
{'micro_f1': 0.8311990686845169, 'precision': 0.8311990686845169, 'False_Dilemma-No_Choice_precision': 0.25, 'False_Dilemma-No_Choice_recall': 0.25301204819277107, 'False_Dilemma-No_Choice_f1-score': 0.25149700598802394, 'False_Dilemma-No_Choice_support': 83.0, 'micro avg_precision': 0.25, 'micro avg_recall': 0.25301204819277107, 'micro avg_f1-score': 0.25149700598802394, 'micro avg_support': 83.0, 'macro avg_precision': 0.25, 'macro avg_recall': 0.25301204819277107, 'macro avg_f1-score': 0.25149700598802394, 'macro avg_support': 83.0, 'weighted avg_precision': 0.25, 'weighted avg_recall': 0.25301204819277107, 'weighted avg_f1-score': 0.25149700598802394, 'weighted avg_support': 83.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 2008, 'epoch': 6}
{'results': [{'micro_f1': 0.749708963911525, 'precision': 0.7497089639115251, 'False_Dilemma-No_Choice_precision': 0.0, 'False_Dilemma-No_Choice_recall': 0.0, 'False_Dilemma-No_Choice_f1-score': 0.0, 'False_Dilemma-No_Choice_support': 110.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 110.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 110.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 110.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 2008, 'epoch': 0}, {'micro_f1': 0.8306169965075669, 'precision': 0.8306169965075669, 'False_Dilemma-No_Choice_precision': 0.11904761904761904, 'False_Dilemma-No_Choice_recall': 0.0847457627118644, 'False_Dilemma-No_Choice_f1-score': 0.09900990099009901, 'False_Dilemma-No_Choice_support': 118.0, 'micro avg_precision': 0.11904761904761904, 'micro avg_recall': 0.0847457627118644, 'micro avg_f1-score': 0.09900990099009901, 'micro avg_support': 118.0, 'macro avg_precision': 0.11904761904761904, 'macro avg_recall': 0.0847457627118644, 'macro avg_f1-score': 0.09900990099009901, 'macro avg_support': 118.0, 'weighted avg_precision': 0.11904761904761904, 'weighted avg_recall': 0.0847457627118644, 'weighted avg_f1-score': 0.099009900990099, 'weighted avg_support': 118.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 2008, 'epoch': 1}, {'micro_f1': 0.8320721769499417, 'precision': 0.8320721769499418, 'False_Dilemma-No_Choice_precision': 0.16666666666666666, 'False_Dilemma-No_Choice_recall': 0.13592233009708737, 'False_Dilemma-No_Choice_f1-score': 0.1497326203208556, 'False_Dilemma-No_Choice_support': 103.0, 'micro avg_precision': 0.16666666666666666, 'micro avg_recall': 0.13592233009708737, 'micro avg_f1-score': 0.1497326203208556, 'micro avg_support': 103.0, 'macro avg_precision': 0.16666666666666666, 'macro avg_recall': 0.13592233009708737, 'macro avg_f1-score': 0.1497326203208556, 'macro avg_support': 103.0, 'weighted avg_precision': 0.16666666666666666, 'weighted avg_recall': 0.13592233009708737, 'weighted avg_f1-score': 0.1497326203208556, 'weighted avg_support': 103.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 2008, 'epoch': 2}, {'micro_f1': 0.8533178114086146, 'precision': 0.8533178114086146, 'False_Dilemma-No_Choice_precision': 0.21428571428571427, 'False_Dilemma-No_Choice_recall': 0.16363636363636364, 'False_Dilemma-No_Choice_f1-score': 0.18556701030927836, 'False_Dilemma-No_Choice_support': 110.0, 'micro avg_precision': 0.21428571428571427, 'micro avg_recall': 0.16363636363636364, 'micro avg_f1-score': 0.18556701030927836, 'micro avg_support': 110.0, 'macro avg_precision': 0.21428571428571427, 'macro avg_recall': 0.16363636363636364, 'macro avg_f1-score': 0.18556701030927836, 'macro avg_support': 110.0, 'weighted avg_precision': 0.21428571428571427, 'weighted avg_recall': 0.16363636363636364, 'weighted avg_f1-score': 0.18556701030927836, 'weighted avg_support': 110.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 2008, 'epoch': 3}, {'micro_f1': 0.8655413271245634, 'precision': 0.8655413271245634, 'False_Dilemma-No_Choice_precision': 0.2619047619047619, 'False_Dilemma-No_Choice_recall': 0.23655913978494625, 'False_Dilemma-No_Choice_f1-score': 0.24858757062146894, 'False_Dilemma-No_Choice_support': 93.0, 'micro avg_precision': 0.2619047619047619, 'micro avg_recall': 0.23655913978494625, 'micro avg_f1-score': 0.24858757062146894, 'micro avg_support': 93.0, 'macro avg_precision': 0.2619047619047619, 'macro avg_recall': 0.23655913978494625, 'macro avg_f1-score': 0.24858757062146894, 'macro avg_support': 93.0, 'weighted avg_precision': 0.2619047619047619, 'weighted avg_recall': 0.23655913978494625, 'weighted avg_f1-score': 0.24858757062146894, 'weighted avg_support': 93.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 2008, 'epoch': 4}, {'micro_f1': 0.8105355064027938, 'precision': 0.8105355064027939, 'False_Dilemma-No_Choice_precision': 0.40476190476190477, 'False_Dilemma-No_Choice_recall': 0.29310344827586204, 'False_Dilemma-No_Choice_f1-score': 0.34, 'False_Dilemma-No_Choice_support': 116.0, 'micro avg_precision': 0.40476190476190477, 'micro avg_recall': 0.29310344827586204, 'micro avg_f1-score': 0.34, 'micro avg_support': 116.0, 'macro avg_precision': 0.40476190476190477, 'macro avg_recall': 0.29310344827586204, 'macro avg_f1-score': 0.34, 'macro avg_support': 116.0, 'weighted avg_precision': 0.40476190476190477, 'weighted avg_recall': 0.29310344827586204, 'weighted avg_f1-score': 0.34, 'weighted avg_support': 116.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 2008, 'epoch': 5}, {'micro_f1': 0.8311990686845169, 'precision': 0.8311990686845169, 'False_Dilemma-No_Choice_precision': 0.25, 'False_Dilemma-No_Choice_recall': 0.25301204819277107, 'False_Dilemma-No_Choice_f1-score': 0.25149700598802394, 'False_Dilemma-No_Choice_support': 83.0, 'micro avg_precision': 0.25, 'micro avg_recall': 0.25301204819277107, 'micro avg_f1-score': 0.25149700598802394, 'micro avg_support': 83.0, 'macro avg_precision': 0.25, 'macro avg_recall': 0.25301204819277107, 'macro avg_f1-score': 0.25149700598802394, 'macro avg_support': 83.0, 'weighted avg_precision': 0.25, 'weighted avg_recall': 0.25301204819277107, 'weighted avg_f1-score': 0.25149700598802394, 'weighted avg_support': 83.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 2008, 'epoch': 6}]}
{'micro_f1': 0.8571012805587893, 'precision': 0.8571012805587893, 'False_Dilemma-No_Choice_precision': 0.35714285714285715, 'False_Dilemma-No_Choice_recall': 0.3225806451612903, 'False_Dilemma-No_Choice_f1-score': 0.3389830508474576, 'False_Dilemma-No_Choice_support': 93.0, 'micro avg_precision': 0.35714285714285715, 'micro avg_recall': 0.3225806451612903, 'micro avg_f1-score': 0.3389830508474576, 'micro avg_support': 93.0, 'macro avg_precision': 0.35714285714285715, 'macro avg_recall': 0.3225806451612903, 'macro avg_f1-score': 0.3389830508474576, 'macro avg_support': 93.0, 'weighted avg_precision': 0.35714285714285715, 'weighted avg_recall': 0.3225806451612903, 'weighted avg_f1-score': 0.3389830508474576, 'weighted avg_support': 93.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 2008, 'epoch': 7}
{'results': [{'micro_f1': 0.749708963911525, 'precision': 0.7497089639115251, 'False_Dilemma-No_Choice_precision': 0.0, 'False_Dilemma-No_Choice_recall': 0.0, 'False_Dilemma-No_Choice_f1-score': 0.0, 'False_Dilemma-No_Choice_support': 110.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 110.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 110.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 110.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 2008, 'epoch': 0}, {'micro_f1': 0.8306169965075669, 'precision': 0.8306169965075669, 'False_Dilemma-No_Choice_precision': 0.11904761904761904, 'False_Dilemma-No_Choice_recall': 0.0847457627118644, 'False_Dilemma-No_Choice_f1-score': 0.09900990099009901, 'False_Dilemma-No_Choice_support': 118.0, 'micro avg_precision': 0.11904761904761904, 'micro avg_recall': 0.0847457627118644, 'micro avg_f1-score': 0.09900990099009901, 'micro avg_support': 118.0, 'macro avg_precision': 0.11904761904761904, 'macro avg_recall': 0.0847457627118644, 'macro avg_f1-score': 0.09900990099009901, 'macro avg_support': 118.0, 'weighted avg_precision': 0.11904761904761904, 'weighted avg_recall': 0.0847457627118644, 'weighted avg_f1-score': 0.099009900990099, 'weighted avg_support': 118.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 2008, 'epoch': 1}, {'micro_f1': 0.8320721769499417, 'precision': 0.8320721769499418, 'False_Dilemma-No_Choice_precision': 0.16666666666666666, 'False_Dilemma-No_Choice_recall': 0.13592233009708737, 'False_Dilemma-No_Choice_f1-score': 0.1497326203208556, 'False_Dilemma-No_Choice_support': 103.0, 'micro avg_precision': 0.16666666666666666, 'micro avg_recall': 0.13592233009708737, 'micro avg_f1-score': 0.1497326203208556, 'micro avg_support': 103.0, 'macro avg_precision': 0.16666666666666666, 'macro avg_recall': 0.13592233009708737, 'macro avg_f1-score': 0.1497326203208556, 'macro avg_support': 103.0, 'weighted avg_precision': 0.16666666666666666, 'weighted avg_recall': 0.13592233009708737, 'weighted avg_f1-score': 0.1497326203208556, 'weighted avg_support': 103.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 2008, 'epoch': 2}, {'micro_f1': 0.8533178114086146, 'precision': 0.8533178114086146, 'False_Dilemma-No_Choice_precision': 0.21428571428571427, 'False_Dilemma-No_Choice_recall': 0.16363636363636364, 'False_Dilemma-No_Choice_f1-score': 0.18556701030927836, 'False_Dilemma-No_Choice_support': 110.0, 'micro avg_precision': 0.21428571428571427, 'micro avg_recall': 0.16363636363636364, 'micro avg_f1-score': 0.18556701030927836, 'micro avg_support': 110.0, 'macro avg_precision': 0.21428571428571427, 'macro avg_recall': 0.16363636363636364, 'macro avg_f1-score': 0.18556701030927836, 'macro avg_support': 110.0, 'weighted avg_precision': 0.21428571428571427, 'weighted avg_recall': 0.16363636363636364, 'weighted avg_f1-score': 0.18556701030927836, 'weighted avg_support': 110.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 2008, 'epoch': 3}, {'micro_f1': 0.8655413271245634, 'precision': 0.8655413271245634, 'False_Dilemma-No_Choice_precision': 0.2619047619047619, 'False_Dilemma-No_Choice_recall': 0.23655913978494625, 'False_Dilemma-No_Choice_f1-score': 0.24858757062146894, 'False_Dilemma-No_Choice_support': 93.0, 'micro avg_precision': 0.2619047619047619, 'micro avg_recall': 0.23655913978494625, 'micro avg_f1-score': 0.24858757062146894, 'micro avg_support': 93.0, 'macro avg_precision': 0.2619047619047619, 'macro avg_recall': 0.23655913978494625, 'macro avg_f1-score': 0.24858757062146894, 'macro avg_support': 93.0, 'weighted avg_precision': 0.2619047619047619, 'weighted avg_recall': 0.23655913978494625, 'weighted avg_f1-score': 0.24858757062146894, 'weighted avg_support': 93.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 2008, 'epoch': 4}, {'micro_f1': 0.8105355064027938, 'precision': 0.8105355064027939, 'False_Dilemma-No_Choice_precision': 0.40476190476190477, 'False_Dilemma-No_Choice_recall': 0.29310344827586204, 'False_Dilemma-No_Choice_f1-score': 0.34, 'False_Dilemma-No_Choice_support': 116.0, 'micro avg_precision': 0.40476190476190477, 'micro avg_recall': 0.29310344827586204, 'micro avg_f1-score': 0.34, 'micro avg_support': 116.0, 'macro avg_precision': 0.40476190476190477, 'macro avg_recall': 0.29310344827586204, 'macro avg_f1-score': 0.34, 'macro avg_support': 116.0, 'weighted avg_precision': 0.40476190476190477, 'weighted avg_recall': 0.29310344827586204, 'weighted avg_f1-score': 0.34, 'weighted avg_support': 116.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 2008, 'epoch': 5}, {'micro_f1': 0.8311990686845169, 'precision': 0.8311990686845169, 'False_Dilemma-No_Choice_precision': 0.25, 'False_Dilemma-No_Choice_recall': 0.25301204819277107, 'False_Dilemma-No_Choice_f1-score': 0.25149700598802394, 'False_Dilemma-No_Choice_support': 83.0, 'micro avg_precision': 0.25, 'micro avg_recall': 0.25301204819277107, 'micro avg_f1-score': 0.25149700598802394, 'micro avg_support': 83.0, 'macro avg_precision': 0.25, 'macro avg_recall': 0.25301204819277107, 'macro avg_f1-score': 0.25149700598802394, 'macro avg_support': 83.0, 'weighted avg_precision': 0.25, 'weighted avg_recall': 0.25301204819277107, 'weighted avg_f1-score': 0.25149700598802394, 'weighted avg_support': 83.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 2008, 'epoch': 6}, {'micro_f1': 0.8571012805587893, 'precision': 0.8571012805587893, 'False_Dilemma-No_Choice_precision': 0.35714285714285715, 'False_Dilemma-No_Choice_recall': 0.3225806451612903, 'False_Dilemma-No_Choice_f1-score': 0.3389830508474576, 'False_Dilemma-No_Choice_support': 93.0, 'micro avg_precision': 0.35714285714285715, 'micro avg_recall': 0.3225806451612903, 'micro avg_f1-score': 0.3389830508474576, 'micro avg_support': 93.0, 'macro avg_precision': 0.35714285714285715, 'macro avg_recall': 0.3225806451612903, 'macro avg_f1-score': 0.3389830508474576, 'macro avg_support': 93.0, 'weighted avg_precision': 0.35714285714285715, 'weighted avg_recall': 0.3225806451612903, 'weighted avg_f1-score': 0.3389830508474576, 'weighted avg_support': 93.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 2008, 'epoch': 7}]}
Early stopping triggered.
Saving model to directory: ./models/M2/2024-05-14-06-51-04_aug_ts0.9/mdeberta-v3-base_6_ME10_target=False_Dilemma-No_Choice_SUBSAMPLED_2024-05-14-06-51-04
Training model no. 7 of 23 for (7, 'Consequential_Oversimplification') persuasion technique...
{'micro_f1': 0.4280254777070064, 'precision': 0.4280254777070064, 'Consequential_Oversimplification_precision': 0.0, 'Consequential_Oversimplification_recall': 0.0, 'Consequential_Oversimplification_f1-score': 0.0, 'Consequential_Oversimplification_support': 3.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 3.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 3.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 3.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 0}
{'results': [{'micro_f1': 0.4280254777070064, 'precision': 0.4280254777070064, 'Consequential_Oversimplification_precision': 0.0, 'Consequential_Oversimplification_recall': 0.0, 'Consequential_Oversimplification_f1-score': 0.0, 'Consequential_Oversimplification_support': 3.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 3.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 3.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 3.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 0}]}
{'micro_f1': 0.8008492569002124, 'precision': 0.8008492569002124, 'Consequential_Oversimplification_precision': 0.0392156862745098, 'Consequential_Oversimplification_recall': 0.01904761904761905, 'Consequential_Oversimplification_f1-score': 0.025641025641025644, 'Consequential_Oversimplification_support': 105.0, 'micro avg_precision': 0.0392156862745098, 'micro avg_recall': 0.01904761904761905, 'micro avg_f1-score': 0.025641025641025644, 'micro avg_support': 105.0, 'macro avg_precision': 0.0392156862745098, 'macro avg_recall': 0.01904761904761905, 'macro avg_f1-score': 0.025641025641025644, 'macro avg_support': 105.0, 'weighted avg_precision': 0.0392156862745098, 'weighted avg_recall': 0.01904761904761905, 'weighted avg_f1-score': 0.025641025641025644, 'weighted avg_support': 105.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 1}
{'results': [{'micro_f1': 0.4280254777070064, 'precision': 0.4280254777070064, 'Consequential_Oversimplification_precision': 0.0, 'Consequential_Oversimplification_recall': 0.0, 'Consequential_Oversimplification_f1-score': 0.0, 'Consequential_Oversimplification_support': 3.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 3.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 3.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 3.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 0}, {'micro_f1': 0.8008492569002124, 'precision': 0.8008492569002124, 'Consequential_Oversimplification_precision': 0.0392156862745098, 'Consequential_Oversimplification_recall': 0.01904761904761905, 'Consequential_Oversimplification_f1-score': 0.025641025641025644, 'Consequential_Oversimplification_support': 105.0, 'micro avg_precision': 0.0392156862745098, 'micro avg_recall': 0.01904761904761905, 'micro avg_f1-score': 0.025641025641025644, 'micro avg_support': 105.0, 'macro avg_precision': 0.0392156862745098, 'macro avg_recall': 0.01904761904761905, 'macro avg_f1-score': 0.025641025641025644, 'macro avg_support': 105.0, 'weighted avg_precision': 0.0392156862745098, 'weighted avg_recall': 0.01904761904761905, 'weighted avg_f1-score': 0.025641025641025644, 'weighted avg_support': 105.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 1}]}
Best model updated: current epoch macro f1 = 0.025641025641025644
{'micro_f1': 0.7766454352441614, 'precision': 0.7766454352441614, 'Consequential_Oversimplification_precision': 0.0784313725490196, 'Consequential_Oversimplification_recall': 0.03278688524590164, 'Consequential_Oversimplification_f1-score': 0.046242774566473986, 'Consequential_Oversimplification_support': 122.0, 'micro avg_precision': 0.0784313725490196, 'micro avg_recall': 0.03278688524590164, 'micro avg_f1-score': 0.046242774566473986, 'micro avg_support': 122.0, 'macro avg_precision': 0.0784313725490196, 'macro avg_recall': 0.03278688524590164, 'macro avg_f1-score': 0.046242774566473986, 'macro avg_support': 122.0, 'weighted avg_precision': 0.0784313725490196, 'weighted avg_recall': 0.03278688524590164, 'weighted avg_f1-score': 0.046242774566473986, 'weighted avg_support': 122.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 2}
{'results': [{'micro_f1': 0.4280254777070064, 'precision': 0.4280254777070064, 'Consequential_Oversimplification_precision': 0.0, 'Consequential_Oversimplification_recall': 0.0, 'Consequential_Oversimplification_f1-score': 0.0, 'Consequential_Oversimplification_support': 3.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 3.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 3.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 3.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 0}, {'micro_f1': 0.8008492569002124, 'precision': 0.8008492569002124, 'Consequential_Oversimplification_precision': 0.0392156862745098, 'Consequential_Oversimplification_recall': 0.01904761904761905, 'Consequential_Oversimplification_f1-score': 0.025641025641025644, 'Consequential_Oversimplification_support': 105.0, 'micro avg_precision': 0.0392156862745098, 'micro avg_recall': 0.01904761904761905, 'micro avg_f1-score': 0.025641025641025644, 'micro avg_support': 105.0, 'macro avg_precision': 0.0392156862745098, 'macro avg_recall': 0.01904761904761905, 'macro avg_f1-score': 0.025641025641025644, 'macro avg_support': 105.0, 'weighted avg_precision': 0.0392156862745098, 'weighted avg_recall': 0.01904761904761905, 'weighted avg_f1-score': 0.025641025641025644, 'weighted avg_support': 105.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 1}, {'micro_f1': 0.7766454352441614, 'precision': 0.7766454352441614, 'Consequential_Oversimplification_precision': 0.0784313725490196, 'Consequential_Oversimplification_recall': 0.03278688524590164, 'Consequential_Oversimplification_f1-score': 0.046242774566473986, 'Consequential_Oversimplification_support': 122.0, 'micro avg_precision': 0.0784313725490196, 'micro avg_recall': 0.03278688524590164, 'micro avg_f1-score': 0.046242774566473986, 'micro avg_support': 122.0, 'macro avg_precision': 0.0784313725490196, 'macro avg_recall': 0.03278688524590164, 'macro avg_f1-score': 0.046242774566473986, 'macro avg_support': 122.0, 'weighted avg_precision': 0.0784313725490196, 'weighted avg_recall': 0.03278688524590164, 'weighted avg_f1-score': 0.046242774566473986, 'weighted avg_support': 122.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 2}]}
Best model updated: current epoch macro f1 = 0.046242774566473986
{'micro_f1': 0.8059447983014862, 'precision': 0.8059447983014862, 'Consequential_Oversimplification_precision': 0.11764705882352941, 'Consequential_Oversimplification_recall': 0.06593406593406594, 'Consequential_Oversimplification_f1-score': 0.08450704225352113, 'Consequential_Oversimplification_support': 91.0, 'micro avg_precision': 0.11764705882352941, 'micro avg_recall': 0.06593406593406594, 'micro avg_f1-score': 0.08450704225352113, 'micro avg_support': 91.0, 'macro avg_precision': 0.11764705882352941, 'macro avg_recall': 0.06593406593406594, 'macro avg_f1-score': 0.08450704225352113, 'macro avg_support': 91.0, 'weighted avg_precision': 0.11764705882352941, 'weighted avg_recall': 0.06593406593406594, 'weighted avg_f1-score': 0.08450704225352113, 'weighted avg_support': 91.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 3}
{'results': [{'micro_f1': 0.4280254777070064, 'precision': 0.4280254777070064, 'Consequential_Oversimplification_precision': 0.0, 'Consequential_Oversimplification_recall': 0.0, 'Consequential_Oversimplification_f1-score': 0.0, 'Consequential_Oversimplification_support': 3.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 3.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 3.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 3.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 0}, {'micro_f1': 0.8008492569002124, 'precision': 0.8008492569002124, 'Consequential_Oversimplification_precision': 0.0392156862745098, 'Consequential_Oversimplification_recall': 0.01904761904761905, 'Consequential_Oversimplification_f1-score': 0.025641025641025644, 'Consequential_Oversimplification_support': 105.0, 'micro avg_precision': 0.0392156862745098, 'micro avg_recall': 0.01904761904761905, 'micro avg_f1-score': 0.025641025641025644, 'micro avg_support': 105.0, 'macro avg_precision': 0.0392156862745098, 'macro avg_recall': 0.01904761904761905, 'macro avg_f1-score': 0.025641025641025644, 'macro avg_support': 105.0, 'weighted avg_precision': 0.0392156862745098, 'weighted avg_recall': 0.01904761904761905, 'weighted avg_f1-score': 0.025641025641025644, 'weighted avg_support': 105.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 1}, {'micro_f1': 0.7766454352441614, 'precision': 0.7766454352441614, 'Consequential_Oversimplification_precision': 0.0784313725490196, 'Consequential_Oversimplification_recall': 0.03278688524590164, 'Consequential_Oversimplification_f1-score': 0.046242774566473986, 'Consequential_Oversimplification_support': 122.0, 'micro avg_precision': 0.0784313725490196, 'micro avg_recall': 0.03278688524590164, 'micro avg_f1-score': 0.046242774566473986, 'micro avg_support': 122.0, 'macro avg_precision': 0.0784313725490196, 'macro avg_recall': 0.03278688524590164, 'macro avg_f1-score': 0.046242774566473986, 'macro avg_support': 122.0, 'weighted avg_precision': 0.0784313725490196, 'weighted avg_recall': 0.03278688524590164, 'weighted avg_f1-score': 0.046242774566473986, 'weighted avg_support': 122.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 2}, {'micro_f1': 0.8059447983014862, 'precision': 0.8059447983014862, 'Consequential_Oversimplification_precision': 0.11764705882352941, 'Consequential_Oversimplification_recall': 0.06593406593406594, 'Consequential_Oversimplification_f1-score': 0.08450704225352113, 'Consequential_Oversimplification_support': 91.0, 'micro avg_precision': 0.11764705882352941, 'micro avg_recall': 0.06593406593406594, 'micro avg_f1-score': 0.08450704225352113, 'micro avg_support': 91.0, 'macro avg_precision': 0.11764705882352941, 'macro avg_recall': 0.06593406593406594, 'macro avg_f1-score': 0.08450704225352113, 'macro avg_support': 91.0, 'weighted avg_precision': 0.11764705882352941, 'weighted avg_recall': 0.06593406593406594, 'weighted avg_f1-score': 0.08450704225352113, 'weighted avg_support': 91.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 3}]}
Best model updated: current epoch macro f1 = 0.08450704225352113
{'micro_f1': 0.8012738853503185, 'precision': 0.8012738853503185, 'Consequential_Oversimplification_precision': 0.13725490196078433, 'Consequential_Oversimplification_recall': 0.06930693069306931, 'Consequential_Oversimplification_f1-score': 0.09210526315789473, 'Consequential_Oversimplification_support': 101.0, 'micro avg_precision': 0.13725490196078433, 'micro avg_recall': 0.06930693069306931, 'micro avg_f1-score': 0.09210526315789473, 'micro avg_support': 101.0, 'macro avg_precision': 0.13725490196078433, 'macro avg_recall': 0.06930693069306931, 'macro avg_f1-score': 0.09210526315789473, 'macro avg_support': 101.0, 'weighted avg_precision': 0.13725490196078433, 'weighted avg_recall': 0.06930693069306931, 'weighted avg_f1-score': 0.09210526315789473, 'weighted avg_support': 101.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 4}
{'results': [{'micro_f1': 0.4280254777070064, 'precision': 0.4280254777070064, 'Consequential_Oversimplification_precision': 0.0, 'Consequential_Oversimplification_recall': 0.0, 'Consequential_Oversimplification_f1-score': 0.0, 'Consequential_Oversimplification_support': 3.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 3.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 3.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 3.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 0}, {'micro_f1': 0.8008492569002124, 'precision': 0.8008492569002124, 'Consequential_Oversimplification_precision': 0.0392156862745098, 'Consequential_Oversimplification_recall': 0.01904761904761905, 'Consequential_Oversimplification_f1-score': 0.025641025641025644, 'Consequential_Oversimplification_support': 105.0, 'micro avg_precision': 0.0392156862745098, 'micro avg_recall': 0.01904761904761905, 'micro avg_f1-score': 0.025641025641025644, 'micro avg_support': 105.0, 'macro avg_precision': 0.0392156862745098, 'macro avg_recall': 0.01904761904761905, 'macro avg_f1-score': 0.025641025641025644, 'macro avg_support': 105.0, 'weighted avg_precision': 0.0392156862745098, 'weighted avg_recall': 0.01904761904761905, 'weighted avg_f1-score': 0.025641025641025644, 'weighted avg_support': 105.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 1}, {'micro_f1': 0.7766454352441614, 'precision': 0.7766454352441614, 'Consequential_Oversimplification_precision': 0.0784313725490196, 'Consequential_Oversimplification_recall': 0.03278688524590164, 'Consequential_Oversimplification_f1-score': 0.046242774566473986, 'Consequential_Oversimplification_support': 122.0, 'micro avg_precision': 0.0784313725490196, 'micro avg_recall': 0.03278688524590164, 'micro avg_f1-score': 0.046242774566473986, 'micro avg_support': 122.0, 'macro avg_precision': 0.0784313725490196, 'macro avg_recall': 0.03278688524590164, 'macro avg_f1-score': 0.046242774566473986, 'macro avg_support': 122.0, 'weighted avg_precision': 0.0784313725490196, 'weighted avg_recall': 0.03278688524590164, 'weighted avg_f1-score': 0.046242774566473986, 'weighted avg_support': 122.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 2}, {'micro_f1': 0.8059447983014862, 'precision': 0.8059447983014862, 'Consequential_Oversimplification_precision': 0.11764705882352941, 'Consequential_Oversimplification_recall': 0.06593406593406594, 'Consequential_Oversimplification_f1-score': 0.08450704225352113, 'Consequential_Oversimplification_support': 91.0, 'micro avg_precision': 0.11764705882352941, 'micro avg_recall': 0.06593406593406594, 'micro avg_f1-score': 0.08450704225352113, 'micro avg_support': 91.0, 'macro avg_precision': 0.11764705882352941, 'macro avg_recall': 0.06593406593406594, 'macro avg_f1-score': 0.08450704225352113, 'macro avg_support': 91.0, 'weighted avg_precision': 0.11764705882352941, 'weighted avg_recall': 0.06593406593406594, 'weighted avg_f1-score': 0.08450704225352113, 'weighted avg_support': 91.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 3}, {'micro_f1': 0.8012738853503185, 'precision': 0.8012738853503185, 'Consequential_Oversimplification_precision': 0.13725490196078433, 'Consequential_Oversimplification_recall': 0.06930693069306931, 'Consequential_Oversimplification_f1-score': 0.09210526315789473, 'Consequential_Oversimplification_support': 101.0, 'micro avg_precision': 0.13725490196078433, 'micro avg_recall': 0.06930693069306931, 'micro avg_f1-score': 0.09210526315789473, 'micro avg_support': 101.0, 'macro avg_precision': 0.13725490196078433, 'macro avg_recall': 0.06930693069306931, 'macro avg_f1-score': 0.09210526315789473, 'macro avg_support': 101.0, 'weighted avg_precision': 0.13725490196078433, 'weighted avg_recall': 0.06930693069306931, 'weighted avg_f1-score': 0.09210526315789473, 'weighted avg_support': 101.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 4}]}
Best model updated: current epoch macro f1 = 0.09210526315789473
{'micro_f1': 0.8182590233545648, 'precision': 0.8182590233545648, 'Consequential_Oversimplification_precision': 0.19607843137254902, 'Consequential_Oversimplification_recall': 0.11627906976744186, 'Consequential_Oversimplification_f1-score': 0.145985401459854, 'Consequential_Oversimplification_support': 86.0, 'micro avg_precision': 0.19607843137254902, 'micro avg_recall': 0.11627906976744186, 'micro avg_f1-score': 0.145985401459854, 'micro avg_support': 86.0, 'macro avg_precision': 0.19607843137254902, 'macro avg_recall': 0.11627906976744186, 'macro avg_f1-score': 0.145985401459854, 'macro avg_support': 86.0, 'weighted avg_precision': 0.19607843137254902, 'weighted avg_recall': 0.11627906976744186, 'weighted avg_f1-score': 0.145985401459854, 'weighted avg_support': 86.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 5}
{'results': [{'micro_f1': 0.4280254777070064, 'precision': 0.4280254777070064, 'Consequential_Oversimplification_precision': 0.0, 'Consequential_Oversimplification_recall': 0.0, 'Consequential_Oversimplification_f1-score': 0.0, 'Consequential_Oversimplification_support': 3.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 3.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 3.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 3.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 0}, {'micro_f1': 0.8008492569002124, 'precision': 0.8008492569002124, 'Consequential_Oversimplification_precision': 0.0392156862745098, 'Consequential_Oversimplification_recall': 0.01904761904761905, 'Consequential_Oversimplification_f1-score': 0.025641025641025644, 'Consequential_Oversimplification_support': 105.0, 'micro avg_precision': 0.0392156862745098, 'micro avg_recall': 0.01904761904761905, 'micro avg_f1-score': 0.025641025641025644, 'micro avg_support': 105.0, 'macro avg_precision': 0.0392156862745098, 'macro avg_recall': 0.01904761904761905, 'macro avg_f1-score': 0.025641025641025644, 'macro avg_support': 105.0, 'weighted avg_precision': 0.0392156862745098, 'weighted avg_recall': 0.01904761904761905, 'weighted avg_f1-score': 0.025641025641025644, 'weighted avg_support': 105.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 1}, {'micro_f1': 0.7766454352441614, 'precision': 0.7766454352441614, 'Consequential_Oversimplification_precision': 0.0784313725490196, 'Consequential_Oversimplification_recall': 0.03278688524590164, 'Consequential_Oversimplification_f1-score': 0.046242774566473986, 'Consequential_Oversimplification_support': 122.0, 'micro avg_precision': 0.0784313725490196, 'micro avg_recall': 0.03278688524590164, 'micro avg_f1-score': 0.046242774566473986, 'micro avg_support': 122.0, 'macro avg_precision': 0.0784313725490196, 'macro avg_recall': 0.03278688524590164, 'macro avg_f1-score': 0.046242774566473986, 'macro avg_support': 122.0, 'weighted avg_precision': 0.0784313725490196, 'weighted avg_recall': 0.03278688524590164, 'weighted avg_f1-score': 0.046242774566473986, 'weighted avg_support': 122.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 2}, {'micro_f1': 0.8059447983014862, 'precision': 0.8059447983014862, 'Consequential_Oversimplification_precision': 0.11764705882352941, 'Consequential_Oversimplification_recall': 0.06593406593406594, 'Consequential_Oversimplification_f1-score': 0.08450704225352113, 'Consequential_Oversimplification_support': 91.0, 'micro avg_precision': 0.11764705882352941, 'micro avg_recall': 0.06593406593406594, 'micro avg_f1-score': 0.08450704225352113, 'micro avg_support': 91.0, 'macro avg_precision': 0.11764705882352941, 'macro avg_recall': 0.06593406593406594, 'macro avg_f1-score': 0.08450704225352113, 'macro avg_support': 91.0, 'weighted avg_precision': 0.11764705882352941, 'weighted avg_recall': 0.06593406593406594, 'weighted avg_f1-score': 0.08450704225352113, 'weighted avg_support': 91.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 3}, {'micro_f1': 0.8012738853503185, 'precision': 0.8012738853503185, 'Consequential_Oversimplification_precision': 0.13725490196078433, 'Consequential_Oversimplification_recall': 0.06930693069306931, 'Consequential_Oversimplification_f1-score': 0.09210526315789473, 'Consequential_Oversimplification_support': 101.0, 'micro avg_precision': 0.13725490196078433, 'micro avg_recall': 0.06930693069306931, 'micro avg_f1-score': 0.09210526315789473, 'micro avg_support': 101.0, 'macro avg_precision': 0.13725490196078433, 'macro avg_recall': 0.06930693069306931, 'macro avg_f1-score': 0.09210526315789473, 'macro avg_support': 101.0, 'weighted avg_precision': 0.13725490196078433, 'weighted avg_recall': 0.06930693069306931, 'weighted avg_f1-score': 0.09210526315789473, 'weighted avg_support': 101.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 4}, {'micro_f1': 0.8182590233545648, 'precision': 0.8182590233545648, 'Consequential_Oversimplification_precision': 0.19607843137254902, 'Consequential_Oversimplification_recall': 0.11627906976744186, 'Consequential_Oversimplification_f1-score': 0.145985401459854, 'Consequential_Oversimplification_support': 86.0, 'micro avg_precision': 0.19607843137254902, 'micro avg_recall': 0.11627906976744186, 'micro avg_f1-score': 0.145985401459854, 'micro avg_support': 86.0, 'macro avg_precision': 0.19607843137254902, 'macro avg_recall': 0.11627906976744186, 'macro avg_f1-score': 0.145985401459854, 'macro avg_support': 86.0, 'weighted avg_precision': 0.19607843137254902, 'weighted avg_recall': 0.11627906976744186, 'weighted avg_f1-score': 0.145985401459854, 'weighted avg_support': 86.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 5}]}
Best model updated: current epoch macro f1 = 0.145985401459854
{'micro_f1': 0.8437367303609343, 'precision': 0.8437367303609342, 'Consequential_Oversimplification_precision': 0.21568627450980393, 'Consequential_Oversimplification_recall': 0.13580246913580246, 'Consequential_Oversimplification_f1-score': 0.16666666666666666, 'Consequential_Oversimplification_support': 81.0, 'micro avg_precision': 0.21568627450980393, 'micro avg_recall': 0.13580246913580246, 'micro avg_f1-score': 0.16666666666666666, 'micro avg_support': 81.0, 'macro avg_precision': 0.21568627450980393, 'macro avg_recall': 0.13580246913580246, 'macro avg_f1-score': 0.16666666666666666, 'macro avg_support': 81.0, 'weighted avg_precision': 0.21568627450980393, 'weighted avg_recall': 0.13580246913580246, 'weighted avg_f1-score': 0.16666666666666666, 'weighted avg_support': 81.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 6}
{'results': [{'micro_f1': 0.4280254777070064, 'precision': 0.4280254777070064, 'Consequential_Oversimplification_precision': 0.0, 'Consequential_Oversimplification_recall': 0.0, 'Consequential_Oversimplification_f1-score': 0.0, 'Consequential_Oversimplification_support': 3.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 3.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 3.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 3.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 0}, {'micro_f1': 0.8008492569002124, 'precision': 0.8008492569002124, 'Consequential_Oversimplification_precision': 0.0392156862745098, 'Consequential_Oversimplification_recall': 0.01904761904761905, 'Consequential_Oversimplification_f1-score': 0.025641025641025644, 'Consequential_Oversimplification_support': 105.0, 'micro avg_precision': 0.0392156862745098, 'micro avg_recall': 0.01904761904761905, 'micro avg_f1-score': 0.025641025641025644, 'micro avg_support': 105.0, 'macro avg_precision': 0.0392156862745098, 'macro avg_recall': 0.01904761904761905, 'macro avg_f1-score': 0.025641025641025644, 'macro avg_support': 105.0, 'weighted avg_precision': 0.0392156862745098, 'weighted avg_recall': 0.01904761904761905, 'weighted avg_f1-score': 0.025641025641025644, 'weighted avg_support': 105.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 1}, {'micro_f1': 0.7766454352441614, 'precision': 0.7766454352441614, 'Consequential_Oversimplification_precision': 0.0784313725490196, 'Consequential_Oversimplification_recall': 0.03278688524590164, 'Consequential_Oversimplification_f1-score': 0.046242774566473986, 'Consequential_Oversimplification_support': 122.0, 'micro avg_precision': 0.0784313725490196, 'micro avg_recall': 0.03278688524590164, 'micro avg_f1-score': 0.046242774566473986, 'micro avg_support': 122.0, 'macro avg_precision': 0.0784313725490196, 'macro avg_recall': 0.03278688524590164, 'macro avg_f1-score': 0.046242774566473986, 'macro avg_support': 122.0, 'weighted avg_precision': 0.0784313725490196, 'weighted avg_recall': 0.03278688524590164, 'weighted avg_f1-score': 0.046242774566473986, 'weighted avg_support': 122.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 2}, {'micro_f1': 0.8059447983014862, 'precision': 0.8059447983014862, 'Consequential_Oversimplification_precision': 0.11764705882352941, 'Consequential_Oversimplification_recall': 0.06593406593406594, 'Consequential_Oversimplification_f1-score': 0.08450704225352113, 'Consequential_Oversimplification_support': 91.0, 'micro avg_precision': 0.11764705882352941, 'micro avg_recall': 0.06593406593406594, 'micro avg_f1-score': 0.08450704225352113, 'micro avg_support': 91.0, 'macro avg_precision': 0.11764705882352941, 'macro avg_recall': 0.06593406593406594, 'macro avg_f1-score': 0.08450704225352113, 'macro avg_support': 91.0, 'weighted avg_precision': 0.11764705882352941, 'weighted avg_recall': 0.06593406593406594, 'weighted avg_f1-score': 0.08450704225352113, 'weighted avg_support': 91.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 3}, {'micro_f1': 0.8012738853503185, 'precision': 0.8012738853503185, 'Consequential_Oversimplification_precision': 0.13725490196078433, 'Consequential_Oversimplification_recall': 0.06930693069306931, 'Consequential_Oversimplification_f1-score': 0.09210526315789473, 'Consequential_Oversimplification_support': 101.0, 'micro avg_precision': 0.13725490196078433, 'micro avg_recall': 0.06930693069306931, 'micro avg_f1-score': 0.09210526315789473, 'micro avg_support': 101.0, 'macro avg_precision': 0.13725490196078433, 'macro avg_recall': 0.06930693069306931, 'macro avg_f1-score': 0.09210526315789473, 'macro avg_support': 101.0, 'weighted avg_precision': 0.13725490196078433, 'weighted avg_recall': 0.06930693069306931, 'weighted avg_f1-score': 0.09210526315789473, 'weighted avg_support': 101.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 4}, {'micro_f1': 0.8182590233545648, 'precision': 0.8182590233545648, 'Consequential_Oversimplification_precision': 0.19607843137254902, 'Consequential_Oversimplification_recall': 0.11627906976744186, 'Consequential_Oversimplification_f1-score': 0.145985401459854, 'Consequential_Oversimplification_support': 86.0, 'micro avg_precision': 0.19607843137254902, 'micro avg_recall': 0.11627906976744186, 'micro avg_f1-score': 0.145985401459854, 'micro avg_support': 86.0, 'macro avg_precision': 0.19607843137254902, 'macro avg_recall': 0.11627906976744186, 'macro avg_f1-score': 0.145985401459854, 'macro avg_support': 86.0, 'weighted avg_precision': 0.19607843137254902, 'weighted avg_recall': 0.11627906976744186, 'weighted avg_f1-score': 0.145985401459854, 'weighted avg_support': 86.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 5}, {'micro_f1': 0.8437367303609343, 'precision': 0.8437367303609342, 'Consequential_Oversimplification_precision': 0.21568627450980393, 'Consequential_Oversimplification_recall': 0.13580246913580246, 'Consequential_Oversimplification_f1-score': 0.16666666666666666, 'Consequential_Oversimplification_support': 81.0, 'micro avg_precision': 0.21568627450980393, 'micro avg_recall': 0.13580246913580246, 'micro avg_f1-score': 0.16666666666666666, 'micro avg_support': 81.0, 'macro avg_precision': 0.21568627450980393, 'macro avg_recall': 0.13580246913580246, 'macro avg_f1-score': 0.16666666666666666, 'macro avg_support': 81.0, 'weighted avg_precision': 0.21568627450980393, 'weighted avg_recall': 0.13580246913580246, 'weighted avg_f1-score': 0.16666666666666666, 'weighted avg_support': 81.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 6}]}
Best model updated: current epoch macro f1 = 0.16666666666666666
{'micro_f1': 0.8144373673036094, 'precision': 0.8144373673036094, 'Consequential_Oversimplification_precision': 0.19607843137254902, 'Consequential_Oversimplification_recall': 0.12048192771084337, 'Consequential_Oversimplification_f1-score': 0.14925373134328357, 'Consequential_Oversimplification_support': 83.0, 'micro avg_precision': 0.19607843137254902, 'micro avg_recall': 0.12048192771084337, 'micro avg_f1-score': 0.14925373134328357, 'micro avg_support': 83.0, 'macro avg_precision': 0.19607843137254902, 'macro avg_recall': 0.12048192771084337, 'macro avg_f1-score': 0.14925373134328357, 'macro avg_support': 83.0, 'weighted avg_precision': 0.19607843137254902, 'weighted avg_recall': 0.12048192771084337, 'weighted avg_f1-score': 0.14925373134328357, 'weighted avg_support': 83.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 7}
{'results': [{'micro_f1': 0.4280254777070064, 'precision': 0.4280254777070064, 'Consequential_Oversimplification_precision': 0.0, 'Consequential_Oversimplification_recall': 0.0, 'Consequential_Oversimplification_f1-score': 0.0, 'Consequential_Oversimplification_support': 3.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 3.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 3.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 3.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 0}, {'micro_f1': 0.8008492569002124, 'precision': 0.8008492569002124, 'Consequential_Oversimplification_precision': 0.0392156862745098, 'Consequential_Oversimplification_recall': 0.01904761904761905, 'Consequential_Oversimplification_f1-score': 0.025641025641025644, 'Consequential_Oversimplification_support': 105.0, 'micro avg_precision': 0.0392156862745098, 'micro avg_recall': 0.01904761904761905, 'micro avg_f1-score': 0.025641025641025644, 'micro avg_support': 105.0, 'macro avg_precision': 0.0392156862745098, 'macro avg_recall': 0.01904761904761905, 'macro avg_f1-score': 0.025641025641025644, 'macro avg_support': 105.0, 'weighted avg_precision': 0.0392156862745098, 'weighted avg_recall': 0.01904761904761905, 'weighted avg_f1-score': 0.025641025641025644, 'weighted avg_support': 105.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 1}, {'micro_f1': 0.7766454352441614, 'precision': 0.7766454352441614, 'Consequential_Oversimplification_precision': 0.0784313725490196, 'Consequential_Oversimplification_recall': 0.03278688524590164, 'Consequential_Oversimplification_f1-score': 0.046242774566473986, 'Consequential_Oversimplification_support': 122.0, 'micro avg_precision': 0.0784313725490196, 'micro avg_recall': 0.03278688524590164, 'micro avg_f1-score': 0.046242774566473986, 'micro avg_support': 122.0, 'macro avg_precision': 0.0784313725490196, 'macro avg_recall': 0.03278688524590164, 'macro avg_f1-score': 0.046242774566473986, 'macro avg_support': 122.0, 'weighted avg_precision': 0.0784313725490196, 'weighted avg_recall': 0.03278688524590164, 'weighted avg_f1-score': 0.046242774566473986, 'weighted avg_support': 122.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 2}, {'micro_f1': 0.8059447983014862, 'precision': 0.8059447983014862, 'Consequential_Oversimplification_precision': 0.11764705882352941, 'Consequential_Oversimplification_recall': 0.06593406593406594, 'Consequential_Oversimplification_f1-score': 0.08450704225352113, 'Consequential_Oversimplification_support': 91.0, 'micro avg_precision': 0.11764705882352941, 'micro avg_recall': 0.06593406593406594, 'micro avg_f1-score': 0.08450704225352113, 'micro avg_support': 91.0, 'macro avg_precision': 0.11764705882352941, 'macro avg_recall': 0.06593406593406594, 'macro avg_f1-score': 0.08450704225352113, 'macro avg_support': 91.0, 'weighted avg_precision': 0.11764705882352941, 'weighted avg_recall': 0.06593406593406594, 'weighted avg_f1-score': 0.08450704225352113, 'weighted avg_support': 91.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 3}, {'micro_f1': 0.8012738853503185, 'precision': 0.8012738853503185, 'Consequential_Oversimplification_precision': 0.13725490196078433, 'Consequential_Oversimplification_recall': 0.06930693069306931, 'Consequential_Oversimplification_f1-score': 0.09210526315789473, 'Consequential_Oversimplification_support': 101.0, 'micro avg_precision': 0.13725490196078433, 'micro avg_recall': 0.06930693069306931, 'micro avg_f1-score': 0.09210526315789473, 'micro avg_support': 101.0, 'macro avg_precision': 0.13725490196078433, 'macro avg_recall': 0.06930693069306931, 'macro avg_f1-score': 0.09210526315789473, 'macro avg_support': 101.0, 'weighted avg_precision': 0.13725490196078433, 'weighted avg_recall': 0.06930693069306931, 'weighted avg_f1-score': 0.09210526315789473, 'weighted avg_support': 101.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 4}, {'micro_f1': 0.8182590233545648, 'precision': 0.8182590233545648, 'Consequential_Oversimplification_precision': 0.19607843137254902, 'Consequential_Oversimplification_recall': 0.11627906976744186, 'Consequential_Oversimplification_f1-score': 0.145985401459854, 'Consequential_Oversimplification_support': 86.0, 'micro avg_precision': 0.19607843137254902, 'micro avg_recall': 0.11627906976744186, 'micro avg_f1-score': 0.145985401459854, 'micro avg_support': 86.0, 'macro avg_precision': 0.19607843137254902, 'macro avg_recall': 0.11627906976744186, 'macro avg_f1-score': 0.145985401459854, 'macro avg_support': 86.0, 'weighted avg_precision': 0.19607843137254902, 'weighted avg_recall': 0.11627906976744186, 'weighted avg_f1-score': 0.145985401459854, 'weighted avg_support': 86.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 5}, {'micro_f1': 0.8437367303609343, 'precision': 0.8437367303609342, 'Consequential_Oversimplification_precision': 0.21568627450980393, 'Consequential_Oversimplification_recall': 0.13580246913580246, 'Consequential_Oversimplification_f1-score': 0.16666666666666666, 'Consequential_Oversimplification_support': 81.0, 'micro avg_precision': 0.21568627450980393, 'micro avg_recall': 0.13580246913580246, 'micro avg_f1-score': 0.16666666666666666, 'micro avg_support': 81.0, 'macro avg_precision': 0.21568627450980393, 'macro avg_recall': 0.13580246913580246, 'macro avg_f1-score': 0.16666666666666666, 'macro avg_support': 81.0, 'weighted avg_precision': 0.21568627450980393, 'weighted avg_recall': 0.13580246913580246, 'weighted avg_f1-score': 0.16666666666666666, 'weighted avg_support': 81.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 6}, {'micro_f1': 0.8144373673036094, 'precision': 0.8144373673036094, 'Consequential_Oversimplification_precision': 0.19607843137254902, 'Consequential_Oversimplification_recall': 0.12048192771084337, 'Consequential_Oversimplification_f1-score': 0.14925373134328357, 'Consequential_Oversimplification_support': 83.0, 'micro avg_precision': 0.19607843137254902, 'micro avg_recall': 0.12048192771084337, 'micro avg_f1-score': 0.14925373134328357, 'micro avg_support': 83.0, 'macro avg_precision': 0.19607843137254902, 'macro avg_recall': 0.12048192771084337, 'macro avg_f1-score': 0.14925373134328357, 'macro avg_support': 83.0, 'weighted avg_precision': 0.19607843137254902, 'weighted avg_recall': 0.12048192771084337, 'weighted avg_f1-score': 0.14925373134328357, 'weighted avg_support': 83.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 7}]}
{'micro_f1': 0.837791932059448, 'precision': 0.837791932059448, 'Consequential_Oversimplification_precision': 0.29411764705882354, 'Consequential_Oversimplification_recall': 0.17857142857142858, 'Consequential_Oversimplification_f1-score': 0.22222222222222224, 'Consequential_Oversimplification_support': 84.0, 'micro avg_precision': 0.29411764705882354, 'micro avg_recall': 0.17857142857142858, 'micro avg_f1-score': 0.22222222222222224, 'micro avg_support': 84.0, 'macro avg_precision': 0.29411764705882354, 'macro avg_recall': 0.17857142857142858, 'macro avg_f1-score': 0.22222222222222224, 'macro avg_support': 84.0, 'weighted avg_precision': 0.29411764705882354, 'weighted avg_recall': 0.17857142857142858, 'weighted avg_f1-score': 0.22222222222222224, 'weighted avg_support': 84.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 8}
{'results': [{'micro_f1': 0.4280254777070064, 'precision': 0.4280254777070064, 'Consequential_Oversimplification_precision': 0.0, 'Consequential_Oversimplification_recall': 0.0, 'Consequential_Oversimplification_f1-score': 0.0, 'Consequential_Oversimplification_support': 3.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 3.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 3.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 3.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 0}, {'micro_f1': 0.8008492569002124, 'precision': 0.8008492569002124, 'Consequential_Oversimplification_precision': 0.0392156862745098, 'Consequential_Oversimplification_recall': 0.01904761904761905, 'Consequential_Oversimplification_f1-score': 0.025641025641025644, 'Consequential_Oversimplification_support': 105.0, 'micro avg_precision': 0.0392156862745098, 'micro avg_recall': 0.01904761904761905, 'micro avg_f1-score': 0.025641025641025644, 'micro avg_support': 105.0, 'macro avg_precision': 0.0392156862745098, 'macro avg_recall': 0.01904761904761905, 'macro avg_f1-score': 0.025641025641025644, 'macro avg_support': 105.0, 'weighted avg_precision': 0.0392156862745098, 'weighted avg_recall': 0.01904761904761905, 'weighted avg_f1-score': 0.025641025641025644, 'weighted avg_support': 105.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 1}, {'micro_f1': 0.7766454352441614, 'precision': 0.7766454352441614, 'Consequential_Oversimplification_precision': 0.0784313725490196, 'Consequential_Oversimplification_recall': 0.03278688524590164, 'Consequential_Oversimplification_f1-score': 0.046242774566473986, 'Consequential_Oversimplification_support': 122.0, 'micro avg_precision': 0.0784313725490196, 'micro avg_recall': 0.03278688524590164, 'micro avg_f1-score': 0.046242774566473986, 'micro avg_support': 122.0, 'macro avg_precision': 0.0784313725490196, 'macro avg_recall': 0.03278688524590164, 'macro avg_f1-score': 0.046242774566473986, 'macro avg_support': 122.0, 'weighted avg_precision': 0.0784313725490196, 'weighted avg_recall': 0.03278688524590164, 'weighted avg_f1-score': 0.046242774566473986, 'weighted avg_support': 122.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 2}, {'micro_f1': 0.8059447983014862, 'precision': 0.8059447983014862, 'Consequential_Oversimplification_precision': 0.11764705882352941, 'Consequential_Oversimplification_recall': 0.06593406593406594, 'Consequential_Oversimplification_f1-score': 0.08450704225352113, 'Consequential_Oversimplification_support': 91.0, 'micro avg_precision': 0.11764705882352941, 'micro avg_recall': 0.06593406593406594, 'micro avg_f1-score': 0.08450704225352113, 'micro avg_support': 91.0, 'macro avg_precision': 0.11764705882352941, 'macro avg_recall': 0.06593406593406594, 'macro avg_f1-score': 0.08450704225352113, 'macro avg_support': 91.0, 'weighted avg_precision': 0.11764705882352941, 'weighted avg_recall': 0.06593406593406594, 'weighted avg_f1-score': 0.08450704225352113, 'weighted avg_support': 91.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 3}, {'micro_f1': 0.8012738853503185, 'precision': 0.8012738853503185, 'Consequential_Oversimplification_precision': 0.13725490196078433, 'Consequential_Oversimplification_recall': 0.06930693069306931, 'Consequential_Oversimplification_f1-score': 0.09210526315789473, 'Consequential_Oversimplification_support': 101.0, 'micro avg_precision': 0.13725490196078433, 'micro avg_recall': 0.06930693069306931, 'micro avg_f1-score': 0.09210526315789473, 'micro avg_support': 101.0, 'macro avg_precision': 0.13725490196078433, 'macro avg_recall': 0.06930693069306931, 'macro avg_f1-score': 0.09210526315789473, 'macro avg_support': 101.0, 'weighted avg_precision': 0.13725490196078433, 'weighted avg_recall': 0.06930693069306931, 'weighted avg_f1-score': 0.09210526315789473, 'weighted avg_support': 101.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 4}, {'micro_f1': 0.8182590233545648, 'precision': 0.8182590233545648, 'Consequential_Oversimplification_precision': 0.19607843137254902, 'Consequential_Oversimplification_recall': 0.11627906976744186, 'Consequential_Oversimplification_f1-score': 0.145985401459854, 'Consequential_Oversimplification_support': 86.0, 'micro avg_precision': 0.19607843137254902, 'micro avg_recall': 0.11627906976744186, 'micro avg_f1-score': 0.145985401459854, 'micro avg_support': 86.0, 'macro avg_precision': 0.19607843137254902, 'macro avg_recall': 0.11627906976744186, 'macro avg_f1-score': 0.145985401459854, 'macro avg_support': 86.0, 'weighted avg_precision': 0.19607843137254902, 'weighted avg_recall': 0.11627906976744186, 'weighted avg_f1-score': 0.145985401459854, 'weighted avg_support': 86.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 5}, {'micro_f1': 0.8437367303609343, 'precision': 0.8437367303609342, 'Consequential_Oversimplification_precision': 0.21568627450980393, 'Consequential_Oversimplification_recall': 0.13580246913580246, 'Consequential_Oversimplification_f1-score': 0.16666666666666666, 'Consequential_Oversimplification_support': 81.0, 'micro avg_precision': 0.21568627450980393, 'micro avg_recall': 0.13580246913580246, 'micro avg_f1-score': 0.16666666666666666, 'micro avg_support': 81.0, 'macro avg_precision': 0.21568627450980393, 'macro avg_recall': 0.13580246913580246, 'macro avg_f1-score': 0.16666666666666666, 'macro avg_support': 81.0, 'weighted avg_precision': 0.21568627450980393, 'weighted avg_recall': 0.13580246913580246, 'weighted avg_f1-score': 0.16666666666666666, 'weighted avg_support': 81.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 6}, {'micro_f1': 0.8144373673036094, 'precision': 0.8144373673036094, 'Consequential_Oversimplification_precision': 0.19607843137254902, 'Consequential_Oversimplification_recall': 0.12048192771084337, 'Consequential_Oversimplification_f1-score': 0.14925373134328357, 'Consequential_Oversimplification_support': 83.0, 'micro avg_precision': 0.19607843137254902, 'micro avg_recall': 0.12048192771084337, 'micro avg_f1-score': 0.14925373134328357, 'micro avg_support': 83.0, 'macro avg_precision': 0.19607843137254902, 'macro avg_recall': 0.12048192771084337, 'macro avg_f1-score': 0.14925373134328357, 'macro avg_support': 83.0, 'weighted avg_precision': 0.19607843137254902, 'weighted avg_recall': 0.12048192771084337, 'weighted avg_f1-score': 0.14925373134328357, 'weighted avg_support': 83.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 7}, {'micro_f1': 0.837791932059448, 'precision': 0.837791932059448, 'Consequential_Oversimplification_precision': 0.29411764705882354, 'Consequential_Oversimplification_recall': 0.17857142857142858, 'Consequential_Oversimplification_f1-score': 0.22222222222222224, 'Consequential_Oversimplification_support': 84.0, 'micro avg_precision': 0.29411764705882354, 'micro avg_recall': 0.17857142857142858, 'micro avg_f1-score': 0.22222222222222224, 'micro avg_support': 84.0, 'macro avg_precision': 0.29411764705882354, 'macro avg_recall': 0.17857142857142858, 'macro avg_f1-score': 0.22222222222222224, 'macro avg_support': 84.0, 'weighted avg_precision': 0.29411764705882354, 'weighted avg_recall': 0.17857142857142858, 'weighted avg_f1-score': 0.22222222222222224, 'weighted avg_support': 84.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 8}]}
Best model updated: current epoch macro f1 = 0.22222222222222224
{'micro_f1': 0.8254777070063694, 'precision': 0.8254777070063695, 'Consequential_Oversimplification_precision': 0.21568627450980393, 'Consequential_Oversimplification_recall': 0.13414634146341464, 'Consequential_Oversimplification_f1-score': 0.16541353383458648, 'Consequential_Oversimplification_support': 82.0, 'micro avg_precision': 0.21568627450980393, 'micro avg_recall': 0.13414634146341464, 'micro avg_f1-score': 0.16541353383458648, 'micro avg_support': 82.0, 'macro avg_precision': 0.21568627450980393, 'macro avg_recall': 0.13414634146341464, 'macro avg_f1-score': 0.16541353383458648, 'macro avg_support': 82.0, 'weighted avg_precision': 0.21568627450980393, 'weighted avg_recall': 0.13414634146341464, 'weighted avg_f1-score': 0.16541353383458648, 'weighted avg_support': 82.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 9}
{'results': [{'micro_f1': 0.4280254777070064, 'precision': 0.4280254777070064, 'Consequential_Oversimplification_precision': 0.0, 'Consequential_Oversimplification_recall': 0.0, 'Consequential_Oversimplification_f1-score': 0.0, 'Consequential_Oversimplification_support': 3.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 3.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 3.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 3.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 0}, {'micro_f1': 0.8008492569002124, 'precision': 0.8008492569002124, 'Consequential_Oversimplification_precision': 0.0392156862745098, 'Consequential_Oversimplification_recall': 0.01904761904761905, 'Consequential_Oversimplification_f1-score': 0.025641025641025644, 'Consequential_Oversimplification_support': 105.0, 'micro avg_precision': 0.0392156862745098, 'micro avg_recall': 0.01904761904761905, 'micro avg_f1-score': 0.025641025641025644, 'micro avg_support': 105.0, 'macro avg_precision': 0.0392156862745098, 'macro avg_recall': 0.01904761904761905, 'macro avg_f1-score': 0.025641025641025644, 'macro avg_support': 105.0, 'weighted avg_precision': 0.0392156862745098, 'weighted avg_recall': 0.01904761904761905, 'weighted avg_f1-score': 0.025641025641025644, 'weighted avg_support': 105.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 1}, {'micro_f1': 0.7766454352441614, 'precision': 0.7766454352441614, 'Consequential_Oversimplification_precision': 0.0784313725490196, 'Consequential_Oversimplification_recall': 0.03278688524590164, 'Consequential_Oversimplification_f1-score': 0.046242774566473986, 'Consequential_Oversimplification_support': 122.0, 'micro avg_precision': 0.0784313725490196, 'micro avg_recall': 0.03278688524590164, 'micro avg_f1-score': 0.046242774566473986, 'micro avg_support': 122.0, 'macro avg_precision': 0.0784313725490196, 'macro avg_recall': 0.03278688524590164, 'macro avg_f1-score': 0.046242774566473986, 'macro avg_support': 122.0, 'weighted avg_precision': 0.0784313725490196, 'weighted avg_recall': 0.03278688524590164, 'weighted avg_f1-score': 0.046242774566473986, 'weighted avg_support': 122.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 2}, {'micro_f1': 0.8059447983014862, 'precision': 0.8059447983014862, 'Consequential_Oversimplification_precision': 0.11764705882352941, 'Consequential_Oversimplification_recall': 0.06593406593406594, 'Consequential_Oversimplification_f1-score': 0.08450704225352113, 'Consequential_Oversimplification_support': 91.0, 'micro avg_precision': 0.11764705882352941, 'micro avg_recall': 0.06593406593406594, 'micro avg_f1-score': 0.08450704225352113, 'micro avg_support': 91.0, 'macro avg_precision': 0.11764705882352941, 'macro avg_recall': 0.06593406593406594, 'macro avg_f1-score': 0.08450704225352113, 'macro avg_support': 91.0, 'weighted avg_precision': 0.11764705882352941, 'weighted avg_recall': 0.06593406593406594, 'weighted avg_f1-score': 0.08450704225352113, 'weighted avg_support': 91.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 3}, {'micro_f1': 0.8012738853503185, 'precision': 0.8012738853503185, 'Consequential_Oversimplification_precision': 0.13725490196078433, 'Consequential_Oversimplification_recall': 0.06930693069306931, 'Consequential_Oversimplification_f1-score': 0.09210526315789473, 'Consequential_Oversimplification_support': 101.0, 'micro avg_precision': 0.13725490196078433, 'micro avg_recall': 0.06930693069306931, 'micro avg_f1-score': 0.09210526315789473, 'micro avg_support': 101.0, 'macro avg_precision': 0.13725490196078433, 'macro avg_recall': 0.06930693069306931, 'macro avg_f1-score': 0.09210526315789473, 'macro avg_support': 101.0, 'weighted avg_precision': 0.13725490196078433, 'weighted avg_recall': 0.06930693069306931, 'weighted avg_f1-score': 0.09210526315789473, 'weighted avg_support': 101.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 4}, {'micro_f1': 0.8182590233545648, 'precision': 0.8182590233545648, 'Consequential_Oversimplification_precision': 0.19607843137254902, 'Consequential_Oversimplification_recall': 0.11627906976744186, 'Consequential_Oversimplification_f1-score': 0.145985401459854, 'Consequential_Oversimplification_support': 86.0, 'micro avg_precision': 0.19607843137254902, 'micro avg_recall': 0.11627906976744186, 'micro avg_f1-score': 0.145985401459854, 'micro avg_support': 86.0, 'macro avg_precision': 0.19607843137254902, 'macro avg_recall': 0.11627906976744186, 'macro avg_f1-score': 0.145985401459854, 'macro avg_support': 86.0, 'weighted avg_precision': 0.19607843137254902, 'weighted avg_recall': 0.11627906976744186, 'weighted avg_f1-score': 0.145985401459854, 'weighted avg_support': 86.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 5}, {'micro_f1': 0.8437367303609343, 'precision': 0.8437367303609342, 'Consequential_Oversimplification_precision': 0.21568627450980393, 'Consequential_Oversimplification_recall': 0.13580246913580246, 'Consequential_Oversimplification_f1-score': 0.16666666666666666, 'Consequential_Oversimplification_support': 81.0, 'micro avg_precision': 0.21568627450980393, 'micro avg_recall': 0.13580246913580246, 'micro avg_f1-score': 0.16666666666666666, 'micro avg_support': 81.0, 'macro avg_precision': 0.21568627450980393, 'macro avg_recall': 0.13580246913580246, 'macro avg_f1-score': 0.16666666666666666, 'macro avg_support': 81.0, 'weighted avg_precision': 0.21568627450980393, 'weighted avg_recall': 0.13580246913580246, 'weighted avg_f1-score': 0.16666666666666666, 'weighted avg_support': 81.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 6}, {'micro_f1': 0.8144373673036094, 'precision': 0.8144373673036094, 'Consequential_Oversimplification_precision': 0.19607843137254902, 'Consequential_Oversimplification_recall': 0.12048192771084337, 'Consequential_Oversimplification_f1-score': 0.14925373134328357, 'Consequential_Oversimplification_support': 83.0, 'micro avg_precision': 0.19607843137254902, 'micro avg_recall': 0.12048192771084337, 'micro avg_f1-score': 0.14925373134328357, 'micro avg_support': 83.0, 'macro avg_precision': 0.19607843137254902, 'macro avg_recall': 0.12048192771084337, 'macro avg_f1-score': 0.14925373134328357, 'macro avg_support': 83.0, 'weighted avg_precision': 0.19607843137254902, 'weighted avg_recall': 0.12048192771084337, 'weighted avg_f1-score': 0.14925373134328357, 'weighted avg_support': 83.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 7}, {'micro_f1': 0.837791932059448, 'precision': 0.837791932059448, 'Consequential_Oversimplification_precision': 0.29411764705882354, 'Consequential_Oversimplification_recall': 0.17857142857142858, 'Consequential_Oversimplification_f1-score': 0.22222222222222224, 'Consequential_Oversimplification_support': 84.0, 'micro avg_precision': 0.29411764705882354, 'micro avg_recall': 0.17857142857142858, 'micro avg_f1-score': 0.22222222222222224, 'micro avg_support': 84.0, 'macro avg_precision': 0.29411764705882354, 'macro avg_recall': 0.17857142857142858, 'macro avg_f1-score': 0.22222222222222224, 'macro avg_support': 84.0, 'weighted avg_precision': 0.29411764705882354, 'weighted avg_recall': 0.17857142857142858, 'weighted avg_f1-score': 0.22222222222222224, 'weighted avg_support': 84.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 8}, {'micro_f1': 0.8254777070063694, 'precision': 0.8254777070063695, 'Consequential_Oversimplification_precision': 0.21568627450980393, 'Consequential_Oversimplification_recall': 0.13414634146341464, 'Consequential_Oversimplification_f1-score': 0.16541353383458648, 'Consequential_Oversimplification_support': 82.0, 'micro avg_precision': 0.21568627450980393, 'micro avg_recall': 0.13414634146341464, 'micro avg_f1-score': 0.16541353383458648, 'micro avg_support': 82.0, 'macro avg_precision': 0.21568627450980393, 'macro avg_recall': 0.13414634146341464, 'macro avg_f1-score': 0.16541353383458648, 'macro avg_support': 82.0, 'weighted avg_precision': 0.21568627450980393, 'weighted avg_recall': 0.13414634146341464, 'weighted avg_f1-score': 0.16541353383458648, 'weighted avg_support': 82.0, 'O_support': 1004, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 9}]}
Saving model to directory: ./models/M2/2024-05-14-06-51-04_aug_ts0.9/mdeberta-v3-base_7_ME10_target=Consequential_Oversimplification_SUBSAMPLED_2024-05-14-06-51-04
Training model no. 8 of 23 for (8, 'Straw_Man') persuasion technique...
{'micro_f1': 0.553757225433526, 'precision': 0.553757225433526, 'Straw_Man_precision': 0.0, 'Straw_Man_recall': 0.0, 'Straw_Man_f1-score': 0.0, 'Straw_Man_support': 1.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 1.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 1.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 1.0, 'O_support': 957, 'B-Straw_Man_support': 45, 'I-Straw_Man_support': 728, 'epoch': 0}
{'results': [{'micro_f1': 0.553757225433526, 'precision': 0.553757225433526, 'Straw_Man_precision': 0.0, 'Straw_Man_recall': 0.0, 'Straw_Man_f1-score': 0.0, 'Straw_Man_support': 1.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 1.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 1.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 1.0, 'O_support': 957, 'B-Straw_Man_support': 45, 'I-Straw_Man_support': 728, 'epoch': 0}]}
{'micro_f1': 0.5531791907514451, 'precision': 0.5531791907514451, 'Straw_Man_precision': 0.0, 'Straw_Man_recall': 0.0, 'Straw_Man_f1-score': 0.0, 'Straw_Man_support': 0.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 0.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 0.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 0.0, 'O_support': 957, 'B-Straw_Man_support': 45, 'I-Straw_Man_support': 728, 'epoch': 1}
{'results': [{'micro_f1': 0.553757225433526, 'precision': 0.553757225433526, 'Straw_Man_precision': 0.0, 'Straw_Man_recall': 0.0, 'Straw_Man_f1-score': 0.0, 'Straw_Man_support': 1.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 1.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 1.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 1.0, 'O_support': 957, 'B-Straw_Man_support': 45, 'I-Straw_Man_support': 728, 'epoch': 0}, {'micro_f1': 0.5531791907514451, 'precision': 0.5531791907514451, 'Straw_Man_precision': 0.0, 'Straw_Man_recall': 0.0, 'Straw_Man_f1-score': 0.0, 'Straw_Man_support': 0.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 0.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 0.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 0.0, 'O_support': 957, 'B-Straw_Man_support': 45, 'I-Straw_Man_support': 728, 'epoch': 1}]}
Early stopping triggered.
Saving model to directory: ./models/M2/2024-05-14-06-51-04_aug_ts0.9/mdeberta-v3-base_8_ME10_target=Straw_Man_SUBSAMPLED_2024-05-14-06-51-04
Training model no. 9 of 23 for (9, 'Red_Herring') persuasion technique...
{'micro_f1': 0.6533687943262412, 'precision': 0.6533687943262412, 'Red_Herring_precision': 0.0, 'Red_Herring_recall': 0.0, 'Red_Herring_f1-score': 0.0, 'Red_Herring_support': 4.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 4.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 4.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 4.0, 'O_support': 732, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 0}
{'results': [{'micro_f1': 0.6533687943262412, 'precision': 0.6533687943262412, 'Red_Herring_precision': 0.0, 'Red_Herring_recall': 0.0, 'Red_Herring_f1-score': 0.0, 'Red_Herring_support': 4.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 4.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 4.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 4.0, 'O_support': 732, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 0}]}
{'micro_f1': 0.7987588652482269, 'precision': 0.7987588652482269, 'Red_Herring_precision': 0.0, 'Red_Herring_recall': 0.0, 'Red_Herring_f1-score': 0.0, 'Red_Herring_support': 47.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 47.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 47.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 47.0, 'O_support': 732, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 1}
{'results': [{'micro_f1': 0.6533687943262412, 'precision': 0.6533687943262412, 'Red_Herring_precision': 0.0, 'Red_Herring_recall': 0.0, 'Red_Herring_f1-score': 0.0, 'Red_Herring_support': 4.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 4.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 4.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 4.0, 'O_support': 732, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 0}, {'micro_f1': 0.7987588652482269, 'precision': 0.7987588652482269, 'Red_Herring_precision': 0.0, 'Red_Herring_recall': 0.0, 'Red_Herring_f1-score': 0.0, 'Red_Herring_support': 47.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 47.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 47.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 47.0, 'O_support': 732, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 1}]}
Early stopping triggered.
Saving model to directory: ./models/M2/2024-05-14-06-51-04_aug_ts0.9/mdeberta-v3-base_9_ME10_target=Red_Herring_SUBSAMPLED_2024-05-14-06-51-04
Training model no. 10 of 23 for (10, 'Whataboutism') persuasion technique...
{'micro_f1': 0.46021093000958774, 'precision': 0.46021093000958774, 'Whataboutism_precision': 0.0, 'Whataboutism_recall': 0.0, 'Whataboutism_f1-score': 0.0, 'Whataboutism_support': 39.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 39.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 39.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 39.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 427, 'epoch': 0}
{'results': [{'micro_f1': 0.46021093000958774, 'precision': 0.46021093000958774, 'Whataboutism_precision': 0.0, 'Whataboutism_recall': 0.0, 'Whataboutism_f1-score': 0.0, 'Whataboutism_support': 39.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 39.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 39.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 39.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 427, 'epoch': 0}]}
{'micro_f1': 0.5580057526366251, 'precision': 0.5580057526366251, 'Whataboutism_precision': 0.0, 'Whataboutism_recall': 0.0, 'Whataboutism_f1-score': 0.0, 'Whataboutism_support': 79.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 79.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 79.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 79.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 427, 'epoch': 1}
{'results': [{'micro_f1': 0.46021093000958774, 'precision': 0.46021093000958774, 'Whataboutism_precision': 0.0, 'Whataboutism_recall': 0.0, 'Whataboutism_f1-score': 0.0, 'Whataboutism_support': 39.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 39.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 39.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 39.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 427, 'epoch': 0}, {'micro_f1': 0.5580057526366251, 'precision': 0.5580057526366251, 'Whataboutism_precision': 0.0, 'Whataboutism_recall': 0.0, 'Whataboutism_f1-score': 0.0, 'Whataboutism_support': 79.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 79.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 79.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 79.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 427, 'epoch': 1}]}
Early stopping triggered.
Saving model to directory: ./models/M2/2024-05-14-06-51-04_aug_ts0.9/mdeberta-v3-base_10_ME10_target=Whataboutism_SUBSAMPLED_2024-05-14-06-51-04
Training model no. 11 of 23 for (11, 'Slogans') persuasion technique...
{'micro_f1': 0.8930734790624177, 'precision': 0.8930734790624177, 'Slogans_precision': 0.10309278350515463, 'Slogans_recall': 0.10638297872340426, 'Slogans_f1-score': 0.10471204188481674, 'Slogans_support': 94.0, 'micro avg_precision': 0.10309278350515463, 'micro avg_recall': 0.10638297872340426, 'micro avg_f1-score': 0.10471204188481674, 'micro avg_support': 94.0, 'macro avg_precision': 0.10309278350515463, 'macro avg_recall': 0.10638297872340426, 'macro avg_f1-score': 0.10471204188481674, 'macro avg_support': 94.0, 'weighted avg_precision': 0.10309278350515463, 'weighted avg_recall': 0.10638297872340426, 'weighted avg_f1-score': 0.10471204188481674, 'weighted avg_support': 94.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 0}
{'results': [{'micro_f1': 0.8930734790624177, 'precision': 0.8930734790624177, 'Slogans_precision': 0.10309278350515463, 'Slogans_recall': 0.10638297872340426, 'Slogans_f1-score': 0.10471204188481674, 'Slogans_support': 94.0, 'micro avg_precision': 0.10309278350515463, 'micro avg_recall': 0.10638297872340426, 'micro avg_f1-score': 0.10471204188481674, 'micro avg_support': 94.0, 'macro avg_precision': 0.10309278350515463, 'macro avg_recall': 0.10638297872340426, 'macro avg_f1-score': 0.10471204188481674, 'macro avg_support': 94.0, 'weighted avg_precision': 0.10309278350515463, 'weighted avg_recall': 0.10638297872340426, 'weighted avg_f1-score': 0.10471204188481674, 'weighted avg_support': 94.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 0}]}
Best model updated: current epoch macro f1 = 0.10471204188481674
{'micro_f1': 0.8949170397682381, 'precision': 0.8949170397682381, 'Slogans_precision': 0.18556701030927836, 'Slogans_recall': 0.23076923076923078, 'Slogans_f1-score': 0.2057142857142857, 'Slogans_support': 78.0, 'micro avg_precision': 0.18556701030927836, 'micro avg_recall': 0.23076923076923078, 'micro avg_f1-score': 0.2057142857142857, 'micro avg_support': 78.0, 'macro avg_precision': 0.18556701030927836, 'macro avg_recall': 0.23076923076923078, 'macro avg_f1-score': 0.2057142857142857, 'macro avg_support': 78.0, 'weighted avg_precision': 0.18556701030927836, 'weighted avg_recall': 0.23076923076923078, 'weighted avg_f1-score': 0.2057142857142857, 'weighted avg_support': 78.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 1}
{'results': [{'micro_f1': 0.8930734790624177, 'precision': 0.8930734790624177, 'Slogans_precision': 0.10309278350515463, 'Slogans_recall': 0.10638297872340426, 'Slogans_f1-score': 0.10471204188481674, 'Slogans_support': 94.0, 'micro avg_precision': 0.10309278350515463, 'micro avg_recall': 0.10638297872340426, 'micro avg_f1-score': 0.10471204188481674, 'micro avg_support': 94.0, 'macro avg_precision': 0.10309278350515463, 'macro avg_recall': 0.10638297872340426, 'macro avg_f1-score': 0.10471204188481674, 'macro avg_support': 94.0, 'weighted avg_precision': 0.10309278350515463, 'weighted avg_recall': 0.10638297872340426, 'weighted avg_f1-score': 0.10471204188481674, 'weighted avg_support': 94.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 0}, {'micro_f1': 0.8949170397682381, 'precision': 0.8949170397682381, 'Slogans_precision': 0.18556701030927836, 'Slogans_recall': 0.23076923076923078, 'Slogans_f1-score': 0.2057142857142857, 'Slogans_support': 78.0, 'micro avg_precision': 0.18556701030927836, 'micro avg_recall': 0.23076923076923078, 'micro avg_f1-score': 0.2057142857142857, 'micro avg_support': 78.0, 'macro avg_precision': 0.18556701030927836, 'macro avg_recall': 0.23076923076923078, 'macro avg_f1-score': 0.2057142857142857, 'macro avg_support': 78.0, 'weighted avg_precision': 0.18556701030927836, 'weighted avg_recall': 0.23076923076923078, 'weighted avg_f1-score': 0.2057142857142857, 'weighted avg_support': 78.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 1}]}
Best model updated: current epoch macro f1 = 0.2057142857142857
{'micro_f1': 0.9057150381880432, 'precision': 0.9057150381880432, 'Slogans_precision': 0.2268041237113402, 'Slogans_recall': 0.2391304347826087, 'Slogans_f1-score': 0.2328042328042328, 'Slogans_support': 92.0, 'micro avg_precision': 0.2268041237113402, 'micro avg_recall': 0.2391304347826087, 'micro avg_f1-score': 0.2328042328042328, 'micro avg_support': 92.0, 'macro avg_precision': 0.2268041237113402, 'macro avg_recall': 0.2391304347826087, 'macro avg_f1-score': 0.2328042328042328, 'macro avg_support': 92.0, 'weighted avg_precision': 0.2268041237113402, 'weighted avg_recall': 0.2391304347826087, 'weighted avg_f1-score': 0.2328042328042328, 'weighted avg_support': 92.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 2}
{'results': [{'micro_f1': 0.8930734790624177, 'precision': 0.8930734790624177, 'Slogans_precision': 0.10309278350515463, 'Slogans_recall': 0.10638297872340426, 'Slogans_f1-score': 0.10471204188481674, 'Slogans_support': 94.0, 'micro avg_precision': 0.10309278350515463, 'micro avg_recall': 0.10638297872340426, 'micro avg_f1-score': 0.10471204188481674, 'micro avg_support': 94.0, 'macro avg_precision': 0.10309278350515463, 'macro avg_recall': 0.10638297872340426, 'macro avg_f1-score': 0.10471204188481674, 'macro avg_support': 94.0, 'weighted avg_precision': 0.10309278350515463, 'weighted avg_recall': 0.10638297872340426, 'weighted avg_f1-score': 0.10471204188481674, 'weighted avg_support': 94.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 0}, {'micro_f1': 0.8949170397682381, 'precision': 0.8949170397682381, 'Slogans_precision': 0.18556701030927836, 'Slogans_recall': 0.23076923076923078, 'Slogans_f1-score': 0.2057142857142857, 'Slogans_support': 78.0, 'micro avg_precision': 0.18556701030927836, 'micro avg_recall': 0.23076923076923078, 'micro avg_f1-score': 0.2057142857142857, 'micro avg_support': 78.0, 'macro avg_precision': 0.18556701030927836, 'macro avg_recall': 0.23076923076923078, 'macro avg_f1-score': 0.2057142857142857, 'macro avg_support': 78.0, 'weighted avg_precision': 0.18556701030927836, 'weighted avg_recall': 0.23076923076923078, 'weighted avg_f1-score': 0.2057142857142857, 'weighted avg_support': 78.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 1}, {'micro_f1': 0.9057150381880432, 'precision': 0.9057150381880432, 'Slogans_precision': 0.2268041237113402, 'Slogans_recall': 0.2391304347826087, 'Slogans_f1-score': 0.2328042328042328, 'Slogans_support': 92.0, 'micro avg_precision': 0.2268041237113402, 'micro avg_recall': 0.2391304347826087, 'micro avg_f1-score': 0.2328042328042328, 'micro avg_support': 92.0, 'macro avg_precision': 0.2268041237113402, 'macro avg_recall': 0.2391304347826087, 'macro avg_f1-score': 0.2328042328042328, 'macro avg_support': 92.0, 'weighted avg_precision': 0.2268041237113402, 'weighted avg_recall': 0.2391304347826087, 'weighted avg_f1-score': 0.2328042328042328, 'weighted avg_support': 92.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 2}]}
Best model updated: current epoch macro f1 = 0.2328042328042328
{'micro_f1': 0.9151962075322623, 'precision': 0.9151962075322623, 'Slogans_precision': 0.29896907216494845, 'Slogans_recall': 0.31521739130434784, 'Slogans_f1-score': 0.3068783068783069, 'Slogans_support': 92.0, 'micro avg_precision': 0.29896907216494845, 'micro avg_recall': 0.31521739130434784, 'micro avg_f1-score': 0.3068783068783069, 'micro avg_support': 92.0, 'macro avg_precision': 0.29896907216494845, 'macro avg_recall': 0.31521739130434784, 'macro avg_f1-score': 0.3068783068783069, 'macro avg_support': 92.0, 'weighted avg_precision': 0.29896907216494845, 'weighted avg_recall': 0.31521739130434784, 'weighted avg_f1-score': 0.3068783068783069, 'weighted avg_support': 92.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 3}
{'results': [{'micro_f1': 0.8930734790624177, 'precision': 0.8930734790624177, 'Slogans_precision': 0.10309278350515463, 'Slogans_recall': 0.10638297872340426, 'Slogans_f1-score': 0.10471204188481674, 'Slogans_support': 94.0, 'micro avg_precision': 0.10309278350515463, 'micro avg_recall': 0.10638297872340426, 'micro avg_f1-score': 0.10471204188481674, 'micro avg_support': 94.0, 'macro avg_precision': 0.10309278350515463, 'macro avg_recall': 0.10638297872340426, 'macro avg_f1-score': 0.10471204188481674, 'macro avg_support': 94.0, 'weighted avg_precision': 0.10309278350515463, 'weighted avg_recall': 0.10638297872340426, 'weighted avg_f1-score': 0.10471204188481674, 'weighted avg_support': 94.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 0}, {'micro_f1': 0.8949170397682381, 'precision': 0.8949170397682381, 'Slogans_precision': 0.18556701030927836, 'Slogans_recall': 0.23076923076923078, 'Slogans_f1-score': 0.2057142857142857, 'Slogans_support': 78.0, 'micro avg_precision': 0.18556701030927836, 'micro avg_recall': 0.23076923076923078, 'micro avg_f1-score': 0.2057142857142857, 'micro avg_support': 78.0, 'macro avg_precision': 0.18556701030927836, 'macro avg_recall': 0.23076923076923078, 'macro avg_f1-score': 0.2057142857142857, 'macro avg_support': 78.0, 'weighted avg_precision': 0.18556701030927836, 'weighted avg_recall': 0.23076923076923078, 'weighted avg_f1-score': 0.2057142857142857, 'weighted avg_support': 78.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 1}, {'micro_f1': 0.9057150381880432, 'precision': 0.9057150381880432, 'Slogans_precision': 0.2268041237113402, 'Slogans_recall': 0.2391304347826087, 'Slogans_f1-score': 0.2328042328042328, 'Slogans_support': 92.0, 'micro avg_precision': 0.2268041237113402, 'micro avg_recall': 0.2391304347826087, 'micro avg_f1-score': 0.2328042328042328, 'micro avg_support': 92.0, 'macro avg_precision': 0.2268041237113402, 'macro avg_recall': 0.2391304347826087, 'macro avg_f1-score': 0.2328042328042328, 'macro avg_support': 92.0, 'weighted avg_precision': 0.2268041237113402, 'weighted avg_recall': 0.2391304347826087, 'weighted avg_f1-score': 0.2328042328042328, 'weighted avg_support': 92.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 2}, {'micro_f1': 0.9151962075322623, 'precision': 0.9151962075322623, 'Slogans_precision': 0.29896907216494845, 'Slogans_recall': 0.31521739130434784, 'Slogans_f1-score': 0.3068783068783069, 'Slogans_support': 92.0, 'micro avg_precision': 0.29896907216494845, 'micro avg_recall': 0.31521739130434784, 'micro avg_f1-score': 0.3068783068783069, 'micro avg_support': 92.0, 'macro avg_precision': 0.29896907216494845, 'macro avg_recall': 0.31521739130434784, 'macro avg_f1-score': 0.3068783068783069, 'macro avg_support': 92.0, 'weighted avg_precision': 0.29896907216494845, 'weighted avg_recall': 0.31521739130434784, 'weighted avg_f1-score': 0.3068783068783069, 'weighted avg_support': 92.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 3}]}
Best model updated: current epoch macro f1 = 0.3068783068783069
{'micro_f1': 0.8983407953647616, 'precision': 0.8983407953647616, 'Slogans_precision': 0.26804123711340205, 'Slogans_recall': 0.3132530120481928, 'Slogans_f1-score': 0.28888888888888886, 'Slogans_support': 83.0, 'micro avg_precision': 0.26804123711340205, 'micro avg_recall': 0.3132530120481928, 'micro avg_f1-score': 0.28888888888888886, 'micro avg_support': 83.0, 'macro avg_precision': 0.26804123711340205, 'macro avg_recall': 0.3132530120481928, 'macro avg_f1-score': 0.28888888888888886, 'macro avg_support': 83.0, 'weighted avg_precision': 0.26804123711340205, 'weighted avg_recall': 0.3132530120481928, 'weighted avg_f1-score': 0.28888888888888886, 'weighted avg_support': 83.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 4}
{'results': [{'micro_f1': 0.8930734790624177, 'precision': 0.8930734790624177, 'Slogans_precision': 0.10309278350515463, 'Slogans_recall': 0.10638297872340426, 'Slogans_f1-score': 0.10471204188481674, 'Slogans_support': 94.0, 'micro avg_precision': 0.10309278350515463, 'micro avg_recall': 0.10638297872340426, 'micro avg_f1-score': 0.10471204188481674, 'micro avg_support': 94.0, 'macro avg_precision': 0.10309278350515463, 'macro avg_recall': 0.10638297872340426, 'macro avg_f1-score': 0.10471204188481674, 'macro avg_support': 94.0, 'weighted avg_precision': 0.10309278350515463, 'weighted avg_recall': 0.10638297872340426, 'weighted avg_f1-score': 0.10471204188481674, 'weighted avg_support': 94.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 0}, {'micro_f1': 0.8949170397682381, 'precision': 0.8949170397682381, 'Slogans_precision': 0.18556701030927836, 'Slogans_recall': 0.23076923076923078, 'Slogans_f1-score': 0.2057142857142857, 'Slogans_support': 78.0, 'micro avg_precision': 0.18556701030927836, 'micro avg_recall': 0.23076923076923078, 'micro avg_f1-score': 0.2057142857142857, 'micro avg_support': 78.0, 'macro avg_precision': 0.18556701030927836, 'macro avg_recall': 0.23076923076923078, 'macro avg_f1-score': 0.2057142857142857, 'macro avg_support': 78.0, 'weighted avg_precision': 0.18556701030927836, 'weighted avg_recall': 0.23076923076923078, 'weighted avg_f1-score': 0.2057142857142857, 'weighted avg_support': 78.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 1}, {'micro_f1': 0.9057150381880432, 'precision': 0.9057150381880432, 'Slogans_precision': 0.2268041237113402, 'Slogans_recall': 0.2391304347826087, 'Slogans_f1-score': 0.2328042328042328, 'Slogans_support': 92.0, 'micro avg_precision': 0.2268041237113402, 'micro avg_recall': 0.2391304347826087, 'micro avg_f1-score': 0.2328042328042328, 'micro avg_support': 92.0, 'macro avg_precision': 0.2268041237113402, 'macro avg_recall': 0.2391304347826087, 'macro avg_f1-score': 0.2328042328042328, 'macro avg_support': 92.0, 'weighted avg_precision': 0.2268041237113402, 'weighted avg_recall': 0.2391304347826087, 'weighted avg_f1-score': 0.2328042328042328, 'weighted avg_support': 92.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 2}, {'micro_f1': 0.9151962075322623, 'precision': 0.9151962075322623, 'Slogans_precision': 0.29896907216494845, 'Slogans_recall': 0.31521739130434784, 'Slogans_f1-score': 0.3068783068783069, 'Slogans_support': 92.0, 'micro avg_precision': 0.29896907216494845, 'micro avg_recall': 0.31521739130434784, 'micro avg_f1-score': 0.3068783068783069, 'micro avg_support': 92.0, 'macro avg_precision': 0.29896907216494845, 'macro avg_recall': 0.31521739130434784, 'macro avg_f1-score': 0.3068783068783069, 'macro avg_support': 92.0, 'weighted avg_precision': 0.29896907216494845, 'weighted avg_recall': 0.31521739130434784, 'weighted avg_f1-score': 0.3068783068783069, 'weighted avg_support': 92.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 3}, {'micro_f1': 0.8983407953647616, 'precision': 0.8983407953647616, 'Slogans_precision': 0.26804123711340205, 'Slogans_recall': 0.3132530120481928, 'Slogans_f1-score': 0.28888888888888886, 'Slogans_support': 83.0, 'micro avg_precision': 0.26804123711340205, 'micro avg_recall': 0.3132530120481928, 'micro avg_f1-score': 0.28888888888888886, 'micro avg_support': 83.0, 'macro avg_precision': 0.26804123711340205, 'macro avg_recall': 0.3132530120481928, 'macro avg_f1-score': 0.28888888888888886, 'macro avg_support': 83.0, 'weighted avg_precision': 0.26804123711340205, 'weighted avg_recall': 0.3132530120481928, 'weighted avg_f1-score': 0.28888888888888886, 'weighted avg_support': 83.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 4}]}
{'micro_f1': 0.9109823544903871, 'precision': 0.9109823544903871, 'Slogans_precision': 0.4020618556701031, 'Slogans_recall': 0.33620689655172414, 'Slogans_f1-score': 0.36619718309859156, 'Slogans_support': 116.0, 'micro avg_precision': 0.4020618556701031, 'micro avg_recall': 0.33620689655172414, 'micro avg_f1-score': 0.36619718309859156, 'micro avg_support': 116.0, 'macro avg_precision': 0.4020618556701031, 'macro avg_recall': 0.33620689655172414, 'macro avg_f1-score': 0.36619718309859156, 'macro avg_support': 116.0, 'weighted avg_precision': 0.4020618556701031, 'weighted avg_recall': 0.33620689655172414, 'weighted avg_f1-score': 0.36619718309859156, 'weighted avg_support': 116.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 5}
{'results': [{'micro_f1': 0.8930734790624177, 'precision': 0.8930734790624177, 'Slogans_precision': 0.10309278350515463, 'Slogans_recall': 0.10638297872340426, 'Slogans_f1-score': 0.10471204188481674, 'Slogans_support': 94.0, 'micro avg_precision': 0.10309278350515463, 'micro avg_recall': 0.10638297872340426, 'micro avg_f1-score': 0.10471204188481674, 'micro avg_support': 94.0, 'macro avg_precision': 0.10309278350515463, 'macro avg_recall': 0.10638297872340426, 'macro avg_f1-score': 0.10471204188481674, 'macro avg_support': 94.0, 'weighted avg_precision': 0.10309278350515463, 'weighted avg_recall': 0.10638297872340426, 'weighted avg_f1-score': 0.10471204188481674, 'weighted avg_support': 94.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 0}, {'micro_f1': 0.8949170397682381, 'precision': 0.8949170397682381, 'Slogans_precision': 0.18556701030927836, 'Slogans_recall': 0.23076923076923078, 'Slogans_f1-score': 0.2057142857142857, 'Slogans_support': 78.0, 'micro avg_precision': 0.18556701030927836, 'micro avg_recall': 0.23076923076923078, 'micro avg_f1-score': 0.2057142857142857, 'micro avg_support': 78.0, 'macro avg_precision': 0.18556701030927836, 'macro avg_recall': 0.23076923076923078, 'macro avg_f1-score': 0.2057142857142857, 'macro avg_support': 78.0, 'weighted avg_precision': 0.18556701030927836, 'weighted avg_recall': 0.23076923076923078, 'weighted avg_f1-score': 0.2057142857142857, 'weighted avg_support': 78.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 1}, {'micro_f1': 0.9057150381880432, 'precision': 0.9057150381880432, 'Slogans_precision': 0.2268041237113402, 'Slogans_recall': 0.2391304347826087, 'Slogans_f1-score': 0.2328042328042328, 'Slogans_support': 92.0, 'micro avg_precision': 0.2268041237113402, 'micro avg_recall': 0.2391304347826087, 'micro avg_f1-score': 0.2328042328042328, 'micro avg_support': 92.0, 'macro avg_precision': 0.2268041237113402, 'macro avg_recall': 0.2391304347826087, 'macro avg_f1-score': 0.2328042328042328, 'macro avg_support': 92.0, 'weighted avg_precision': 0.2268041237113402, 'weighted avg_recall': 0.2391304347826087, 'weighted avg_f1-score': 0.2328042328042328, 'weighted avg_support': 92.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 2}, {'micro_f1': 0.9151962075322623, 'precision': 0.9151962075322623, 'Slogans_precision': 0.29896907216494845, 'Slogans_recall': 0.31521739130434784, 'Slogans_f1-score': 0.3068783068783069, 'Slogans_support': 92.0, 'micro avg_precision': 0.29896907216494845, 'micro avg_recall': 0.31521739130434784, 'micro avg_f1-score': 0.3068783068783069, 'micro avg_support': 92.0, 'macro avg_precision': 0.29896907216494845, 'macro avg_recall': 0.31521739130434784, 'macro avg_f1-score': 0.3068783068783069, 'macro avg_support': 92.0, 'weighted avg_precision': 0.29896907216494845, 'weighted avg_recall': 0.31521739130434784, 'weighted avg_f1-score': 0.3068783068783069, 'weighted avg_support': 92.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 3}, {'micro_f1': 0.8983407953647616, 'precision': 0.8983407953647616, 'Slogans_precision': 0.26804123711340205, 'Slogans_recall': 0.3132530120481928, 'Slogans_f1-score': 0.28888888888888886, 'Slogans_support': 83.0, 'micro avg_precision': 0.26804123711340205, 'micro avg_recall': 0.3132530120481928, 'micro avg_f1-score': 0.28888888888888886, 'micro avg_support': 83.0, 'macro avg_precision': 0.26804123711340205, 'macro avg_recall': 0.3132530120481928, 'macro avg_f1-score': 0.28888888888888886, 'macro avg_support': 83.0, 'weighted avg_precision': 0.26804123711340205, 'weighted avg_recall': 0.3132530120481928, 'weighted avg_f1-score': 0.28888888888888886, 'weighted avg_support': 83.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 4}, {'micro_f1': 0.9109823544903871, 'precision': 0.9109823544903871, 'Slogans_precision': 0.4020618556701031, 'Slogans_recall': 0.33620689655172414, 'Slogans_f1-score': 0.36619718309859156, 'Slogans_support': 116.0, 'micro avg_precision': 0.4020618556701031, 'micro avg_recall': 0.33620689655172414, 'micro avg_f1-score': 0.36619718309859156, 'micro avg_support': 116.0, 'macro avg_precision': 0.4020618556701031, 'macro avg_recall': 0.33620689655172414, 'macro avg_f1-score': 0.36619718309859156, 'macro avg_support': 116.0, 'weighted avg_precision': 0.4020618556701031, 'weighted avg_recall': 0.33620689655172414, 'weighted avg_f1-score': 0.36619718309859156, 'weighted avg_support': 116.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 5}]}
Best model updated: current epoch macro f1 = 0.36619718309859156
{'micro_f1': 0.9186199631287859, 'precision': 0.9186199631287859, 'Slogans_precision': 0.4020618556701031, 'Slogans_recall': 0.41935483870967744, 'Slogans_f1-score': 0.41052631578947374, 'Slogans_support': 93.0, 'micro avg_precision': 0.4020618556701031, 'micro avg_recall': 0.41935483870967744, 'micro avg_f1-score': 0.41052631578947374, 'micro avg_support': 93.0, 'macro avg_precision': 0.4020618556701031, 'macro avg_recall': 0.41935483870967744, 'macro avg_f1-score': 0.41052631578947374, 'macro avg_support': 93.0, 'weighted avg_precision': 0.40206185567010305, 'weighted avg_recall': 0.41935483870967744, 'weighted avg_f1-score': 0.41052631578947374, 'weighted avg_support': 93.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 6}
{'results': [{'micro_f1': 0.8930734790624177, 'precision': 0.8930734790624177, 'Slogans_precision': 0.10309278350515463, 'Slogans_recall': 0.10638297872340426, 'Slogans_f1-score': 0.10471204188481674, 'Slogans_support': 94.0, 'micro avg_precision': 0.10309278350515463, 'micro avg_recall': 0.10638297872340426, 'micro avg_f1-score': 0.10471204188481674, 'micro avg_support': 94.0, 'macro avg_precision': 0.10309278350515463, 'macro avg_recall': 0.10638297872340426, 'macro avg_f1-score': 0.10471204188481674, 'macro avg_support': 94.0, 'weighted avg_precision': 0.10309278350515463, 'weighted avg_recall': 0.10638297872340426, 'weighted avg_f1-score': 0.10471204188481674, 'weighted avg_support': 94.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 0}, {'micro_f1': 0.8949170397682381, 'precision': 0.8949170397682381, 'Slogans_precision': 0.18556701030927836, 'Slogans_recall': 0.23076923076923078, 'Slogans_f1-score': 0.2057142857142857, 'Slogans_support': 78.0, 'micro avg_precision': 0.18556701030927836, 'micro avg_recall': 0.23076923076923078, 'micro avg_f1-score': 0.2057142857142857, 'micro avg_support': 78.0, 'macro avg_precision': 0.18556701030927836, 'macro avg_recall': 0.23076923076923078, 'macro avg_f1-score': 0.2057142857142857, 'macro avg_support': 78.0, 'weighted avg_precision': 0.18556701030927836, 'weighted avg_recall': 0.23076923076923078, 'weighted avg_f1-score': 0.2057142857142857, 'weighted avg_support': 78.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 1}, {'micro_f1': 0.9057150381880432, 'precision': 0.9057150381880432, 'Slogans_precision': 0.2268041237113402, 'Slogans_recall': 0.2391304347826087, 'Slogans_f1-score': 0.2328042328042328, 'Slogans_support': 92.0, 'micro avg_precision': 0.2268041237113402, 'micro avg_recall': 0.2391304347826087, 'micro avg_f1-score': 0.2328042328042328, 'micro avg_support': 92.0, 'macro avg_precision': 0.2268041237113402, 'macro avg_recall': 0.2391304347826087, 'macro avg_f1-score': 0.2328042328042328, 'macro avg_support': 92.0, 'weighted avg_precision': 0.2268041237113402, 'weighted avg_recall': 0.2391304347826087, 'weighted avg_f1-score': 0.2328042328042328, 'weighted avg_support': 92.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 2}, {'micro_f1': 0.9151962075322623, 'precision': 0.9151962075322623, 'Slogans_precision': 0.29896907216494845, 'Slogans_recall': 0.31521739130434784, 'Slogans_f1-score': 0.3068783068783069, 'Slogans_support': 92.0, 'micro avg_precision': 0.29896907216494845, 'micro avg_recall': 0.31521739130434784, 'micro avg_f1-score': 0.3068783068783069, 'micro avg_support': 92.0, 'macro avg_precision': 0.29896907216494845, 'macro avg_recall': 0.31521739130434784, 'macro avg_f1-score': 0.3068783068783069, 'macro avg_support': 92.0, 'weighted avg_precision': 0.29896907216494845, 'weighted avg_recall': 0.31521739130434784, 'weighted avg_f1-score': 0.3068783068783069, 'weighted avg_support': 92.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 3}, {'micro_f1': 0.8983407953647616, 'precision': 0.8983407953647616, 'Slogans_precision': 0.26804123711340205, 'Slogans_recall': 0.3132530120481928, 'Slogans_f1-score': 0.28888888888888886, 'Slogans_support': 83.0, 'micro avg_precision': 0.26804123711340205, 'micro avg_recall': 0.3132530120481928, 'micro avg_f1-score': 0.28888888888888886, 'micro avg_support': 83.0, 'macro avg_precision': 0.26804123711340205, 'macro avg_recall': 0.3132530120481928, 'macro avg_f1-score': 0.28888888888888886, 'macro avg_support': 83.0, 'weighted avg_precision': 0.26804123711340205, 'weighted avg_recall': 0.3132530120481928, 'weighted avg_f1-score': 0.28888888888888886, 'weighted avg_support': 83.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 4}, {'micro_f1': 0.9109823544903871, 'precision': 0.9109823544903871, 'Slogans_precision': 0.4020618556701031, 'Slogans_recall': 0.33620689655172414, 'Slogans_f1-score': 0.36619718309859156, 'Slogans_support': 116.0, 'micro avg_precision': 0.4020618556701031, 'micro avg_recall': 0.33620689655172414, 'micro avg_f1-score': 0.36619718309859156, 'micro avg_support': 116.0, 'macro avg_precision': 0.4020618556701031, 'macro avg_recall': 0.33620689655172414, 'macro avg_f1-score': 0.36619718309859156, 'macro avg_support': 116.0, 'weighted avg_precision': 0.4020618556701031, 'weighted avg_recall': 0.33620689655172414, 'weighted avg_f1-score': 0.36619718309859156, 'weighted avg_support': 116.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 5}, {'micro_f1': 0.9186199631287859, 'precision': 0.9186199631287859, 'Slogans_precision': 0.4020618556701031, 'Slogans_recall': 0.41935483870967744, 'Slogans_f1-score': 0.41052631578947374, 'Slogans_support': 93.0, 'micro avg_precision': 0.4020618556701031, 'micro avg_recall': 0.41935483870967744, 'micro avg_f1-score': 0.41052631578947374, 'micro avg_support': 93.0, 'macro avg_precision': 0.4020618556701031, 'macro avg_recall': 0.41935483870967744, 'macro avg_f1-score': 0.41052631578947374, 'macro avg_support': 93.0, 'weighted avg_precision': 0.40206185567010305, 'weighted avg_recall': 0.41935483870967744, 'weighted avg_f1-score': 0.41052631578947374, 'weighted avg_support': 93.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 6}]}
Best model updated: current epoch macro f1 = 0.41052631578947374
{'micro_f1': 0.9262575717671846, 'precision': 0.9262575717671846, 'Slogans_precision': 0.4329896907216495, 'Slogans_recall': 0.4158415841584158, 'Slogans_f1-score': 0.4242424242424243, 'Slogans_support': 101.0, 'micro avg_precision': 0.4329896907216495, 'micro avg_recall': 0.4158415841584158, 'micro avg_f1-score': 0.4242424242424243, 'micro avg_support': 101.0, 'macro avg_precision': 0.4329896907216495, 'macro avg_recall': 0.4158415841584158, 'macro avg_f1-score': 0.4242424242424243, 'macro avg_support': 101.0, 'weighted avg_precision': 0.4329896907216495, 'weighted avg_recall': 0.4158415841584158, 'weighted avg_f1-score': 0.42424242424242437, 'weighted avg_support': 101.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 7}
{'results': [{'micro_f1': 0.8930734790624177, 'precision': 0.8930734790624177, 'Slogans_precision': 0.10309278350515463, 'Slogans_recall': 0.10638297872340426, 'Slogans_f1-score': 0.10471204188481674, 'Slogans_support': 94.0, 'micro avg_precision': 0.10309278350515463, 'micro avg_recall': 0.10638297872340426, 'micro avg_f1-score': 0.10471204188481674, 'micro avg_support': 94.0, 'macro avg_precision': 0.10309278350515463, 'macro avg_recall': 0.10638297872340426, 'macro avg_f1-score': 0.10471204188481674, 'macro avg_support': 94.0, 'weighted avg_precision': 0.10309278350515463, 'weighted avg_recall': 0.10638297872340426, 'weighted avg_f1-score': 0.10471204188481674, 'weighted avg_support': 94.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 0}, {'micro_f1': 0.8949170397682381, 'precision': 0.8949170397682381, 'Slogans_precision': 0.18556701030927836, 'Slogans_recall': 0.23076923076923078, 'Slogans_f1-score': 0.2057142857142857, 'Slogans_support': 78.0, 'micro avg_precision': 0.18556701030927836, 'micro avg_recall': 0.23076923076923078, 'micro avg_f1-score': 0.2057142857142857, 'micro avg_support': 78.0, 'macro avg_precision': 0.18556701030927836, 'macro avg_recall': 0.23076923076923078, 'macro avg_f1-score': 0.2057142857142857, 'macro avg_support': 78.0, 'weighted avg_precision': 0.18556701030927836, 'weighted avg_recall': 0.23076923076923078, 'weighted avg_f1-score': 0.2057142857142857, 'weighted avg_support': 78.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 1}, {'micro_f1': 0.9057150381880432, 'precision': 0.9057150381880432, 'Slogans_precision': 0.2268041237113402, 'Slogans_recall': 0.2391304347826087, 'Slogans_f1-score': 0.2328042328042328, 'Slogans_support': 92.0, 'micro avg_precision': 0.2268041237113402, 'micro avg_recall': 0.2391304347826087, 'micro avg_f1-score': 0.2328042328042328, 'micro avg_support': 92.0, 'macro avg_precision': 0.2268041237113402, 'macro avg_recall': 0.2391304347826087, 'macro avg_f1-score': 0.2328042328042328, 'macro avg_support': 92.0, 'weighted avg_precision': 0.2268041237113402, 'weighted avg_recall': 0.2391304347826087, 'weighted avg_f1-score': 0.2328042328042328, 'weighted avg_support': 92.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 2}, {'micro_f1': 0.9151962075322623, 'precision': 0.9151962075322623, 'Slogans_precision': 0.29896907216494845, 'Slogans_recall': 0.31521739130434784, 'Slogans_f1-score': 0.3068783068783069, 'Slogans_support': 92.0, 'micro avg_precision': 0.29896907216494845, 'micro avg_recall': 0.31521739130434784, 'micro avg_f1-score': 0.3068783068783069, 'micro avg_support': 92.0, 'macro avg_precision': 0.29896907216494845, 'macro avg_recall': 0.31521739130434784, 'macro avg_f1-score': 0.3068783068783069, 'macro avg_support': 92.0, 'weighted avg_precision': 0.29896907216494845, 'weighted avg_recall': 0.31521739130434784, 'weighted avg_f1-score': 0.3068783068783069, 'weighted avg_support': 92.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 3}, {'micro_f1': 0.8983407953647616, 'precision': 0.8983407953647616, 'Slogans_precision': 0.26804123711340205, 'Slogans_recall': 0.3132530120481928, 'Slogans_f1-score': 0.28888888888888886, 'Slogans_support': 83.0, 'micro avg_precision': 0.26804123711340205, 'micro avg_recall': 0.3132530120481928, 'micro avg_f1-score': 0.28888888888888886, 'micro avg_support': 83.0, 'macro avg_precision': 0.26804123711340205, 'macro avg_recall': 0.3132530120481928, 'macro avg_f1-score': 0.28888888888888886, 'macro avg_support': 83.0, 'weighted avg_precision': 0.26804123711340205, 'weighted avg_recall': 0.3132530120481928, 'weighted avg_f1-score': 0.28888888888888886, 'weighted avg_support': 83.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 4}, {'micro_f1': 0.9109823544903871, 'precision': 0.9109823544903871, 'Slogans_precision': 0.4020618556701031, 'Slogans_recall': 0.33620689655172414, 'Slogans_f1-score': 0.36619718309859156, 'Slogans_support': 116.0, 'micro avg_precision': 0.4020618556701031, 'micro avg_recall': 0.33620689655172414, 'micro avg_f1-score': 0.36619718309859156, 'micro avg_support': 116.0, 'macro avg_precision': 0.4020618556701031, 'macro avg_recall': 0.33620689655172414, 'macro avg_f1-score': 0.36619718309859156, 'macro avg_support': 116.0, 'weighted avg_precision': 0.4020618556701031, 'weighted avg_recall': 0.33620689655172414, 'weighted avg_f1-score': 0.36619718309859156, 'weighted avg_support': 116.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 5}, {'micro_f1': 0.9186199631287859, 'precision': 0.9186199631287859, 'Slogans_precision': 0.4020618556701031, 'Slogans_recall': 0.41935483870967744, 'Slogans_f1-score': 0.41052631578947374, 'Slogans_support': 93.0, 'micro avg_precision': 0.4020618556701031, 'micro avg_recall': 0.41935483870967744, 'micro avg_f1-score': 0.41052631578947374, 'micro avg_support': 93.0, 'macro avg_precision': 0.4020618556701031, 'macro avg_recall': 0.41935483870967744, 'macro avg_f1-score': 0.41052631578947374, 'macro avg_support': 93.0, 'weighted avg_precision': 0.40206185567010305, 'weighted avg_recall': 0.41935483870967744, 'weighted avg_f1-score': 0.41052631578947374, 'weighted avg_support': 93.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 6}, {'micro_f1': 0.9262575717671846, 'precision': 0.9262575717671846, 'Slogans_precision': 0.4329896907216495, 'Slogans_recall': 0.4158415841584158, 'Slogans_f1-score': 0.4242424242424243, 'Slogans_support': 101.0, 'micro avg_precision': 0.4329896907216495, 'micro avg_recall': 0.4158415841584158, 'micro avg_f1-score': 0.4242424242424243, 'micro avg_support': 101.0, 'macro avg_precision': 0.4329896907216495, 'macro avg_recall': 0.4158415841584158, 'macro avg_f1-score': 0.4242424242424243, 'macro avg_support': 101.0, 'weighted avg_precision': 0.4329896907216495, 'weighted avg_recall': 0.4158415841584158, 'weighted avg_f1-score': 0.42424242424242437, 'weighted avg_support': 101.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 7}]}
Best model updated: current epoch macro f1 = 0.4242424242424243
{'micro_f1': 0.9230971819857783, 'precision': 0.9230971819857783, 'Slogans_precision': 0.44329896907216493, 'Slogans_recall': 0.40186915887850466, 'Slogans_f1-score': 0.4215686274509804, 'Slogans_support': 107.0, 'micro avg_precision': 0.44329896907216493, 'micro avg_recall': 0.40186915887850466, 'micro avg_f1-score': 0.4215686274509804, 'micro avg_support': 107.0, 'macro avg_precision': 0.44329896907216493, 'macro avg_recall': 0.40186915887850466, 'macro avg_f1-score': 0.4215686274509804, 'macro avg_support': 107.0, 'weighted avg_precision': 0.44329896907216493, 'weighted avg_recall': 0.40186915887850466, 'weighted avg_f1-score': 0.4215686274509804, 'weighted avg_support': 107.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 8}
{'results': [{'micro_f1': 0.8930734790624177, 'precision': 0.8930734790624177, 'Slogans_precision': 0.10309278350515463, 'Slogans_recall': 0.10638297872340426, 'Slogans_f1-score': 0.10471204188481674, 'Slogans_support': 94.0, 'micro avg_precision': 0.10309278350515463, 'micro avg_recall': 0.10638297872340426, 'micro avg_f1-score': 0.10471204188481674, 'micro avg_support': 94.0, 'macro avg_precision': 0.10309278350515463, 'macro avg_recall': 0.10638297872340426, 'macro avg_f1-score': 0.10471204188481674, 'macro avg_support': 94.0, 'weighted avg_precision': 0.10309278350515463, 'weighted avg_recall': 0.10638297872340426, 'weighted avg_f1-score': 0.10471204188481674, 'weighted avg_support': 94.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 0}, {'micro_f1': 0.8949170397682381, 'precision': 0.8949170397682381, 'Slogans_precision': 0.18556701030927836, 'Slogans_recall': 0.23076923076923078, 'Slogans_f1-score': 0.2057142857142857, 'Slogans_support': 78.0, 'micro avg_precision': 0.18556701030927836, 'micro avg_recall': 0.23076923076923078, 'micro avg_f1-score': 0.2057142857142857, 'micro avg_support': 78.0, 'macro avg_precision': 0.18556701030927836, 'macro avg_recall': 0.23076923076923078, 'macro avg_f1-score': 0.2057142857142857, 'macro avg_support': 78.0, 'weighted avg_precision': 0.18556701030927836, 'weighted avg_recall': 0.23076923076923078, 'weighted avg_f1-score': 0.2057142857142857, 'weighted avg_support': 78.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 1}, {'micro_f1': 0.9057150381880432, 'precision': 0.9057150381880432, 'Slogans_precision': 0.2268041237113402, 'Slogans_recall': 0.2391304347826087, 'Slogans_f1-score': 0.2328042328042328, 'Slogans_support': 92.0, 'micro avg_precision': 0.2268041237113402, 'micro avg_recall': 0.2391304347826087, 'micro avg_f1-score': 0.2328042328042328, 'micro avg_support': 92.0, 'macro avg_precision': 0.2268041237113402, 'macro avg_recall': 0.2391304347826087, 'macro avg_f1-score': 0.2328042328042328, 'macro avg_support': 92.0, 'weighted avg_precision': 0.2268041237113402, 'weighted avg_recall': 0.2391304347826087, 'weighted avg_f1-score': 0.2328042328042328, 'weighted avg_support': 92.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 2}, {'micro_f1': 0.9151962075322623, 'precision': 0.9151962075322623, 'Slogans_precision': 0.29896907216494845, 'Slogans_recall': 0.31521739130434784, 'Slogans_f1-score': 0.3068783068783069, 'Slogans_support': 92.0, 'micro avg_precision': 0.29896907216494845, 'micro avg_recall': 0.31521739130434784, 'micro avg_f1-score': 0.3068783068783069, 'micro avg_support': 92.0, 'macro avg_precision': 0.29896907216494845, 'macro avg_recall': 0.31521739130434784, 'macro avg_f1-score': 0.3068783068783069, 'macro avg_support': 92.0, 'weighted avg_precision': 0.29896907216494845, 'weighted avg_recall': 0.31521739130434784, 'weighted avg_f1-score': 0.3068783068783069, 'weighted avg_support': 92.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 3}, {'micro_f1': 0.8983407953647616, 'precision': 0.8983407953647616, 'Slogans_precision': 0.26804123711340205, 'Slogans_recall': 0.3132530120481928, 'Slogans_f1-score': 0.28888888888888886, 'Slogans_support': 83.0, 'micro avg_precision': 0.26804123711340205, 'micro avg_recall': 0.3132530120481928, 'micro avg_f1-score': 0.28888888888888886, 'micro avg_support': 83.0, 'macro avg_precision': 0.26804123711340205, 'macro avg_recall': 0.3132530120481928, 'macro avg_f1-score': 0.28888888888888886, 'macro avg_support': 83.0, 'weighted avg_precision': 0.26804123711340205, 'weighted avg_recall': 0.3132530120481928, 'weighted avg_f1-score': 0.28888888888888886, 'weighted avg_support': 83.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 4}, {'micro_f1': 0.9109823544903871, 'precision': 0.9109823544903871, 'Slogans_precision': 0.4020618556701031, 'Slogans_recall': 0.33620689655172414, 'Slogans_f1-score': 0.36619718309859156, 'Slogans_support': 116.0, 'micro avg_precision': 0.4020618556701031, 'micro avg_recall': 0.33620689655172414, 'micro avg_f1-score': 0.36619718309859156, 'micro avg_support': 116.0, 'macro avg_precision': 0.4020618556701031, 'macro avg_recall': 0.33620689655172414, 'macro avg_f1-score': 0.36619718309859156, 'macro avg_support': 116.0, 'weighted avg_precision': 0.4020618556701031, 'weighted avg_recall': 0.33620689655172414, 'weighted avg_f1-score': 0.36619718309859156, 'weighted avg_support': 116.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 5}, {'micro_f1': 0.9186199631287859, 'precision': 0.9186199631287859, 'Slogans_precision': 0.4020618556701031, 'Slogans_recall': 0.41935483870967744, 'Slogans_f1-score': 0.41052631578947374, 'Slogans_support': 93.0, 'micro avg_precision': 0.4020618556701031, 'micro avg_recall': 0.41935483870967744, 'micro avg_f1-score': 0.41052631578947374, 'micro avg_support': 93.0, 'macro avg_precision': 0.4020618556701031, 'macro avg_recall': 0.41935483870967744, 'macro avg_f1-score': 0.41052631578947374, 'macro avg_support': 93.0, 'weighted avg_precision': 0.40206185567010305, 'weighted avg_recall': 0.41935483870967744, 'weighted avg_f1-score': 0.41052631578947374, 'weighted avg_support': 93.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 6}, {'micro_f1': 0.9262575717671846, 'precision': 0.9262575717671846, 'Slogans_precision': 0.4329896907216495, 'Slogans_recall': 0.4158415841584158, 'Slogans_f1-score': 0.4242424242424243, 'Slogans_support': 101.0, 'micro avg_precision': 0.4329896907216495, 'micro avg_recall': 0.4158415841584158, 'micro avg_f1-score': 0.4242424242424243, 'micro avg_support': 101.0, 'macro avg_precision': 0.4329896907216495, 'macro avg_recall': 0.4158415841584158, 'macro avg_f1-score': 0.4242424242424243, 'macro avg_support': 101.0, 'weighted avg_precision': 0.4329896907216495, 'weighted avg_recall': 0.4158415841584158, 'weighted avg_f1-score': 0.42424242424242437, 'weighted avg_support': 101.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 7}, {'micro_f1': 0.9230971819857783, 'precision': 0.9230971819857783, 'Slogans_precision': 0.44329896907216493, 'Slogans_recall': 0.40186915887850466, 'Slogans_f1-score': 0.4215686274509804, 'Slogans_support': 107.0, 'micro avg_precision': 0.44329896907216493, 'micro avg_recall': 0.40186915887850466, 'micro avg_f1-score': 0.4215686274509804, 'micro avg_support': 107.0, 'macro avg_precision': 0.44329896907216493, 'macro avg_recall': 0.40186915887850466, 'macro avg_f1-score': 0.4215686274509804, 'macro avg_support': 107.0, 'weighted avg_precision': 0.44329896907216493, 'weighted avg_recall': 0.40186915887850466, 'weighted avg_f1-score': 0.4215686274509804, 'weighted avg_support': 107.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 8}]}
{'micro_f1': 0.9265209375823018, 'precision': 0.9265209375823018, 'Slogans_precision': 0.4845360824742268, 'Slogans_recall': 0.4017094017094017, 'Slogans_f1-score': 0.4392523364485982, 'Slogans_support': 117.0, 'micro avg_precision': 0.4845360824742268, 'micro avg_recall': 0.4017094017094017, 'micro avg_f1-score': 0.4392523364485982, 'micro avg_support': 117.0, 'macro avg_precision': 0.4845360824742268, 'macro avg_recall': 0.4017094017094017, 'macro avg_f1-score': 0.4392523364485982, 'macro avg_support': 117.0, 'weighted avg_precision': 0.4845360824742268, 'weighted avg_recall': 0.4017094017094017, 'weighted avg_f1-score': 0.4392523364485982, 'weighted avg_support': 117.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 9}
{'results': [{'micro_f1': 0.8930734790624177, 'precision': 0.8930734790624177, 'Slogans_precision': 0.10309278350515463, 'Slogans_recall': 0.10638297872340426, 'Slogans_f1-score': 0.10471204188481674, 'Slogans_support': 94.0, 'micro avg_precision': 0.10309278350515463, 'micro avg_recall': 0.10638297872340426, 'micro avg_f1-score': 0.10471204188481674, 'micro avg_support': 94.0, 'macro avg_precision': 0.10309278350515463, 'macro avg_recall': 0.10638297872340426, 'macro avg_f1-score': 0.10471204188481674, 'macro avg_support': 94.0, 'weighted avg_precision': 0.10309278350515463, 'weighted avg_recall': 0.10638297872340426, 'weighted avg_f1-score': 0.10471204188481674, 'weighted avg_support': 94.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 0}, {'micro_f1': 0.8949170397682381, 'precision': 0.8949170397682381, 'Slogans_precision': 0.18556701030927836, 'Slogans_recall': 0.23076923076923078, 'Slogans_f1-score': 0.2057142857142857, 'Slogans_support': 78.0, 'micro avg_precision': 0.18556701030927836, 'micro avg_recall': 0.23076923076923078, 'micro avg_f1-score': 0.2057142857142857, 'micro avg_support': 78.0, 'macro avg_precision': 0.18556701030927836, 'macro avg_recall': 0.23076923076923078, 'macro avg_f1-score': 0.2057142857142857, 'macro avg_support': 78.0, 'weighted avg_precision': 0.18556701030927836, 'weighted avg_recall': 0.23076923076923078, 'weighted avg_f1-score': 0.2057142857142857, 'weighted avg_support': 78.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 1}, {'micro_f1': 0.9057150381880432, 'precision': 0.9057150381880432, 'Slogans_precision': 0.2268041237113402, 'Slogans_recall': 0.2391304347826087, 'Slogans_f1-score': 0.2328042328042328, 'Slogans_support': 92.0, 'micro avg_precision': 0.2268041237113402, 'micro avg_recall': 0.2391304347826087, 'micro avg_f1-score': 0.2328042328042328, 'micro avg_support': 92.0, 'macro avg_precision': 0.2268041237113402, 'macro avg_recall': 0.2391304347826087, 'macro avg_f1-score': 0.2328042328042328, 'macro avg_support': 92.0, 'weighted avg_precision': 0.2268041237113402, 'weighted avg_recall': 0.2391304347826087, 'weighted avg_f1-score': 0.2328042328042328, 'weighted avg_support': 92.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 2}, {'micro_f1': 0.9151962075322623, 'precision': 0.9151962075322623, 'Slogans_precision': 0.29896907216494845, 'Slogans_recall': 0.31521739130434784, 'Slogans_f1-score': 0.3068783068783069, 'Slogans_support': 92.0, 'micro avg_precision': 0.29896907216494845, 'micro avg_recall': 0.31521739130434784, 'micro avg_f1-score': 0.3068783068783069, 'micro avg_support': 92.0, 'macro avg_precision': 0.29896907216494845, 'macro avg_recall': 0.31521739130434784, 'macro avg_f1-score': 0.3068783068783069, 'macro avg_support': 92.0, 'weighted avg_precision': 0.29896907216494845, 'weighted avg_recall': 0.31521739130434784, 'weighted avg_f1-score': 0.3068783068783069, 'weighted avg_support': 92.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 3}, {'micro_f1': 0.8983407953647616, 'precision': 0.8983407953647616, 'Slogans_precision': 0.26804123711340205, 'Slogans_recall': 0.3132530120481928, 'Slogans_f1-score': 0.28888888888888886, 'Slogans_support': 83.0, 'micro avg_precision': 0.26804123711340205, 'micro avg_recall': 0.3132530120481928, 'micro avg_f1-score': 0.28888888888888886, 'micro avg_support': 83.0, 'macro avg_precision': 0.26804123711340205, 'macro avg_recall': 0.3132530120481928, 'macro avg_f1-score': 0.28888888888888886, 'macro avg_support': 83.0, 'weighted avg_precision': 0.26804123711340205, 'weighted avg_recall': 0.3132530120481928, 'weighted avg_f1-score': 0.28888888888888886, 'weighted avg_support': 83.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 4}, {'micro_f1': 0.9109823544903871, 'precision': 0.9109823544903871, 'Slogans_precision': 0.4020618556701031, 'Slogans_recall': 0.33620689655172414, 'Slogans_f1-score': 0.36619718309859156, 'Slogans_support': 116.0, 'micro avg_precision': 0.4020618556701031, 'micro avg_recall': 0.33620689655172414, 'micro avg_f1-score': 0.36619718309859156, 'micro avg_support': 116.0, 'macro avg_precision': 0.4020618556701031, 'macro avg_recall': 0.33620689655172414, 'macro avg_f1-score': 0.36619718309859156, 'macro avg_support': 116.0, 'weighted avg_precision': 0.4020618556701031, 'weighted avg_recall': 0.33620689655172414, 'weighted avg_f1-score': 0.36619718309859156, 'weighted avg_support': 116.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 5}, {'micro_f1': 0.9186199631287859, 'precision': 0.9186199631287859, 'Slogans_precision': 0.4020618556701031, 'Slogans_recall': 0.41935483870967744, 'Slogans_f1-score': 0.41052631578947374, 'Slogans_support': 93.0, 'micro avg_precision': 0.4020618556701031, 'micro avg_recall': 0.41935483870967744, 'micro avg_f1-score': 0.41052631578947374, 'micro avg_support': 93.0, 'macro avg_precision': 0.4020618556701031, 'macro avg_recall': 0.41935483870967744, 'macro avg_f1-score': 0.41052631578947374, 'macro avg_support': 93.0, 'weighted avg_precision': 0.40206185567010305, 'weighted avg_recall': 0.41935483870967744, 'weighted avg_f1-score': 0.41052631578947374, 'weighted avg_support': 93.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 6}, {'micro_f1': 0.9262575717671846, 'precision': 0.9262575717671846, 'Slogans_precision': 0.4329896907216495, 'Slogans_recall': 0.4158415841584158, 'Slogans_f1-score': 0.4242424242424243, 'Slogans_support': 101.0, 'micro avg_precision': 0.4329896907216495, 'micro avg_recall': 0.4158415841584158, 'micro avg_f1-score': 0.4242424242424243, 'micro avg_support': 101.0, 'macro avg_precision': 0.4329896907216495, 'macro avg_recall': 0.4158415841584158, 'macro avg_f1-score': 0.4242424242424243, 'macro avg_support': 101.0, 'weighted avg_precision': 0.4329896907216495, 'weighted avg_recall': 0.4158415841584158, 'weighted avg_f1-score': 0.42424242424242437, 'weighted avg_support': 101.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 7}, {'micro_f1': 0.9230971819857783, 'precision': 0.9230971819857783, 'Slogans_precision': 0.44329896907216493, 'Slogans_recall': 0.40186915887850466, 'Slogans_f1-score': 0.4215686274509804, 'Slogans_support': 107.0, 'micro avg_precision': 0.44329896907216493, 'micro avg_recall': 0.40186915887850466, 'micro avg_f1-score': 0.4215686274509804, 'micro avg_support': 107.0, 'macro avg_precision': 0.44329896907216493, 'macro avg_recall': 0.40186915887850466, 'macro avg_f1-score': 0.4215686274509804, 'macro avg_support': 107.0, 'weighted avg_precision': 0.44329896907216493, 'weighted avg_recall': 0.40186915887850466, 'weighted avg_f1-score': 0.4215686274509804, 'weighted avg_support': 107.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 8}, {'micro_f1': 0.9265209375823018, 'precision': 0.9265209375823018, 'Slogans_precision': 0.4845360824742268, 'Slogans_recall': 0.4017094017094017, 'Slogans_f1-score': 0.4392523364485982, 'Slogans_support': 117.0, 'micro avg_precision': 0.4845360824742268, 'micro avg_recall': 0.4017094017094017, 'micro avg_f1-score': 0.4392523364485982, 'micro avg_support': 117.0, 'macro avg_precision': 0.4845360824742268, 'macro avg_recall': 0.4017094017094017, 'macro avg_f1-score': 0.4392523364485982, 'macro avg_support': 117.0, 'weighted avg_precision': 0.4845360824742268, 'weighted avg_recall': 0.4017094017094017, 'weighted avg_f1-score': 0.4392523364485982, 'weighted avg_support': 117.0, 'O_support': 3141, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 9}]}
Best model updated: current epoch macro f1 = 0.4392523364485982
Saving model to directory: ./models/M2/2024-05-14-06-51-04_aug_ts0.9/mdeberta-v3-base_11_ME10_target=Slogans_SUBSAMPLED_2024-05-14-06-51-04
Training model no. 12 of 23 for (12, 'Appeal_to_Time') persuasion technique...
{'micro_f1': 0.6134020618556701, 'precision': 0.6134020618556701, 'Appeal_to_Time_precision': 0.0, 'Appeal_to_Time_recall': 0.0, 'Appeal_to_Time_f1-score': 0.0, 'Appeal_to_Time_support': 0.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 0.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 0.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 0.0, 'O_support': 476, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 0}
{'results': [{'micro_f1': 0.6134020618556701, 'precision': 0.6134020618556701, 'Appeal_to_Time_precision': 0.0, 'Appeal_to_Time_recall': 0.0, 'Appeal_to_Time_f1-score': 0.0, 'Appeal_to_Time_support': 0.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 0.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 0.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 0.0, 'O_support': 476, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 0}]}
{'micro_f1': 0.6301546391752577, 'precision': 0.6301546391752577, 'Appeal_to_Time_precision': 0.037037037037037035, 'Appeal_to_Time_recall': 0.045454545454545456, 'Appeal_to_Time_f1-score': 0.04081632653061224, 'Appeal_to_Time_support': 22.0, 'micro avg_precision': 0.037037037037037035, 'micro avg_recall': 0.045454545454545456, 'micro avg_f1-score': 0.04081632653061224, 'micro avg_support': 22.0, 'macro avg_precision': 0.037037037037037035, 'macro avg_recall': 0.045454545454545456, 'macro avg_f1-score': 0.04081632653061224, 'macro avg_support': 22.0, 'weighted avg_precision': 0.037037037037037035, 'weighted avg_recall': 0.045454545454545456, 'weighted avg_f1-score': 0.04081632653061224, 'weighted avg_support': 22.0, 'O_support': 476, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 1}
{'results': [{'micro_f1': 0.6134020618556701, 'precision': 0.6134020618556701, 'Appeal_to_Time_precision': 0.0, 'Appeal_to_Time_recall': 0.0, 'Appeal_to_Time_f1-score': 0.0, 'Appeal_to_Time_support': 0.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 0.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 0.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 0.0, 'O_support': 476, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 0}, {'micro_f1': 0.6301546391752577, 'precision': 0.6301546391752577, 'Appeal_to_Time_precision': 0.037037037037037035, 'Appeal_to_Time_recall': 0.045454545454545456, 'Appeal_to_Time_f1-score': 0.04081632653061224, 'Appeal_to_Time_support': 22.0, 'micro avg_precision': 0.037037037037037035, 'micro avg_recall': 0.045454545454545456, 'micro avg_f1-score': 0.04081632653061224, 'micro avg_support': 22.0, 'macro avg_precision': 0.037037037037037035, 'macro avg_recall': 0.045454545454545456, 'macro avg_f1-score': 0.04081632653061224, 'macro avg_support': 22.0, 'weighted avg_precision': 0.037037037037037035, 'weighted avg_recall': 0.045454545454545456, 'weighted avg_f1-score': 0.04081632653061224, 'weighted avg_support': 22.0, 'O_support': 476, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 1}]}
Best model updated: current epoch macro f1 = 0.04081632653061224
{'micro_f1': 0.6920103092783505, 'precision': 0.6920103092783505, 'Appeal_to_Time_precision': 0.037037037037037035, 'Appeal_to_Time_recall': 0.023809523809523808, 'Appeal_to_Time_f1-score': 0.028985507246376812, 'Appeal_to_Time_support': 42.0, 'micro avg_precision': 0.037037037037037035, 'micro avg_recall': 0.023809523809523808, 'micro avg_f1-score': 0.028985507246376812, 'micro avg_support': 42.0, 'macro avg_precision': 0.037037037037037035, 'macro avg_recall': 0.023809523809523808, 'macro avg_f1-score': 0.028985507246376812, 'macro avg_support': 42.0, 'weighted avg_precision': 0.037037037037037035, 'weighted avg_recall': 0.023809523809523808, 'weighted avg_f1-score': 0.028985507246376812, 'weighted avg_support': 42.0, 'O_support': 476, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 2}
{'results': [{'micro_f1': 0.6134020618556701, 'precision': 0.6134020618556701, 'Appeal_to_Time_precision': 0.0, 'Appeal_to_Time_recall': 0.0, 'Appeal_to_Time_f1-score': 0.0, 'Appeal_to_Time_support': 0.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 0.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 0.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 0.0, 'O_support': 476, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 0}, {'micro_f1': 0.6301546391752577, 'precision': 0.6301546391752577, 'Appeal_to_Time_precision': 0.037037037037037035, 'Appeal_to_Time_recall': 0.045454545454545456, 'Appeal_to_Time_f1-score': 0.04081632653061224, 'Appeal_to_Time_support': 22.0, 'micro avg_precision': 0.037037037037037035, 'micro avg_recall': 0.045454545454545456, 'micro avg_f1-score': 0.04081632653061224, 'micro avg_support': 22.0, 'macro avg_precision': 0.037037037037037035, 'macro avg_recall': 0.045454545454545456, 'macro avg_f1-score': 0.04081632653061224, 'macro avg_support': 22.0, 'weighted avg_precision': 0.037037037037037035, 'weighted avg_recall': 0.045454545454545456, 'weighted avg_f1-score': 0.04081632653061224, 'weighted avg_support': 22.0, 'O_support': 476, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 1}, {'micro_f1': 0.6920103092783505, 'precision': 0.6920103092783505, 'Appeal_to_Time_precision': 0.037037037037037035, 'Appeal_to_Time_recall': 0.023809523809523808, 'Appeal_to_Time_f1-score': 0.028985507246376812, 'Appeal_to_Time_support': 42.0, 'micro avg_precision': 0.037037037037037035, 'micro avg_recall': 0.023809523809523808, 'micro avg_f1-score': 0.028985507246376812, 'micro avg_support': 42.0, 'macro avg_precision': 0.037037037037037035, 'macro avg_recall': 0.023809523809523808, 'macro avg_f1-score': 0.028985507246376812, 'macro avg_support': 42.0, 'weighted avg_precision': 0.037037037037037035, 'weighted avg_recall': 0.023809523809523808, 'weighted avg_f1-score': 0.028985507246376812, 'weighted avg_support': 42.0, 'O_support': 476, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 2}]}
{'micro_f1': 0.7036082474226805, 'precision': 0.7036082474226805, 'Appeal_to_Time_precision': 0.07407407407407407, 'Appeal_to_Time_recall': 0.06896551724137931, 'Appeal_to_Time_f1-score': 0.07142857142857142, 'Appeal_to_Time_support': 29.0, 'micro avg_precision': 0.07407407407407407, 'micro avg_recall': 0.06896551724137931, 'micro avg_f1-score': 0.07142857142857142, 'micro avg_support': 29.0, 'macro avg_precision': 0.07407407407407407, 'macro avg_recall': 0.06896551724137931, 'macro avg_f1-score': 0.07142857142857142, 'macro avg_support': 29.0, 'weighted avg_precision': 0.07407407407407407, 'weighted avg_recall': 0.06896551724137931, 'weighted avg_f1-score': 0.07142857142857142, 'weighted avg_support': 29.0, 'O_support': 476, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 3}
{'results': [{'micro_f1': 0.6134020618556701, 'precision': 0.6134020618556701, 'Appeal_to_Time_precision': 0.0, 'Appeal_to_Time_recall': 0.0, 'Appeal_to_Time_f1-score': 0.0, 'Appeal_to_Time_support': 0.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 0.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 0.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 0.0, 'O_support': 476, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 0}, {'micro_f1': 0.6301546391752577, 'precision': 0.6301546391752577, 'Appeal_to_Time_precision': 0.037037037037037035, 'Appeal_to_Time_recall': 0.045454545454545456, 'Appeal_to_Time_f1-score': 0.04081632653061224, 'Appeal_to_Time_support': 22.0, 'micro avg_precision': 0.037037037037037035, 'micro avg_recall': 0.045454545454545456, 'micro avg_f1-score': 0.04081632653061224, 'micro avg_support': 22.0, 'macro avg_precision': 0.037037037037037035, 'macro avg_recall': 0.045454545454545456, 'macro avg_f1-score': 0.04081632653061224, 'macro avg_support': 22.0, 'weighted avg_precision': 0.037037037037037035, 'weighted avg_recall': 0.045454545454545456, 'weighted avg_f1-score': 0.04081632653061224, 'weighted avg_support': 22.0, 'O_support': 476, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 1}, {'micro_f1': 0.6920103092783505, 'precision': 0.6920103092783505, 'Appeal_to_Time_precision': 0.037037037037037035, 'Appeal_to_Time_recall': 0.023809523809523808, 'Appeal_to_Time_f1-score': 0.028985507246376812, 'Appeal_to_Time_support': 42.0, 'micro avg_precision': 0.037037037037037035, 'micro avg_recall': 0.023809523809523808, 'micro avg_f1-score': 0.028985507246376812, 'micro avg_support': 42.0, 'macro avg_precision': 0.037037037037037035, 'macro avg_recall': 0.023809523809523808, 'macro avg_f1-score': 0.028985507246376812, 'macro avg_support': 42.0, 'weighted avg_precision': 0.037037037037037035, 'weighted avg_recall': 0.023809523809523808, 'weighted avg_f1-score': 0.028985507246376812, 'weighted avg_support': 42.0, 'O_support': 476, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 2}, {'micro_f1': 0.7036082474226805, 'precision': 0.7036082474226805, 'Appeal_to_Time_precision': 0.07407407407407407, 'Appeal_to_Time_recall': 0.06896551724137931, 'Appeal_to_Time_f1-score': 0.07142857142857142, 'Appeal_to_Time_support': 29.0, 'micro avg_precision': 0.07407407407407407, 'micro avg_recall': 0.06896551724137931, 'micro avg_f1-score': 0.07142857142857142, 'micro avg_support': 29.0, 'macro avg_precision': 0.07407407407407407, 'macro avg_recall': 0.06896551724137931, 'macro avg_f1-score': 0.07142857142857142, 'macro avg_support': 29.0, 'weighted avg_precision': 0.07407407407407407, 'weighted avg_recall': 0.06896551724137931, 'weighted avg_f1-score': 0.07142857142857142, 'weighted avg_support': 29.0, 'O_support': 476, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 3}]}
Best model updated: current epoch macro f1 = 0.07142857142857142
{'micro_f1': 0.7551546391752577, 'precision': 0.7551546391752577, 'Appeal_to_Time_precision': 0.14814814814814814, 'Appeal_to_Time_recall': 0.12121212121212122, 'Appeal_to_Time_f1-score': 0.13333333333333333, 'Appeal_to_Time_support': 33.0, 'micro avg_precision': 0.14814814814814814, 'micro avg_recall': 0.12121212121212122, 'micro avg_f1-score': 0.13333333333333333, 'micro avg_support': 33.0, 'macro avg_precision': 0.14814814814814814, 'macro avg_recall': 0.12121212121212122, 'macro avg_f1-score': 0.13333333333333333, 'macro avg_support': 33.0, 'weighted avg_precision': 0.14814814814814814, 'weighted avg_recall': 0.12121212121212122, 'weighted avg_f1-score': 0.13333333333333333, 'weighted avg_support': 33.0, 'O_support': 476, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 4}
{'results': [{'micro_f1': 0.6134020618556701, 'precision': 0.6134020618556701, 'Appeal_to_Time_precision': 0.0, 'Appeal_to_Time_recall': 0.0, 'Appeal_to_Time_f1-score': 0.0, 'Appeal_to_Time_support': 0.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 0.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 0.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 0.0, 'O_support': 476, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 0}, {'micro_f1': 0.6301546391752577, 'precision': 0.6301546391752577, 'Appeal_to_Time_precision': 0.037037037037037035, 'Appeal_to_Time_recall': 0.045454545454545456, 'Appeal_to_Time_f1-score': 0.04081632653061224, 'Appeal_to_Time_support': 22.0, 'micro avg_precision': 0.037037037037037035, 'micro avg_recall': 0.045454545454545456, 'micro avg_f1-score': 0.04081632653061224, 'micro avg_support': 22.0, 'macro avg_precision': 0.037037037037037035, 'macro avg_recall': 0.045454545454545456, 'macro avg_f1-score': 0.04081632653061224, 'macro avg_support': 22.0, 'weighted avg_precision': 0.037037037037037035, 'weighted avg_recall': 0.045454545454545456, 'weighted avg_f1-score': 0.04081632653061224, 'weighted avg_support': 22.0, 'O_support': 476, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 1}, {'micro_f1': 0.6920103092783505, 'precision': 0.6920103092783505, 'Appeal_to_Time_precision': 0.037037037037037035, 'Appeal_to_Time_recall': 0.023809523809523808, 'Appeal_to_Time_f1-score': 0.028985507246376812, 'Appeal_to_Time_support': 42.0, 'micro avg_precision': 0.037037037037037035, 'micro avg_recall': 0.023809523809523808, 'micro avg_f1-score': 0.028985507246376812, 'micro avg_support': 42.0, 'macro avg_precision': 0.037037037037037035, 'macro avg_recall': 0.023809523809523808, 'macro avg_f1-score': 0.028985507246376812, 'macro avg_support': 42.0, 'weighted avg_precision': 0.037037037037037035, 'weighted avg_recall': 0.023809523809523808, 'weighted avg_f1-score': 0.028985507246376812, 'weighted avg_support': 42.0, 'O_support': 476, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 2}, {'micro_f1': 0.7036082474226805, 'precision': 0.7036082474226805, 'Appeal_to_Time_precision': 0.07407407407407407, 'Appeal_to_Time_recall': 0.06896551724137931, 'Appeal_to_Time_f1-score': 0.07142857142857142, 'Appeal_to_Time_support': 29.0, 'micro avg_precision': 0.07407407407407407, 'micro avg_recall': 0.06896551724137931, 'micro avg_f1-score': 0.07142857142857142, 'micro avg_support': 29.0, 'macro avg_precision': 0.07407407407407407, 'macro avg_recall': 0.06896551724137931, 'macro avg_f1-score': 0.07142857142857142, 'macro avg_support': 29.0, 'weighted avg_precision': 0.07407407407407407, 'weighted avg_recall': 0.06896551724137931, 'weighted avg_f1-score': 0.07142857142857142, 'weighted avg_support': 29.0, 'O_support': 476, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 3}, {'micro_f1': 0.7551546391752577, 'precision': 0.7551546391752577, 'Appeal_to_Time_precision': 0.14814814814814814, 'Appeal_to_Time_recall': 0.12121212121212122, 'Appeal_to_Time_f1-score': 0.13333333333333333, 'Appeal_to_Time_support': 33.0, 'micro avg_precision': 0.14814814814814814, 'micro avg_recall': 0.12121212121212122, 'micro avg_f1-score': 0.13333333333333333, 'micro avg_support': 33.0, 'macro avg_precision': 0.14814814814814814, 'macro avg_recall': 0.12121212121212122, 'macro avg_f1-score': 0.13333333333333333, 'macro avg_support': 33.0, 'weighted avg_precision': 0.14814814814814814, 'weighted avg_recall': 0.12121212121212122, 'weighted avg_f1-score': 0.13333333333333333, 'weighted avg_support': 33.0, 'O_support': 476, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 4}]}
Best model updated: current epoch macro f1 = 0.13333333333333333
{'micro_f1': 0.752577319587629, 'precision': 0.7525773195876289, 'Appeal_to_Time_precision': 0.07407407407407407, 'Appeal_to_Time_recall': 0.06451612903225806, 'Appeal_to_Time_f1-score': 0.06896551724137931, 'Appeal_to_Time_support': 31.0, 'micro avg_precision': 0.07407407407407407, 'micro avg_recall': 0.06451612903225806, 'micro avg_f1-score': 0.06896551724137931, 'micro avg_support': 31.0, 'macro avg_precision': 0.07407407407407407, 'macro avg_recall': 0.06451612903225806, 'macro avg_f1-score': 0.06896551724137931, 'macro avg_support': 31.0, 'weighted avg_precision': 0.07407407407407407, 'weighted avg_recall': 0.06451612903225806, 'weighted avg_f1-score': 0.06896551724137931, 'weighted avg_support': 31.0, 'O_support': 476, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 5}
{'results': [{'micro_f1': 0.6134020618556701, 'precision': 0.6134020618556701, 'Appeal_to_Time_precision': 0.0, 'Appeal_to_Time_recall': 0.0, 'Appeal_to_Time_f1-score': 0.0, 'Appeal_to_Time_support': 0.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 0.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 0.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 0.0, 'O_support': 476, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 0}, {'micro_f1': 0.6301546391752577, 'precision': 0.6301546391752577, 'Appeal_to_Time_precision': 0.037037037037037035, 'Appeal_to_Time_recall': 0.045454545454545456, 'Appeal_to_Time_f1-score': 0.04081632653061224, 'Appeal_to_Time_support': 22.0, 'micro avg_precision': 0.037037037037037035, 'micro avg_recall': 0.045454545454545456, 'micro avg_f1-score': 0.04081632653061224, 'micro avg_support': 22.0, 'macro avg_precision': 0.037037037037037035, 'macro avg_recall': 0.045454545454545456, 'macro avg_f1-score': 0.04081632653061224, 'macro avg_support': 22.0, 'weighted avg_precision': 0.037037037037037035, 'weighted avg_recall': 0.045454545454545456, 'weighted avg_f1-score': 0.04081632653061224, 'weighted avg_support': 22.0, 'O_support': 476, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 1}, {'micro_f1': 0.6920103092783505, 'precision': 0.6920103092783505, 'Appeal_to_Time_precision': 0.037037037037037035, 'Appeal_to_Time_recall': 0.023809523809523808, 'Appeal_to_Time_f1-score': 0.028985507246376812, 'Appeal_to_Time_support': 42.0, 'micro avg_precision': 0.037037037037037035, 'micro avg_recall': 0.023809523809523808, 'micro avg_f1-score': 0.028985507246376812, 'micro avg_support': 42.0, 'macro avg_precision': 0.037037037037037035, 'macro avg_recall': 0.023809523809523808, 'macro avg_f1-score': 0.028985507246376812, 'macro avg_support': 42.0, 'weighted avg_precision': 0.037037037037037035, 'weighted avg_recall': 0.023809523809523808, 'weighted avg_f1-score': 0.028985507246376812, 'weighted avg_support': 42.0, 'O_support': 476, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 2}, {'micro_f1': 0.7036082474226805, 'precision': 0.7036082474226805, 'Appeal_to_Time_precision': 0.07407407407407407, 'Appeal_to_Time_recall': 0.06896551724137931, 'Appeal_to_Time_f1-score': 0.07142857142857142, 'Appeal_to_Time_support': 29.0, 'micro avg_precision': 0.07407407407407407, 'micro avg_recall': 0.06896551724137931, 'micro avg_f1-score': 0.07142857142857142, 'micro avg_support': 29.0, 'macro avg_precision': 0.07407407407407407, 'macro avg_recall': 0.06896551724137931, 'macro avg_f1-score': 0.07142857142857142, 'macro avg_support': 29.0, 'weighted avg_precision': 0.07407407407407407, 'weighted avg_recall': 0.06896551724137931, 'weighted avg_f1-score': 0.07142857142857142, 'weighted avg_support': 29.0, 'O_support': 476, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 3}, {'micro_f1': 0.7551546391752577, 'precision': 0.7551546391752577, 'Appeal_to_Time_precision': 0.14814814814814814, 'Appeal_to_Time_recall': 0.12121212121212122, 'Appeal_to_Time_f1-score': 0.13333333333333333, 'Appeal_to_Time_support': 33.0, 'micro avg_precision': 0.14814814814814814, 'micro avg_recall': 0.12121212121212122, 'micro avg_f1-score': 0.13333333333333333, 'micro avg_support': 33.0, 'macro avg_precision': 0.14814814814814814, 'macro avg_recall': 0.12121212121212122, 'macro avg_f1-score': 0.13333333333333333, 'macro avg_support': 33.0, 'weighted avg_precision': 0.14814814814814814, 'weighted avg_recall': 0.12121212121212122, 'weighted avg_f1-score': 0.13333333333333333, 'weighted avg_support': 33.0, 'O_support': 476, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 4}, {'micro_f1': 0.752577319587629, 'precision': 0.7525773195876289, 'Appeal_to_Time_precision': 0.07407407407407407, 'Appeal_to_Time_recall': 0.06451612903225806, 'Appeal_to_Time_f1-score': 0.06896551724137931, 'Appeal_to_Time_support': 31.0, 'micro avg_precision': 0.07407407407407407, 'micro avg_recall': 0.06451612903225806, 'micro avg_f1-score': 0.06896551724137931, 'micro avg_support': 31.0, 'macro avg_precision': 0.07407407407407407, 'macro avg_recall': 0.06451612903225806, 'macro avg_f1-score': 0.06896551724137931, 'macro avg_support': 31.0, 'weighted avg_precision': 0.07407407407407407, 'weighted avg_recall': 0.06451612903225806, 'weighted avg_f1-score': 0.06896551724137931, 'weighted avg_support': 31.0, 'O_support': 476, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 5}]}
{'micro_f1': 0.7603092783505153, 'precision': 0.7603092783505154, 'Appeal_to_Time_precision': 0.07407407407407407, 'Appeal_to_Time_recall': 0.05128205128205128, 'Appeal_to_Time_f1-score': 0.060606060606060615, 'Appeal_to_Time_support': 39.0, 'micro avg_precision': 0.07407407407407407, 'micro avg_recall': 0.05128205128205128, 'micro avg_f1-score': 0.060606060606060615, 'micro avg_support': 39.0, 'macro avg_precision': 0.07407407407407407, 'macro avg_recall': 0.05128205128205128, 'macro avg_f1-score': 0.060606060606060615, 'macro avg_support': 39.0, 'weighted avg_precision': 0.07407407407407407, 'weighted avg_recall': 0.05128205128205128, 'weighted avg_f1-score': 0.06060606060606061, 'weighted avg_support': 39.0, 'O_support': 476, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 6}
{'results': [{'micro_f1': 0.6134020618556701, 'precision': 0.6134020618556701, 'Appeal_to_Time_precision': 0.0, 'Appeal_to_Time_recall': 0.0, 'Appeal_to_Time_f1-score': 0.0, 'Appeal_to_Time_support': 0.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 0.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 0.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 0.0, 'O_support': 476, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 0}, {'micro_f1': 0.6301546391752577, 'precision': 0.6301546391752577, 'Appeal_to_Time_precision': 0.037037037037037035, 'Appeal_to_Time_recall': 0.045454545454545456, 'Appeal_to_Time_f1-score': 0.04081632653061224, 'Appeal_to_Time_support': 22.0, 'micro avg_precision': 0.037037037037037035, 'micro avg_recall': 0.045454545454545456, 'micro avg_f1-score': 0.04081632653061224, 'micro avg_support': 22.0, 'macro avg_precision': 0.037037037037037035, 'macro avg_recall': 0.045454545454545456, 'macro avg_f1-score': 0.04081632653061224, 'macro avg_support': 22.0, 'weighted avg_precision': 0.037037037037037035, 'weighted avg_recall': 0.045454545454545456, 'weighted avg_f1-score': 0.04081632653061224, 'weighted avg_support': 22.0, 'O_support': 476, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 1}, {'micro_f1': 0.6920103092783505, 'precision': 0.6920103092783505, 'Appeal_to_Time_precision': 0.037037037037037035, 'Appeal_to_Time_recall': 0.023809523809523808, 'Appeal_to_Time_f1-score': 0.028985507246376812, 'Appeal_to_Time_support': 42.0, 'micro avg_precision': 0.037037037037037035, 'micro avg_recall': 0.023809523809523808, 'micro avg_f1-score': 0.028985507246376812, 'micro avg_support': 42.0, 'macro avg_precision': 0.037037037037037035, 'macro avg_recall': 0.023809523809523808, 'macro avg_f1-score': 0.028985507246376812, 'macro avg_support': 42.0, 'weighted avg_precision': 0.037037037037037035, 'weighted avg_recall': 0.023809523809523808, 'weighted avg_f1-score': 0.028985507246376812, 'weighted avg_support': 42.0, 'O_support': 476, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 2}, {'micro_f1': 0.7036082474226805, 'precision': 0.7036082474226805, 'Appeal_to_Time_precision': 0.07407407407407407, 'Appeal_to_Time_recall': 0.06896551724137931, 'Appeal_to_Time_f1-score': 0.07142857142857142, 'Appeal_to_Time_support': 29.0, 'micro avg_precision': 0.07407407407407407, 'micro avg_recall': 0.06896551724137931, 'micro avg_f1-score': 0.07142857142857142, 'micro avg_support': 29.0, 'macro avg_precision': 0.07407407407407407, 'macro avg_recall': 0.06896551724137931, 'macro avg_f1-score': 0.07142857142857142, 'macro avg_support': 29.0, 'weighted avg_precision': 0.07407407407407407, 'weighted avg_recall': 0.06896551724137931, 'weighted avg_f1-score': 0.07142857142857142, 'weighted avg_support': 29.0, 'O_support': 476, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 3}, {'micro_f1': 0.7551546391752577, 'precision': 0.7551546391752577, 'Appeal_to_Time_precision': 0.14814814814814814, 'Appeal_to_Time_recall': 0.12121212121212122, 'Appeal_to_Time_f1-score': 0.13333333333333333, 'Appeal_to_Time_support': 33.0, 'micro avg_precision': 0.14814814814814814, 'micro avg_recall': 0.12121212121212122, 'micro avg_f1-score': 0.13333333333333333, 'micro avg_support': 33.0, 'macro avg_precision': 0.14814814814814814, 'macro avg_recall': 0.12121212121212122, 'macro avg_f1-score': 0.13333333333333333, 'macro avg_support': 33.0, 'weighted avg_precision': 0.14814814814814814, 'weighted avg_recall': 0.12121212121212122, 'weighted avg_f1-score': 0.13333333333333333, 'weighted avg_support': 33.0, 'O_support': 476, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 4}, {'micro_f1': 0.752577319587629, 'precision': 0.7525773195876289, 'Appeal_to_Time_precision': 0.07407407407407407, 'Appeal_to_Time_recall': 0.06451612903225806, 'Appeal_to_Time_f1-score': 0.06896551724137931, 'Appeal_to_Time_support': 31.0, 'micro avg_precision': 0.07407407407407407, 'micro avg_recall': 0.06451612903225806, 'micro avg_f1-score': 0.06896551724137931, 'micro avg_support': 31.0, 'macro avg_precision': 0.07407407407407407, 'macro avg_recall': 0.06451612903225806, 'macro avg_f1-score': 0.06896551724137931, 'macro avg_support': 31.0, 'weighted avg_precision': 0.07407407407407407, 'weighted avg_recall': 0.06451612903225806, 'weighted avg_f1-score': 0.06896551724137931, 'weighted avg_support': 31.0, 'O_support': 476, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 5}, {'micro_f1': 0.7603092783505153, 'precision': 0.7603092783505154, 'Appeal_to_Time_precision': 0.07407407407407407, 'Appeal_to_Time_recall': 0.05128205128205128, 'Appeal_to_Time_f1-score': 0.060606060606060615, 'Appeal_to_Time_support': 39.0, 'micro avg_precision': 0.07407407407407407, 'micro avg_recall': 0.05128205128205128, 'micro avg_f1-score': 0.060606060606060615, 'micro avg_support': 39.0, 'macro avg_precision': 0.07407407407407407, 'macro avg_recall': 0.05128205128205128, 'macro avg_f1-score': 0.060606060606060615, 'macro avg_support': 39.0, 'weighted avg_precision': 0.07407407407407407, 'weighted avg_recall': 0.05128205128205128, 'weighted avg_f1-score': 0.06060606060606061, 'weighted avg_support': 39.0, 'O_support': 476, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 6}]}
Early stopping triggered.
Saving model to directory: ./models/M2/2024-05-14-06-51-04_aug_ts0.9/mdeberta-v3-base_12_ME10_target=Appeal_to_Time_SUBSAMPLED_2024-05-14-06-51-04
Training model no. 13 of 23 for (13, 'Conversation_Killer') persuasion technique...
{'micro_f1': 0.8132976533552903, 'precision': 0.8132976533552903, 'Conversation_Killer_precision': 0.06802721088435375, 'Conversation_Killer_recall': 0.06896551724137931, 'Conversation_Killer_f1-score': 0.06849315068493152, 'Conversation_Killer_support': 145.0, 'micro avg_precision': 0.06802721088435375, 'micro avg_recall': 0.06896551724137931, 'micro avg_f1-score': 0.06849315068493152, 'micro avg_support': 145.0, 'macro avg_precision': 0.06802721088435375, 'macro avg_recall': 0.06896551724137931, 'macro avg_f1-score': 0.06849315068493152, 'macro avg_support': 145.0, 'weighted avg_precision': 0.06802721088435375, 'weighted avg_recall': 0.06896551724137931, 'weighted avg_f1-score': 0.06849315068493152, 'weighted avg_support': 145.0, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'O_support': 3673, 'epoch': 0}
{'results': [{'micro_f1': 0.8132976533552903, 'precision': 0.8132976533552903, 'Conversation_Killer_precision': 0.06802721088435375, 'Conversation_Killer_recall': 0.06896551724137931, 'Conversation_Killer_f1-score': 0.06849315068493152, 'Conversation_Killer_support': 145.0, 'micro avg_precision': 0.06802721088435375, 'micro avg_recall': 0.06896551724137931, 'micro avg_f1-score': 0.06849315068493152, 'micro avg_support': 145.0, 'macro avg_precision': 0.06802721088435375, 'macro avg_recall': 0.06896551724137931, 'macro avg_f1-score': 0.06849315068493152, 'macro avg_support': 145.0, 'weighted avg_precision': 0.06802721088435375, 'weighted avg_recall': 0.06896551724137931, 'weighted avg_f1-score': 0.06849315068493152, 'weighted avg_support': 145.0, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'O_support': 3673, 'epoch': 0}]}
Best model updated: current epoch macro f1 = 0.06849315068493152
{'micro_f1': 0.8174145738987237, 'precision': 0.8174145738987237, 'Conversation_Killer_precision': 0.1564625850340136, 'Conversation_Killer_recall': 0.22330097087378642, 'Conversation_Killer_f1-score': 0.18400000000000002, 'Conversation_Killer_support': 103.0, 'micro avg_precision': 0.1564625850340136, 'micro avg_recall': 0.22330097087378642, 'micro avg_f1-score': 0.18400000000000002, 'micro avg_support': 103.0, 'macro avg_precision': 0.1564625850340136, 'macro avg_recall': 0.22330097087378642, 'macro avg_f1-score': 0.18400000000000002, 'macro avg_support': 103.0, 'weighted avg_precision': 0.1564625850340136, 'weighted avg_recall': 0.22330097087378642, 'weighted avg_f1-score': 0.18400000000000002, 'weighted avg_support': 103.0, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'O_support': 3673, 'epoch': 1}
{'results': [{'micro_f1': 0.8132976533552903, 'precision': 0.8132976533552903, 'Conversation_Killer_precision': 0.06802721088435375, 'Conversation_Killer_recall': 0.06896551724137931, 'Conversation_Killer_f1-score': 0.06849315068493152, 'Conversation_Killer_support': 145.0, 'micro avg_precision': 0.06802721088435375, 'micro avg_recall': 0.06896551724137931, 'micro avg_f1-score': 0.06849315068493152, 'micro avg_support': 145.0, 'macro avg_precision': 0.06802721088435375, 'macro avg_recall': 0.06896551724137931, 'macro avg_f1-score': 0.06849315068493152, 'macro avg_support': 145.0, 'weighted avg_precision': 0.06802721088435375, 'weighted avg_recall': 0.06896551724137931, 'weighted avg_f1-score': 0.06849315068493152, 'weighted avg_support': 145.0, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'O_support': 3673, 'epoch': 0}, {'micro_f1': 0.8174145738987237, 'precision': 0.8174145738987237, 'Conversation_Killer_precision': 0.1564625850340136, 'Conversation_Killer_recall': 0.22330097087378642, 'Conversation_Killer_f1-score': 0.18400000000000002, 'Conversation_Killer_support': 103.0, 'micro avg_precision': 0.1564625850340136, 'micro avg_recall': 0.22330097087378642, 'micro avg_f1-score': 0.18400000000000002, 'micro avg_support': 103.0, 'macro avg_precision': 0.1564625850340136, 'macro avg_recall': 0.22330097087378642, 'macro avg_f1-score': 0.18400000000000002, 'macro avg_support': 103.0, 'weighted avg_precision': 0.1564625850340136, 'weighted avg_recall': 0.22330097087378642, 'weighted avg_f1-score': 0.18400000000000002, 'weighted avg_support': 103.0, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'O_support': 3673, 'epoch': 1}]}
Best model updated: current epoch macro f1 = 0.18400000000000002
{'micro_f1': 0.8357348703170029, 'precision': 0.8357348703170029, 'Conversation_Killer_precision': 0.1836734693877551, 'Conversation_Killer_recall': 0.1875, 'Conversation_Killer_f1-score': 0.18556701030927839, 'Conversation_Killer_support': 144.0, 'micro avg_precision': 0.1836734693877551, 'micro avg_recall': 0.1875, 'micro avg_f1-score': 0.18556701030927839, 'micro avg_support': 144.0, 'macro avg_precision': 0.1836734693877551, 'macro avg_recall': 0.1875, 'macro avg_f1-score': 0.18556701030927839, 'macro avg_support': 144.0, 'weighted avg_precision': 0.1836734693877551, 'weighted avg_recall': 0.1875, 'weighted avg_f1-score': 0.18556701030927839, 'weighted avg_support': 144.0, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'O_support': 3673, 'epoch': 2}
{'results': [{'micro_f1': 0.8132976533552903, 'precision': 0.8132976533552903, 'Conversation_Killer_precision': 0.06802721088435375, 'Conversation_Killer_recall': 0.06896551724137931, 'Conversation_Killer_f1-score': 0.06849315068493152, 'Conversation_Killer_support': 145.0, 'micro avg_precision': 0.06802721088435375, 'micro avg_recall': 0.06896551724137931, 'micro avg_f1-score': 0.06849315068493152, 'micro avg_support': 145.0, 'macro avg_precision': 0.06802721088435375, 'macro avg_recall': 0.06896551724137931, 'macro avg_f1-score': 0.06849315068493152, 'macro avg_support': 145.0, 'weighted avg_precision': 0.06802721088435375, 'weighted avg_recall': 0.06896551724137931, 'weighted avg_f1-score': 0.06849315068493152, 'weighted avg_support': 145.0, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'O_support': 3673, 'epoch': 0}, {'micro_f1': 0.8174145738987237, 'precision': 0.8174145738987237, 'Conversation_Killer_precision': 0.1564625850340136, 'Conversation_Killer_recall': 0.22330097087378642, 'Conversation_Killer_f1-score': 0.18400000000000002, 'Conversation_Killer_support': 103.0, 'micro avg_precision': 0.1564625850340136, 'micro avg_recall': 0.22330097087378642, 'micro avg_f1-score': 0.18400000000000002, 'micro avg_support': 103.0, 'macro avg_precision': 0.1564625850340136, 'macro avg_recall': 0.22330097087378642, 'macro avg_f1-score': 0.18400000000000002, 'macro avg_support': 103.0, 'weighted avg_precision': 0.1564625850340136, 'weighted avg_recall': 0.22330097087378642, 'weighted avg_f1-score': 0.18400000000000002, 'weighted avg_support': 103.0, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'O_support': 3673, 'epoch': 1}, {'micro_f1': 0.8357348703170029, 'precision': 0.8357348703170029, 'Conversation_Killer_precision': 0.1836734693877551, 'Conversation_Killer_recall': 0.1875, 'Conversation_Killer_f1-score': 0.18556701030927839, 'Conversation_Killer_support': 144.0, 'micro avg_precision': 0.1836734693877551, 'micro avg_recall': 0.1875, 'micro avg_f1-score': 0.18556701030927839, 'micro avg_support': 144.0, 'macro avg_precision': 0.1836734693877551, 'macro avg_recall': 0.1875, 'macro avg_f1-score': 0.18556701030927839, 'macro avg_support': 144.0, 'weighted avg_precision': 0.1836734693877551, 'weighted avg_recall': 0.1875, 'weighted avg_f1-score': 0.18556701030927839, 'weighted avg_support': 144.0, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'O_support': 3673, 'epoch': 2}]}
Best model updated: current epoch macro f1 = 0.18556701030927839
{'micro_f1': 0.8417044051049815, 'precision': 0.8417044051049815, 'Conversation_Killer_precision': 0.29931972789115646, 'Conversation_Killer_recall': 0.2972972972972973, 'Conversation_Killer_f1-score': 0.2983050847457627, 'Conversation_Killer_support': 148.0, 'micro avg_precision': 0.29931972789115646, 'micro avg_recall': 0.2972972972972973, 'micro avg_f1-score': 0.2983050847457627, 'micro avg_support': 148.0, 'macro avg_precision': 0.29931972789115646, 'macro avg_recall': 0.2972972972972973, 'macro avg_f1-score': 0.2983050847457627, 'macro avg_support': 148.0, 'weighted avg_precision': 0.29931972789115646, 'weighted avg_recall': 0.2972972972972973, 'weighted avg_f1-score': 0.2983050847457627, 'weighted avg_support': 148.0, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'O_support': 3673, 'epoch': 3}
{'results': [{'micro_f1': 0.8132976533552903, 'precision': 0.8132976533552903, 'Conversation_Killer_precision': 0.06802721088435375, 'Conversation_Killer_recall': 0.06896551724137931, 'Conversation_Killer_f1-score': 0.06849315068493152, 'Conversation_Killer_support': 145.0, 'micro avg_precision': 0.06802721088435375, 'micro avg_recall': 0.06896551724137931, 'micro avg_f1-score': 0.06849315068493152, 'micro avg_support': 145.0, 'macro avg_precision': 0.06802721088435375, 'macro avg_recall': 0.06896551724137931, 'macro avg_f1-score': 0.06849315068493152, 'macro avg_support': 145.0, 'weighted avg_precision': 0.06802721088435375, 'weighted avg_recall': 0.06896551724137931, 'weighted avg_f1-score': 0.06849315068493152, 'weighted avg_support': 145.0, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'O_support': 3673, 'epoch': 0}, {'micro_f1': 0.8174145738987237, 'precision': 0.8174145738987237, 'Conversation_Killer_precision': 0.1564625850340136, 'Conversation_Killer_recall': 0.22330097087378642, 'Conversation_Killer_f1-score': 0.18400000000000002, 'Conversation_Killer_support': 103.0, 'micro avg_precision': 0.1564625850340136, 'micro avg_recall': 0.22330097087378642, 'micro avg_f1-score': 0.18400000000000002, 'micro avg_support': 103.0, 'macro avg_precision': 0.1564625850340136, 'macro avg_recall': 0.22330097087378642, 'macro avg_f1-score': 0.18400000000000002, 'macro avg_support': 103.0, 'weighted avg_precision': 0.1564625850340136, 'weighted avg_recall': 0.22330097087378642, 'weighted avg_f1-score': 0.18400000000000002, 'weighted avg_support': 103.0, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'O_support': 3673, 'epoch': 1}, {'micro_f1': 0.8357348703170029, 'precision': 0.8357348703170029, 'Conversation_Killer_precision': 0.1836734693877551, 'Conversation_Killer_recall': 0.1875, 'Conversation_Killer_f1-score': 0.18556701030927839, 'Conversation_Killer_support': 144.0, 'micro avg_precision': 0.1836734693877551, 'micro avg_recall': 0.1875, 'micro avg_f1-score': 0.18556701030927839, 'micro avg_support': 144.0, 'macro avg_precision': 0.1836734693877551, 'macro avg_recall': 0.1875, 'macro avg_f1-score': 0.18556701030927839, 'macro avg_support': 144.0, 'weighted avg_precision': 0.1836734693877551, 'weighted avg_recall': 0.1875, 'weighted avg_f1-score': 0.18556701030927839, 'weighted avg_support': 144.0, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'O_support': 3673, 'epoch': 2}, {'micro_f1': 0.8417044051049815, 'precision': 0.8417044051049815, 'Conversation_Killer_precision': 0.29931972789115646, 'Conversation_Killer_recall': 0.2972972972972973, 'Conversation_Killer_f1-score': 0.2983050847457627, 'Conversation_Killer_support': 148.0, 'micro avg_precision': 0.29931972789115646, 'micro avg_recall': 0.2972972972972973, 'micro avg_f1-score': 0.2983050847457627, 'micro avg_support': 148.0, 'macro avg_precision': 0.29931972789115646, 'macro avg_recall': 0.2972972972972973, 'macro avg_f1-score': 0.2983050847457627, 'macro avg_support': 148.0, 'weighted avg_precision': 0.29931972789115646, 'weighted avg_recall': 0.2972972972972973, 'weighted avg_f1-score': 0.2983050847457627, 'weighted avg_support': 148.0, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'O_support': 3673, 'epoch': 3}]}
Best model updated: current epoch macro f1 = 0.2983050847457627
{'micro_f1': 0.8439687114038698, 'precision': 0.8439687114038699, 'Conversation_Killer_precision': 0.23129251700680273, 'Conversation_Killer_recall': 0.2537313432835821, 'Conversation_Killer_f1-score': 0.24199288256227758, 'Conversation_Killer_support': 134.0, 'micro avg_precision': 0.23129251700680273, 'micro avg_recall': 0.2537313432835821, 'micro avg_f1-score': 0.24199288256227758, 'micro avg_support': 134.0, 'macro avg_precision': 0.23129251700680273, 'macro avg_recall': 0.2537313432835821, 'macro avg_f1-score': 0.24199288256227758, 'macro avg_support': 134.0, 'weighted avg_precision': 0.23129251700680273, 'weighted avg_recall': 0.2537313432835821, 'weighted avg_f1-score': 0.24199288256227758, 'weighted avg_support': 134.0, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'O_support': 3673, 'epoch': 4}
{'results': [{'micro_f1': 0.8132976533552903, 'precision': 0.8132976533552903, 'Conversation_Killer_precision': 0.06802721088435375, 'Conversation_Killer_recall': 0.06896551724137931, 'Conversation_Killer_f1-score': 0.06849315068493152, 'Conversation_Killer_support': 145.0, 'micro avg_precision': 0.06802721088435375, 'micro avg_recall': 0.06896551724137931, 'micro avg_f1-score': 0.06849315068493152, 'micro avg_support': 145.0, 'macro avg_precision': 0.06802721088435375, 'macro avg_recall': 0.06896551724137931, 'macro avg_f1-score': 0.06849315068493152, 'macro avg_support': 145.0, 'weighted avg_precision': 0.06802721088435375, 'weighted avg_recall': 0.06896551724137931, 'weighted avg_f1-score': 0.06849315068493152, 'weighted avg_support': 145.0, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'O_support': 3673, 'epoch': 0}, {'micro_f1': 0.8174145738987237, 'precision': 0.8174145738987237, 'Conversation_Killer_precision': 0.1564625850340136, 'Conversation_Killer_recall': 0.22330097087378642, 'Conversation_Killer_f1-score': 0.18400000000000002, 'Conversation_Killer_support': 103.0, 'micro avg_precision': 0.1564625850340136, 'micro avg_recall': 0.22330097087378642, 'micro avg_f1-score': 0.18400000000000002, 'micro avg_support': 103.0, 'macro avg_precision': 0.1564625850340136, 'macro avg_recall': 0.22330097087378642, 'macro avg_f1-score': 0.18400000000000002, 'macro avg_support': 103.0, 'weighted avg_precision': 0.1564625850340136, 'weighted avg_recall': 0.22330097087378642, 'weighted avg_f1-score': 0.18400000000000002, 'weighted avg_support': 103.0, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'O_support': 3673, 'epoch': 1}, {'micro_f1': 0.8357348703170029, 'precision': 0.8357348703170029, 'Conversation_Killer_precision': 0.1836734693877551, 'Conversation_Killer_recall': 0.1875, 'Conversation_Killer_f1-score': 0.18556701030927839, 'Conversation_Killer_support': 144.0, 'micro avg_precision': 0.1836734693877551, 'micro avg_recall': 0.1875, 'micro avg_f1-score': 0.18556701030927839, 'micro avg_support': 144.0, 'macro avg_precision': 0.1836734693877551, 'macro avg_recall': 0.1875, 'macro avg_f1-score': 0.18556701030927839, 'macro avg_support': 144.0, 'weighted avg_precision': 0.1836734693877551, 'weighted avg_recall': 0.1875, 'weighted avg_f1-score': 0.18556701030927839, 'weighted avg_support': 144.0, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'O_support': 3673, 'epoch': 2}, {'micro_f1': 0.8417044051049815, 'precision': 0.8417044051049815, 'Conversation_Killer_precision': 0.29931972789115646, 'Conversation_Killer_recall': 0.2972972972972973, 'Conversation_Killer_f1-score': 0.2983050847457627, 'Conversation_Killer_support': 148.0, 'micro avg_precision': 0.29931972789115646, 'micro avg_recall': 0.2972972972972973, 'micro avg_f1-score': 0.2983050847457627, 'micro avg_support': 148.0, 'macro avg_precision': 0.29931972789115646, 'macro avg_recall': 0.2972972972972973, 'macro avg_f1-score': 0.2983050847457627, 'macro avg_support': 148.0, 'weighted avg_precision': 0.29931972789115646, 'weighted avg_recall': 0.2972972972972973, 'weighted avg_f1-score': 0.2983050847457627, 'weighted avg_support': 148.0, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'O_support': 3673, 'epoch': 3}, {'micro_f1': 0.8439687114038698, 'precision': 0.8439687114038699, 'Conversation_Killer_precision': 0.23129251700680273, 'Conversation_Killer_recall': 0.2537313432835821, 'Conversation_Killer_f1-score': 0.24199288256227758, 'Conversation_Killer_support': 134.0, 'micro avg_precision': 0.23129251700680273, 'micro avg_recall': 0.2537313432835821, 'micro avg_f1-score': 0.24199288256227758, 'micro avg_support': 134.0, 'macro avg_precision': 0.23129251700680273, 'macro avg_recall': 0.2537313432835821, 'macro avg_f1-score': 0.24199288256227758, 'macro avg_support': 134.0, 'weighted avg_precision': 0.23129251700680273, 'weighted avg_recall': 0.2537313432835821, 'weighted avg_f1-score': 0.24199288256227758, 'weighted avg_support': 134.0, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'O_support': 3673, 'epoch': 4}]}
{'micro_f1': 0.8573487031700289, 'precision': 0.8573487031700289, 'Conversation_Killer_precision': 0.3333333333333333, 'Conversation_Killer_recall': 0.3161290322580645, 'Conversation_Killer_f1-score': 0.32450331125827814, 'Conversation_Killer_support': 155.0, 'micro avg_precision': 0.3333333333333333, 'micro avg_recall': 0.3161290322580645, 'micro avg_f1-score': 0.32450331125827814, 'micro avg_support': 155.0, 'macro avg_precision': 0.3333333333333333, 'macro avg_recall': 0.3161290322580645, 'macro avg_f1-score': 0.32450331125827814, 'macro avg_support': 155.0, 'weighted avg_precision': 0.3333333333333333, 'weighted avg_recall': 0.3161290322580645, 'weighted avg_f1-score': 0.32450331125827814, 'weighted avg_support': 155.0, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'O_support': 3673, 'epoch': 5}
{'results': [{'micro_f1': 0.8132976533552903, 'precision': 0.8132976533552903, 'Conversation_Killer_precision': 0.06802721088435375, 'Conversation_Killer_recall': 0.06896551724137931, 'Conversation_Killer_f1-score': 0.06849315068493152, 'Conversation_Killer_support': 145.0, 'micro avg_precision': 0.06802721088435375, 'micro avg_recall': 0.06896551724137931, 'micro avg_f1-score': 0.06849315068493152, 'micro avg_support': 145.0, 'macro avg_precision': 0.06802721088435375, 'macro avg_recall': 0.06896551724137931, 'macro avg_f1-score': 0.06849315068493152, 'macro avg_support': 145.0, 'weighted avg_precision': 0.06802721088435375, 'weighted avg_recall': 0.06896551724137931, 'weighted avg_f1-score': 0.06849315068493152, 'weighted avg_support': 145.0, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'O_support': 3673, 'epoch': 0}, {'micro_f1': 0.8174145738987237, 'precision': 0.8174145738987237, 'Conversation_Killer_precision': 0.1564625850340136, 'Conversation_Killer_recall': 0.22330097087378642, 'Conversation_Killer_f1-score': 0.18400000000000002, 'Conversation_Killer_support': 103.0, 'micro avg_precision': 0.1564625850340136, 'micro avg_recall': 0.22330097087378642, 'micro avg_f1-score': 0.18400000000000002, 'micro avg_support': 103.0, 'macro avg_precision': 0.1564625850340136, 'macro avg_recall': 0.22330097087378642, 'macro avg_f1-score': 0.18400000000000002, 'macro avg_support': 103.0, 'weighted avg_precision': 0.1564625850340136, 'weighted avg_recall': 0.22330097087378642, 'weighted avg_f1-score': 0.18400000000000002, 'weighted avg_support': 103.0, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'O_support': 3673, 'epoch': 1}, {'micro_f1': 0.8357348703170029, 'precision': 0.8357348703170029, 'Conversation_Killer_precision': 0.1836734693877551, 'Conversation_Killer_recall': 0.1875, 'Conversation_Killer_f1-score': 0.18556701030927839, 'Conversation_Killer_support': 144.0, 'micro avg_precision': 0.1836734693877551, 'micro avg_recall': 0.1875, 'micro avg_f1-score': 0.18556701030927839, 'micro avg_support': 144.0, 'macro avg_precision': 0.1836734693877551, 'macro avg_recall': 0.1875, 'macro avg_f1-score': 0.18556701030927839, 'macro avg_support': 144.0, 'weighted avg_precision': 0.1836734693877551, 'weighted avg_recall': 0.1875, 'weighted avg_f1-score': 0.18556701030927839, 'weighted avg_support': 144.0, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'O_support': 3673, 'epoch': 2}, {'micro_f1': 0.8417044051049815, 'precision': 0.8417044051049815, 'Conversation_Killer_precision': 0.29931972789115646, 'Conversation_Killer_recall': 0.2972972972972973, 'Conversation_Killer_f1-score': 0.2983050847457627, 'Conversation_Killer_support': 148.0, 'micro avg_precision': 0.29931972789115646, 'micro avg_recall': 0.2972972972972973, 'micro avg_f1-score': 0.2983050847457627, 'micro avg_support': 148.0, 'macro avg_precision': 0.29931972789115646, 'macro avg_recall': 0.2972972972972973, 'macro avg_f1-score': 0.2983050847457627, 'macro avg_support': 148.0, 'weighted avg_precision': 0.29931972789115646, 'weighted avg_recall': 0.2972972972972973, 'weighted avg_f1-score': 0.2983050847457627, 'weighted avg_support': 148.0, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'O_support': 3673, 'epoch': 3}, {'micro_f1': 0.8439687114038698, 'precision': 0.8439687114038699, 'Conversation_Killer_precision': 0.23129251700680273, 'Conversation_Killer_recall': 0.2537313432835821, 'Conversation_Killer_f1-score': 0.24199288256227758, 'Conversation_Killer_support': 134.0, 'micro avg_precision': 0.23129251700680273, 'micro avg_recall': 0.2537313432835821, 'micro avg_f1-score': 0.24199288256227758, 'micro avg_support': 134.0, 'macro avg_precision': 0.23129251700680273, 'macro avg_recall': 0.2537313432835821, 'macro avg_f1-score': 0.24199288256227758, 'macro avg_support': 134.0, 'weighted avg_precision': 0.23129251700680273, 'weighted avg_recall': 0.2537313432835821, 'weighted avg_f1-score': 0.24199288256227758, 'weighted avg_support': 134.0, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'O_support': 3673, 'epoch': 4}, {'micro_f1': 0.8573487031700289, 'precision': 0.8573487031700289, 'Conversation_Killer_precision': 0.3333333333333333, 'Conversation_Killer_recall': 0.3161290322580645, 'Conversation_Killer_f1-score': 0.32450331125827814, 'Conversation_Killer_support': 155.0, 'micro avg_precision': 0.3333333333333333, 'micro avg_recall': 0.3161290322580645, 'micro avg_f1-score': 0.32450331125827814, 'micro avg_support': 155.0, 'macro avg_precision': 0.3333333333333333, 'macro avg_recall': 0.3161290322580645, 'macro avg_f1-score': 0.32450331125827814, 'macro avg_support': 155.0, 'weighted avg_precision': 0.3333333333333333, 'weighted avg_recall': 0.3161290322580645, 'weighted avg_f1-score': 0.32450331125827814, 'weighted avg_support': 155.0, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'O_support': 3673, 'epoch': 5}]}
Best model updated: current epoch macro f1 = 0.32450331125827814
{'micro_f1': 0.8472622478386167, 'precision': 0.8472622478386167, 'Conversation_Killer_precision': 0.3129251700680272, 'Conversation_Killer_recall': 0.3006535947712418, 'Conversation_Killer_f1-score': 0.3066666666666667, 'Conversation_Killer_support': 153.0, 'micro avg_precision': 0.3129251700680272, 'micro avg_recall': 0.3006535947712418, 'micro avg_f1-score': 0.3066666666666667, 'micro avg_support': 153.0, 'macro avg_precision': 0.3129251700680272, 'macro avg_recall': 0.3006535947712418, 'macro avg_f1-score': 0.3066666666666667, 'macro avg_support': 153.0, 'weighted avg_precision': 0.3129251700680272, 'weighted avg_recall': 0.3006535947712418, 'weighted avg_f1-score': 0.3066666666666667, 'weighted avg_support': 153.0, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'O_support': 3673, 'epoch': 6}
{'results': [{'micro_f1': 0.8132976533552903, 'precision': 0.8132976533552903, 'Conversation_Killer_precision': 0.06802721088435375, 'Conversation_Killer_recall': 0.06896551724137931, 'Conversation_Killer_f1-score': 0.06849315068493152, 'Conversation_Killer_support': 145.0, 'micro avg_precision': 0.06802721088435375, 'micro avg_recall': 0.06896551724137931, 'micro avg_f1-score': 0.06849315068493152, 'micro avg_support': 145.0, 'macro avg_precision': 0.06802721088435375, 'macro avg_recall': 0.06896551724137931, 'macro avg_f1-score': 0.06849315068493152, 'macro avg_support': 145.0, 'weighted avg_precision': 0.06802721088435375, 'weighted avg_recall': 0.06896551724137931, 'weighted avg_f1-score': 0.06849315068493152, 'weighted avg_support': 145.0, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'O_support': 3673, 'epoch': 0}, {'micro_f1': 0.8174145738987237, 'precision': 0.8174145738987237, 'Conversation_Killer_precision': 0.1564625850340136, 'Conversation_Killer_recall': 0.22330097087378642, 'Conversation_Killer_f1-score': 0.18400000000000002, 'Conversation_Killer_support': 103.0, 'micro avg_precision': 0.1564625850340136, 'micro avg_recall': 0.22330097087378642, 'micro avg_f1-score': 0.18400000000000002, 'micro avg_support': 103.0, 'macro avg_precision': 0.1564625850340136, 'macro avg_recall': 0.22330097087378642, 'macro avg_f1-score': 0.18400000000000002, 'macro avg_support': 103.0, 'weighted avg_precision': 0.1564625850340136, 'weighted avg_recall': 0.22330097087378642, 'weighted avg_f1-score': 0.18400000000000002, 'weighted avg_support': 103.0, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'O_support': 3673, 'epoch': 1}, {'micro_f1': 0.8357348703170029, 'precision': 0.8357348703170029, 'Conversation_Killer_precision': 0.1836734693877551, 'Conversation_Killer_recall': 0.1875, 'Conversation_Killer_f1-score': 0.18556701030927839, 'Conversation_Killer_support': 144.0, 'micro avg_precision': 0.1836734693877551, 'micro avg_recall': 0.1875, 'micro avg_f1-score': 0.18556701030927839, 'micro avg_support': 144.0, 'macro avg_precision': 0.1836734693877551, 'macro avg_recall': 0.1875, 'macro avg_f1-score': 0.18556701030927839, 'macro avg_support': 144.0, 'weighted avg_precision': 0.1836734693877551, 'weighted avg_recall': 0.1875, 'weighted avg_f1-score': 0.18556701030927839, 'weighted avg_support': 144.0, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'O_support': 3673, 'epoch': 2}, {'micro_f1': 0.8417044051049815, 'precision': 0.8417044051049815, 'Conversation_Killer_precision': 0.29931972789115646, 'Conversation_Killer_recall': 0.2972972972972973, 'Conversation_Killer_f1-score': 0.2983050847457627, 'Conversation_Killer_support': 148.0, 'micro avg_precision': 0.29931972789115646, 'micro avg_recall': 0.2972972972972973, 'micro avg_f1-score': 0.2983050847457627, 'micro avg_support': 148.0, 'macro avg_precision': 0.29931972789115646, 'macro avg_recall': 0.2972972972972973, 'macro avg_f1-score': 0.2983050847457627, 'macro avg_support': 148.0, 'weighted avg_precision': 0.29931972789115646, 'weighted avg_recall': 0.2972972972972973, 'weighted avg_f1-score': 0.2983050847457627, 'weighted avg_support': 148.0, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'O_support': 3673, 'epoch': 3}, {'micro_f1': 0.8439687114038698, 'precision': 0.8439687114038699, 'Conversation_Killer_precision': 0.23129251700680273, 'Conversation_Killer_recall': 0.2537313432835821, 'Conversation_Killer_f1-score': 0.24199288256227758, 'Conversation_Killer_support': 134.0, 'micro avg_precision': 0.23129251700680273, 'micro avg_recall': 0.2537313432835821, 'micro avg_f1-score': 0.24199288256227758, 'micro avg_support': 134.0, 'macro avg_precision': 0.23129251700680273, 'macro avg_recall': 0.2537313432835821, 'macro avg_f1-score': 0.24199288256227758, 'macro avg_support': 134.0, 'weighted avg_precision': 0.23129251700680273, 'weighted avg_recall': 0.2537313432835821, 'weighted avg_f1-score': 0.24199288256227758, 'weighted avg_support': 134.0, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'O_support': 3673, 'epoch': 4}, {'micro_f1': 0.8573487031700289, 'precision': 0.8573487031700289, 'Conversation_Killer_precision': 0.3333333333333333, 'Conversation_Killer_recall': 0.3161290322580645, 'Conversation_Killer_f1-score': 0.32450331125827814, 'Conversation_Killer_support': 155.0, 'micro avg_precision': 0.3333333333333333, 'micro avg_recall': 0.3161290322580645, 'micro avg_f1-score': 0.32450331125827814, 'micro avg_support': 155.0, 'macro avg_precision': 0.3333333333333333, 'macro avg_recall': 0.3161290322580645, 'macro avg_f1-score': 0.32450331125827814, 'macro avg_support': 155.0, 'weighted avg_precision': 0.3333333333333333, 'weighted avg_recall': 0.3161290322580645, 'weighted avg_f1-score': 0.32450331125827814, 'weighted avg_support': 155.0, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'O_support': 3673, 'epoch': 5}, {'micro_f1': 0.8472622478386167, 'precision': 0.8472622478386167, 'Conversation_Killer_precision': 0.3129251700680272, 'Conversation_Killer_recall': 0.3006535947712418, 'Conversation_Killer_f1-score': 0.3066666666666667, 'Conversation_Killer_support': 153.0, 'micro avg_precision': 0.3129251700680272, 'micro avg_recall': 0.3006535947712418, 'micro avg_f1-score': 0.3066666666666667, 'micro avg_support': 153.0, 'macro avg_precision': 0.3129251700680272, 'macro avg_recall': 0.3006535947712418, 'macro avg_f1-score': 0.3066666666666667, 'macro avg_support': 153.0, 'weighted avg_precision': 0.3129251700680272, 'weighted avg_recall': 0.3006535947712418, 'weighted avg_f1-score': 0.3066666666666667, 'weighted avg_support': 153.0, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'O_support': 3673, 'epoch': 6}]}
{'micro_f1': 0.8476739398929601, 'precision': 0.84767393989296, 'Conversation_Killer_precision': 0.2857142857142857, 'Conversation_Killer_recall': 0.28378378378378377, 'Conversation_Killer_f1-score': 0.2847457627118644, 'Conversation_Killer_support': 148.0, 'micro avg_precision': 0.2857142857142857, 'micro avg_recall': 0.28378378378378377, 'micro avg_f1-score': 0.2847457627118644, 'micro avg_support': 148.0, 'macro avg_precision': 0.2857142857142857, 'macro avg_recall': 0.28378378378378377, 'macro avg_f1-score': 0.2847457627118644, 'macro avg_support': 148.0, 'weighted avg_precision': 0.2857142857142857, 'weighted avg_recall': 0.28378378378378377, 'weighted avg_f1-score': 0.2847457627118644, 'weighted avg_support': 148.0, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'O_support': 3673, 'epoch': 7}
{'results': [{'micro_f1': 0.8132976533552903, 'precision': 0.8132976533552903, 'Conversation_Killer_precision': 0.06802721088435375, 'Conversation_Killer_recall': 0.06896551724137931, 'Conversation_Killer_f1-score': 0.06849315068493152, 'Conversation_Killer_support': 145.0, 'micro avg_precision': 0.06802721088435375, 'micro avg_recall': 0.06896551724137931, 'micro avg_f1-score': 0.06849315068493152, 'micro avg_support': 145.0, 'macro avg_precision': 0.06802721088435375, 'macro avg_recall': 0.06896551724137931, 'macro avg_f1-score': 0.06849315068493152, 'macro avg_support': 145.0, 'weighted avg_precision': 0.06802721088435375, 'weighted avg_recall': 0.06896551724137931, 'weighted avg_f1-score': 0.06849315068493152, 'weighted avg_support': 145.0, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'O_support': 3673, 'epoch': 0}, {'micro_f1': 0.8174145738987237, 'precision': 0.8174145738987237, 'Conversation_Killer_precision': 0.1564625850340136, 'Conversation_Killer_recall': 0.22330097087378642, 'Conversation_Killer_f1-score': 0.18400000000000002, 'Conversation_Killer_support': 103.0, 'micro avg_precision': 0.1564625850340136, 'micro avg_recall': 0.22330097087378642, 'micro avg_f1-score': 0.18400000000000002, 'micro avg_support': 103.0, 'macro avg_precision': 0.1564625850340136, 'macro avg_recall': 0.22330097087378642, 'macro avg_f1-score': 0.18400000000000002, 'macro avg_support': 103.0, 'weighted avg_precision': 0.1564625850340136, 'weighted avg_recall': 0.22330097087378642, 'weighted avg_f1-score': 0.18400000000000002, 'weighted avg_support': 103.0, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'O_support': 3673, 'epoch': 1}, {'micro_f1': 0.8357348703170029, 'precision': 0.8357348703170029, 'Conversation_Killer_precision': 0.1836734693877551, 'Conversation_Killer_recall': 0.1875, 'Conversation_Killer_f1-score': 0.18556701030927839, 'Conversation_Killer_support': 144.0, 'micro avg_precision': 0.1836734693877551, 'micro avg_recall': 0.1875, 'micro avg_f1-score': 0.18556701030927839, 'micro avg_support': 144.0, 'macro avg_precision': 0.1836734693877551, 'macro avg_recall': 0.1875, 'macro avg_f1-score': 0.18556701030927839, 'macro avg_support': 144.0, 'weighted avg_precision': 0.1836734693877551, 'weighted avg_recall': 0.1875, 'weighted avg_f1-score': 0.18556701030927839, 'weighted avg_support': 144.0, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'O_support': 3673, 'epoch': 2}, {'micro_f1': 0.8417044051049815, 'precision': 0.8417044051049815, 'Conversation_Killer_precision': 0.29931972789115646, 'Conversation_Killer_recall': 0.2972972972972973, 'Conversation_Killer_f1-score': 0.2983050847457627, 'Conversation_Killer_support': 148.0, 'micro avg_precision': 0.29931972789115646, 'micro avg_recall': 0.2972972972972973, 'micro avg_f1-score': 0.2983050847457627, 'micro avg_support': 148.0, 'macro avg_precision': 0.29931972789115646, 'macro avg_recall': 0.2972972972972973, 'macro avg_f1-score': 0.2983050847457627, 'macro avg_support': 148.0, 'weighted avg_precision': 0.29931972789115646, 'weighted avg_recall': 0.2972972972972973, 'weighted avg_f1-score': 0.2983050847457627, 'weighted avg_support': 148.0, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'O_support': 3673, 'epoch': 3}, {'micro_f1': 0.8439687114038698, 'precision': 0.8439687114038699, 'Conversation_Killer_precision': 0.23129251700680273, 'Conversation_Killer_recall': 0.2537313432835821, 'Conversation_Killer_f1-score': 0.24199288256227758, 'Conversation_Killer_support': 134.0, 'micro avg_precision': 0.23129251700680273, 'micro avg_recall': 0.2537313432835821, 'micro avg_f1-score': 0.24199288256227758, 'micro avg_support': 134.0, 'macro avg_precision': 0.23129251700680273, 'macro avg_recall': 0.2537313432835821, 'macro avg_f1-score': 0.24199288256227758, 'macro avg_support': 134.0, 'weighted avg_precision': 0.23129251700680273, 'weighted avg_recall': 0.2537313432835821, 'weighted avg_f1-score': 0.24199288256227758, 'weighted avg_support': 134.0, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'O_support': 3673, 'epoch': 4}, {'micro_f1': 0.8573487031700289, 'precision': 0.8573487031700289, 'Conversation_Killer_precision': 0.3333333333333333, 'Conversation_Killer_recall': 0.3161290322580645, 'Conversation_Killer_f1-score': 0.32450331125827814, 'Conversation_Killer_support': 155.0, 'micro avg_precision': 0.3333333333333333, 'micro avg_recall': 0.3161290322580645, 'micro avg_f1-score': 0.32450331125827814, 'micro avg_support': 155.0, 'macro avg_precision': 0.3333333333333333, 'macro avg_recall': 0.3161290322580645, 'macro avg_f1-score': 0.32450331125827814, 'macro avg_support': 155.0, 'weighted avg_precision': 0.3333333333333333, 'weighted avg_recall': 0.3161290322580645, 'weighted avg_f1-score': 0.32450331125827814, 'weighted avg_support': 155.0, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'O_support': 3673, 'epoch': 5}, {'micro_f1': 0.8472622478386167, 'precision': 0.8472622478386167, 'Conversation_Killer_precision': 0.3129251700680272, 'Conversation_Killer_recall': 0.3006535947712418, 'Conversation_Killer_f1-score': 0.3066666666666667, 'Conversation_Killer_support': 153.0, 'micro avg_precision': 0.3129251700680272, 'micro avg_recall': 0.3006535947712418, 'micro avg_f1-score': 0.3066666666666667, 'micro avg_support': 153.0, 'macro avg_precision': 0.3129251700680272, 'macro avg_recall': 0.3006535947712418, 'macro avg_f1-score': 0.3066666666666667, 'macro avg_support': 153.0, 'weighted avg_precision': 0.3129251700680272, 'weighted avg_recall': 0.3006535947712418, 'weighted avg_f1-score': 0.3066666666666667, 'weighted avg_support': 153.0, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'O_support': 3673, 'epoch': 6}, {'micro_f1': 0.8476739398929601, 'precision': 0.84767393989296, 'Conversation_Killer_precision': 0.2857142857142857, 'Conversation_Killer_recall': 0.28378378378378377, 'Conversation_Killer_f1-score': 0.2847457627118644, 'Conversation_Killer_support': 148.0, 'micro avg_precision': 0.2857142857142857, 'micro avg_recall': 0.28378378378378377, 'micro avg_f1-score': 0.2847457627118644, 'micro avg_support': 148.0, 'macro avg_precision': 0.2857142857142857, 'macro avg_recall': 0.28378378378378377, 'macro avg_f1-score': 0.2847457627118644, 'macro avg_support': 148.0, 'weighted avg_precision': 0.2857142857142857, 'weighted avg_recall': 0.28378378378378377, 'weighted avg_f1-score': 0.2847457627118644, 'weighted avg_support': 148.0, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'O_support': 3673, 'epoch': 7}]}
Early stopping triggered.
Saving model to directory: ./models/M2/2024-05-14-06-51-04_aug_ts0.9/mdeberta-v3-base_13_ME10_target=Conversation_Killer_SUBSAMPLED_2024-05-14-06-51-04
Training model no. 14 of 23 for (14, 'Loaded_Language') persuasion technique...
{'micro_f1': 0.8894663243796047, 'precision': 0.8894663243796047, 'Loaded_Language_precision': 0.02610966057441253, 'Loaded_Language_recall': 0.13274336283185842, 'Loaded_Language_f1-score': 0.04363636363636364, 'Loaded_Language_support': 226.0, 'micro avg_precision': 0.02610966057441253, 'micro avg_recall': 0.13274336283185842, 'micro avg_f1-score': 0.04363636363636364, 'micro avg_support': 226.0, 'macro avg_precision': 0.02610966057441253, 'macro avg_recall': 0.13274336283185842, 'macro avg_f1-score': 0.04363636363636364, 'macro avg_support': 226.0, 'weighted avg_precision': 0.02610966057441253, 'weighted avg_recall': 0.13274336283185842, 'weighted avg_f1-score': 0.04363636363636364, 'weighted avg_support': 226.0, 'O_support': 42290, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 0}
{'results': [{'micro_f1': 0.8894663243796047, 'precision': 0.8894663243796047, 'Loaded_Language_precision': 0.02610966057441253, 'Loaded_Language_recall': 0.13274336283185842, 'Loaded_Language_f1-score': 0.04363636363636364, 'Loaded_Language_support': 226.0, 'micro avg_precision': 0.02610966057441253, 'micro avg_recall': 0.13274336283185842, 'micro avg_f1-score': 0.04363636363636364, 'micro avg_support': 226.0, 'macro avg_precision': 0.02610966057441253, 'macro avg_recall': 0.13274336283185842, 'macro avg_f1-score': 0.04363636363636364, 'macro avg_support': 226.0, 'weighted avg_precision': 0.02610966057441253, 'weighted avg_recall': 0.13274336283185842, 'weighted avg_f1-score': 0.04363636363636364, 'weighted avg_support': 226.0, 'O_support': 42290, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 0}]}
Best model updated: current epoch macro f1 = 0.04363636363636364
{'micro_f1': 0.8990461878822031, 'precision': 0.8990461878822031, 'Loaded_Language_precision': 0.024369016536118365, 'Loaded_Language_recall': 0.11067193675889328, 'Loaded_Language_f1-score': 0.039942938659058486, 'Loaded_Language_support': 253.0, 'micro avg_precision': 0.024369016536118365, 'micro avg_recall': 0.11067193675889328, 'micro avg_f1-score': 0.039942938659058486, 'micro avg_support': 253.0, 'macro avg_precision': 0.024369016536118365, 'macro avg_recall': 0.11067193675889328, 'macro avg_f1-score': 0.039942938659058486, 'macro avg_support': 253.0, 'weighted avg_precision': 0.024369016536118365, 'weighted avg_recall': 0.11067193675889328, 'weighted avg_f1-score': 0.039942938659058486, 'weighted avg_support': 253.0, 'O_support': 42290, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 1}
{'results': [{'micro_f1': 0.8894663243796047, 'precision': 0.8894663243796047, 'Loaded_Language_precision': 0.02610966057441253, 'Loaded_Language_recall': 0.13274336283185842, 'Loaded_Language_f1-score': 0.04363636363636364, 'Loaded_Language_support': 226.0, 'micro avg_precision': 0.02610966057441253, 'micro avg_recall': 0.13274336283185842, 'micro avg_f1-score': 0.04363636363636364, 'micro avg_support': 226.0, 'macro avg_precision': 0.02610966057441253, 'macro avg_recall': 0.13274336283185842, 'macro avg_f1-score': 0.04363636363636364, 'macro avg_support': 226.0, 'weighted avg_precision': 0.02610966057441253, 'weighted avg_recall': 0.13274336283185842, 'weighted avg_f1-score': 0.04363636363636364, 'weighted avg_support': 226.0, 'O_support': 42290, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 0}, {'micro_f1': 0.8990461878822031, 'precision': 0.8990461878822031, 'Loaded_Language_precision': 0.024369016536118365, 'Loaded_Language_recall': 0.11067193675889328, 'Loaded_Language_f1-score': 0.039942938659058486, 'Loaded_Language_support': 253.0, 'micro avg_precision': 0.024369016536118365, 'micro avg_recall': 0.11067193675889328, 'micro avg_f1-score': 0.039942938659058486, 'micro avg_support': 253.0, 'macro avg_precision': 0.024369016536118365, 'macro avg_recall': 0.11067193675889328, 'macro avg_f1-score': 0.039942938659058486, 'macro avg_support': 253.0, 'weighted avg_precision': 0.024369016536118365, 'weighted avg_recall': 0.11067193675889328, 'weighted avg_f1-score': 0.039942938659058486, 'weighted avg_support': 253.0, 'O_support': 42290, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 1}]}
