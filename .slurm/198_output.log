[?7l[?7l

Training model no. 0 of 23 for (0, 'Appeal_to_Authority') persuasion technique...
{'micro_f1': 0.6286367414796342, 'precision': 0.6286367414796342, 'Appeal_to_Authority_precision': 0.0, 'Appeal_to_Authority_recall': 0.0, 'Appeal_to_Authority_f1-score': 0.0, 'Appeal_to_Authority_support': 137.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 137.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 137.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 137.0, 'O_support': 2767, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 0}
{'results': [{'micro_f1': 0.6286367414796342, 'precision': 0.6286367414796342, 'Appeal_to_Authority_precision': 0.0, 'Appeal_to_Authority_recall': 0.0, 'Appeal_to_Authority_f1-score': 0.0, 'Appeal_to_Authority_support': 137.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 137.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 137.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 137.0, 'O_support': 2767, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 0}]}
{'micro_f1': 0.758520365752286, 'precision': 0.758520365752286, 'Appeal_to_Authority_precision': 0.10256410256410256, 'Appeal_to_Authority_recall': 0.0736196319018405, 'Appeal_to_Authority_f1-score': 0.08571428571428573, 'Appeal_to_Authority_support': 163.0, 'micro avg_precision': 0.10256410256410256, 'micro avg_recall': 0.0736196319018405, 'micro avg_f1-score': 0.08571428571428573, 'micro avg_support': 163.0, 'macro avg_precision': 0.10256410256410256, 'macro avg_recall': 0.0736196319018405, 'macro avg_f1-score': 0.08571428571428573, 'macro avg_support': 163.0, 'weighted avg_precision': 0.10256410256410257, 'weighted avg_recall': 0.0736196319018405, 'weighted avg_f1-score': 0.08571428571428573, 'weighted avg_support': 163.0, 'O_support': 2767, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 1}
{'results': [{'micro_f1': 0.6286367414796342, 'precision': 0.6286367414796342, 'Appeal_to_Authority_precision': 0.0, 'Appeal_to_Authority_recall': 0.0, 'Appeal_to_Authority_f1-score': 0.0, 'Appeal_to_Authority_support': 137.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 137.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 137.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 137.0, 'O_support': 2767, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 0}, {'micro_f1': 0.758520365752286, 'precision': 0.758520365752286, 'Appeal_to_Authority_precision': 0.10256410256410256, 'Appeal_to_Authority_recall': 0.0736196319018405, 'Appeal_to_Authority_f1-score': 0.08571428571428573, 'Appeal_to_Authority_support': 163.0, 'micro avg_precision': 0.10256410256410256, 'micro avg_recall': 0.0736196319018405, 'micro avg_f1-score': 0.08571428571428573, 'micro avg_support': 163.0, 'macro avg_precision': 0.10256410256410256, 'macro avg_recall': 0.0736196319018405, 'macro avg_f1-score': 0.08571428571428573, 'macro avg_support': 163.0, 'weighted avg_precision': 0.10256410256410257, 'weighted avg_recall': 0.0736196319018405, 'weighted avg_f1-score': 0.08571428571428573, 'weighted avg_support': 163.0, 'O_support': 2767, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 1}]}
Best model updated: current epoch macro f1 = 0.08571428571428573
{'micro_f1': 0.7649625935162094, 'precision': 0.7649625935162094, 'Appeal_to_Authority_precision': 0.19658119658119658, 'Appeal_to_Authority_recall': 0.125, 'Appeal_to_Authority_f1-score': 0.15282392026578073, 'Appeal_to_Authority_support': 184.0, 'micro avg_precision': 0.19658119658119658, 'micro avg_recall': 0.125, 'micro avg_f1-score': 0.15282392026578073, 'micro avg_support': 184.0, 'macro avg_precision': 0.19658119658119658, 'macro avg_recall': 0.125, 'macro avg_f1-score': 0.15282392026578073, 'macro avg_support': 184.0, 'weighted avg_precision': 0.19658119658119658, 'weighted avg_recall': 0.125, 'weighted avg_f1-score': 0.15282392026578073, 'weighted avg_support': 184.0, 'O_support': 2767, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 2}
{'results': [{'micro_f1': 0.6286367414796342, 'precision': 0.6286367414796342, 'Appeal_to_Authority_precision': 0.0, 'Appeal_to_Authority_recall': 0.0, 'Appeal_to_Authority_f1-score': 0.0, 'Appeal_to_Authority_support': 137.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 137.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 137.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 137.0, 'O_support': 2767, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 0}, {'micro_f1': 0.758520365752286, 'precision': 0.758520365752286, 'Appeal_to_Authority_precision': 0.10256410256410256, 'Appeal_to_Authority_recall': 0.0736196319018405, 'Appeal_to_Authority_f1-score': 0.08571428571428573, 'Appeal_to_Authority_support': 163.0, 'micro avg_precision': 0.10256410256410256, 'micro avg_recall': 0.0736196319018405, 'micro avg_f1-score': 0.08571428571428573, 'micro avg_support': 163.0, 'macro avg_precision': 0.10256410256410256, 'macro avg_recall': 0.0736196319018405, 'macro avg_f1-score': 0.08571428571428573, 'macro avg_support': 163.0, 'weighted avg_precision': 0.10256410256410257, 'weighted avg_recall': 0.0736196319018405, 'weighted avg_f1-score': 0.08571428571428573, 'weighted avg_support': 163.0, 'O_support': 2767, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 1}, {'micro_f1': 0.7649625935162094, 'precision': 0.7649625935162094, 'Appeal_to_Authority_precision': 0.19658119658119658, 'Appeal_to_Authority_recall': 0.125, 'Appeal_to_Authority_f1-score': 0.15282392026578073, 'Appeal_to_Authority_support': 184.0, 'micro avg_precision': 0.19658119658119658, 'micro avg_recall': 0.125, 'micro avg_f1-score': 0.15282392026578073, 'micro avg_support': 184.0, 'macro avg_precision': 0.19658119658119658, 'macro avg_recall': 0.125, 'macro avg_f1-score': 0.15282392026578073, 'macro avg_support': 184.0, 'weighted avg_precision': 0.19658119658119658, 'weighted avg_recall': 0.125, 'weighted avg_f1-score': 0.15282392026578073, 'weighted avg_support': 184.0, 'O_support': 2767, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 2}]}
Best model updated: current epoch macro f1 = 0.15282392026578073
{'micro_f1': 0.7753532834580215, 'precision': 0.7753532834580216, 'Appeal_to_Authority_precision': 0.13675213675213677, 'Appeal_to_Authority_recall': 0.11188811188811189, 'Appeal_to_Authority_f1-score': 0.12307692307692308, 'Appeal_to_Authority_support': 143.0, 'micro avg_precision': 0.13675213675213677, 'micro avg_recall': 0.11188811188811189, 'micro avg_f1-score': 0.12307692307692308, 'micro avg_support': 143.0, 'macro avg_precision': 0.13675213675213677, 'macro avg_recall': 0.11188811188811189, 'macro avg_f1-score': 0.12307692307692308, 'macro avg_support': 143.0, 'weighted avg_precision': 0.13675213675213677, 'weighted avg_recall': 0.11188811188811189, 'weighted avg_f1-score': 0.12307692307692308, 'weighted avg_support': 143.0, 'O_support': 2767, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 3}
{'results': [{'micro_f1': 0.6286367414796342, 'precision': 0.6286367414796342, 'Appeal_to_Authority_precision': 0.0, 'Appeal_to_Authority_recall': 0.0, 'Appeal_to_Authority_f1-score': 0.0, 'Appeal_to_Authority_support': 137.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 137.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 137.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 137.0, 'O_support': 2767, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 0}, {'micro_f1': 0.758520365752286, 'precision': 0.758520365752286, 'Appeal_to_Authority_precision': 0.10256410256410256, 'Appeal_to_Authority_recall': 0.0736196319018405, 'Appeal_to_Authority_f1-score': 0.08571428571428573, 'Appeal_to_Authority_support': 163.0, 'micro avg_precision': 0.10256410256410256, 'micro avg_recall': 0.0736196319018405, 'micro avg_f1-score': 0.08571428571428573, 'micro avg_support': 163.0, 'macro avg_precision': 0.10256410256410256, 'macro avg_recall': 0.0736196319018405, 'macro avg_f1-score': 0.08571428571428573, 'macro avg_support': 163.0, 'weighted avg_precision': 0.10256410256410257, 'weighted avg_recall': 0.0736196319018405, 'weighted avg_f1-score': 0.08571428571428573, 'weighted avg_support': 163.0, 'O_support': 2767, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 1}, {'micro_f1': 0.7649625935162094, 'precision': 0.7649625935162094, 'Appeal_to_Authority_precision': 0.19658119658119658, 'Appeal_to_Authority_recall': 0.125, 'Appeal_to_Authority_f1-score': 0.15282392026578073, 'Appeal_to_Authority_support': 184.0, 'micro avg_precision': 0.19658119658119658, 'micro avg_recall': 0.125, 'micro avg_f1-score': 0.15282392026578073, 'micro avg_support': 184.0, 'macro avg_precision': 0.19658119658119658, 'macro avg_recall': 0.125, 'macro avg_f1-score': 0.15282392026578073, 'macro avg_support': 184.0, 'weighted avg_precision': 0.19658119658119658, 'weighted avg_recall': 0.125, 'weighted avg_f1-score': 0.15282392026578073, 'weighted avg_support': 184.0, 'O_support': 2767, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 2}, {'micro_f1': 0.7753532834580215, 'precision': 0.7753532834580216, 'Appeal_to_Authority_precision': 0.13675213675213677, 'Appeal_to_Authority_recall': 0.11188811188811189, 'Appeal_to_Authority_f1-score': 0.12307692307692308, 'Appeal_to_Authority_support': 143.0, 'micro avg_precision': 0.13675213675213677, 'micro avg_recall': 0.11188811188811189, 'micro avg_f1-score': 0.12307692307692308, 'micro avg_support': 143.0, 'macro avg_precision': 0.13675213675213677, 'macro avg_recall': 0.11188811188811189, 'macro avg_f1-score': 0.12307692307692308, 'macro avg_support': 143.0, 'weighted avg_precision': 0.13675213675213677, 'weighted avg_recall': 0.11188811188811189, 'weighted avg_f1-score': 0.12307692307692308, 'weighted avg_support': 143.0, 'O_support': 2767, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 3}]}
{'micro_f1': 0.7684954280964256, 'precision': 0.7684954280964256, 'Appeal_to_Authority_precision': 0.21367521367521367, 'Appeal_to_Authority_recall': 0.1592356687898089, 'Appeal_to_Authority_f1-score': 0.18248175182481752, 'Appeal_to_Authority_support': 157.0, 'micro avg_precision': 0.21367521367521367, 'micro avg_recall': 0.1592356687898089, 'micro avg_f1-score': 0.18248175182481752, 'micro avg_support': 157.0, 'macro avg_precision': 0.21367521367521367, 'macro avg_recall': 0.1592356687898089, 'macro avg_f1-score': 0.18248175182481752, 'macro avg_support': 157.0, 'weighted avg_precision': 0.21367521367521367, 'weighted avg_recall': 0.1592356687898089, 'weighted avg_f1-score': 0.18248175182481752, 'weighted avg_support': 157.0, 'O_support': 2767, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 4}
{'results': [{'micro_f1': 0.6286367414796342, 'precision': 0.6286367414796342, 'Appeal_to_Authority_precision': 0.0, 'Appeal_to_Authority_recall': 0.0, 'Appeal_to_Authority_f1-score': 0.0, 'Appeal_to_Authority_support': 137.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 137.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 137.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 137.0, 'O_support': 2767, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 0}, {'micro_f1': 0.758520365752286, 'precision': 0.758520365752286, 'Appeal_to_Authority_precision': 0.10256410256410256, 'Appeal_to_Authority_recall': 0.0736196319018405, 'Appeal_to_Authority_f1-score': 0.08571428571428573, 'Appeal_to_Authority_support': 163.0, 'micro avg_precision': 0.10256410256410256, 'micro avg_recall': 0.0736196319018405, 'micro avg_f1-score': 0.08571428571428573, 'micro avg_support': 163.0, 'macro avg_precision': 0.10256410256410256, 'macro avg_recall': 0.0736196319018405, 'macro avg_f1-score': 0.08571428571428573, 'macro avg_support': 163.0, 'weighted avg_precision': 0.10256410256410257, 'weighted avg_recall': 0.0736196319018405, 'weighted avg_f1-score': 0.08571428571428573, 'weighted avg_support': 163.0, 'O_support': 2767, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 1}, {'micro_f1': 0.7649625935162094, 'precision': 0.7649625935162094, 'Appeal_to_Authority_precision': 0.19658119658119658, 'Appeal_to_Authority_recall': 0.125, 'Appeal_to_Authority_f1-score': 0.15282392026578073, 'Appeal_to_Authority_support': 184.0, 'micro avg_precision': 0.19658119658119658, 'micro avg_recall': 0.125, 'micro avg_f1-score': 0.15282392026578073, 'micro avg_support': 184.0, 'macro avg_precision': 0.19658119658119658, 'macro avg_recall': 0.125, 'macro avg_f1-score': 0.15282392026578073, 'macro avg_support': 184.0, 'weighted avg_precision': 0.19658119658119658, 'weighted avg_recall': 0.125, 'weighted avg_f1-score': 0.15282392026578073, 'weighted avg_support': 184.0, 'O_support': 2767, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 2}, {'micro_f1': 0.7753532834580215, 'precision': 0.7753532834580216, 'Appeal_to_Authority_precision': 0.13675213675213677, 'Appeal_to_Authority_recall': 0.11188811188811189, 'Appeal_to_Authority_f1-score': 0.12307692307692308, 'Appeal_to_Authority_support': 143.0, 'micro avg_precision': 0.13675213675213677, 'micro avg_recall': 0.11188811188811189, 'micro avg_f1-score': 0.12307692307692308, 'micro avg_support': 143.0, 'macro avg_precision': 0.13675213675213677, 'macro avg_recall': 0.11188811188811189, 'macro avg_f1-score': 0.12307692307692308, 'macro avg_support': 143.0, 'weighted avg_precision': 0.13675213675213677, 'weighted avg_recall': 0.11188811188811189, 'weighted avg_f1-score': 0.12307692307692308, 'weighted avg_support': 143.0, 'O_support': 2767, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 3}, {'micro_f1': 0.7684954280964256, 'precision': 0.7684954280964256, 'Appeal_to_Authority_precision': 0.21367521367521367, 'Appeal_to_Authority_recall': 0.1592356687898089, 'Appeal_to_Authority_f1-score': 0.18248175182481752, 'Appeal_to_Authority_support': 157.0, 'micro avg_precision': 0.21367521367521367, 'micro avg_recall': 0.1592356687898089, 'micro avg_f1-score': 0.18248175182481752, 'micro avg_support': 157.0, 'macro avg_precision': 0.21367521367521367, 'macro avg_recall': 0.1592356687898089, 'macro avg_f1-score': 0.18248175182481752, 'macro avg_support': 157.0, 'weighted avg_precision': 0.21367521367521367, 'weighted avg_recall': 0.1592356687898089, 'weighted avg_f1-score': 0.18248175182481752, 'weighted avg_support': 157.0, 'O_support': 2767, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 4}]}
Best model updated: current epoch macro f1 = 0.18248175182481752
{'micro_f1': 0.7847049044056525, 'precision': 0.7847049044056525, 'Appeal_to_Authority_precision': 0.3076923076923077, 'Appeal_to_Authority_recall': 0.1945945945945946, 'Appeal_to_Authority_f1-score': 0.23841059602649006, 'Appeal_to_Authority_support': 185.0, 'micro avg_precision': 0.3076923076923077, 'micro avg_recall': 0.1945945945945946, 'micro avg_f1-score': 0.23841059602649006, 'micro avg_support': 185.0, 'macro avg_precision': 0.3076923076923077, 'macro avg_recall': 0.1945945945945946, 'macro avg_f1-score': 0.23841059602649006, 'macro avg_support': 185.0, 'weighted avg_precision': 0.3076923076923077, 'weighted avg_recall': 0.1945945945945946, 'weighted avg_f1-score': 0.23841059602649006, 'weighted avg_support': 185.0, 'O_support': 2767, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 5}
{'results': [{'micro_f1': 0.6286367414796342, 'precision': 0.6286367414796342, 'Appeal_to_Authority_precision': 0.0, 'Appeal_to_Authority_recall': 0.0, 'Appeal_to_Authority_f1-score': 0.0, 'Appeal_to_Authority_support': 137.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 137.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 137.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 137.0, 'O_support': 2767, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 0}, {'micro_f1': 0.758520365752286, 'precision': 0.758520365752286, 'Appeal_to_Authority_precision': 0.10256410256410256, 'Appeal_to_Authority_recall': 0.0736196319018405, 'Appeal_to_Authority_f1-score': 0.08571428571428573, 'Appeal_to_Authority_support': 163.0, 'micro avg_precision': 0.10256410256410256, 'micro avg_recall': 0.0736196319018405, 'micro avg_f1-score': 0.08571428571428573, 'micro avg_support': 163.0, 'macro avg_precision': 0.10256410256410256, 'macro avg_recall': 0.0736196319018405, 'macro avg_f1-score': 0.08571428571428573, 'macro avg_support': 163.0, 'weighted avg_precision': 0.10256410256410257, 'weighted avg_recall': 0.0736196319018405, 'weighted avg_f1-score': 0.08571428571428573, 'weighted avg_support': 163.0, 'O_support': 2767, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 1}, {'micro_f1': 0.7649625935162094, 'precision': 0.7649625935162094, 'Appeal_to_Authority_precision': 0.19658119658119658, 'Appeal_to_Authority_recall': 0.125, 'Appeal_to_Authority_f1-score': 0.15282392026578073, 'Appeal_to_Authority_support': 184.0, 'micro avg_precision': 0.19658119658119658, 'micro avg_recall': 0.125, 'micro avg_f1-score': 0.15282392026578073, 'micro avg_support': 184.0, 'macro avg_precision': 0.19658119658119658, 'macro avg_recall': 0.125, 'macro avg_f1-score': 0.15282392026578073, 'macro avg_support': 184.0, 'weighted avg_precision': 0.19658119658119658, 'weighted avg_recall': 0.125, 'weighted avg_f1-score': 0.15282392026578073, 'weighted avg_support': 184.0, 'O_support': 2767, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 2}, {'micro_f1': 0.7753532834580215, 'precision': 0.7753532834580216, 'Appeal_to_Authority_precision': 0.13675213675213677, 'Appeal_to_Authority_recall': 0.11188811188811189, 'Appeal_to_Authority_f1-score': 0.12307692307692308, 'Appeal_to_Authority_support': 143.0, 'micro avg_precision': 0.13675213675213677, 'micro avg_recall': 0.11188811188811189, 'micro avg_f1-score': 0.12307692307692308, 'micro avg_support': 143.0, 'macro avg_precision': 0.13675213675213677, 'macro avg_recall': 0.11188811188811189, 'macro avg_f1-score': 0.12307692307692308, 'macro avg_support': 143.0, 'weighted avg_precision': 0.13675213675213677, 'weighted avg_recall': 0.11188811188811189, 'weighted avg_f1-score': 0.12307692307692308, 'weighted avg_support': 143.0, 'O_support': 2767, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 3}, {'micro_f1': 0.7684954280964256, 'precision': 0.7684954280964256, 'Appeal_to_Authority_precision': 0.21367521367521367, 'Appeal_to_Authority_recall': 0.1592356687898089, 'Appeal_to_Authority_f1-score': 0.18248175182481752, 'Appeal_to_Authority_support': 157.0, 'micro avg_precision': 0.21367521367521367, 'micro avg_recall': 0.1592356687898089, 'micro avg_f1-score': 0.18248175182481752, 'micro avg_support': 157.0, 'macro avg_precision': 0.21367521367521367, 'macro avg_recall': 0.1592356687898089, 'macro avg_f1-score': 0.18248175182481752, 'macro avg_support': 157.0, 'weighted avg_precision': 0.21367521367521367, 'weighted avg_recall': 0.1592356687898089, 'weighted avg_f1-score': 0.18248175182481752, 'weighted avg_support': 157.0, 'O_support': 2767, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 4}, {'micro_f1': 0.7847049044056525, 'precision': 0.7847049044056525, 'Appeal_to_Authority_precision': 0.3076923076923077, 'Appeal_to_Authority_recall': 0.1945945945945946, 'Appeal_to_Authority_f1-score': 0.23841059602649006, 'Appeal_to_Authority_support': 185.0, 'micro avg_precision': 0.3076923076923077, 'micro avg_recall': 0.1945945945945946, 'micro avg_f1-score': 0.23841059602649006, 'micro avg_support': 185.0, 'macro avg_precision': 0.3076923076923077, 'macro avg_recall': 0.1945945945945946, 'macro avg_f1-score': 0.23841059602649006, 'macro avg_support': 185.0, 'weighted avg_precision': 0.3076923076923077, 'weighted avg_recall': 0.1945945945945946, 'weighted avg_f1-score': 0.23841059602649006, 'weighted avg_support': 185.0, 'O_support': 2767, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 5}]}
Best model updated: current epoch macro f1 = 0.23841059602649006
{'micro_f1': 0.7766001662510391, 'precision': 0.7766001662510391, 'Appeal_to_Authority_precision': 0.3247863247863248, 'Appeal_to_Authority_recall': 0.2289156626506024, 'Appeal_to_Authority_f1-score': 0.26855123674911663, 'Appeal_to_Authority_support': 166.0, 'micro avg_precision': 0.3247863247863248, 'micro avg_recall': 0.2289156626506024, 'micro avg_f1-score': 0.26855123674911663, 'micro avg_support': 166.0, 'macro avg_precision': 0.3247863247863248, 'macro avg_recall': 0.2289156626506024, 'macro avg_f1-score': 0.26855123674911663, 'macro avg_support': 166.0, 'weighted avg_precision': 0.3247863247863248, 'weighted avg_recall': 0.2289156626506024, 'weighted avg_f1-score': 0.26855123674911663, 'weighted avg_support': 166.0, 'O_support': 2767, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 6}
{'results': [{'micro_f1': 0.6286367414796342, 'precision': 0.6286367414796342, 'Appeal_to_Authority_precision': 0.0, 'Appeal_to_Authority_recall': 0.0, 'Appeal_to_Authority_f1-score': 0.0, 'Appeal_to_Authority_support': 137.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 137.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 137.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 137.0, 'O_support': 2767, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 0}, {'micro_f1': 0.758520365752286, 'precision': 0.758520365752286, 'Appeal_to_Authority_precision': 0.10256410256410256, 'Appeal_to_Authority_recall': 0.0736196319018405, 'Appeal_to_Authority_f1-score': 0.08571428571428573, 'Appeal_to_Authority_support': 163.0, 'micro avg_precision': 0.10256410256410256, 'micro avg_recall': 0.0736196319018405, 'micro avg_f1-score': 0.08571428571428573, 'micro avg_support': 163.0, 'macro avg_precision': 0.10256410256410256, 'macro avg_recall': 0.0736196319018405, 'macro avg_f1-score': 0.08571428571428573, 'macro avg_support': 163.0, 'weighted avg_precision': 0.10256410256410257, 'weighted avg_recall': 0.0736196319018405, 'weighted avg_f1-score': 0.08571428571428573, 'weighted avg_support': 163.0, 'O_support': 2767, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 1}, {'micro_f1': 0.7649625935162094, 'precision': 0.7649625935162094, 'Appeal_to_Authority_precision': 0.19658119658119658, 'Appeal_to_Authority_recall': 0.125, 'Appeal_to_Authority_f1-score': 0.15282392026578073, 'Appeal_to_Authority_support': 184.0, 'micro avg_precision': 0.19658119658119658, 'micro avg_recall': 0.125, 'micro avg_f1-score': 0.15282392026578073, 'micro avg_support': 184.0, 'macro avg_precision': 0.19658119658119658, 'macro avg_recall': 0.125, 'macro avg_f1-score': 0.15282392026578073, 'macro avg_support': 184.0, 'weighted avg_precision': 0.19658119658119658, 'weighted avg_recall': 0.125, 'weighted avg_f1-score': 0.15282392026578073, 'weighted avg_support': 184.0, 'O_support': 2767, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 2}, {'micro_f1': 0.7753532834580215, 'precision': 0.7753532834580216, 'Appeal_to_Authority_precision': 0.13675213675213677, 'Appeal_to_Authority_recall': 0.11188811188811189, 'Appeal_to_Authority_f1-score': 0.12307692307692308, 'Appeal_to_Authority_support': 143.0, 'micro avg_precision': 0.13675213675213677, 'micro avg_recall': 0.11188811188811189, 'micro avg_f1-score': 0.12307692307692308, 'micro avg_support': 143.0, 'macro avg_precision': 0.13675213675213677, 'macro avg_recall': 0.11188811188811189, 'macro avg_f1-score': 0.12307692307692308, 'macro avg_support': 143.0, 'weighted avg_precision': 0.13675213675213677, 'weighted avg_recall': 0.11188811188811189, 'weighted avg_f1-score': 0.12307692307692308, 'weighted avg_support': 143.0, 'O_support': 2767, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 3}, {'micro_f1': 0.7684954280964256, 'precision': 0.7684954280964256, 'Appeal_to_Authority_precision': 0.21367521367521367, 'Appeal_to_Authority_recall': 0.1592356687898089, 'Appeal_to_Authority_f1-score': 0.18248175182481752, 'Appeal_to_Authority_support': 157.0, 'micro avg_precision': 0.21367521367521367, 'micro avg_recall': 0.1592356687898089, 'micro avg_f1-score': 0.18248175182481752, 'micro avg_support': 157.0, 'macro avg_precision': 0.21367521367521367, 'macro avg_recall': 0.1592356687898089, 'macro avg_f1-score': 0.18248175182481752, 'macro avg_support': 157.0, 'weighted avg_precision': 0.21367521367521367, 'weighted avg_recall': 0.1592356687898089, 'weighted avg_f1-score': 0.18248175182481752, 'weighted avg_support': 157.0, 'O_support': 2767, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 4}, {'micro_f1': 0.7847049044056525, 'precision': 0.7847049044056525, 'Appeal_to_Authority_precision': 0.3076923076923077, 'Appeal_to_Authority_recall': 0.1945945945945946, 'Appeal_to_Authority_f1-score': 0.23841059602649006, 'Appeal_to_Authority_support': 185.0, 'micro avg_precision': 0.3076923076923077, 'micro avg_recall': 0.1945945945945946, 'micro avg_f1-score': 0.23841059602649006, 'micro avg_support': 185.0, 'macro avg_precision': 0.3076923076923077, 'macro avg_recall': 0.1945945945945946, 'macro avg_f1-score': 0.23841059602649006, 'macro avg_support': 185.0, 'weighted avg_precision': 0.3076923076923077, 'weighted avg_recall': 0.1945945945945946, 'weighted avg_f1-score': 0.23841059602649006, 'weighted avg_support': 185.0, 'O_support': 2767, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 5}, {'micro_f1': 0.7766001662510391, 'precision': 0.7766001662510391, 'Appeal_to_Authority_precision': 0.3247863247863248, 'Appeal_to_Authority_recall': 0.2289156626506024, 'Appeal_to_Authority_f1-score': 0.26855123674911663, 'Appeal_to_Authority_support': 166.0, 'micro avg_precision': 0.3247863247863248, 'micro avg_recall': 0.2289156626506024, 'micro avg_f1-score': 0.26855123674911663, 'micro avg_support': 166.0, 'macro avg_precision': 0.3247863247863248, 'macro avg_recall': 0.2289156626506024, 'macro avg_f1-score': 0.26855123674911663, 'macro avg_support': 166.0, 'weighted avg_precision': 0.3247863247863248, 'weighted avg_recall': 0.2289156626506024, 'weighted avg_f1-score': 0.26855123674911663, 'weighted avg_support': 166.0, 'O_support': 2767, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 6}]}
Best model updated: current epoch macro f1 = 0.26855123674911663
{'micro_f1': 0.7651704073150458, 'precision': 0.7651704073150457, 'Appeal_to_Authority_precision': 0.26495726495726496, 'Appeal_to_Authority_recall': 0.21830985915492956, 'Appeal_to_Authority_f1-score': 0.23938223938223938, 'Appeal_to_Authority_support': 142.0, 'micro avg_precision': 0.26495726495726496, 'micro avg_recall': 0.21830985915492956, 'micro avg_f1-score': 0.23938223938223938, 'micro avg_support': 142.0, 'macro avg_precision': 0.26495726495726496, 'macro avg_recall': 0.21830985915492956, 'macro avg_f1-score': 0.23938223938223938, 'macro avg_support': 142.0, 'weighted avg_precision': 0.26495726495726496, 'weighted avg_recall': 0.21830985915492956, 'weighted avg_f1-score': 0.23938223938223938, 'weighted avg_support': 142.0, 'O_support': 2767, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 7}
{'results': [{'micro_f1': 0.6286367414796342, 'precision': 0.6286367414796342, 'Appeal_to_Authority_precision': 0.0, 'Appeal_to_Authority_recall': 0.0, 'Appeal_to_Authority_f1-score': 0.0, 'Appeal_to_Authority_support': 137.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 137.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 137.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 137.0, 'O_support': 2767, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 0}, {'micro_f1': 0.758520365752286, 'precision': 0.758520365752286, 'Appeal_to_Authority_precision': 0.10256410256410256, 'Appeal_to_Authority_recall': 0.0736196319018405, 'Appeal_to_Authority_f1-score': 0.08571428571428573, 'Appeal_to_Authority_support': 163.0, 'micro avg_precision': 0.10256410256410256, 'micro avg_recall': 0.0736196319018405, 'micro avg_f1-score': 0.08571428571428573, 'micro avg_support': 163.0, 'macro avg_precision': 0.10256410256410256, 'macro avg_recall': 0.0736196319018405, 'macro avg_f1-score': 0.08571428571428573, 'macro avg_support': 163.0, 'weighted avg_precision': 0.10256410256410257, 'weighted avg_recall': 0.0736196319018405, 'weighted avg_f1-score': 0.08571428571428573, 'weighted avg_support': 163.0, 'O_support': 2767, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 1}, {'micro_f1': 0.7649625935162094, 'precision': 0.7649625935162094, 'Appeal_to_Authority_precision': 0.19658119658119658, 'Appeal_to_Authority_recall': 0.125, 'Appeal_to_Authority_f1-score': 0.15282392026578073, 'Appeal_to_Authority_support': 184.0, 'micro avg_precision': 0.19658119658119658, 'micro avg_recall': 0.125, 'micro avg_f1-score': 0.15282392026578073, 'micro avg_support': 184.0, 'macro avg_precision': 0.19658119658119658, 'macro avg_recall': 0.125, 'macro avg_f1-score': 0.15282392026578073, 'macro avg_support': 184.0, 'weighted avg_precision': 0.19658119658119658, 'weighted avg_recall': 0.125, 'weighted avg_f1-score': 0.15282392026578073, 'weighted avg_support': 184.0, 'O_support': 2767, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 2}, {'micro_f1': 0.7753532834580215, 'precision': 0.7753532834580216, 'Appeal_to_Authority_precision': 0.13675213675213677, 'Appeal_to_Authority_recall': 0.11188811188811189, 'Appeal_to_Authority_f1-score': 0.12307692307692308, 'Appeal_to_Authority_support': 143.0, 'micro avg_precision': 0.13675213675213677, 'micro avg_recall': 0.11188811188811189, 'micro avg_f1-score': 0.12307692307692308, 'micro avg_support': 143.0, 'macro avg_precision': 0.13675213675213677, 'macro avg_recall': 0.11188811188811189, 'macro avg_f1-score': 0.12307692307692308, 'macro avg_support': 143.0, 'weighted avg_precision': 0.13675213675213677, 'weighted avg_recall': 0.11188811188811189, 'weighted avg_f1-score': 0.12307692307692308, 'weighted avg_support': 143.0, 'O_support': 2767, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 3}, {'micro_f1': 0.7684954280964256, 'precision': 0.7684954280964256, 'Appeal_to_Authority_precision': 0.21367521367521367, 'Appeal_to_Authority_recall': 0.1592356687898089, 'Appeal_to_Authority_f1-score': 0.18248175182481752, 'Appeal_to_Authority_support': 157.0, 'micro avg_precision': 0.21367521367521367, 'micro avg_recall': 0.1592356687898089, 'micro avg_f1-score': 0.18248175182481752, 'micro avg_support': 157.0, 'macro avg_precision': 0.21367521367521367, 'macro avg_recall': 0.1592356687898089, 'macro avg_f1-score': 0.18248175182481752, 'macro avg_support': 157.0, 'weighted avg_precision': 0.21367521367521367, 'weighted avg_recall': 0.1592356687898089, 'weighted avg_f1-score': 0.18248175182481752, 'weighted avg_support': 157.0, 'O_support': 2767, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 4}, {'micro_f1': 0.7847049044056525, 'precision': 0.7847049044056525, 'Appeal_to_Authority_precision': 0.3076923076923077, 'Appeal_to_Authority_recall': 0.1945945945945946, 'Appeal_to_Authority_f1-score': 0.23841059602649006, 'Appeal_to_Authority_support': 185.0, 'micro avg_precision': 0.3076923076923077, 'micro avg_recall': 0.1945945945945946, 'micro avg_f1-score': 0.23841059602649006, 'micro avg_support': 185.0, 'macro avg_precision': 0.3076923076923077, 'macro avg_recall': 0.1945945945945946, 'macro avg_f1-score': 0.23841059602649006, 'macro avg_support': 185.0, 'weighted avg_precision': 0.3076923076923077, 'weighted avg_recall': 0.1945945945945946, 'weighted avg_f1-score': 0.23841059602649006, 'weighted avg_support': 185.0, 'O_support': 2767, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 5}, {'micro_f1': 0.7766001662510391, 'precision': 0.7766001662510391, 'Appeal_to_Authority_precision': 0.3247863247863248, 'Appeal_to_Authority_recall': 0.2289156626506024, 'Appeal_to_Authority_f1-score': 0.26855123674911663, 'Appeal_to_Authority_support': 166.0, 'micro avg_precision': 0.3247863247863248, 'micro avg_recall': 0.2289156626506024, 'micro avg_f1-score': 0.26855123674911663, 'micro avg_support': 166.0, 'macro avg_precision': 0.3247863247863248, 'macro avg_recall': 0.2289156626506024, 'macro avg_f1-score': 0.26855123674911663, 'macro avg_support': 166.0, 'weighted avg_precision': 0.3247863247863248, 'weighted avg_recall': 0.2289156626506024, 'weighted avg_f1-score': 0.26855123674911663, 'weighted avg_support': 166.0, 'O_support': 2767, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 6}, {'micro_f1': 0.7651704073150458, 'precision': 0.7651704073150457, 'Appeal_to_Authority_precision': 0.26495726495726496, 'Appeal_to_Authority_recall': 0.21830985915492956, 'Appeal_to_Authority_f1-score': 0.23938223938223938, 'Appeal_to_Authority_support': 142.0, 'micro avg_precision': 0.26495726495726496, 'micro avg_recall': 0.21830985915492956, 'micro avg_f1-score': 0.23938223938223938, 'micro avg_support': 142.0, 'macro avg_precision': 0.26495726495726496, 'macro avg_recall': 0.21830985915492956, 'macro avg_f1-score': 0.23938223938223938, 'macro avg_support': 142.0, 'weighted avg_precision': 0.26495726495726496, 'weighted avg_recall': 0.21830985915492956, 'weighted avg_f1-score': 0.23938223938223938, 'weighted avg_support': 142.0, 'O_support': 2767, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 7}]}
{'micro_f1': 0.7921862011637573, 'precision': 0.7921862011637573, 'Appeal_to_Authority_precision': 0.3247863247863248, 'Appeal_to_Authority_recall': 0.2159090909090909, 'Appeal_to_Authority_f1-score': 0.25938566552901027, 'Appeal_to_Authority_support': 176.0, 'micro avg_precision': 0.3247863247863248, 'micro avg_recall': 0.2159090909090909, 'micro avg_f1-score': 0.25938566552901027, 'micro avg_support': 176.0, 'macro avg_precision': 0.3247863247863248, 'macro avg_recall': 0.2159090909090909, 'macro avg_f1-score': 0.25938566552901027, 'macro avg_support': 176.0, 'weighted avg_precision': 0.3247863247863248, 'weighted avg_recall': 0.2159090909090909, 'weighted avg_f1-score': 0.25938566552901027, 'weighted avg_support': 176.0, 'O_support': 2767, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 8}
{'results': [{'micro_f1': 0.6286367414796342, 'precision': 0.6286367414796342, 'Appeal_to_Authority_precision': 0.0, 'Appeal_to_Authority_recall': 0.0, 'Appeal_to_Authority_f1-score': 0.0, 'Appeal_to_Authority_support': 137.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 137.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 137.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 137.0, 'O_support': 2767, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 0}, {'micro_f1': 0.758520365752286, 'precision': 0.758520365752286, 'Appeal_to_Authority_precision': 0.10256410256410256, 'Appeal_to_Authority_recall': 0.0736196319018405, 'Appeal_to_Authority_f1-score': 0.08571428571428573, 'Appeal_to_Authority_support': 163.0, 'micro avg_precision': 0.10256410256410256, 'micro avg_recall': 0.0736196319018405, 'micro avg_f1-score': 0.08571428571428573, 'micro avg_support': 163.0, 'macro avg_precision': 0.10256410256410256, 'macro avg_recall': 0.0736196319018405, 'macro avg_f1-score': 0.08571428571428573, 'macro avg_support': 163.0, 'weighted avg_precision': 0.10256410256410257, 'weighted avg_recall': 0.0736196319018405, 'weighted avg_f1-score': 0.08571428571428573, 'weighted avg_support': 163.0, 'O_support': 2767, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 1}, {'micro_f1': 0.7649625935162094, 'precision': 0.7649625935162094, 'Appeal_to_Authority_precision': 0.19658119658119658, 'Appeal_to_Authority_recall': 0.125, 'Appeal_to_Authority_f1-score': 0.15282392026578073, 'Appeal_to_Authority_support': 184.0, 'micro avg_precision': 0.19658119658119658, 'micro avg_recall': 0.125, 'micro avg_f1-score': 0.15282392026578073, 'micro avg_support': 184.0, 'macro avg_precision': 0.19658119658119658, 'macro avg_recall': 0.125, 'macro avg_f1-score': 0.15282392026578073, 'macro avg_support': 184.0, 'weighted avg_precision': 0.19658119658119658, 'weighted avg_recall': 0.125, 'weighted avg_f1-score': 0.15282392026578073, 'weighted avg_support': 184.0, 'O_support': 2767, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 2}, {'micro_f1': 0.7753532834580215, 'precision': 0.7753532834580216, 'Appeal_to_Authority_precision': 0.13675213675213677, 'Appeal_to_Authority_recall': 0.11188811188811189, 'Appeal_to_Authority_f1-score': 0.12307692307692308, 'Appeal_to_Authority_support': 143.0, 'micro avg_precision': 0.13675213675213677, 'micro avg_recall': 0.11188811188811189, 'micro avg_f1-score': 0.12307692307692308, 'micro avg_support': 143.0, 'macro avg_precision': 0.13675213675213677, 'macro avg_recall': 0.11188811188811189, 'macro avg_f1-score': 0.12307692307692308, 'macro avg_support': 143.0, 'weighted avg_precision': 0.13675213675213677, 'weighted avg_recall': 0.11188811188811189, 'weighted avg_f1-score': 0.12307692307692308, 'weighted avg_support': 143.0, 'O_support': 2767, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 3}, {'micro_f1': 0.7684954280964256, 'precision': 0.7684954280964256, 'Appeal_to_Authority_precision': 0.21367521367521367, 'Appeal_to_Authority_recall': 0.1592356687898089, 'Appeal_to_Authority_f1-score': 0.18248175182481752, 'Appeal_to_Authority_support': 157.0, 'micro avg_precision': 0.21367521367521367, 'micro avg_recall': 0.1592356687898089, 'micro avg_f1-score': 0.18248175182481752, 'micro avg_support': 157.0, 'macro avg_precision': 0.21367521367521367, 'macro avg_recall': 0.1592356687898089, 'macro avg_f1-score': 0.18248175182481752, 'macro avg_support': 157.0, 'weighted avg_precision': 0.21367521367521367, 'weighted avg_recall': 0.1592356687898089, 'weighted avg_f1-score': 0.18248175182481752, 'weighted avg_support': 157.0, 'O_support': 2767, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 4}, {'micro_f1': 0.7847049044056525, 'precision': 0.7847049044056525, 'Appeal_to_Authority_precision': 0.3076923076923077, 'Appeal_to_Authority_recall': 0.1945945945945946, 'Appeal_to_Authority_f1-score': 0.23841059602649006, 'Appeal_to_Authority_support': 185.0, 'micro avg_precision': 0.3076923076923077, 'micro avg_recall': 0.1945945945945946, 'micro avg_f1-score': 0.23841059602649006, 'micro avg_support': 185.0, 'macro avg_precision': 0.3076923076923077, 'macro avg_recall': 0.1945945945945946, 'macro avg_f1-score': 0.23841059602649006, 'macro avg_support': 185.0, 'weighted avg_precision': 0.3076923076923077, 'weighted avg_recall': 0.1945945945945946, 'weighted avg_f1-score': 0.23841059602649006, 'weighted avg_support': 185.0, 'O_support': 2767, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 5}, {'micro_f1': 0.7766001662510391, 'precision': 0.7766001662510391, 'Appeal_to_Authority_precision': 0.3247863247863248, 'Appeal_to_Authority_recall': 0.2289156626506024, 'Appeal_to_Authority_f1-score': 0.26855123674911663, 'Appeal_to_Authority_support': 166.0, 'micro avg_precision': 0.3247863247863248, 'micro avg_recall': 0.2289156626506024, 'micro avg_f1-score': 0.26855123674911663, 'micro avg_support': 166.0, 'macro avg_precision': 0.3247863247863248, 'macro avg_recall': 0.2289156626506024, 'macro avg_f1-score': 0.26855123674911663, 'macro avg_support': 166.0, 'weighted avg_precision': 0.3247863247863248, 'weighted avg_recall': 0.2289156626506024, 'weighted avg_f1-score': 0.26855123674911663, 'weighted avg_support': 166.0, 'O_support': 2767, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 6}, {'micro_f1': 0.7651704073150458, 'precision': 0.7651704073150457, 'Appeal_to_Authority_precision': 0.26495726495726496, 'Appeal_to_Authority_recall': 0.21830985915492956, 'Appeal_to_Authority_f1-score': 0.23938223938223938, 'Appeal_to_Authority_support': 142.0, 'micro avg_precision': 0.26495726495726496, 'micro avg_recall': 0.21830985915492956, 'micro avg_f1-score': 0.23938223938223938, 'micro avg_support': 142.0, 'macro avg_precision': 0.26495726495726496, 'macro avg_recall': 0.21830985915492956, 'macro avg_f1-score': 0.23938223938223938, 'macro avg_support': 142.0, 'weighted avg_precision': 0.26495726495726496, 'weighted avg_recall': 0.21830985915492956, 'weighted avg_f1-score': 0.23938223938223938, 'weighted avg_support': 142.0, 'O_support': 2767, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 7}, {'micro_f1': 0.7921862011637573, 'precision': 0.7921862011637573, 'Appeal_to_Authority_precision': 0.3247863247863248, 'Appeal_to_Authority_recall': 0.2159090909090909, 'Appeal_to_Authority_f1-score': 0.25938566552901027, 'Appeal_to_Authority_support': 176.0, 'micro avg_precision': 0.3247863247863248, 'micro avg_recall': 0.2159090909090909, 'micro avg_f1-score': 0.25938566552901027, 'micro avg_support': 176.0, 'macro avg_precision': 0.3247863247863248, 'macro avg_recall': 0.2159090909090909, 'macro avg_f1-score': 0.25938566552901027, 'macro avg_support': 176.0, 'weighted avg_precision': 0.3247863247863248, 'weighted avg_recall': 0.2159090909090909, 'weighted avg_f1-score': 0.25938566552901027, 'weighted avg_support': 176.0, 'O_support': 2767, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 8}]}
Early stopping triggered.
Saving model to directory: ./models/M2/2024-05-13-23-08-48_aug/mdeberta-v3-base_0_ME10_target=Appeal_to_Authority_SUBSAMPLED_2024-05-13-23-08-48
Training model no. 1 of 23 for (1, 'Appeal_to_Popularity') persuasion technique...
{'micro_f1': 0.750503018108652, 'precision': 0.7505030181086519, 'Appeal_to_Popularity_precision': 0.02127659574468085, 'Appeal_to_Popularity_recall': 0.007518796992481203, 'Appeal_to_Popularity_f1-score': 0.011111111111111112, 'Appeal_to_Popularity_support': 133.0, 'micro avg_precision': 0.02127659574468085, 'micro avg_recall': 0.007518796992481203, 'micro avg_f1-score': 0.011111111111111112, 'micro avg_support': 133.0, 'macro avg_precision': 0.02127659574468085, 'macro avg_recall': 0.007518796992481203, 'macro avg_f1-score': 0.011111111111111112, 'macro avg_support': 133.0, 'weighted avg_precision': 0.02127659574468085, 'weighted avg_recall': 0.007518796992481203, 'weighted avg_f1-score': 0.011111111111111112, 'weighted avg_support': 133.0, 'O_support': 1320, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 0}
{'results': [{'micro_f1': 0.750503018108652, 'precision': 0.7505030181086519, 'Appeal_to_Popularity_precision': 0.02127659574468085, 'Appeal_to_Popularity_recall': 0.007518796992481203, 'Appeal_to_Popularity_f1-score': 0.011111111111111112, 'Appeal_to_Popularity_support': 133.0, 'micro avg_precision': 0.02127659574468085, 'micro avg_recall': 0.007518796992481203, 'micro avg_f1-score': 0.011111111111111112, 'micro avg_support': 133.0, 'macro avg_precision': 0.02127659574468085, 'macro avg_recall': 0.007518796992481203, 'macro avg_f1-score': 0.011111111111111112, 'macro avg_support': 133.0, 'weighted avg_precision': 0.02127659574468085, 'weighted avg_recall': 0.007518796992481203, 'weighted avg_f1-score': 0.011111111111111112, 'weighted avg_support': 133.0, 'O_support': 1320, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 0}]}
Best model updated: current epoch macro f1 = 0.011111111111111112
{'micro_f1': 0.7716297786720322, 'precision': 0.7716297786720322, 'Appeal_to_Popularity_precision': 0.06382978723404255, 'Appeal_to_Popularity_recall': 0.04477611940298507, 'Appeal_to_Popularity_f1-score': 0.05263157894736841, 'Appeal_to_Popularity_support': 67.0, 'micro avg_precision': 0.06382978723404255, 'micro avg_recall': 0.04477611940298507, 'micro avg_f1-score': 0.05263157894736841, 'micro avg_support': 67.0, 'macro avg_precision': 0.06382978723404255, 'macro avg_recall': 0.04477611940298507, 'macro avg_f1-score': 0.05263157894736841, 'macro avg_support': 67.0, 'weighted avg_precision': 0.06382978723404255, 'weighted avg_recall': 0.04477611940298507, 'weighted avg_f1-score': 0.05263157894736841, 'weighted avg_support': 67.0, 'O_support': 1320, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 1}
{'results': [{'micro_f1': 0.750503018108652, 'precision': 0.7505030181086519, 'Appeal_to_Popularity_precision': 0.02127659574468085, 'Appeal_to_Popularity_recall': 0.007518796992481203, 'Appeal_to_Popularity_f1-score': 0.011111111111111112, 'Appeal_to_Popularity_support': 133.0, 'micro avg_precision': 0.02127659574468085, 'micro avg_recall': 0.007518796992481203, 'micro avg_f1-score': 0.011111111111111112, 'micro avg_support': 133.0, 'macro avg_precision': 0.02127659574468085, 'macro avg_recall': 0.007518796992481203, 'macro avg_f1-score': 0.011111111111111112, 'macro avg_support': 133.0, 'weighted avg_precision': 0.02127659574468085, 'weighted avg_recall': 0.007518796992481203, 'weighted avg_f1-score': 0.011111111111111112, 'weighted avg_support': 133.0, 'O_support': 1320, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 0}, {'micro_f1': 0.7716297786720322, 'precision': 0.7716297786720322, 'Appeal_to_Popularity_precision': 0.06382978723404255, 'Appeal_to_Popularity_recall': 0.04477611940298507, 'Appeal_to_Popularity_f1-score': 0.05263157894736841, 'Appeal_to_Popularity_support': 67.0, 'micro avg_precision': 0.06382978723404255, 'micro avg_recall': 0.04477611940298507, 'micro avg_f1-score': 0.05263157894736841, 'micro avg_support': 67.0, 'macro avg_precision': 0.06382978723404255, 'macro avg_recall': 0.04477611940298507, 'macro avg_f1-score': 0.05263157894736841, 'macro avg_support': 67.0, 'weighted avg_precision': 0.06382978723404255, 'weighted avg_recall': 0.04477611940298507, 'weighted avg_f1-score': 0.05263157894736841, 'weighted avg_support': 67.0, 'O_support': 1320, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 1}]}
Best model updated: current epoch macro f1 = 0.05263157894736841
{'micro_f1': 0.7449698189134809, 'precision': 0.7449698189134809, 'Appeal_to_Popularity_precision': 0.19148936170212766, 'Appeal_to_Popularity_recall': 0.0989010989010989, 'Appeal_to_Popularity_f1-score': 0.13043478260869565, 'Appeal_to_Popularity_support': 91.0, 'micro avg_precision': 0.19148936170212766, 'micro avg_recall': 0.0989010989010989, 'micro avg_f1-score': 0.13043478260869565, 'micro avg_support': 91.0, 'macro avg_precision': 0.19148936170212766, 'macro avg_recall': 0.0989010989010989, 'macro avg_f1-score': 0.13043478260869565, 'macro avg_support': 91.0, 'weighted avg_precision': 0.19148936170212766, 'weighted avg_recall': 0.0989010989010989, 'weighted avg_f1-score': 0.13043478260869565, 'weighted avg_support': 91.0, 'O_support': 1320, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 2}
{'results': [{'micro_f1': 0.750503018108652, 'precision': 0.7505030181086519, 'Appeal_to_Popularity_precision': 0.02127659574468085, 'Appeal_to_Popularity_recall': 0.007518796992481203, 'Appeal_to_Popularity_f1-score': 0.011111111111111112, 'Appeal_to_Popularity_support': 133.0, 'micro avg_precision': 0.02127659574468085, 'micro avg_recall': 0.007518796992481203, 'micro avg_f1-score': 0.011111111111111112, 'micro avg_support': 133.0, 'macro avg_precision': 0.02127659574468085, 'macro avg_recall': 0.007518796992481203, 'macro avg_f1-score': 0.011111111111111112, 'macro avg_support': 133.0, 'weighted avg_precision': 0.02127659574468085, 'weighted avg_recall': 0.007518796992481203, 'weighted avg_f1-score': 0.011111111111111112, 'weighted avg_support': 133.0, 'O_support': 1320, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 0}, {'micro_f1': 0.7716297786720322, 'precision': 0.7716297786720322, 'Appeal_to_Popularity_precision': 0.06382978723404255, 'Appeal_to_Popularity_recall': 0.04477611940298507, 'Appeal_to_Popularity_f1-score': 0.05263157894736841, 'Appeal_to_Popularity_support': 67.0, 'micro avg_precision': 0.06382978723404255, 'micro avg_recall': 0.04477611940298507, 'micro avg_f1-score': 0.05263157894736841, 'micro avg_support': 67.0, 'macro avg_precision': 0.06382978723404255, 'macro avg_recall': 0.04477611940298507, 'macro avg_f1-score': 0.05263157894736841, 'macro avg_support': 67.0, 'weighted avg_precision': 0.06382978723404255, 'weighted avg_recall': 0.04477611940298507, 'weighted avg_f1-score': 0.05263157894736841, 'weighted avg_support': 67.0, 'O_support': 1320, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 1}, {'micro_f1': 0.7449698189134809, 'precision': 0.7449698189134809, 'Appeal_to_Popularity_precision': 0.19148936170212766, 'Appeal_to_Popularity_recall': 0.0989010989010989, 'Appeal_to_Popularity_f1-score': 0.13043478260869565, 'Appeal_to_Popularity_support': 91.0, 'micro avg_precision': 0.19148936170212766, 'micro avg_recall': 0.0989010989010989, 'micro avg_f1-score': 0.13043478260869565, 'micro avg_support': 91.0, 'macro avg_precision': 0.19148936170212766, 'macro avg_recall': 0.0989010989010989, 'macro avg_f1-score': 0.13043478260869565, 'macro avg_support': 91.0, 'weighted avg_precision': 0.19148936170212766, 'weighted avg_recall': 0.0989010989010989, 'weighted avg_f1-score': 0.13043478260869565, 'weighted avg_support': 91.0, 'O_support': 1320, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 2}]}
Best model updated: current epoch macro f1 = 0.13043478260869565
{'micro_f1': 0.7525150905432596, 'precision': 0.7525150905432596, 'Appeal_to_Popularity_precision': 0.23404255319148937, 'Appeal_to_Popularity_recall': 0.125, 'Appeal_to_Popularity_f1-score': 0.16296296296296298, 'Appeal_to_Popularity_support': 88.0, 'micro avg_precision': 0.23404255319148937, 'micro avg_recall': 0.125, 'micro avg_f1-score': 0.16296296296296298, 'micro avg_support': 88.0, 'macro avg_precision': 0.23404255319148937, 'macro avg_recall': 0.125, 'macro avg_f1-score': 0.16296296296296298, 'macro avg_support': 88.0, 'weighted avg_precision': 0.23404255319148934, 'weighted avg_recall': 0.125, 'weighted avg_f1-score': 0.16296296296296298, 'weighted avg_support': 88.0, 'O_support': 1320, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 3}
{'results': [{'micro_f1': 0.750503018108652, 'precision': 0.7505030181086519, 'Appeal_to_Popularity_precision': 0.02127659574468085, 'Appeal_to_Popularity_recall': 0.007518796992481203, 'Appeal_to_Popularity_f1-score': 0.011111111111111112, 'Appeal_to_Popularity_support': 133.0, 'micro avg_precision': 0.02127659574468085, 'micro avg_recall': 0.007518796992481203, 'micro avg_f1-score': 0.011111111111111112, 'micro avg_support': 133.0, 'macro avg_precision': 0.02127659574468085, 'macro avg_recall': 0.007518796992481203, 'macro avg_f1-score': 0.011111111111111112, 'macro avg_support': 133.0, 'weighted avg_precision': 0.02127659574468085, 'weighted avg_recall': 0.007518796992481203, 'weighted avg_f1-score': 0.011111111111111112, 'weighted avg_support': 133.0, 'O_support': 1320, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 0}, {'micro_f1': 0.7716297786720322, 'precision': 0.7716297786720322, 'Appeal_to_Popularity_precision': 0.06382978723404255, 'Appeal_to_Popularity_recall': 0.04477611940298507, 'Appeal_to_Popularity_f1-score': 0.05263157894736841, 'Appeal_to_Popularity_support': 67.0, 'micro avg_precision': 0.06382978723404255, 'micro avg_recall': 0.04477611940298507, 'micro avg_f1-score': 0.05263157894736841, 'micro avg_support': 67.0, 'macro avg_precision': 0.06382978723404255, 'macro avg_recall': 0.04477611940298507, 'macro avg_f1-score': 0.05263157894736841, 'macro avg_support': 67.0, 'weighted avg_precision': 0.06382978723404255, 'weighted avg_recall': 0.04477611940298507, 'weighted avg_f1-score': 0.05263157894736841, 'weighted avg_support': 67.0, 'O_support': 1320, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 1}, {'micro_f1': 0.7449698189134809, 'precision': 0.7449698189134809, 'Appeal_to_Popularity_precision': 0.19148936170212766, 'Appeal_to_Popularity_recall': 0.0989010989010989, 'Appeal_to_Popularity_f1-score': 0.13043478260869565, 'Appeal_to_Popularity_support': 91.0, 'micro avg_precision': 0.19148936170212766, 'micro avg_recall': 0.0989010989010989, 'micro avg_f1-score': 0.13043478260869565, 'micro avg_support': 91.0, 'macro avg_precision': 0.19148936170212766, 'macro avg_recall': 0.0989010989010989, 'macro avg_f1-score': 0.13043478260869565, 'macro avg_support': 91.0, 'weighted avg_precision': 0.19148936170212766, 'weighted avg_recall': 0.0989010989010989, 'weighted avg_f1-score': 0.13043478260869565, 'weighted avg_support': 91.0, 'O_support': 1320, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 2}, {'micro_f1': 0.7525150905432596, 'precision': 0.7525150905432596, 'Appeal_to_Popularity_precision': 0.23404255319148937, 'Appeal_to_Popularity_recall': 0.125, 'Appeal_to_Popularity_f1-score': 0.16296296296296298, 'Appeal_to_Popularity_support': 88.0, 'micro avg_precision': 0.23404255319148937, 'micro avg_recall': 0.125, 'micro avg_f1-score': 0.16296296296296298, 'micro avg_support': 88.0, 'macro avg_precision': 0.23404255319148937, 'macro avg_recall': 0.125, 'macro avg_f1-score': 0.16296296296296298, 'macro avg_support': 88.0, 'weighted avg_precision': 0.23404255319148934, 'weighted avg_recall': 0.125, 'weighted avg_f1-score': 0.16296296296296298, 'weighted avg_support': 88.0, 'O_support': 1320, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 3}]}
Best model updated: current epoch macro f1 = 0.16296296296296298
{'micro_f1': 0.7676056338028169, 'precision': 0.7676056338028169, 'Appeal_to_Popularity_precision': 0.2127659574468085, 'Appeal_to_Popularity_recall': 0.12658227848101267, 'Appeal_to_Popularity_f1-score': 0.15873015873015875, 'Appeal_to_Popularity_support': 79.0, 'micro avg_precision': 0.2127659574468085, 'micro avg_recall': 0.12658227848101267, 'micro avg_f1-score': 0.15873015873015875, 'micro avg_support': 79.0, 'macro avg_precision': 0.2127659574468085, 'macro avg_recall': 0.12658227848101267, 'macro avg_f1-score': 0.15873015873015875, 'macro avg_support': 79.0, 'weighted avg_precision': 0.2127659574468085, 'weighted avg_recall': 0.12658227848101267, 'weighted avg_f1-score': 0.15873015873015875, 'weighted avg_support': 79.0, 'O_support': 1320, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 4}
{'results': [{'micro_f1': 0.750503018108652, 'precision': 0.7505030181086519, 'Appeal_to_Popularity_precision': 0.02127659574468085, 'Appeal_to_Popularity_recall': 0.007518796992481203, 'Appeal_to_Popularity_f1-score': 0.011111111111111112, 'Appeal_to_Popularity_support': 133.0, 'micro avg_precision': 0.02127659574468085, 'micro avg_recall': 0.007518796992481203, 'micro avg_f1-score': 0.011111111111111112, 'micro avg_support': 133.0, 'macro avg_precision': 0.02127659574468085, 'macro avg_recall': 0.007518796992481203, 'macro avg_f1-score': 0.011111111111111112, 'macro avg_support': 133.0, 'weighted avg_precision': 0.02127659574468085, 'weighted avg_recall': 0.007518796992481203, 'weighted avg_f1-score': 0.011111111111111112, 'weighted avg_support': 133.0, 'O_support': 1320, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 0}, {'micro_f1': 0.7716297786720322, 'precision': 0.7716297786720322, 'Appeal_to_Popularity_precision': 0.06382978723404255, 'Appeal_to_Popularity_recall': 0.04477611940298507, 'Appeal_to_Popularity_f1-score': 0.05263157894736841, 'Appeal_to_Popularity_support': 67.0, 'micro avg_precision': 0.06382978723404255, 'micro avg_recall': 0.04477611940298507, 'micro avg_f1-score': 0.05263157894736841, 'micro avg_support': 67.0, 'macro avg_precision': 0.06382978723404255, 'macro avg_recall': 0.04477611940298507, 'macro avg_f1-score': 0.05263157894736841, 'macro avg_support': 67.0, 'weighted avg_precision': 0.06382978723404255, 'weighted avg_recall': 0.04477611940298507, 'weighted avg_f1-score': 0.05263157894736841, 'weighted avg_support': 67.0, 'O_support': 1320, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 1}, {'micro_f1': 0.7449698189134809, 'precision': 0.7449698189134809, 'Appeal_to_Popularity_precision': 0.19148936170212766, 'Appeal_to_Popularity_recall': 0.0989010989010989, 'Appeal_to_Popularity_f1-score': 0.13043478260869565, 'Appeal_to_Popularity_support': 91.0, 'micro avg_precision': 0.19148936170212766, 'micro avg_recall': 0.0989010989010989, 'micro avg_f1-score': 0.13043478260869565, 'micro avg_support': 91.0, 'macro avg_precision': 0.19148936170212766, 'macro avg_recall': 0.0989010989010989, 'macro avg_f1-score': 0.13043478260869565, 'macro avg_support': 91.0, 'weighted avg_precision': 0.19148936170212766, 'weighted avg_recall': 0.0989010989010989, 'weighted avg_f1-score': 0.13043478260869565, 'weighted avg_support': 91.0, 'O_support': 1320, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 2}, {'micro_f1': 0.7525150905432596, 'precision': 0.7525150905432596, 'Appeal_to_Popularity_precision': 0.23404255319148937, 'Appeal_to_Popularity_recall': 0.125, 'Appeal_to_Popularity_f1-score': 0.16296296296296298, 'Appeal_to_Popularity_support': 88.0, 'micro avg_precision': 0.23404255319148937, 'micro avg_recall': 0.125, 'micro avg_f1-score': 0.16296296296296298, 'micro avg_support': 88.0, 'macro avg_precision': 0.23404255319148937, 'macro avg_recall': 0.125, 'macro avg_f1-score': 0.16296296296296298, 'macro avg_support': 88.0, 'weighted avg_precision': 0.23404255319148934, 'weighted avg_recall': 0.125, 'weighted avg_f1-score': 0.16296296296296298, 'weighted avg_support': 88.0, 'O_support': 1320, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 3}, {'micro_f1': 0.7676056338028169, 'precision': 0.7676056338028169, 'Appeal_to_Popularity_precision': 0.2127659574468085, 'Appeal_to_Popularity_recall': 0.12658227848101267, 'Appeal_to_Popularity_f1-score': 0.15873015873015875, 'Appeal_to_Popularity_support': 79.0, 'micro avg_precision': 0.2127659574468085, 'micro avg_recall': 0.12658227848101267, 'micro avg_f1-score': 0.15873015873015875, 'micro avg_support': 79.0, 'macro avg_precision': 0.2127659574468085, 'macro avg_recall': 0.12658227848101267, 'macro avg_f1-score': 0.15873015873015875, 'macro avg_support': 79.0, 'weighted avg_precision': 0.2127659574468085, 'weighted avg_recall': 0.12658227848101267, 'weighted avg_f1-score': 0.15873015873015875, 'weighted avg_support': 79.0, 'O_support': 1320, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 4}]}
{'micro_f1': 0.7751509054325956, 'precision': 0.7751509054325956, 'Appeal_to_Popularity_precision': 0.3191489361702128, 'Appeal_to_Popularity_recall': 0.17045454545454544, 'Appeal_to_Popularity_f1-score': 0.22222222222222224, 'Appeal_to_Popularity_support': 88.0, 'micro avg_precision': 0.3191489361702128, 'micro avg_recall': 0.17045454545454544, 'micro avg_f1-score': 0.22222222222222224, 'micro avg_support': 88.0, 'macro avg_precision': 0.3191489361702128, 'macro avg_recall': 0.17045454545454544, 'macro avg_f1-score': 0.22222222222222224, 'macro avg_support': 88.0, 'weighted avg_precision': 0.3191489361702128, 'weighted avg_recall': 0.17045454545454544, 'weighted avg_f1-score': 0.22222222222222224, 'weighted avg_support': 88.0, 'O_support': 1320, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 5}
{'results': [{'micro_f1': 0.750503018108652, 'precision': 0.7505030181086519, 'Appeal_to_Popularity_precision': 0.02127659574468085, 'Appeal_to_Popularity_recall': 0.007518796992481203, 'Appeal_to_Popularity_f1-score': 0.011111111111111112, 'Appeal_to_Popularity_support': 133.0, 'micro avg_precision': 0.02127659574468085, 'micro avg_recall': 0.007518796992481203, 'micro avg_f1-score': 0.011111111111111112, 'micro avg_support': 133.0, 'macro avg_precision': 0.02127659574468085, 'macro avg_recall': 0.007518796992481203, 'macro avg_f1-score': 0.011111111111111112, 'macro avg_support': 133.0, 'weighted avg_precision': 0.02127659574468085, 'weighted avg_recall': 0.007518796992481203, 'weighted avg_f1-score': 0.011111111111111112, 'weighted avg_support': 133.0, 'O_support': 1320, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 0}, {'micro_f1': 0.7716297786720322, 'precision': 0.7716297786720322, 'Appeal_to_Popularity_precision': 0.06382978723404255, 'Appeal_to_Popularity_recall': 0.04477611940298507, 'Appeal_to_Popularity_f1-score': 0.05263157894736841, 'Appeal_to_Popularity_support': 67.0, 'micro avg_precision': 0.06382978723404255, 'micro avg_recall': 0.04477611940298507, 'micro avg_f1-score': 0.05263157894736841, 'micro avg_support': 67.0, 'macro avg_precision': 0.06382978723404255, 'macro avg_recall': 0.04477611940298507, 'macro avg_f1-score': 0.05263157894736841, 'macro avg_support': 67.0, 'weighted avg_precision': 0.06382978723404255, 'weighted avg_recall': 0.04477611940298507, 'weighted avg_f1-score': 0.05263157894736841, 'weighted avg_support': 67.0, 'O_support': 1320, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 1}, {'micro_f1': 0.7449698189134809, 'precision': 0.7449698189134809, 'Appeal_to_Popularity_precision': 0.19148936170212766, 'Appeal_to_Popularity_recall': 0.0989010989010989, 'Appeal_to_Popularity_f1-score': 0.13043478260869565, 'Appeal_to_Popularity_support': 91.0, 'micro avg_precision': 0.19148936170212766, 'micro avg_recall': 0.0989010989010989, 'micro avg_f1-score': 0.13043478260869565, 'micro avg_support': 91.0, 'macro avg_precision': 0.19148936170212766, 'macro avg_recall': 0.0989010989010989, 'macro avg_f1-score': 0.13043478260869565, 'macro avg_support': 91.0, 'weighted avg_precision': 0.19148936170212766, 'weighted avg_recall': 0.0989010989010989, 'weighted avg_f1-score': 0.13043478260869565, 'weighted avg_support': 91.0, 'O_support': 1320, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 2}, {'micro_f1': 0.7525150905432596, 'precision': 0.7525150905432596, 'Appeal_to_Popularity_precision': 0.23404255319148937, 'Appeal_to_Popularity_recall': 0.125, 'Appeal_to_Popularity_f1-score': 0.16296296296296298, 'Appeal_to_Popularity_support': 88.0, 'micro avg_precision': 0.23404255319148937, 'micro avg_recall': 0.125, 'micro avg_f1-score': 0.16296296296296298, 'micro avg_support': 88.0, 'macro avg_precision': 0.23404255319148937, 'macro avg_recall': 0.125, 'macro avg_f1-score': 0.16296296296296298, 'macro avg_support': 88.0, 'weighted avg_precision': 0.23404255319148934, 'weighted avg_recall': 0.125, 'weighted avg_f1-score': 0.16296296296296298, 'weighted avg_support': 88.0, 'O_support': 1320, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 3}, {'micro_f1': 0.7676056338028169, 'precision': 0.7676056338028169, 'Appeal_to_Popularity_precision': 0.2127659574468085, 'Appeal_to_Popularity_recall': 0.12658227848101267, 'Appeal_to_Popularity_f1-score': 0.15873015873015875, 'Appeal_to_Popularity_support': 79.0, 'micro avg_precision': 0.2127659574468085, 'micro avg_recall': 0.12658227848101267, 'micro avg_f1-score': 0.15873015873015875, 'micro avg_support': 79.0, 'macro avg_precision': 0.2127659574468085, 'macro avg_recall': 0.12658227848101267, 'macro avg_f1-score': 0.15873015873015875, 'macro avg_support': 79.0, 'weighted avg_precision': 0.2127659574468085, 'weighted avg_recall': 0.12658227848101267, 'weighted avg_f1-score': 0.15873015873015875, 'weighted avg_support': 79.0, 'O_support': 1320, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 4}, {'micro_f1': 0.7751509054325956, 'precision': 0.7751509054325956, 'Appeal_to_Popularity_precision': 0.3191489361702128, 'Appeal_to_Popularity_recall': 0.17045454545454544, 'Appeal_to_Popularity_f1-score': 0.22222222222222224, 'Appeal_to_Popularity_support': 88.0, 'micro avg_precision': 0.3191489361702128, 'micro avg_recall': 0.17045454545454544, 'micro avg_f1-score': 0.22222222222222224, 'micro avg_support': 88.0, 'macro avg_precision': 0.3191489361702128, 'macro avg_recall': 0.17045454545454544, 'macro avg_f1-score': 0.22222222222222224, 'macro avg_support': 88.0, 'weighted avg_precision': 0.3191489361702128, 'weighted avg_recall': 0.17045454545454544, 'weighted avg_f1-score': 0.22222222222222224, 'weighted avg_support': 88.0, 'O_support': 1320, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 5}]}
Best model updated: current epoch macro f1 = 0.22222222222222224
{'micro_f1': 0.7847082494969819, 'precision': 0.7847082494969819, 'Appeal_to_Popularity_precision': 0.2765957446808511, 'Appeal_to_Popularity_recall': 0.1625, 'Appeal_to_Popularity_f1-score': 0.2047244094488189, 'Appeal_to_Popularity_support': 80.0, 'micro avg_precision': 0.2765957446808511, 'micro avg_recall': 0.1625, 'micro avg_f1-score': 0.2047244094488189, 'micro avg_support': 80.0, 'macro avg_precision': 0.2765957446808511, 'macro avg_recall': 0.1625, 'macro avg_f1-score': 0.2047244094488189, 'macro avg_support': 80.0, 'weighted avg_precision': 0.2765957446808511, 'weighted avg_recall': 0.1625, 'weighted avg_f1-score': 0.2047244094488189, 'weighted avg_support': 80.0, 'O_support': 1320, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 6}
{'results': [{'micro_f1': 0.750503018108652, 'precision': 0.7505030181086519, 'Appeal_to_Popularity_precision': 0.02127659574468085, 'Appeal_to_Popularity_recall': 0.007518796992481203, 'Appeal_to_Popularity_f1-score': 0.011111111111111112, 'Appeal_to_Popularity_support': 133.0, 'micro avg_precision': 0.02127659574468085, 'micro avg_recall': 0.007518796992481203, 'micro avg_f1-score': 0.011111111111111112, 'micro avg_support': 133.0, 'macro avg_precision': 0.02127659574468085, 'macro avg_recall': 0.007518796992481203, 'macro avg_f1-score': 0.011111111111111112, 'macro avg_support': 133.0, 'weighted avg_precision': 0.02127659574468085, 'weighted avg_recall': 0.007518796992481203, 'weighted avg_f1-score': 0.011111111111111112, 'weighted avg_support': 133.0, 'O_support': 1320, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 0}, {'micro_f1': 0.7716297786720322, 'precision': 0.7716297786720322, 'Appeal_to_Popularity_precision': 0.06382978723404255, 'Appeal_to_Popularity_recall': 0.04477611940298507, 'Appeal_to_Popularity_f1-score': 0.05263157894736841, 'Appeal_to_Popularity_support': 67.0, 'micro avg_precision': 0.06382978723404255, 'micro avg_recall': 0.04477611940298507, 'micro avg_f1-score': 0.05263157894736841, 'micro avg_support': 67.0, 'macro avg_precision': 0.06382978723404255, 'macro avg_recall': 0.04477611940298507, 'macro avg_f1-score': 0.05263157894736841, 'macro avg_support': 67.0, 'weighted avg_precision': 0.06382978723404255, 'weighted avg_recall': 0.04477611940298507, 'weighted avg_f1-score': 0.05263157894736841, 'weighted avg_support': 67.0, 'O_support': 1320, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 1}, {'micro_f1': 0.7449698189134809, 'precision': 0.7449698189134809, 'Appeal_to_Popularity_precision': 0.19148936170212766, 'Appeal_to_Popularity_recall': 0.0989010989010989, 'Appeal_to_Popularity_f1-score': 0.13043478260869565, 'Appeal_to_Popularity_support': 91.0, 'micro avg_precision': 0.19148936170212766, 'micro avg_recall': 0.0989010989010989, 'micro avg_f1-score': 0.13043478260869565, 'micro avg_support': 91.0, 'macro avg_precision': 0.19148936170212766, 'macro avg_recall': 0.0989010989010989, 'macro avg_f1-score': 0.13043478260869565, 'macro avg_support': 91.0, 'weighted avg_precision': 0.19148936170212766, 'weighted avg_recall': 0.0989010989010989, 'weighted avg_f1-score': 0.13043478260869565, 'weighted avg_support': 91.0, 'O_support': 1320, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 2}, {'micro_f1': 0.7525150905432596, 'precision': 0.7525150905432596, 'Appeal_to_Popularity_precision': 0.23404255319148937, 'Appeal_to_Popularity_recall': 0.125, 'Appeal_to_Popularity_f1-score': 0.16296296296296298, 'Appeal_to_Popularity_support': 88.0, 'micro avg_precision': 0.23404255319148937, 'micro avg_recall': 0.125, 'micro avg_f1-score': 0.16296296296296298, 'micro avg_support': 88.0, 'macro avg_precision': 0.23404255319148937, 'macro avg_recall': 0.125, 'macro avg_f1-score': 0.16296296296296298, 'macro avg_support': 88.0, 'weighted avg_precision': 0.23404255319148934, 'weighted avg_recall': 0.125, 'weighted avg_f1-score': 0.16296296296296298, 'weighted avg_support': 88.0, 'O_support': 1320, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 3}, {'micro_f1': 0.7676056338028169, 'precision': 0.7676056338028169, 'Appeal_to_Popularity_precision': 0.2127659574468085, 'Appeal_to_Popularity_recall': 0.12658227848101267, 'Appeal_to_Popularity_f1-score': 0.15873015873015875, 'Appeal_to_Popularity_support': 79.0, 'micro avg_precision': 0.2127659574468085, 'micro avg_recall': 0.12658227848101267, 'micro avg_f1-score': 0.15873015873015875, 'micro avg_support': 79.0, 'macro avg_precision': 0.2127659574468085, 'macro avg_recall': 0.12658227848101267, 'macro avg_f1-score': 0.15873015873015875, 'macro avg_support': 79.0, 'weighted avg_precision': 0.2127659574468085, 'weighted avg_recall': 0.12658227848101267, 'weighted avg_f1-score': 0.15873015873015875, 'weighted avg_support': 79.0, 'O_support': 1320, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 4}, {'micro_f1': 0.7751509054325956, 'precision': 0.7751509054325956, 'Appeal_to_Popularity_precision': 0.3191489361702128, 'Appeal_to_Popularity_recall': 0.17045454545454544, 'Appeal_to_Popularity_f1-score': 0.22222222222222224, 'Appeal_to_Popularity_support': 88.0, 'micro avg_precision': 0.3191489361702128, 'micro avg_recall': 0.17045454545454544, 'micro avg_f1-score': 0.22222222222222224, 'micro avg_support': 88.0, 'macro avg_precision': 0.3191489361702128, 'macro avg_recall': 0.17045454545454544, 'macro avg_f1-score': 0.22222222222222224, 'macro avg_support': 88.0, 'weighted avg_precision': 0.3191489361702128, 'weighted avg_recall': 0.17045454545454544, 'weighted avg_f1-score': 0.22222222222222224, 'weighted avg_support': 88.0, 'O_support': 1320, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 5}, {'micro_f1': 0.7847082494969819, 'precision': 0.7847082494969819, 'Appeal_to_Popularity_precision': 0.2765957446808511, 'Appeal_to_Popularity_recall': 0.1625, 'Appeal_to_Popularity_f1-score': 0.2047244094488189, 'Appeal_to_Popularity_support': 80.0, 'micro avg_precision': 0.2765957446808511, 'micro avg_recall': 0.1625, 'micro avg_f1-score': 0.2047244094488189, 'micro avg_support': 80.0, 'macro avg_precision': 0.2765957446808511, 'macro avg_recall': 0.1625, 'macro avg_f1-score': 0.2047244094488189, 'macro avg_support': 80.0, 'weighted avg_precision': 0.2765957446808511, 'weighted avg_recall': 0.1625, 'weighted avg_f1-score': 0.2047244094488189, 'weighted avg_support': 80.0, 'O_support': 1320, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 6}]}
{'micro_f1': 0.7877263581488932, 'precision': 0.7877263581488934, 'Appeal_to_Popularity_precision': 0.2765957446808511, 'Appeal_to_Popularity_recall': 0.16049382716049382, 'Appeal_to_Popularity_f1-score': 0.203125, 'Appeal_to_Popularity_support': 81.0, 'micro avg_precision': 0.2765957446808511, 'micro avg_recall': 0.16049382716049382, 'micro avg_f1-score': 0.203125, 'micro avg_support': 81.0, 'macro avg_precision': 0.2765957446808511, 'macro avg_recall': 0.16049382716049382, 'macro avg_f1-score': 0.203125, 'macro avg_support': 81.0, 'weighted avg_precision': 0.2765957446808511, 'weighted avg_recall': 0.16049382716049382, 'weighted avg_f1-score': 0.203125, 'weighted avg_support': 81.0, 'O_support': 1320, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 7}
{'results': [{'micro_f1': 0.750503018108652, 'precision': 0.7505030181086519, 'Appeal_to_Popularity_precision': 0.02127659574468085, 'Appeal_to_Popularity_recall': 0.007518796992481203, 'Appeal_to_Popularity_f1-score': 0.011111111111111112, 'Appeal_to_Popularity_support': 133.0, 'micro avg_precision': 0.02127659574468085, 'micro avg_recall': 0.007518796992481203, 'micro avg_f1-score': 0.011111111111111112, 'micro avg_support': 133.0, 'macro avg_precision': 0.02127659574468085, 'macro avg_recall': 0.007518796992481203, 'macro avg_f1-score': 0.011111111111111112, 'macro avg_support': 133.0, 'weighted avg_precision': 0.02127659574468085, 'weighted avg_recall': 0.007518796992481203, 'weighted avg_f1-score': 0.011111111111111112, 'weighted avg_support': 133.0, 'O_support': 1320, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 0}, {'micro_f1': 0.7716297786720322, 'precision': 0.7716297786720322, 'Appeal_to_Popularity_precision': 0.06382978723404255, 'Appeal_to_Popularity_recall': 0.04477611940298507, 'Appeal_to_Popularity_f1-score': 0.05263157894736841, 'Appeal_to_Popularity_support': 67.0, 'micro avg_precision': 0.06382978723404255, 'micro avg_recall': 0.04477611940298507, 'micro avg_f1-score': 0.05263157894736841, 'micro avg_support': 67.0, 'macro avg_precision': 0.06382978723404255, 'macro avg_recall': 0.04477611940298507, 'macro avg_f1-score': 0.05263157894736841, 'macro avg_support': 67.0, 'weighted avg_precision': 0.06382978723404255, 'weighted avg_recall': 0.04477611940298507, 'weighted avg_f1-score': 0.05263157894736841, 'weighted avg_support': 67.0, 'O_support': 1320, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 1}, {'micro_f1': 0.7449698189134809, 'precision': 0.7449698189134809, 'Appeal_to_Popularity_precision': 0.19148936170212766, 'Appeal_to_Popularity_recall': 0.0989010989010989, 'Appeal_to_Popularity_f1-score': 0.13043478260869565, 'Appeal_to_Popularity_support': 91.0, 'micro avg_precision': 0.19148936170212766, 'micro avg_recall': 0.0989010989010989, 'micro avg_f1-score': 0.13043478260869565, 'micro avg_support': 91.0, 'macro avg_precision': 0.19148936170212766, 'macro avg_recall': 0.0989010989010989, 'macro avg_f1-score': 0.13043478260869565, 'macro avg_support': 91.0, 'weighted avg_precision': 0.19148936170212766, 'weighted avg_recall': 0.0989010989010989, 'weighted avg_f1-score': 0.13043478260869565, 'weighted avg_support': 91.0, 'O_support': 1320, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 2}, {'micro_f1': 0.7525150905432596, 'precision': 0.7525150905432596, 'Appeal_to_Popularity_precision': 0.23404255319148937, 'Appeal_to_Popularity_recall': 0.125, 'Appeal_to_Popularity_f1-score': 0.16296296296296298, 'Appeal_to_Popularity_support': 88.0, 'micro avg_precision': 0.23404255319148937, 'micro avg_recall': 0.125, 'micro avg_f1-score': 0.16296296296296298, 'micro avg_support': 88.0, 'macro avg_precision': 0.23404255319148937, 'macro avg_recall': 0.125, 'macro avg_f1-score': 0.16296296296296298, 'macro avg_support': 88.0, 'weighted avg_precision': 0.23404255319148934, 'weighted avg_recall': 0.125, 'weighted avg_f1-score': 0.16296296296296298, 'weighted avg_support': 88.0, 'O_support': 1320, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 3}, {'micro_f1': 0.7676056338028169, 'precision': 0.7676056338028169, 'Appeal_to_Popularity_precision': 0.2127659574468085, 'Appeal_to_Popularity_recall': 0.12658227848101267, 'Appeal_to_Popularity_f1-score': 0.15873015873015875, 'Appeal_to_Popularity_support': 79.0, 'micro avg_precision': 0.2127659574468085, 'micro avg_recall': 0.12658227848101267, 'micro avg_f1-score': 0.15873015873015875, 'micro avg_support': 79.0, 'macro avg_precision': 0.2127659574468085, 'macro avg_recall': 0.12658227848101267, 'macro avg_f1-score': 0.15873015873015875, 'macro avg_support': 79.0, 'weighted avg_precision': 0.2127659574468085, 'weighted avg_recall': 0.12658227848101267, 'weighted avg_f1-score': 0.15873015873015875, 'weighted avg_support': 79.0, 'O_support': 1320, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 4}, {'micro_f1': 0.7751509054325956, 'precision': 0.7751509054325956, 'Appeal_to_Popularity_precision': 0.3191489361702128, 'Appeal_to_Popularity_recall': 0.17045454545454544, 'Appeal_to_Popularity_f1-score': 0.22222222222222224, 'Appeal_to_Popularity_support': 88.0, 'micro avg_precision': 0.3191489361702128, 'micro avg_recall': 0.17045454545454544, 'micro avg_f1-score': 0.22222222222222224, 'micro avg_support': 88.0, 'macro avg_precision': 0.3191489361702128, 'macro avg_recall': 0.17045454545454544, 'macro avg_f1-score': 0.22222222222222224, 'macro avg_support': 88.0, 'weighted avg_precision': 0.3191489361702128, 'weighted avg_recall': 0.17045454545454544, 'weighted avg_f1-score': 0.22222222222222224, 'weighted avg_support': 88.0, 'O_support': 1320, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 5}, {'micro_f1': 0.7847082494969819, 'precision': 0.7847082494969819, 'Appeal_to_Popularity_precision': 0.2765957446808511, 'Appeal_to_Popularity_recall': 0.1625, 'Appeal_to_Popularity_f1-score': 0.2047244094488189, 'Appeal_to_Popularity_support': 80.0, 'micro avg_precision': 0.2765957446808511, 'micro avg_recall': 0.1625, 'micro avg_f1-score': 0.2047244094488189, 'micro avg_support': 80.0, 'macro avg_precision': 0.2765957446808511, 'macro avg_recall': 0.1625, 'macro avg_f1-score': 0.2047244094488189, 'macro avg_support': 80.0, 'weighted avg_precision': 0.2765957446808511, 'weighted avg_recall': 0.1625, 'weighted avg_f1-score': 0.2047244094488189, 'weighted avg_support': 80.0, 'O_support': 1320, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 6}, {'micro_f1': 0.7877263581488932, 'precision': 0.7877263581488934, 'Appeal_to_Popularity_precision': 0.2765957446808511, 'Appeal_to_Popularity_recall': 0.16049382716049382, 'Appeal_to_Popularity_f1-score': 0.203125, 'Appeal_to_Popularity_support': 81.0, 'micro avg_precision': 0.2765957446808511, 'micro avg_recall': 0.16049382716049382, 'micro avg_f1-score': 0.203125, 'micro avg_support': 81.0, 'macro avg_precision': 0.2765957446808511, 'macro avg_recall': 0.16049382716049382, 'macro avg_f1-score': 0.203125, 'macro avg_support': 81.0, 'weighted avg_precision': 0.2765957446808511, 'weighted avg_recall': 0.16049382716049382, 'weighted avg_f1-score': 0.203125, 'weighted avg_support': 81.0, 'O_support': 1320, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 7}]}
Early stopping triggered.
Saving model to directory: ./models/M2/2024-05-13-23-08-48_aug/mdeberta-v3-base_1_ME10_target=Appeal_to_Popularity_SUBSAMPLED_2024-05-13-23-08-48
Training model no. 2 of 23 for (2, 'Appeal_to_Values') persuasion technique...
{'micro_f1': 0.7809791520262358, 'precision': 0.7809791520262357, 'Appeal_to_Values_precision': 0.030303030303030304, 'Appeal_to_Values_recall': 0.014285714285714285, 'Appeal_to_Values_f1-score': 0.01941747572815534, 'Appeal_to_Values_support': 210.0, 'micro avg_precision': 0.030303030303030304, 'micro avg_recall': 0.014285714285714285, 'micro avg_f1-score': 0.01941747572815534, 'micro avg_support': 210.0, 'macro avg_precision': 0.030303030303030304, 'macro avg_recall': 0.014285714285714285, 'macro avg_f1-score': 0.01941747572815534, 'macro avg_support': 210.0, 'weighted avg_precision': 0.030303030303030307, 'weighted avg_recall': 0.014285714285714285, 'weighted avg_f1-score': 0.019417475728155338, 'weighted avg_support': 210.0, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'O_support': 2462, 'epoch': 0}
{'results': [{'micro_f1': 0.7809791520262358, 'precision': 0.7809791520262357, 'Appeal_to_Values_precision': 0.030303030303030304, 'Appeal_to_Values_recall': 0.014285714285714285, 'Appeal_to_Values_f1-score': 0.01941747572815534, 'Appeal_to_Values_support': 210.0, 'micro avg_precision': 0.030303030303030304, 'micro avg_recall': 0.014285714285714285, 'micro avg_f1-score': 0.01941747572815534, 'micro avg_support': 210.0, 'macro avg_precision': 0.030303030303030304, 'macro avg_recall': 0.014285714285714285, 'macro avg_f1-score': 0.01941747572815534, 'macro avg_support': 210.0, 'weighted avg_precision': 0.030303030303030307, 'weighted avg_recall': 0.014285714285714285, 'weighted avg_f1-score': 0.019417475728155338, 'weighted avg_support': 210.0, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'O_support': 2462, 'epoch': 0}]}
Best model updated: current epoch macro f1 = 0.01941747572815534
{'micro_f1': 0.7800421644413211, 'precision': 0.7800421644413211, 'Appeal_to_Values_precision': 0.08080808080808081, 'Appeal_to_Values_recall': 0.04, 'Appeal_to_Values_f1-score': 0.053511705685618735, 'Appeal_to_Values_support': 200.0, 'micro avg_precision': 0.08080808080808081, 'micro avg_recall': 0.04, 'micro avg_f1-score': 0.053511705685618735, 'micro avg_support': 200.0, 'macro avg_precision': 0.08080808080808081, 'macro avg_recall': 0.04, 'macro avg_f1-score': 0.053511705685618735, 'macro avg_support': 200.0, 'weighted avg_precision': 0.08080808080808081, 'weighted avg_recall': 0.04, 'weighted avg_f1-score': 0.053511705685618735, 'weighted avg_support': 200.0, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'O_support': 2462, 'epoch': 1}
{'results': [{'micro_f1': 0.7809791520262358, 'precision': 0.7809791520262357, 'Appeal_to_Values_precision': 0.030303030303030304, 'Appeal_to_Values_recall': 0.014285714285714285, 'Appeal_to_Values_f1-score': 0.01941747572815534, 'Appeal_to_Values_support': 210.0, 'micro avg_precision': 0.030303030303030304, 'micro avg_recall': 0.014285714285714285, 'micro avg_f1-score': 0.01941747572815534, 'micro avg_support': 210.0, 'macro avg_precision': 0.030303030303030304, 'macro avg_recall': 0.014285714285714285, 'macro avg_f1-score': 0.01941747572815534, 'macro avg_support': 210.0, 'weighted avg_precision': 0.030303030303030307, 'weighted avg_recall': 0.014285714285714285, 'weighted avg_f1-score': 0.019417475728155338, 'weighted avg_support': 210.0, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'O_support': 2462, 'epoch': 0}, {'micro_f1': 0.7800421644413211, 'precision': 0.7800421644413211, 'Appeal_to_Values_precision': 0.08080808080808081, 'Appeal_to_Values_recall': 0.04, 'Appeal_to_Values_f1-score': 0.053511705685618735, 'Appeal_to_Values_support': 200.0, 'micro avg_precision': 0.08080808080808081, 'micro avg_recall': 0.04, 'micro avg_f1-score': 0.053511705685618735, 'micro avg_support': 200.0, 'macro avg_precision': 0.08080808080808081, 'macro avg_recall': 0.04, 'macro avg_f1-score': 0.053511705685618735, 'macro avg_support': 200.0, 'weighted avg_precision': 0.08080808080808081, 'weighted avg_recall': 0.04, 'weighted avg_f1-score': 0.053511705685618735, 'weighted avg_support': 200.0, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'O_support': 2462, 'epoch': 1}]}
Best model updated: current epoch macro f1 = 0.053511705685618735
{'micro_f1': 0.7706722885921762, 'precision': 0.7706722885921762, 'Appeal_to_Values_precision': 0.12121212121212122, 'Appeal_to_Values_recall': 0.08450704225352113, 'Appeal_to_Values_f1-score': 0.0995850622406639, 'Appeal_to_Values_support': 142.0, 'micro avg_precision': 0.12121212121212122, 'micro avg_recall': 0.08450704225352113, 'micro avg_f1-score': 0.0995850622406639, 'micro avg_support': 142.0, 'macro avg_precision': 0.12121212121212122, 'macro avg_recall': 0.08450704225352113, 'macro avg_f1-score': 0.0995850622406639, 'macro avg_support': 142.0, 'weighted avg_precision': 0.1212121212121212, 'weighted avg_recall': 0.08450704225352113, 'weighted avg_f1-score': 0.0995850622406639, 'weighted avg_support': 142.0, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'O_support': 2462, 'epoch': 2}
{'results': [{'micro_f1': 0.7809791520262358, 'precision': 0.7809791520262357, 'Appeal_to_Values_precision': 0.030303030303030304, 'Appeal_to_Values_recall': 0.014285714285714285, 'Appeal_to_Values_f1-score': 0.01941747572815534, 'Appeal_to_Values_support': 210.0, 'micro avg_precision': 0.030303030303030304, 'micro avg_recall': 0.014285714285714285, 'micro avg_f1-score': 0.01941747572815534, 'micro avg_support': 210.0, 'macro avg_precision': 0.030303030303030304, 'macro avg_recall': 0.014285714285714285, 'macro avg_f1-score': 0.01941747572815534, 'macro avg_support': 210.0, 'weighted avg_precision': 0.030303030303030307, 'weighted avg_recall': 0.014285714285714285, 'weighted avg_f1-score': 0.019417475728155338, 'weighted avg_support': 210.0, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'O_support': 2462, 'epoch': 0}, {'micro_f1': 0.7800421644413211, 'precision': 0.7800421644413211, 'Appeal_to_Values_precision': 0.08080808080808081, 'Appeal_to_Values_recall': 0.04, 'Appeal_to_Values_f1-score': 0.053511705685618735, 'Appeal_to_Values_support': 200.0, 'micro avg_precision': 0.08080808080808081, 'micro avg_recall': 0.04, 'micro avg_f1-score': 0.053511705685618735, 'micro avg_support': 200.0, 'macro avg_precision': 0.08080808080808081, 'macro avg_recall': 0.04, 'macro avg_f1-score': 0.053511705685618735, 'macro avg_support': 200.0, 'weighted avg_precision': 0.08080808080808081, 'weighted avg_recall': 0.04, 'weighted avg_f1-score': 0.053511705685618735, 'weighted avg_support': 200.0, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'O_support': 2462, 'epoch': 1}, {'micro_f1': 0.7706722885921762, 'precision': 0.7706722885921762, 'Appeal_to_Values_precision': 0.12121212121212122, 'Appeal_to_Values_recall': 0.08450704225352113, 'Appeal_to_Values_f1-score': 0.0995850622406639, 'Appeal_to_Values_support': 142.0, 'micro avg_precision': 0.12121212121212122, 'micro avg_recall': 0.08450704225352113, 'micro avg_f1-score': 0.0995850622406639, 'micro avg_support': 142.0, 'macro avg_precision': 0.12121212121212122, 'macro avg_recall': 0.08450704225352113, 'macro avg_f1-score': 0.0995850622406639, 'macro avg_support': 142.0, 'weighted avg_precision': 0.1212121212121212, 'weighted avg_recall': 0.08450704225352113, 'weighted avg_f1-score': 0.0995850622406639, 'weighted avg_support': 142.0, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'O_support': 2462, 'epoch': 2}]}
Best model updated: current epoch macro f1 = 0.0995850622406639
{'micro_f1': 0.739517451393769, 'precision': 0.739517451393769, 'Appeal_to_Values_precision': 0.09090909090909091, 'Appeal_to_Values_recall': 0.0703125, 'Appeal_to_Values_f1-score': 0.07929515418502203, 'Appeal_to_Values_support': 128.0, 'micro avg_precision': 0.09090909090909091, 'micro avg_recall': 0.0703125, 'micro avg_f1-score': 0.07929515418502203, 'micro avg_support': 128.0, 'macro avg_precision': 0.09090909090909091, 'macro avg_recall': 0.0703125, 'macro avg_f1-score': 0.07929515418502203, 'macro avg_support': 128.0, 'weighted avg_precision': 0.09090909090909091, 'weighted avg_recall': 0.0703125, 'weighted avg_f1-score': 0.07929515418502203, 'weighted avg_support': 128.0, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'O_support': 2462, 'epoch': 3}
{'results': [{'micro_f1': 0.7809791520262358, 'precision': 0.7809791520262357, 'Appeal_to_Values_precision': 0.030303030303030304, 'Appeal_to_Values_recall': 0.014285714285714285, 'Appeal_to_Values_f1-score': 0.01941747572815534, 'Appeal_to_Values_support': 210.0, 'micro avg_precision': 0.030303030303030304, 'micro avg_recall': 0.014285714285714285, 'micro avg_f1-score': 0.01941747572815534, 'micro avg_support': 210.0, 'macro avg_precision': 0.030303030303030304, 'macro avg_recall': 0.014285714285714285, 'macro avg_f1-score': 0.01941747572815534, 'macro avg_support': 210.0, 'weighted avg_precision': 0.030303030303030307, 'weighted avg_recall': 0.014285714285714285, 'weighted avg_f1-score': 0.019417475728155338, 'weighted avg_support': 210.0, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'O_support': 2462, 'epoch': 0}, {'micro_f1': 0.7800421644413211, 'precision': 0.7800421644413211, 'Appeal_to_Values_precision': 0.08080808080808081, 'Appeal_to_Values_recall': 0.04, 'Appeal_to_Values_f1-score': 0.053511705685618735, 'Appeal_to_Values_support': 200.0, 'micro avg_precision': 0.08080808080808081, 'micro avg_recall': 0.04, 'micro avg_f1-score': 0.053511705685618735, 'micro avg_support': 200.0, 'macro avg_precision': 0.08080808080808081, 'macro avg_recall': 0.04, 'macro avg_f1-score': 0.053511705685618735, 'macro avg_support': 200.0, 'weighted avg_precision': 0.08080808080808081, 'weighted avg_recall': 0.04, 'weighted avg_f1-score': 0.053511705685618735, 'weighted avg_support': 200.0, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'O_support': 2462, 'epoch': 1}, {'micro_f1': 0.7706722885921762, 'precision': 0.7706722885921762, 'Appeal_to_Values_precision': 0.12121212121212122, 'Appeal_to_Values_recall': 0.08450704225352113, 'Appeal_to_Values_f1-score': 0.0995850622406639, 'Appeal_to_Values_support': 142.0, 'micro avg_precision': 0.12121212121212122, 'micro avg_recall': 0.08450704225352113, 'micro avg_f1-score': 0.0995850622406639, 'micro avg_support': 142.0, 'macro avg_precision': 0.12121212121212122, 'macro avg_recall': 0.08450704225352113, 'macro avg_f1-score': 0.0995850622406639, 'macro avg_support': 142.0, 'weighted avg_precision': 0.1212121212121212, 'weighted avg_recall': 0.08450704225352113, 'weighted avg_f1-score': 0.0995850622406639, 'weighted avg_support': 142.0, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'O_support': 2462, 'epoch': 2}, {'micro_f1': 0.739517451393769, 'precision': 0.739517451393769, 'Appeal_to_Values_precision': 0.09090909090909091, 'Appeal_to_Values_recall': 0.0703125, 'Appeal_to_Values_f1-score': 0.07929515418502203, 'Appeal_to_Values_support': 128.0, 'micro avg_precision': 0.09090909090909091, 'micro avg_recall': 0.0703125, 'micro avg_f1-score': 0.07929515418502203, 'micro avg_support': 128.0, 'macro avg_precision': 0.09090909090909091, 'macro avg_recall': 0.0703125, 'macro avg_f1-score': 0.07929515418502203, 'macro avg_support': 128.0, 'weighted avg_precision': 0.09090909090909091, 'weighted avg_recall': 0.0703125, 'weighted avg_f1-score': 0.07929515418502203, 'weighted avg_support': 128.0, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'O_support': 2462, 'epoch': 3}]}
{'micro_f1': 0.7894120402904662, 'precision': 0.7894120402904662, 'Appeal_to_Values_precision': 0.1919191919191919, 'Appeal_to_Values_recall': 0.10160427807486631, 'Appeal_to_Values_f1-score': 0.13286713286713286, 'Appeal_to_Values_support': 187.0, 'micro avg_precision': 0.1919191919191919, 'micro avg_recall': 0.10160427807486631, 'micro avg_f1-score': 0.13286713286713286, 'micro avg_support': 187.0, 'macro avg_precision': 0.1919191919191919, 'macro avg_recall': 0.10160427807486631, 'macro avg_f1-score': 0.13286713286713286, 'macro avg_support': 187.0, 'weighted avg_precision': 0.1919191919191919, 'weighted avg_recall': 0.10160427807486631, 'weighted avg_f1-score': 0.13286713286713286, 'weighted avg_support': 187.0, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'O_support': 2462, 'epoch': 4}
{'results': [{'micro_f1': 0.7809791520262358, 'precision': 0.7809791520262357, 'Appeal_to_Values_precision': 0.030303030303030304, 'Appeal_to_Values_recall': 0.014285714285714285, 'Appeal_to_Values_f1-score': 0.01941747572815534, 'Appeal_to_Values_support': 210.0, 'micro avg_precision': 0.030303030303030304, 'micro avg_recall': 0.014285714285714285, 'micro avg_f1-score': 0.01941747572815534, 'micro avg_support': 210.0, 'macro avg_precision': 0.030303030303030304, 'macro avg_recall': 0.014285714285714285, 'macro avg_f1-score': 0.01941747572815534, 'macro avg_support': 210.0, 'weighted avg_precision': 0.030303030303030307, 'weighted avg_recall': 0.014285714285714285, 'weighted avg_f1-score': 0.019417475728155338, 'weighted avg_support': 210.0, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'O_support': 2462, 'epoch': 0}, {'micro_f1': 0.7800421644413211, 'precision': 0.7800421644413211, 'Appeal_to_Values_precision': 0.08080808080808081, 'Appeal_to_Values_recall': 0.04, 'Appeal_to_Values_f1-score': 0.053511705685618735, 'Appeal_to_Values_support': 200.0, 'micro avg_precision': 0.08080808080808081, 'micro avg_recall': 0.04, 'micro avg_f1-score': 0.053511705685618735, 'micro avg_support': 200.0, 'macro avg_precision': 0.08080808080808081, 'macro avg_recall': 0.04, 'macro avg_f1-score': 0.053511705685618735, 'macro avg_support': 200.0, 'weighted avg_precision': 0.08080808080808081, 'weighted avg_recall': 0.04, 'weighted avg_f1-score': 0.053511705685618735, 'weighted avg_support': 200.0, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'O_support': 2462, 'epoch': 1}, {'micro_f1': 0.7706722885921762, 'precision': 0.7706722885921762, 'Appeal_to_Values_precision': 0.12121212121212122, 'Appeal_to_Values_recall': 0.08450704225352113, 'Appeal_to_Values_f1-score': 0.0995850622406639, 'Appeal_to_Values_support': 142.0, 'micro avg_precision': 0.12121212121212122, 'micro avg_recall': 0.08450704225352113, 'micro avg_f1-score': 0.0995850622406639, 'micro avg_support': 142.0, 'macro avg_precision': 0.12121212121212122, 'macro avg_recall': 0.08450704225352113, 'macro avg_f1-score': 0.0995850622406639, 'macro avg_support': 142.0, 'weighted avg_precision': 0.1212121212121212, 'weighted avg_recall': 0.08450704225352113, 'weighted avg_f1-score': 0.0995850622406639, 'weighted avg_support': 142.0, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'O_support': 2462, 'epoch': 2}, {'micro_f1': 0.739517451393769, 'precision': 0.739517451393769, 'Appeal_to_Values_precision': 0.09090909090909091, 'Appeal_to_Values_recall': 0.0703125, 'Appeal_to_Values_f1-score': 0.07929515418502203, 'Appeal_to_Values_support': 128.0, 'micro avg_precision': 0.09090909090909091, 'micro avg_recall': 0.0703125, 'micro avg_f1-score': 0.07929515418502203, 'micro avg_support': 128.0, 'macro avg_precision': 0.09090909090909091, 'macro avg_recall': 0.0703125, 'macro avg_f1-score': 0.07929515418502203, 'macro avg_support': 128.0, 'weighted avg_precision': 0.09090909090909091, 'weighted avg_recall': 0.0703125, 'weighted avg_f1-score': 0.07929515418502203, 'weighted avg_support': 128.0, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'O_support': 2462, 'epoch': 3}, {'micro_f1': 0.7894120402904662, 'precision': 0.7894120402904662, 'Appeal_to_Values_precision': 0.1919191919191919, 'Appeal_to_Values_recall': 0.10160427807486631, 'Appeal_to_Values_f1-score': 0.13286713286713286, 'Appeal_to_Values_support': 187.0, 'micro avg_precision': 0.1919191919191919, 'micro avg_recall': 0.10160427807486631, 'micro avg_f1-score': 0.13286713286713286, 'micro avg_support': 187.0, 'macro avg_precision': 0.1919191919191919, 'macro avg_recall': 0.10160427807486631, 'macro avg_f1-score': 0.13286713286713286, 'macro avg_support': 187.0, 'weighted avg_precision': 0.1919191919191919, 'weighted avg_recall': 0.10160427807486631, 'weighted avg_f1-score': 0.13286713286713286, 'weighted avg_support': 187.0, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'O_support': 2462, 'epoch': 4}]}
Best model updated: current epoch macro f1 = 0.13286713286713286
{'micro_f1': 0.8109627547434997, 'precision': 0.8109627547434997, 'Appeal_to_Values_precision': 0.2828282828282828, 'Appeal_to_Values_recall': 0.1686746987951807, 'Appeal_to_Values_f1-score': 0.2113207547169811, 'Appeal_to_Values_support': 166.0, 'micro avg_precision': 0.2828282828282828, 'micro avg_recall': 0.1686746987951807, 'micro avg_f1-score': 0.2113207547169811, 'micro avg_support': 166.0, 'macro avg_precision': 0.2828282828282828, 'macro avg_recall': 0.1686746987951807, 'macro avg_f1-score': 0.2113207547169811, 'macro avg_support': 166.0, 'weighted avg_precision': 0.2828282828282828, 'weighted avg_recall': 0.1686746987951807, 'weighted avg_f1-score': 0.2113207547169811, 'weighted avg_support': 166.0, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'O_support': 2462, 'epoch': 5}
{'results': [{'micro_f1': 0.7809791520262358, 'precision': 0.7809791520262357, 'Appeal_to_Values_precision': 0.030303030303030304, 'Appeal_to_Values_recall': 0.014285714285714285, 'Appeal_to_Values_f1-score': 0.01941747572815534, 'Appeal_to_Values_support': 210.0, 'micro avg_precision': 0.030303030303030304, 'micro avg_recall': 0.014285714285714285, 'micro avg_f1-score': 0.01941747572815534, 'micro avg_support': 210.0, 'macro avg_precision': 0.030303030303030304, 'macro avg_recall': 0.014285714285714285, 'macro avg_f1-score': 0.01941747572815534, 'macro avg_support': 210.0, 'weighted avg_precision': 0.030303030303030307, 'weighted avg_recall': 0.014285714285714285, 'weighted avg_f1-score': 0.019417475728155338, 'weighted avg_support': 210.0, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'O_support': 2462, 'epoch': 0}, {'micro_f1': 0.7800421644413211, 'precision': 0.7800421644413211, 'Appeal_to_Values_precision': 0.08080808080808081, 'Appeal_to_Values_recall': 0.04, 'Appeal_to_Values_f1-score': 0.053511705685618735, 'Appeal_to_Values_support': 200.0, 'micro avg_precision': 0.08080808080808081, 'micro avg_recall': 0.04, 'micro avg_f1-score': 0.053511705685618735, 'micro avg_support': 200.0, 'macro avg_precision': 0.08080808080808081, 'macro avg_recall': 0.04, 'macro avg_f1-score': 0.053511705685618735, 'macro avg_support': 200.0, 'weighted avg_precision': 0.08080808080808081, 'weighted avg_recall': 0.04, 'weighted avg_f1-score': 0.053511705685618735, 'weighted avg_support': 200.0, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'O_support': 2462, 'epoch': 1}, {'micro_f1': 0.7706722885921762, 'precision': 0.7706722885921762, 'Appeal_to_Values_precision': 0.12121212121212122, 'Appeal_to_Values_recall': 0.08450704225352113, 'Appeal_to_Values_f1-score': 0.0995850622406639, 'Appeal_to_Values_support': 142.0, 'micro avg_precision': 0.12121212121212122, 'micro avg_recall': 0.08450704225352113, 'micro avg_f1-score': 0.0995850622406639, 'micro avg_support': 142.0, 'macro avg_precision': 0.12121212121212122, 'macro avg_recall': 0.08450704225352113, 'macro avg_f1-score': 0.0995850622406639, 'macro avg_support': 142.0, 'weighted avg_precision': 0.1212121212121212, 'weighted avg_recall': 0.08450704225352113, 'weighted avg_f1-score': 0.0995850622406639, 'weighted avg_support': 142.0, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'O_support': 2462, 'epoch': 2}, {'micro_f1': 0.739517451393769, 'precision': 0.739517451393769, 'Appeal_to_Values_precision': 0.09090909090909091, 'Appeal_to_Values_recall': 0.0703125, 'Appeal_to_Values_f1-score': 0.07929515418502203, 'Appeal_to_Values_support': 128.0, 'micro avg_precision': 0.09090909090909091, 'micro avg_recall': 0.0703125, 'micro avg_f1-score': 0.07929515418502203, 'micro avg_support': 128.0, 'macro avg_precision': 0.09090909090909091, 'macro avg_recall': 0.0703125, 'macro avg_f1-score': 0.07929515418502203, 'macro avg_support': 128.0, 'weighted avg_precision': 0.09090909090909091, 'weighted avg_recall': 0.0703125, 'weighted avg_f1-score': 0.07929515418502203, 'weighted avg_support': 128.0, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'O_support': 2462, 'epoch': 3}, {'micro_f1': 0.7894120402904662, 'precision': 0.7894120402904662, 'Appeal_to_Values_precision': 0.1919191919191919, 'Appeal_to_Values_recall': 0.10160427807486631, 'Appeal_to_Values_f1-score': 0.13286713286713286, 'Appeal_to_Values_support': 187.0, 'micro avg_precision': 0.1919191919191919, 'micro avg_recall': 0.10160427807486631, 'micro avg_f1-score': 0.13286713286713286, 'micro avg_support': 187.0, 'macro avg_precision': 0.1919191919191919, 'macro avg_recall': 0.10160427807486631, 'macro avg_f1-score': 0.13286713286713286, 'macro avg_support': 187.0, 'weighted avg_precision': 0.1919191919191919, 'weighted avg_recall': 0.10160427807486631, 'weighted avg_f1-score': 0.13286713286713286, 'weighted avg_support': 187.0, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'O_support': 2462, 'epoch': 4}, {'micro_f1': 0.8109627547434997, 'precision': 0.8109627547434997, 'Appeal_to_Values_precision': 0.2828282828282828, 'Appeal_to_Values_recall': 0.1686746987951807, 'Appeal_to_Values_f1-score': 0.2113207547169811, 'Appeal_to_Values_support': 166.0, 'micro avg_precision': 0.2828282828282828, 'micro avg_recall': 0.1686746987951807, 'micro avg_f1-score': 0.2113207547169811, 'micro avg_support': 166.0, 'macro avg_precision': 0.2828282828282828, 'macro avg_recall': 0.1686746987951807, 'macro avg_f1-score': 0.2113207547169811, 'macro avg_support': 166.0, 'weighted avg_precision': 0.2828282828282828, 'weighted avg_recall': 0.1686746987951807, 'weighted avg_f1-score': 0.2113207547169811, 'weighted avg_support': 166.0, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'O_support': 2462, 'epoch': 5}]}
Best model updated: current epoch macro f1 = 0.2113207547169811
{'micro_f1': 0.8299367533380184, 'precision': 0.8299367533380183, 'Appeal_to_Values_precision': 0.3434343434343434, 'Appeal_to_Values_recall': 0.2251655629139073, 'Appeal_to_Values_f1-score': 0.272, 'Appeal_to_Values_support': 151.0, 'micro avg_precision': 0.3434343434343434, 'micro avg_recall': 0.2251655629139073, 'micro avg_f1-score': 0.272, 'micro avg_support': 151.0, 'macro avg_precision': 0.3434343434343434, 'macro avg_recall': 0.2251655629139073, 'macro avg_f1-score': 0.272, 'macro avg_support': 151.0, 'weighted avg_precision': 0.3434343434343434, 'weighted avg_recall': 0.2251655629139073, 'weighted avg_f1-score': 0.272, 'weighted avg_support': 151.0, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'O_support': 2462, 'epoch': 6}
{'results': [{'micro_f1': 0.7809791520262358, 'precision': 0.7809791520262357, 'Appeal_to_Values_precision': 0.030303030303030304, 'Appeal_to_Values_recall': 0.014285714285714285, 'Appeal_to_Values_f1-score': 0.01941747572815534, 'Appeal_to_Values_support': 210.0, 'micro avg_precision': 0.030303030303030304, 'micro avg_recall': 0.014285714285714285, 'micro avg_f1-score': 0.01941747572815534, 'micro avg_support': 210.0, 'macro avg_precision': 0.030303030303030304, 'macro avg_recall': 0.014285714285714285, 'macro avg_f1-score': 0.01941747572815534, 'macro avg_support': 210.0, 'weighted avg_precision': 0.030303030303030307, 'weighted avg_recall': 0.014285714285714285, 'weighted avg_f1-score': 0.019417475728155338, 'weighted avg_support': 210.0, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'O_support': 2462, 'epoch': 0}, {'micro_f1': 0.7800421644413211, 'precision': 0.7800421644413211, 'Appeal_to_Values_precision': 0.08080808080808081, 'Appeal_to_Values_recall': 0.04, 'Appeal_to_Values_f1-score': 0.053511705685618735, 'Appeal_to_Values_support': 200.0, 'micro avg_precision': 0.08080808080808081, 'micro avg_recall': 0.04, 'micro avg_f1-score': 0.053511705685618735, 'micro avg_support': 200.0, 'macro avg_precision': 0.08080808080808081, 'macro avg_recall': 0.04, 'macro avg_f1-score': 0.053511705685618735, 'macro avg_support': 200.0, 'weighted avg_precision': 0.08080808080808081, 'weighted avg_recall': 0.04, 'weighted avg_f1-score': 0.053511705685618735, 'weighted avg_support': 200.0, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'O_support': 2462, 'epoch': 1}, {'micro_f1': 0.7706722885921762, 'precision': 0.7706722885921762, 'Appeal_to_Values_precision': 0.12121212121212122, 'Appeal_to_Values_recall': 0.08450704225352113, 'Appeal_to_Values_f1-score': 0.0995850622406639, 'Appeal_to_Values_support': 142.0, 'micro avg_precision': 0.12121212121212122, 'micro avg_recall': 0.08450704225352113, 'micro avg_f1-score': 0.0995850622406639, 'micro avg_support': 142.0, 'macro avg_precision': 0.12121212121212122, 'macro avg_recall': 0.08450704225352113, 'macro avg_f1-score': 0.0995850622406639, 'macro avg_support': 142.0, 'weighted avg_precision': 0.1212121212121212, 'weighted avg_recall': 0.08450704225352113, 'weighted avg_f1-score': 0.0995850622406639, 'weighted avg_support': 142.0, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'O_support': 2462, 'epoch': 2}, {'micro_f1': 0.739517451393769, 'precision': 0.739517451393769, 'Appeal_to_Values_precision': 0.09090909090909091, 'Appeal_to_Values_recall': 0.0703125, 'Appeal_to_Values_f1-score': 0.07929515418502203, 'Appeal_to_Values_support': 128.0, 'micro avg_precision': 0.09090909090909091, 'micro avg_recall': 0.0703125, 'micro avg_f1-score': 0.07929515418502203, 'micro avg_support': 128.0, 'macro avg_precision': 0.09090909090909091, 'macro avg_recall': 0.0703125, 'macro avg_f1-score': 0.07929515418502203, 'macro avg_support': 128.0, 'weighted avg_precision': 0.09090909090909091, 'weighted avg_recall': 0.0703125, 'weighted avg_f1-score': 0.07929515418502203, 'weighted avg_support': 128.0, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'O_support': 2462, 'epoch': 3}, {'micro_f1': 0.7894120402904662, 'precision': 0.7894120402904662, 'Appeal_to_Values_precision': 0.1919191919191919, 'Appeal_to_Values_recall': 0.10160427807486631, 'Appeal_to_Values_f1-score': 0.13286713286713286, 'Appeal_to_Values_support': 187.0, 'micro avg_precision': 0.1919191919191919, 'micro avg_recall': 0.10160427807486631, 'micro avg_f1-score': 0.13286713286713286, 'micro avg_support': 187.0, 'macro avg_precision': 0.1919191919191919, 'macro avg_recall': 0.10160427807486631, 'macro avg_f1-score': 0.13286713286713286, 'macro avg_support': 187.0, 'weighted avg_precision': 0.1919191919191919, 'weighted avg_recall': 0.10160427807486631, 'weighted avg_f1-score': 0.13286713286713286, 'weighted avg_support': 187.0, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'O_support': 2462, 'epoch': 4}, {'micro_f1': 0.8109627547434997, 'precision': 0.8109627547434997, 'Appeal_to_Values_precision': 0.2828282828282828, 'Appeal_to_Values_recall': 0.1686746987951807, 'Appeal_to_Values_f1-score': 0.2113207547169811, 'Appeal_to_Values_support': 166.0, 'micro avg_precision': 0.2828282828282828, 'micro avg_recall': 0.1686746987951807, 'micro avg_f1-score': 0.2113207547169811, 'micro avg_support': 166.0, 'macro avg_precision': 0.2828282828282828, 'macro avg_recall': 0.1686746987951807, 'macro avg_f1-score': 0.2113207547169811, 'macro avg_support': 166.0, 'weighted avg_precision': 0.2828282828282828, 'weighted avg_recall': 0.1686746987951807, 'weighted avg_f1-score': 0.2113207547169811, 'weighted avg_support': 166.0, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'O_support': 2462, 'epoch': 5}, {'micro_f1': 0.8299367533380184, 'precision': 0.8299367533380183, 'Appeal_to_Values_precision': 0.3434343434343434, 'Appeal_to_Values_recall': 0.2251655629139073, 'Appeal_to_Values_f1-score': 0.272, 'Appeal_to_Values_support': 151.0, 'micro avg_precision': 0.3434343434343434, 'micro avg_recall': 0.2251655629139073, 'micro avg_f1-score': 0.272, 'micro avg_support': 151.0, 'macro avg_precision': 0.3434343434343434, 'macro avg_recall': 0.2251655629139073, 'macro avg_f1-score': 0.272, 'macro avg_support': 151.0, 'weighted avg_precision': 0.3434343434343434, 'weighted avg_recall': 0.2251655629139073, 'weighted avg_f1-score': 0.272, 'weighted avg_support': 151.0, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'O_support': 2462, 'epoch': 6}]}
Best model updated: current epoch macro f1 = 0.272
{'micro_f1': 0.8090887795736706, 'precision': 0.8090887795736706, 'Appeal_to_Values_precision': 0.2727272727272727, 'Appeal_to_Values_recall': 0.17307692307692307, 'Appeal_to_Values_f1-score': 0.21176470588235294, 'Appeal_to_Values_support': 156.0, 'micro avg_precision': 0.2727272727272727, 'micro avg_recall': 0.17307692307692307, 'micro avg_f1-score': 0.21176470588235294, 'micro avg_support': 156.0, 'macro avg_precision': 0.2727272727272727, 'macro avg_recall': 0.17307692307692307, 'macro avg_f1-score': 0.21176470588235294, 'macro avg_support': 156.0, 'weighted avg_precision': 0.2727272727272727, 'weighted avg_recall': 0.17307692307692307, 'weighted avg_f1-score': 0.2117647058823529, 'weighted avg_support': 156.0, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'O_support': 2462, 'epoch': 7}
{'results': [{'micro_f1': 0.7809791520262358, 'precision': 0.7809791520262357, 'Appeal_to_Values_precision': 0.030303030303030304, 'Appeal_to_Values_recall': 0.014285714285714285, 'Appeal_to_Values_f1-score': 0.01941747572815534, 'Appeal_to_Values_support': 210.0, 'micro avg_precision': 0.030303030303030304, 'micro avg_recall': 0.014285714285714285, 'micro avg_f1-score': 0.01941747572815534, 'micro avg_support': 210.0, 'macro avg_precision': 0.030303030303030304, 'macro avg_recall': 0.014285714285714285, 'macro avg_f1-score': 0.01941747572815534, 'macro avg_support': 210.0, 'weighted avg_precision': 0.030303030303030307, 'weighted avg_recall': 0.014285714285714285, 'weighted avg_f1-score': 0.019417475728155338, 'weighted avg_support': 210.0, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'O_support': 2462, 'epoch': 0}, {'micro_f1': 0.7800421644413211, 'precision': 0.7800421644413211, 'Appeal_to_Values_precision': 0.08080808080808081, 'Appeal_to_Values_recall': 0.04, 'Appeal_to_Values_f1-score': 0.053511705685618735, 'Appeal_to_Values_support': 200.0, 'micro avg_precision': 0.08080808080808081, 'micro avg_recall': 0.04, 'micro avg_f1-score': 0.053511705685618735, 'micro avg_support': 200.0, 'macro avg_precision': 0.08080808080808081, 'macro avg_recall': 0.04, 'macro avg_f1-score': 0.053511705685618735, 'macro avg_support': 200.0, 'weighted avg_precision': 0.08080808080808081, 'weighted avg_recall': 0.04, 'weighted avg_f1-score': 0.053511705685618735, 'weighted avg_support': 200.0, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'O_support': 2462, 'epoch': 1}, {'micro_f1': 0.7706722885921762, 'precision': 0.7706722885921762, 'Appeal_to_Values_precision': 0.12121212121212122, 'Appeal_to_Values_recall': 0.08450704225352113, 'Appeal_to_Values_f1-score': 0.0995850622406639, 'Appeal_to_Values_support': 142.0, 'micro avg_precision': 0.12121212121212122, 'micro avg_recall': 0.08450704225352113, 'micro avg_f1-score': 0.0995850622406639, 'micro avg_support': 142.0, 'macro avg_precision': 0.12121212121212122, 'macro avg_recall': 0.08450704225352113, 'macro avg_f1-score': 0.0995850622406639, 'macro avg_support': 142.0, 'weighted avg_precision': 0.1212121212121212, 'weighted avg_recall': 0.08450704225352113, 'weighted avg_f1-score': 0.0995850622406639, 'weighted avg_support': 142.0, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'O_support': 2462, 'epoch': 2}, {'micro_f1': 0.739517451393769, 'precision': 0.739517451393769, 'Appeal_to_Values_precision': 0.09090909090909091, 'Appeal_to_Values_recall': 0.0703125, 'Appeal_to_Values_f1-score': 0.07929515418502203, 'Appeal_to_Values_support': 128.0, 'micro avg_precision': 0.09090909090909091, 'micro avg_recall': 0.0703125, 'micro avg_f1-score': 0.07929515418502203, 'micro avg_support': 128.0, 'macro avg_precision': 0.09090909090909091, 'macro avg_recall': 0.0703125, 'macro avg_f1-score': 0.07929515418502203, 'macro avg_support': 128.0, 'weighted avg_precision': 0.09090909090909091, 'weighted avg_recall': 0.0703125, 'weighted avg_f1-score': 0.07929515418502203, 'weighted avg_support': 128.0, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'O_support': 2462, 'epoch': 3}, {'micro_f1': 0.7894120402904662, 'precision': 0.7894120402904662, 'Appeal_to_Values_precision': 0.1919191919191919, 'Appeal_to_Values_recall': 0.10160427807486631, 'Appeal_to_Values_f1-score': 0.13286713286713286, 'Appeal_to_Values_support': 187.0, 'micro avg_precision': 0.1919191919191919, 'micro avg_recall': 0.10160427807486631, 'micro avg_f1-score': 0.13286713286713286, 'micro avg_support': 187.0, 'macro avg_precision': 0.1919191919191919, 'macro avg_recall': 0.10160427807486631, 'macro avg_f1-score': 0.13286713286713286, 'macro avg_support': 187.0, 'weighted avg_precision': 0.1919191919191919, 'weighted avg_recall': 0.10160427807486631, 'weighted avg_f1-score': 0.13286713286713286, 'weighted avg_support': 187.0, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'O_support': 2462, 'epoch': 4}, {'micro_f1': 0.8109627547434997, 'precision': 0.8109627547434997, 'Appeal_to_Values_precision': 0.2828282828282828, 'Appeal_to_Values_recall': 0.1686746987951807, 'Appeal_to_Values_f1-score': 0.2113207547169811, 'Appeal_to_Values_support': 166.0, 'micro avg_precision': 0.2828282828282828, 'micro avg_recall': 0.1686746987951807, 'micro avg_f1-score': 0.2113207547169811, 'micro avg_support': 166.0, 'macro avg_precision': 0.2828282828282828, 'macro avg_recall': 0.1686746987951807, 'macro avg_f1-score': 0.2113207547169811, 'macro avg_support': 166.0, 'weighted avg_precision': 0.2828282828282828, 'weighted avg_recall': 0.1686746987951807, 'weighted avg_f1-score': 0.2113207547169811, 'weighted avg_support': 166.0, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'O_support': 2462, 'epoch': 5}, {'micro_f1': 0.8299367533380184, 'precision': 0.8299367533380183, 'Appeal_to_Values_precision': 0.3434343434343434, 'Appeal_to_Values_recall': 0.2251655629139073, 'Appeal_to_Values_f1-score': 0.272, 'Appeal_to_Values_support': 151.0, 'micro avg_precision': 0.3434343434343434, 'micro avg_recall': 0.2251655629139073, 'micro avg_f1-score': 0.272, 'micro avg_support': 151.0, 'macro avg_precision': 0.3434343434343434, 'macro avg_recall': 0.2251655629139073, 'macro avg_f1-score': 0.272, 'macro avg_support': 151.0, 'weighted avg_precision': 0.3434343434343434, 'weighted avg_recall': 0.2251655629139073, 'weighted avg_f1-score': 0.272, 'weighted avg_support': 151.0, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'O_support': 2462, 'epoch': 6}, {'micro_f1': 0.8090887795736706, 'precision': 0.8090887795736706, 'Appeal_to_Values_precision': 0.2727272727272727, 'Appeal_to_Values_recall': 0.17307692307692307, 'Appeal_to_Values_f1-score': 0.21176470588235294, 'Appeal_to_Values_support': 156.0, 'micro avg_precision': 0.2727272727272727, 'micro avg_recall': 0.17307692307692307, 'micro avg_f1-score': 0.21176470588235294, 'micro avg_support': 156.0, 'macro avg_precision': 0.2727272727272727, 'macro avg_recall': 0.17307692307692307, 'macro avg_f1-score': 0.21176470588235294, 'macro avg_support': 156.0, 'weighted avg_precision': 0.2727272727272727, 'weighted avg_recall': 0.17307692307692307, 'weighted avg_f1-score': 0.2117647058823529, 'weighted avg_support': 156.0, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'O_support': 2462, 'epoch': 7}]}
{'micro_f1': 0.811431248535957, 'precision': 0.8114312485359569, 'Appeal_to_Values_precision': 0.25252525252525254, 'Appeal_to_Values_recall': 0.1524390243902439, 'Appeal_to_Values_f1-score': 0.19011406844106465, 'Appeal_to_Values_support': 164.0, 'micro avg_precision': 0.25252525252525254, 'micro avg_recall': 0.1524390243902439, 'micro avg_f1-score': 0.19011406844106465, 'micro avg_support': 164.0, 'macro avg_precision': 0.25252525252525254, 'macro avg_recall': 0.1524390243902439, 'macro avg_f1-score': 0.19011406844106465, 'macro avg_support': 164.0, 'weighted avg_precision': 0.25252525252525254, 'weighted avg_recall': 0.1524390243902439, 'weighted avg_f1-score': 0.19011406844106465, 'weighted avg_support': 164.0, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'O_support': 2462, 'epoch': 8}
{'results': [{'micro_f1': 0.7809791520262358, 'precision': 0.7809791520262357, 'Appeal_to_Values_precision': 0.030303030303030304, 'Appeal_to_Values_recall': 0.014285714285714285, 'Appeal_to_Values_f1-score': 0.01941747572815534, 'Appeal_to_Values_support': 210.0, 'micro avg_precision': 0.030303030303030304, 'micro avg_recall': 0.014285714285714285, 'micro avg_f1-score': 0.01941747572815534, 'micro avg_support': 210.0, 'macro avg_precision': 0.030303030303030304, 'macro avg_recall': 0.014285714285714285, 'macro avg_f1-score': 0.01941747572815534, 'macro avg_support': 210.0, 'weighted avg_precision': 0.030303030303030307, 'weighted avg_recall': 0.014285714285714285, 'weighted avg_f1-score': 0.019417475728155338, 'weighted avg_support': 210.0, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'O_support': 2462, 'epoch': 0}, {'micro_f1': 0.7800421644413211, 'precision': 0.7800421644413211, 'Appeal_to_Values_precision': 0.08080808080808081, 'Appeal_to_Values_recall': 0.04, 'Appeal_to_Values_f1-score': 0.053511705685618735, 'Appeal_to_Values_support': 200.0, 'micro avg_precision': 0.08080808080808081, 'micro avg_recall': 0.04, 'micro avg_f1-score': 0.053511705685618735, 'micro avg_support': 200.0, 'macro avg_precision': 0.08080808080808081, 'macro avg_recall': 0.04, 'macro avg_f1-score': 0.053511705685618735, 'macro avg_support': 200.0, 'weighted avg_precision': 0.08080808080808081, 'weighted avg_recall': 0.04, 'weighted avg_f1-score': 0.053511705685618735, 'weighted avg_support': 200.0, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'O_support': 2462, 'epoch': 1}, {'micro_f1': 0.7706722885921762, 'precision': 0.7706722885921762, 'Appeal_to_Values_precision': 0.12121212121212122, 'Appeal_to_Values_recall': 0.08450704225352113, 'Appeal_to_Values_f1-score': 0.0995850622406639, 'Appeal_to_Values_support': 142.0, 'micro avg_precision': 0.12121212121212122, 'micro avg_recall': 0.08450704225352113, 'micro avg_f1-score': 0.0995850622406639, 'micro avg_support': 142.0, 'macro avg_precision': 0.12121212121212122, 'macro avg_recall': 0.08450704225352113, 'macro avg_f1-score': 0.0995850622406639, 'macro avg_support': 142.0, 'weighted avg_precision': 0.1212121212121212, 'weighted avg_recall': 0.08450704225352113, 'weighted avg_f1-score': 0.0995850622406639, 'weighted avg_support': 142.0, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'O_support': 2462, 'epoch': 2}, {'micro_f1': 0.739517451393769, 'precision': 0.739517451393769, 'Appeal_to_Values_precision': 0.09090909090909091, 'Appeal_to_Values_recall': 0.0703125, 'Appeal_to_Values_f1-score': 0.07929515418502203, 'Appeal_to_Values_support': 128.0, 'micro avg_precision': 0.09090909090909091, 'micro avg_recall': 0.0703125, 'micro avg_f1-score': 0.07929515418502203, 'micro avg_support': 128.0, 'macro avg_precision': 0.09090909090909091, 'macro avg_recall': 0.0703125, 'macro avg_f1-score': 0.07929515418502203, 'macro avg_support': 128.0, 'weighted avg_precision': 0.09090909090909091, 'weighted avg_recall': 0.0703125, 'weighted avg_f1-score': 0.07929515418502203, 'weighted avg_support': 128.0, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'O_support': 2462, 'epoch': 3}, {'micro_f1': 0.7894120402904662, 'precision': 0.7894120402904662, 'Appeal_to_Values_precision': 0.1919191919191919, 'Appeal_to_Values_recall': 0.10160427807486631, 'Appeal_to_Values_f1-score': 0.13286713286713286, 'Appeal_to_Values_support': 187.0, 'micro avg_precision': 0.1919191919191919, 'micro avg_recall': 0.10160427807486631, 'micro avg_f1-score': 0.13286713286713286, 'micro avg_support': 187.0, 'macro avg_precision': 0.1919191919191919, 'macro avg_recall': 0.10160427807486631, 'macro avg_f1-score': 0.13286713286713286, 'macro avg_support': 187.0, 'weighted avg_precision': 0.1919191919191919, 'weighted avg_recall': 0.10160427807486631, 'weighted avg_f1-score': 0.13286713286713286, 'weighted avg_support': 187.0, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'O_support': 2462, 'epoch': 4}, {'micro_f1': 0.8109627547434997, 'precision': 0.8109627547434997, 'Appeal_to_Values_precision': 0.2828282828282828, 'Appeal_to_Values_recall': 0.1686746987951807, 'Appeal_to_Values_f1-score': 0.2113207547169811, 'Appeal_to_Values_support': 166.0, 'micro avg_precision': 0.2828282828282828, 'micro avg_recall': 0.1686746987951807, 'micro avg_f1-score': 0.2113207547169811, 'micro avg_support': 166.0, 'macro avg_precision': 0.2828282828282828, 'macro avg_recall': 0.1686746987951807, 'macro avg_f1-score': 0.2113207547169811, 'macro avg_support': 166.0, 'weighted avg_precision': 0.2828282828282828, 'weighted avg_recall': 0.1686746987951807, 'weighted avg_f1-score': 0.2113207547169811, 'weighted avg_support': 166.0, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'O_support': 2462, 'epoch': 5}, {'micro_f1': 0.8299367533380184, 'precision': 0.8299367533380183, 'Appeal_to_Values_precision': 0.3434343434343434, 'Appeal_to_Values_recall': 0.2251655629139073, 'Appeal_to_Values_f1-score': 0.272, 'Appeal_to_Values_support': 151.0, 'micro avg_precision': 0.3434343434343434, 'micro avg_recall': 0.2251655629139073, 'micro avg_f1-score': 0.272, 'micro avg_support': 151.0, 'macro avg_precision': 0.3434343434343434, 'macro avg_recall': 0.2251655629139073, 'macro avg_f1-score': 0.272, 'macro avg_support': 151.0, 'weighted avg_precision': 0.3434343434343434, 'weighted avg_recall': 0.2251655629139073, 'weighted avg_f1-score': 0.272, 'weighted avg_support': 151.0, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'O_support': 2462, 'epoch': 6}, {'micro_f1': 0.8090887795736706, 'precision': 0.8090887795736706, 'Appeal_to_Values_precision': 0.2727272727272727, 'Appeal_to_Values_recall': 0.17307692307692307, 'Appeal_to_Values_f1-score': 0.21176470588235294, 'Appeal_to_Values_support': 156.0, 'micro avg_precision': 0.2727272727272727, 'micro avg_recall': 0.17307692307692307, 'micro avg_f1-score': 0.21176470588235294, 'micro avg_support': 156.0, 'macro avg_precision': 0.2727272727272727, 'macro avg_recall': 0.17307692307692307, 'macro avg_f1-score': 0.21176470588235294, 'macro avg_support': 156.0, 'weighted avg_precision': 0.2727272727272727, 'weighted avg_recall': 0.17307692307692307, 'weighted avg_f1-score': 0.2117647058823529, 'weighted avg_support': 156.0, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'O_support': 2462, 'epoch': 7}, {'micro_f1': 0.811431248535957, 'precision': 0.8114312485359569, 'Appeal_to_Values_precision': 0.25252525252525254, 'Appeal_to_Values_recall': 0.1524390243902439, 'Appeal_to_Values_f1-score': 0.19011406844106465, 'Appeal_to_Values_support': 164.0, 'micro avg_precision': 0.25252525252525254, 'micro avg_recall': 0.1524390243902439, 'micro avg_f1-score': 0.19011406844106465, 'micro avg_support': 164.0, 'macro avg_precision': 0.25252525252525254, 'macro avg_recall': 0.1524390243902439, 'macro avg_f1-score': 0.19011406844106465, 'macro avg_support': 164.0, 'weighted avg_precision': 0.25252525252525254, 'weighted avg_recall': 0.1524390243902439, 'weighted avg_f1-score': 0.19011406844106465, 'weighted avg_support': 164.0, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'O_support': 2462, 'epoch': 8}]}
Early stopping triggered.
Saving model to directory: ./models/M2/2024-05-13-23-08-48_aug/mdeberta-v3-base_2_ME10_target=Appeal_to_Values_SUBSAMPLED_2024-05-13-23-08-48
Training model no. 3 of 23 for (3, 'Appeal_to_Fear-Prejudice') persuasion technique...
{'micro_f1': 0.7698320111992534, 'precision': 0.7698320111992534, 'Appeal_to_Fear-Prejudice_precision': 0.0273224043715847, 'Appeal_to_Fear-Prejudice_recall': 0.024630541871921183, 'Appeal_to_Fear-Prejudice_f1-score': 0.02590673575129534, 'Appeal_to_Fear-Prejudice_support': 203.0, 'micro avg_precision': 0.0273224043715847, 'micro avg_recall': 0.024630541871921183, 'micro avg_f1-score': 0.02590673575129534, 'micro avg_support': 203.0, 'macro avg_precision': 0.0273224043715847, 'macro avg_recall': 0.024630541871921183, 'macro avg_f1-score': 0.02590673575129534, 'macro avg_support': 203.0, 'weighted avg_precision': 0.0273224043715847, 'weighted avg_recall': 0.024630541871921183, 'weighted avg_f1-score': 0.02590673575129534, 'weighted avg_support': 203.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5648, 'epoch': 0}
{'results': [{'micro_f1': 0.7698320111992534, 'precision': 0.7698320111992534, 'Appeal_to_Fear-Prejudice_precision': 0.0273224043715847, 'Appeal_to_Fear-Prejudice_recall': 0.024630541871921183, 'Appeal_to_Fear-Prejudice_f1-score': 0.02590673575129534, 'Appeal_to_Fear-Prejudice_support': 203.0, 'micro avg_precision': 0.0273224043715847, 'micro avg_recall': 0.024630541871921183, 'micro avg_f1-score': 0.02590673575129534, 'micro avg_support': 203.0, 'macro avg_precision': 0.0273224043715847, 'macro avg_recall': 0.024630541871921183, 'macro avg_f1-score': 0.02590673575129534, 'macro avg_support': 203.0, 'weighted avg_precision': 0.0273224043715847, 'weighted avg_recall': 0.024630541871921183, 'weighted avg_f1-score': 0.02590673575129534, 'weighted avg_support': 203.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5648, 'epoch': 0}]}
Best model updated: current epoch macro f1 = 0.02590673575129534
{'micro_f1': 0.8077461502566496, 'precision': 0.8077461502566495, 'Appeal_to_Fear-Prejudice_precision': 0.10382513661202186, 'Appeal_to_Fear-Prejudice_recall': 0.08260869565217391, 'Appeal_to_Fear-Prejudice_f1-score': 0.0920096852300242, 'Appeal_to_Fear-Prejudice_support': 230.0, 'micro avg_precision': 0.10382513661202186, 'micro avg_recall': 0.08260869565217391, 'micro avg_f1-score': 0.0920096852300242, 'micro avg_support': 230.0, 'macro avg_precision': 0.10382513661202186, 'macro avg_recall': 0.08260869565217391, 'macro avg_f1-score': 0.0920096852300242, 'macro avg_support': 230.0, 'weighted avg_precision': 0.10382513661202186, 'weighted avg_recall': 0.08260869565217391, 'weighted avg_f1-score': 0.0920096852300242, 'weighted avg_support': 230.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5648, 'epoch': 1}
{'results': [{'micro_f1': 0.7698320111992534, 'precision': 0.7698320111992534, 'Appeal_to_Fear-Prejudice_precision': 0.0273224043715847, 'Appeal_to_Fear-Prejudice_recall': 0.024630541871921183, 'Appeal_to_Fear-Prejudice_f1-score': 0.02590673575129534, 'Appeal_to_Fear-Prejudice_support': 203.0, 'micro avg_precision': 0.0273224043715847, 'micro avg_recall': 0.024630541871921183, 'micro avg_f1-score': 0.02590673575129534, 'micro avg_support': 203.0, 'macro avg_precision': 0.0273224043715847, 'macro avg_recall': 0.024630541871921183, 'macro avg_f1-score': 0.02590673575129534, 'macro avg_support': 203.0, 'weighted avg_precision': 0.0273224043715847, 'weighted avg_recall': 0.024630541871921183, 'weighted avg_f1-score': 0.02590673575129534, 'weighted avg_support': 203.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5648, 'epoch': 0}, {'micro_f1': 0.8077461502566496, 'precision': 0.8077461502566495, 'Appeal_to_Fear-Prejudice_precision': 0.10382513661202186, 'Appeal_to_Fear-Prejudice_recall': 0.08260869565217391, 'Appeal_to_Fear-Prejudice_f1-score': 0.0920096852300242, 'Appeal_to_Fear-Prejudice_support': 230.0, 'micro avg_precision': 0.10382513661202186, 'micro avg_recall': 0.08260869565217391, 'micro avg_f1-score': 0.0920096852300242, 'micro avg_support': 230.0, 'macro avg_precision': 0.10382513661202186, 'macro avg_recall': 0.08260869565217391, 'macro avg_f1-score': 0.0920096852300242, 'macro avg_support': 230.0, 'weighted avg_precision': 0.10382513661202186, 'weighted avg_recall': 0.08260869565217391, 'weighted avg_f1-score': 0.0920096852300242, 'weighted avg_support': 230.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5648, 'epoch': 1}]}
Best model updated: current epoch macro f1 = 0.0920096852300242
{'micro_f1': 0.8108959402706485, 'precision': 0.8108959402706486, 'Appeal_to_Fear-Prejudice_precision': 0.14754098360655737, 'Appeal_to_Fear-Prejudice_recall': 0.10546875, 'Appeal_to_Fear-Prejudice_f1-score': 0.12300683371298404, 'Appeal_to_Fear-Prejudice_support': 256.0, 'micro avg_precision': 0.14754098360655737, 'micro avg_recall': 0.10546875, 'micro avg_f1-score': 0.12300683371298404, 'micro avg_support': 256.0, 'macro avg_precision': 0.14754098360655737, 'macro avg_recall': 0.10546875, 'macro avg_f1-score': 0.12300683371298404, 'macro avg_support': 256.0, 'weighted avg_precision': 0.14754098360655737, 'weighted avg_recall': 0.10546875, 'weighted avg_f1-score': 0.12300683371298404, 'weighted avg_support': 256.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5648, 'epoch': 2}
{'results': [{'micro_f1': 0.7698320111992534, 'precision': 0.7698320111992534, 'Appeal_to_Fear-Prejudice_precision': 0.0273224043715847, 'Appeal_to_Fear-Prejudice_recall': 0.024630541871921183, 'Appeal_to_Fear-Prejudice_f1-score': 0.02590673575129534, 'Appeal_to_Fear-Prejudice_support': 203.0, 'micro avg_precision': 0.0273224043715847, 'micro avg_recall': 0.024630541871921183, 'micro avg_f1-score': 0.02590673575129534, 'micro avg_support': 203.0, 'macro avg_precision': 0.0273224043715847, 'macro avg_recall': 0.024630541871921183, 'macro avg_f1-score': 0.02590673575129534, 'macro avg_support': 203.0, 'weighted avg_precision': 0.0273224043715847, 'weighted avg_recall': 0.024630541871921183, 'weighted avg_f1-score': 0.02590673575129534, 'weighted avg_support': 203.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5648, 'epoch': 0}, {'micro_f1': 0.8077461502566496, 'precision': 0.8077461502566495, 'Appeal_to_Fear-Prejudice_precision': 0.10382513661202186, 'Appeal_to_Fear-Prejudice_recall': 0.08260869565217391, 'Appeal_to_Fear-Prejudice_f1-score': 0.0920096852300242, 'Appeal_to_Fear-Prejudice_support': 230.0, 'micro avg_precision': 0.10382513661202186, 'micro avg_recall': 0.08260869565217391, 'micro avg_f1-score': 0.0920096852300242, 'micro avg_support': 230.0, 'macro avg_precision': 0.10382513661202186, 'macro avg_recall': 0.08260869565217391, 'macro avg_f1-score': 0.0920096852300242, 'macro avg_support': 230.0, 'weighted avg_precision': 0.10382513661202186, 'weighted avg_recall': 0.08260869565217391, 'weighted avg_f1-score': 0.0920096852300242, 'weighted avg_support': 230.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5648, 'epoch': 1}, {'micro_f1': 0.8108959402706485, 'precision': 0.8108959402706486, 'Appeal_to_Fear-Prejudice_precision': 0.14754098360655737, 'Appeal_to_Fear-Prejudice_recall': 0.10546875, 'Appeal_to_Fear-Prejudice_f1-score': 0.12300683371298404, 'Appeal_to_Fear-Prejudice_support': 256.0, 'micro avg_precision': 0.14754098360655737, 'micro avg_recall': 0.10546875, 'micro avg_f1-score': 0.12300683371298404, 'micro avg_support': 256.0, 'macro avg_precision': 0.14754098360655737, 'macro avg_recall': 0.10546875, 'macro avg_f1-score': 0.12300683371298404, 'macro avg_support': 256.0, 'weighted avg_precision': 0.14754098360655737, 'weighted avg_recall': 0.10546875, 'weighted avg_f1-score': 0.12300683371298404, 'weighted avg_support': 256.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5648, 'epoch': 2}]}
Best model updated: current epoch macro f1 = 0.12300683371298404
{'micro_f1': 0.8189454036397573, 'precision': 0.8189454036397573, 'Appeal_to_Fear-Prejudice_precision': 0.26229508196721313, 'Appeal_to_Fear-Prejudice_recall': 0.17647058823529413, 'Appeal_to_Fear-Prejudice_f1-score': 0.21098901098901102, 'Appeal_to_Fear-Prejudice_support': 272.0, 'micro avg_precision': 0.26229508196721313, 'micro avg_recall': 0.17647058823529413, 'micro avg_f1-score': 0.21098901098901102, 'micro avg_support': 272.0, 'macro avg_precision': 0.26229508196721313, 'macro avg_recall': 0.17647058823529413, 'macro avg_f1-score': 0.21098901098901102, 'macro avg_support': 272.0, 'weighted avg_precision': 0.26229508196721313, 'weighted avg_recall': 0.17647058823529413, 'weighted avg_f1-score': 0.21098901098901102, 'weighted avg_support': 272.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5648, 'epoch': 3}
{'results': [{'micro_f1': 0.7698320111992534, 'precision': 0.7698320111992534, 'Appeal_to_Fear-Prejudice_precision': 0.0273224043715847, 'Appeal_to_Fear-Prejudice_recall': 0.024630541871921183, 'Appeal_to_Fear-Prejudice_f1-score': 0.02590673575129534, 'Appeal_to_Fear-Prejudice_support': 203.0, 'micro avg_precision': 0.0273224043715847, 'micro avg_recall': 0.024630541871921183, 'micro avg_f1-score': 0.02590673575129534, 'micro avg_support': 203.0, 'macro avg_precision': 0.0273224043715847, 'macro avg_recall': 0.024630541871921183, 'macro avg_f1-score': 0.02590673575129534, 'macro avg_support': 203.0, 'weighted avg_precision': 0.0273224043715847, 'weighted avg_recall': 0.024630541871921183, 'weighted avg_f1-score': 0.02590673575129534, 'weighted avg_support': 203.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5648, 'epoch': 0}, {'micro_f1': 0.8077461502566496, 'precision': 0.8077461502566495, 'Appeal_to_Fear-Prejudice_precision': 0.10382513661202186, 'Appeal_to_Fear-Prejudice_recall': 0.08260869565217391, 'Appeal_to_Fear-Prejudice_f1-score': 0.0920096852300242, 'Appeal_to_Fear-Prejudice_support': 230.0, 'micro avg_precision': 0.10382513661202186, 'micro avg_recall': 0.08260869565217391, 'micro avg_f1-score': 0.0920096852300242, 'micro avg_support': 230.0, 'macro avg_precision': 0.10382513661202186, 'macro avg_recall': 0.08260869565217391, 'macro avg_f1-score': 0.0920096852300242, 'macro avg_support': 230.0, 'weighted avg_precision': 0.10382513661202186, 'weighted avg_recall': 0.08260869565217391, 'weighted avg_f1-score': 0.0920096852300242, 'weighted avg_support': 230.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5648, 'epoch': 1}, {'micro_f1': 0.8108959402706485, 'precision': 0.8108959402706486, 'Appeal_to_Fear-Prejudice_precision': 0.14754098360655737, 'Appeal_to_Fear-Prejudice_recall': 0.10546875, 'Appeal_to_Fear-Prejudice_f1-score': 0.12300683371298404, 'Appeal_to_Fear-Prejudice_support': 256.0, 'micro avg_precision': 0.14754098360655737, 'micro avg_recall': 0.10546875, 'micro avg_f1-score': 0.12300683371298404, 'micro avg_support': 256.0, 'macro avg_precision': 0.14754098360655737, 'macro avg_recall': 0.10546875, 'macro avg_f1-score': 0.12300683371298404, 'macro avg_support': 256.0, 'weighted avg_precision': 0.14754098360655737, 'weighted avg_recall': 0.10546875, 'weighted avg_f1-score': 0.12300683371298404, 'weighted avg_support': 256.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5648, 'epoch': 2}, {'micro_f1': 0.8189454036397573, 'precision': 0.8189454036397573, 'Appeal_to_Fear-Prejudice_precision': 0.26229508196721313, 'Appeal_to_Fear-Prejudice_recall': 0.17647058823529413, 'Appeal_to_Fear-Prejudice_f1-score': 0.21098901098901102, 'Appeal_to_Fear-Prejudice_support': 272.0, 'micro avg_precision': 0.26229508196721313, 'micro avg_recall': 0.17647058823529413, 'micro avg_f1-score': 0.21098901098901102, 'micro avg_support': 272.0, 'macro avg_precision': 0.26229508196721313, 'macro avg_recall': 0.17647058823529413, 'macro avg_f1-score': 0.21098901098901102, 'macro avg_support': 272.0, 'weighted avg_precision': 0.26229508196721313, 'weighted avg_recall': 0.17647058823529413, 'weighted avg_f1-score': 0.21098901098901102, 'weighted avg_support': 272.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5648, 'epoch': 3}]}
Best model updated: current epoch macro f1 = 0.21098901098901102
{'micro_f1': 0.8135790947270182, 'precision': 0.8135790947270182, 'Appeal_to_Fear-Prejudice_precision': 0.34972677595628415, 'Appeal_to_Fear-Prejudice_recall': 0.2379182156133829, 'Appeal_to_Fear-Prejudice_f1-score': 0.28318584070796454, 'Appeal_to_Fear-Prejudice_support': 269.0, 'micro avg_precision': 0.34972677595628415, 'micro avg_recall': 0.2379182156133829, 'micro avg_f1-score': 0.28318584070796454, 'micro avg_support': 269.0, 'macro avg_precision': 0.34972677595628415, 'macro avg_recall': 0.2379182156133829, 'macro avg_f1-score': 0.28318584070796454, 'macro avg_support': 269.0, 'weighted avg_precision': 0.34972677595628415, 'weighted avg_recall': 0.2379182156133829, 'weighted avg_f1-score': 0.28318584070796454, 'weighted avg_support': 269.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5648, 'epoch': 4}
{'results': [{'micro_f1': 0.7698320111992534, 'precision': 0.7698320111992534, 'Appeal_to_Fear-Prejudice_precision': 0.0273224043715847, 'Appeal_to_Fear-Prejudice_recall': 0.024630541871921183, 'Appeal_to_Fear-Prejudice_f1-score': 0.02590673575129534, 'Appeal_to_Fear-Prejudice_support': 203.0, 'micro avg_precision': 0.0273224043715847, 'micro avg_recall': 0.024630541871921183, 'micro avg_f1-score': 0.02590673575129534, 'micro avg_support': 203.0, 'macro avg_precision': 0.0273224043715847, 'macro avg_recall': 0.024630541871921183, 'macro avg_f1-score': 0.02590673575129534, 'macro avg_support': 203.0, 'weighted avg_precision': 0.0273224043715847, 'weighted avg_recall': 0.024630541871921183, 'weighted avg_f1-score': 0.02590673575129534, 'weighted avg_support': 203.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5648, 'epoch': 0}, {'micro_f1': 0.8077461502566496, 'precision': 0.8077461502566495, 'Appeal_to_Fear-Prejudice_precision': 0.10382513661202186, 'Appeal_to_Fear-Prejudice_recall': 0.08260869565217391, 'Appeal_to_Fear-Prejudice_f1-score': 0.0920096852300242, 'Appeal_to_Fear-Prejudice_support': 230.0, 'micro avg_precision': 0.10382513661202186, 'micro avg_recall': 0.08260869565217391, 'micro avg_f1-score': 0.0920096852300242, 'micro avg_support': 230.0, 'macro avg_precision': 0.10382513661202186, 'macro avg_recall': 0.08260869565217391, 'macro avg_f1-score': 0.0920096852300242, 'macro avg_support': 230.0, 'weighted avg_precision': 0.10382513661202186, 'weighted avg_recall': 0.08260869565217391, 'weighted avg_f1-score': 0.0920096852300242, 'weighted avg_support': 230.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5648, 'epoch': 1}, {'micro_f1': 0.8108959402706485, 'precision': 0.8108959402706486, 'Appeal_to_Fear-Prejudice_precision': 0.14754098360655737, 'Appeal_to_Fear-Prejudice_recall': 0.10546875, 'Appeal_to_Fear-Prejudice_f1-score': 0.12300683371298404, 'Appeal_to_Fear-Prejudice_support': 256.0, 'micro avg_precision': 0.14754098360655737, 'micro avg_recall': 0.10546875, 'micro avg_f1-score': 0.12300683371298404, 'micro avg_support': 256.0, 'macro avg_precision': 0.14754098360655737, 'macro avg_recall': 0.10546875, 'macro avg_f1-score': 0.12300683371298404, 'macro avg_support': 256.0, 'weighted avg_precision': 0.14754098360655737, 'weighted avg_recall': 0.10546875, 'weighted avg_f1-score': 0.12300683371298404, 'weighted avg_support': 256.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5648, 'epoch': 2}, {'micro_f1': 0.8189454036397573, 'precision': 0.8189454036397573, 'Appeal_to_Fear-Prejudice_precision': 0.26229508196721313, 'Appeal_to_Fear-Prejudice_recall': 0.17647058823529413, 'Appeal_to_Fear-Prejudice_f1-score': 0.21098901098901102, 'Appeal_to_Fear-Prejudice_support': 272.0, 'micro avg_precision': 0.26229508196721313, 'micro avg_recall': 0.17647058823529413, 'micro avg_f1-score': 0.21098901098901102, 'micro avg_support': 272.0, 'macro avg_precision': 0.26229508196721313, 'macro avg_recall': 0.17647058823529413, 'macro avg_f1-score': 0.21098901098901102, 'macro avg_support': 272.0, 'weighted avg_precision': 0.26229508196721313, 'weighted avg_recall': 0.17647058823529413, 'weighted avg_f1-score': 0.21098901098901102, 'weighted avg_support': 272.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5648, 'epoch': 3}, {'micro_f1': 0.8135790947270182, 'precision': 0.8135790947270182, 'Appeal_to_Fear-Prejudice_precision': 0.34972677595628415, 'Appeal_to_Fear-Prejudice_recall': 0.2379182156133829, 'Appeal_to_Fear-Prejudice_f1-score': 0.28318584070796454, 'Appeal_to_Fear-Prejudice_support': 269.0, 'micro avg_precision': 0.34972677595628415, 'micro avg_recall': 0.2379182156133829, 'micro avg_f1-score': 0.28318584070796454, 'micro avg_support': 269.0, 'macro avg_precision': 0.34972677595628415, 'macro avg_recall': 0.2379182156133829, 'macro avg_f1-score': 0.28318584070796454, 'macro avg_support': 269.0, 'weighted avg_precision': 0.34972677595628415, 'weighted avg_recall': 0.2379182156133829, 'weighted avg_f1-score': 0.28318584070796454, 'weighted avg_support': 269.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5648, 'epoch': 4}]}
Best model updated: current epoch macro f1 = 0.28318584070796454
{'micro_f1': 0.7951469902006533, 'precision': 0.7951469902006533, 'Appeal_to_Fear-Prejudice_precision': 0.2896174863387978, 'Appeal_to_Fear-Prejudice_recall': 0.17549668874172186, 'Appeal_to_Fear-Prejudice_f1-score': 0.21855670103092784, 'Appeal_to_Fear-Prejudice_support': 302.0, 'micro avg_precision': 0.2896174863387978, 'micro avg_recall': 0.17549668874172186, 'micro avg_f1-score': 0.21855670103092784, 'micro avg_support': 302.0, 'macro avg_precision': 0.2896174863387978, 'macro avg_recall': 0.17549668874172186, 'macro avg_f1-score': 0.21855670103092784, 'macro avg_support': 302.0, 'weighted avg_precision': 0.2896174863387978, 'weighted avg_recall': 0.17549668874172186, 'weighted avg_f1-score': 0.21855670103092786, 'weighted avg_support': 302.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5648, 'epoch': 5}
{'results': [{'micro_f1': 0.7698320111992534, 'precision': 0.7698320111992534, 'Appeal_to_Fear-Prejudice_precision': 0.0273224043715847, 'Appeal_to_Fear-Prejudice_recall': 0.024630541871921183, 'Appeal_to_Fear-Prejudice_f1-score': 0.02590673575129534, 'Appeal_to_Fear-Prejudice_support': 203.0, 'micro avg_precision': 0.0273224043715847, 'micro avg_recall': 0.024630541871921183, 'micro avg_f1-score': 0.02590673575129534, 'micro avg_support': 203.0, 'macro avg_precision': 0.0273224043715847, 'macro avg_recall': 0.024630541871921183, 'macro avg_f1-score': 0.02590673575129534, 'macro avg_support': 203.0, 'weighted avg_precision': 0.0273224043715847, 'weighted avg_recall': 0.024630541871921183, 'weighted avg_f1-score': 0.02590673575129534, 'weighted avg_support': 203.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5648, 'epoch': 0}, {'micro_f1': 0.8077461502566496, 'precision': 0.8077461502566495, 'Appeal_to_Fear-Prejudice_precision': 0.10382513661202186, 'Appeal_to_Fear-Prejudice_recall': 0.08260869565217391, 'Appeal_to_Fear-Prejudice_f1-score': 0.0920096852300242, 'Appeal_to_Fear-Prejudice_support': 230.0, 'micro avg_precision': 0.10382513661202186, 'micro avg_recall': 0.08260869565217391, 'micro avg_f1-score': 0.0920096852300242, 'micro avg_support': 230.0, 'macro avg_precision': 0.10382513661202186, 'macro avg_recall': 0.08260869565217391, 'macro avg_f1-score': 0.0920096852300242, 'macro avg_support': 230.0, 'weighted avg_precision': 0.10382513661202186, 'weighted avg_recall': 0.08260869565217391, 'weighted avg_f1-score': 0.0920096852300242, 'weighted avg_support': 230.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5648, 'epoch': 1}, {'micro_f1': 0.8108959402706485, 'precision': 0.8108959402706486, 'Appeal_to_Fear-Prejudice_precision': 0.14754098360655737, 'Appeal_to_Fear-Prejudice_recall': 0.10546875, 'Appeal_to_Fear-Prejudice_f1-score': 0.12300683371298404, 'Appeal_to_Fear-Prejudice_support': 256.0, 'micro avg_precision': 0.14754098360655737, 'micro avg_recall': 0.10546875, 'micro avg_f1-score': 0.12300683371298404, 'micro avg_support': 256.0, 'macro avg_precision': 0.14754098360655737, 'macro avg_recall': 0.10546875, 'macro avg_f1-score': 0.12300683371298404, 'macro avg_support': 256.0, 'weighted avg_precision': 0.14754098360655737, 'weighted avg_recall': 0.10546875, 'weighted avg_f1-score': 0.12300683371298404, 'weighted avg_support': 256.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5648, 'epoch': 2}, {'micro_f1': 0.8189454036397573, 'precision': 0.8189454036397573, 'Appeal_to_Fear-Prejudice_precision': 0.26229508196721313, 'Appeal_to_Fear-Prejudice_recall': 0.17647058823529413, 'Appeal_to_Fear-Prejudice_f1-score': 0.21098901098901102, 'Appeal_to_Fear-Prejudice_support': 272.0, 'micro avg_precision': 0.26229508196721313, 'micro avg_recall': 0.17647058823529413, 'micro avg_f1-score': 0.21098901098901102, 'micro avg_support': 272.0, 'macro avg_precision': 0.26229508196721313, 'macro avg_recall': 0.17647058823529413, 'macro avg_f1-score': 0.21098901098901102, 'macro avg_support': 272.0, 'weighted avg_precision': 0.26229508196721313, 'weighted avg_recall': 0.17647058823529413, 'weighted avg_f1-score': 0.21098901098901102, 'weighted avg_support': 272.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5648, 'epoch': 3}, {'micro_f1': 0.8135790947270182, 'precision': 0.8135790947270182, 'Appeal_to_Fear-Prejudice_precision': 0.34972677595628415, 'Appeal_to_Fear-Prejudice_recall': 0.2379182156133829, 'Appeal_to_Fear-Prejudice_f1-score': 0.28318584070796454, 'Appeal_to_Fear-Prejudice_support': 269.0, 'micro avg_precision': 0.34972677595628415, 'micro avg_recall': 0.2379182156133829, 'micro avg_f1-score': 0.28318584070796454, 'micro avg_support': 269.0, 'macro avg_precision': 0.34972677595628415, 'macro avg_recall': 0.2379182156133829, 'macro avg_f1-score': 0.28318584070796454, 'macro avg_support': 269.0, 'weighted avg_precision': 0.34972677595628415, 'weighted avg_recall': 0.2379182156133829, 'weighted avg_f1-score': 0.28318584070796454, 'weighted avg_support': 269.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5648, 'epoch': 4}, {'micro_f1': 0.7951469902006533, 'precision': 0.7951469902006533, 'Appeal_to_Fear-Prejudice_precision': 0.2896174863387978, 'Appeal_to_Fear-Prejudice_recall': 0.17549668874172186, 'Appeal_to_Fear-Prejudice_f1-score': 0.21855670103092784, 'Appeal_to_Fear-Prejudice_support': 302.0, 'micro avg_precision': 0.2896174863387978, 'micro avg_recall': 0.17549668874172186, 'micro avg_f1-score': 0.21855670103092784, 'micro avg_support': 302.0, 'macro avg_precision': 0.2896174863387978, 'macro avg_recall': 0.17549668874172186, 'macro avg_f1-score': 0.21855670103092784, 'macro avg_support': 302.0, 'weighted avg_precision': 0.2896174863387978, 'weighted avg_recall': 0.17549668874172186, 'weighted avg_f1-score': 0.21855670103092786, 'weighted avg_support': 302.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5648, 'epoch': 5}]}
{'micro_f1': 0.8118292113859076, 'precision': 0.8118292113859076, 'Appeal_to_Fear-Prejudice_precision': 0.3333333333333333, 'Appeal_to_Fear-Prejudice_recall': 0.21863799283154123, 'Appeal_to_Fear-Prejudice_f1-score': 0.26406926406926406, 'Appeal_to_Fear-Prejudice_support': 279.0, 'micro avg_precision': 0.3333333333333333, 'micro avg_recall': 0.21863799283154123, 'micro avg_f1-score': 0.26406926406926406, 'micro avg_support': 279.0, 'macro avg_precision': 0.3333333333333333, 'macro avg_recall': 0.21863799283154123, 'macro avg_f1-score': 0.26406926406926406, 'macro avg_support': 279.0, 'weighted avg_precision': 0.3333333333333333, 'weighted avg_recall': 0.21863799283154123, 'weighted avg_f1-score': 0.26406926406926406, 'weighted avg_support': 279.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5648, 'epoch': 6}
{'results': [{'micro_f1': 0.7698320111992534, 'precision': 0.7698320111992534, 'Appeal_to_Fear-Prejudice_precision': 0.0273224043715847, 'Appeal_to_Fear-Prejudice_recall': 0.024630541871921183, 'Appeal_to_Fear-Prejudice_f1-score': 0.02590673575129534, 'Appeal_to_Fear-Prejudice_support': 203.0, 'micro avg_precision': 0.0273224043715847, 'micro avg_recall': 0.024630541871921183, 'micro avg_f1-score': 0.02590673575129534, 'micro avg_support': 203.0, 'macro avg_precision': 0.0273224043715847, 'macro avg_recall': 0.024630541871921183, 'macro avg_f1-score': 0.02590673575129534, 'macro avg_support': 203.0, 'weighted avg_precision': 0.0273224043715847, 'weighted avg_recall': 0.024630541871921183, 'weighted avg_f1-score': 0.02590673575129534, 'weighted avg_support': 203.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5648, 'epoch': 0}, {'micro_f1': 0.8077461502566496, 'precision': 0.8077461502566495, 'Appeal_to_Fear-Prejudice_precision': 0.10382513661202186, 'Appeal_to_Fear-Prejudice_recall': 0.08260869565217391, 'Appeal_to_Fear-Prejudice_f1-score': 0.0920096852300242, 'Appeal_to_Fear-Prejudice_support': 230.0, 'micro avg_precision': 0.10382513661202186, 'micro avg_recall': 0.08260869565217391, 'micro avg_f1-score': 0.0920096852300242, 'micro avg_support': 230.0, 'macro avg_precision': 0.10382513661202186, 'macro avg_recall': 0.08260869565217391, 'macro avg_f1-score': 0.0920096852300242, 'macro avg_support': 230.0, 'weighted avg_precision': 0.10382513661202186, 'weighted avg_recall': 0.08260869565217391, 'weighted avg_f1-score': 0.0920096852300242, 'weighted avg_support': 230.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5648, 'epoch': 1}, {'micro_f1': 0.8108959402706485, 'precision': 0.8108959402706486, 'Appeal_to_Fear-Prejudice_precision': 0.14754098360655737, 'Appeal_to_Fear-Prejudice_recall': 0.10546875, 'Appeal_to_Fear-Prejudice_f1-score': 0.12300683371298404, 'Appeal_to_Fear-Prejudice_support': 256.0, 'micro avg_precision': 0.14754098360655737, 'micro avg_recall': 0.10546875, 'micro avg_f1-score': 0.12300683371298404, 'micro avg_support': 256.0, 'macro avg_precision': 0.14754098360655737, 'macro avg_recall': 0.10546875, 'macro avg_f1-score': 0.12300683371298404, 'macro avg_support': 256.0, 'weighted avg_precision': 0.14754098360655737, 'weighted avg_recall': 0.10546875, 'weighted avg_f1-score': 0.12300683371298404, 'weighted avg_support': 256.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5648, 'epoch': 2}, {'micro_f1': 0.8189454036397573, 'precision': 0.8189454036397573, 'Appeal_to_Fear-Prejudice_precision': 0.26229508196721313, 'Appeal_to_Fear-Prejudice_recall': 0.17647058823529413, 'Appeal_to_Fear-Prejudice_f1-score': 0.21098901098901102, 'Appeal_to_Fear-Prejudice_support': 272.0, 'micro avg_precision': 0.26229508196721313, 'micro avg_recall': 0.17647058823529413, 'micro avg_f1-score': 0.21098901098901102, 'micro avg_support': 272.0, 'macro avg_precision': 0.26229508196721313, 'macro avg_recall': 0.17647058823529413, 'macro avg_f1-score': 0.21098901098901102, 'macro avg_support': 272.0, 'weighted avg_precision': 0.26229508196721313, 'weighted avg_recall': 0.17647058823529413, 'weighted avg_f1-score': 0.21098901098901102, 'weighted avg_support': 272.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5648, 'epoch': 3}, {'micro_f1': 0.8135790947270182, 'precision': 0.8135790947270182, 'Appeal_to_Fear-Prejudice_precision': 0.34972677595628415, 'Appeal_to_Fear-Prejudice_recall': 0.2379182156133829, 'Appeal_to_Fear-Prejudice_f1-score': 0.28318584070796454, 'Appeal_to_Fear-Prejudice_support': 269.0, 'micro avg_precision': 0.34972677595628415, 'micro avg_recall': 0.2379182156133829, 'micro avg_f1-score': 0.28318584070796454, 'micro avg_support': 269.0, 'macro avg_precision': 0.34972677595628415, 'macro avg_recall': 0.2379182156133829, 'macro avg_f1-score': 0.28318584070796454, 'macro avg_support': 269.0, 'weighted avg_precision': 0.34972677595628415, 'weighted avg_recall': 0.2379182156133829, 'weighted avg_f1-score': 0.28318584070796454, 'weighted avg_support': 269.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5648, 'epoch': 4}, {'micro_f1': 0.7951469902006533, 'precision': 0.7951469902006533, 'Appeal_to_Fear-Prejudice_precision': 0.2896174863387978, 'Appeal_to_Fear-Prejudice_recall': 0.17549668874172186, 'Appeal_to_Fear-Prejudice_f1-score': 0.21855670103092784, 'Appeal_to_Fear-Prejudice_support': 302.0, 'micro avg_precision': 0.2896174863387978, 'micro avg_recall': 0.17549668874172186, 'micro avg_f1-score': 0.21855670103092784, 'micro avg_support': 302.0, 'macro avg_precision': 0.2896174863387978, 'macro avg_recall': 0.17549668874172186, 'macro avg_f1-score': 0.21855670103092784, 'macro avg_support': 302.0, 'weighted avg_precision': 0.2896174863387978, 'weighted avg_recall': 0.17549668874172186, 'weighted avg_f1-score': 0.21855670103092786, 'weighted avg_support': 302.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5648, 'epoch': 5}, {'micro_f1': 0.8118292113859076, 'precision': 0.8118292113859076, 'Appeal_to_Fear-Prejudice_precision': 0.3333333333333333, 'Appeal_to_Fear-Prejudice_recall': 0.21863799283154123, 'Appeal_to_Fear-Prejudice_f1-score': 0.26406926406926406, 'Appeal_to_Fear-Prejudice_support': 279.0, 'micro avg_precision': 0.3333333333333333, 'micro avg_recall': 0.21863799283154123, 'micro avg_f1-score': 0.26406926406926406, 'micro avg_support': 279.0, 'macro avg_precision': 0.3333333333333333, 'macro avg_recall': 0.21863799283154123, 'macro avg_f1-score': 0.26406926406926406, 'macro avg_support': 279.0, 'weighted avg_precision': 0.3333333333333333, 'weighted avg_recall': 0.21863799283154123, 'weighted avg_f1-score': 0.26406926406926406, 'weighted avg_support': 279.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5648, 'epoch': 6}]}
Early stopping triggered.
Saving model to directory: ./models/M2/2024-05-13-23-08-48_aug/mdeberta-v3-base_3_ME10_target=Appeal_to_Fear-Prejudice_SUBSAMPLED_2024-05-13-23-08-48
Training model no. 4 of 23 for (4, 'Flag_Waving') persuasion technique...
{'micro_f1': 0.820990681706719, 'precision': 0.820990681706719, 'Flag_Waving_precision': 0.15384615384615385, 'Flag_Waving_recall': 0.10526315789473684, 'Flag_Waving_f1-score': 0.125, 'Flag_Waving_support': 133.0, 'micro avg_precision': 0.15384615384615385, 'micro avg_recall': 0.10526315789473684, 'micro avg_f1-score': 0.125, 'micro avg_support': 133.0, 'macro avg_precision': 0.15384615384615385, 'macro avg_recall': 0.10526315789473684, 'macro avg_f1-score': 0.125, 'macro avg_support': 133.0, 'weighted avg_precision': 0.15384615384615385, 'weighted avg_recall': 0.10526315789473684, 'weighted avg_f1-score': 0.125, 'weighted avg_support': 133.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2938, 'epoch': 0}
{'results': [{'micro_f1': 0.820990681706719, 'precision': 0.820990681706719, 'Flag_Waving_precision': 0.15384615384615385, 'Flag_Waving_recall': 0.10526315789473684, 'Flag_Waving_f1-score': 0.125, 'Flag_Waving_support': 133.0, 'micro avg_precision': 0.15384615384615385, 'micro avg_recall': 0.10526315789473684, 'micro avg_f1-score': 0.125, 'micro avg_support': 133.0, 'macro avg_precision': 0.15384615384615385, 'macro avg_recall': 0.10526315789473684, 'macro avg_f1-score': 0.125, 'macro avg_support': 133.0, 'weighted avg_precision': 0.15384615384615385, 'weighted avg_recall': 0.10526315789473684, 'weighted avg_f1-score': 0.125, 'weighted avg_support': 133.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2938, 'epoch': 0}]}
Best model updated: current epoch macro f1 = 0.125
{'micro_f1': 0.8523786169691026, 'precision': 0.8523786169691026, 'Flag_Waving_precision': 0.2087912087912088, 'Flag_Waving_recall': 0.16666666666666666, 'Flag_Waving_f1-score': 0.18536585365853658, 'Flag_Waving_support': 114.0, 'micro avg_precision': 0.2087912087912088, 'micro avg_recall': 0.16666666666666666, 'micro avg_f1-score': 0.18536585365853658, 'micro avg_support': 114.0, 'macro avg_precision': 0.2087912087912088, 'macro avg_recall': 0.16666666666666666, 'macro avg_f1-score': 0.18536585365853658, 'macro avg_support': 114.0, 'weighted avg_precision': 0.2087912087912088, 'weighted avg_recall': 0.16666666666666666, 'weighted avg_f1-score': 0.18536585365853658, 'weighted avg_support': 114.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2938, 'epoch': 1}
{'results': [{'micro_f1': 0.820990681706719, 'precision': 0.820990681706719, 'Flag_Waving_precision': 0.15384615384615385, 'Flag_Waving_recall': 0.10526315789473684, 'Flag_Waving_f1-score': 0.125, 'Flag_Waving_support': 133.0, 'micro avg_precision': 0.15384615384615385, 'micro avg_recall': 0.10526315789473684, 'micro avg_f1-score': 0.125, 'micro avg_support': 133.0, 'macro avg_precision': 0.15384615384615385, 'macro avg_recall': 0.10526315789473684, 'macro avg_f1-score': 0.125, 'macro avg_support': 133.0, 'weighted avg_precision': 0.15384615384615385, 'weighted avg_recall': 0.10526315789473684, 'weighted avg_f1-score': 0.125, 'weighted avg_support': 133.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2938, 'epoch': 0}, {'micro_f1': 0.8523786169691026, 'precision': 0.8523786169691026, 'Flag_Waving_precision': 0.2087912087912088, 'Flag_Waving_recall': 0.16666666666666666, 'Flag_Waving_f1-score': 0.18536585365853658, 'Flag_Waving_support': 114.0, 'micro avg_precision': 0.2087912087912088, 'micro avg_recall': 0.16666666666666666, 'micro avg_f1-score': 0.18536585365853658, 'micro avg_support': 114.0, 'macro avg_precision': 0.2087912087912088, 'macro avg_recall': 0.16666666666666666, 'macro avg_f1-score': 0.18536585365853658, 'macro avg_support': 114.0, 'weighted avg_precision': 0.2087912087912088, 'weighted avg_recall': 0.16666666666666666, 'weighted avg_f1-score': 0.18536585365853658, 'weighted avg_support': 114.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2938, 'epoch': 1}]}
Best model updated: current epoch macro f1 = 0.18536585365853658
{'micro_f1': 0.8452672878862187, 'precision': 0.8452672878862187, 'Flag_Waving_precision': 0.3626373626373626, 'Flag_Waving_recall': 0.28448275862068967, 'Flag_Waving_f1-score': 0.31884057971014496, 'Flag_Waving_support': 116.0, 'micro avg_precision': 0.3626373626373626, 'micro avg_recall': 0.28448275862068967, 'micro avg_f1-score': 0.31884057971014496, 'micro avg_support': 116.0, 'macro avg_precision': 0.3626373626373626, 'macro avg_recall': 0.28448275862068967, 'macro avg_f1-score': 0.31884057971014496, 'macro avg_support': 116.0, 'weighted avg_precision': 0.3626373626373626, 'weighted avg_recall': 0.28448275862068967, 'weighted avg_f1-score': 0.31884057971014496, 'weighted avg_support': 116.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2938, 'epoch': 2}
{'results': [{'micro_f1': 0.820990681706719, 'precision': 0.820990681706719, 'Flag_Waving_precision': 0.15384615384615385, 'Flag_Waving_recall': 0.10526315789473684, 'Flag_Waving_f1-score': 0.125, 'Flag_Waving_support': 133.0, 'micro avg_precision': 0.15384615384615385, 'micro avg_recall': 0.10526315789473684, 'micro avg_f1-score': 0.125, 'micro avg_support': 133.0, 'macro avg_precision': 0.15384615384615385, 'macro avg_recall': 0.10526315789473684, 'macro avg_f1-score': 0.125, 'macro avg_support': 133.0, 'weighted avg_precision': 0.15384615384615385, 'weighted avg_recall': 0.10526315789473684, 'weighted avg_f1-score': 0.125, 'weighted avg_support': 133.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2938, 'epoch': 0}, {'micro_f1': 0.8523786169691026, 'precision': 0.8523786169691026, 'Flag_Waving_precision': 0.2087912087912088, 'Flag_Waving_recall': 0.16666666666666666, 'Flag_Waving_f1-score': 0.18536585365853658, 'Flag_Waving_support': 114.0, 'micro avg_precision': 0.2087912087912088, 'micro avg_recall': 0.16666666666666666, 'micro avg_f1-score': 0.18536585365853658, 'micro avg_support': 114.0, 'macro avg_precision': 0.2087912087912088, 'macro avg_recall': 0.16666666666666666, 'macro avg_f1-score': 0.18536585365853658, 'macro avg_support': 114.0, 'weighted avg_precision': 0.2087912087912088, 'weighted avg_recall': 0.16666666666666666, 'weighted avg_f1-score': 0.18536585365853658, 'weighted avg_support': 114.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2938, 'epoch': 1}, {'micro_f1': 0.8452672878862187, 'precision': 0.8452672878862187, 'Flag_Waving_precision': 0.3626373626373626, 'Flag_Waving_recall': 0.28448275862068967, 'Flag_Waving_f1-score': 0.31884057971014496, 'Flag_Waving_support': 116.0, 'micro avg_precision': 0.3626373626373626, 'micro avg_recall': 0.28448275862068967, 'micro avg_f1-score': 0.31884057971014496, 'micro avg_support': 116.0, 'macro avg_precision': 0.3626373626373626, 'macro avg_recall': 0.28448275862068967, 'macro avg_f1-score': 0.31884057971014496, 'macro avg_support': 116.0, 'weighted avg_precision': 0.3626373626373626, 'weighted avg_recall': 0.28448275862068967, 'weighted avg_f1-score': 0.31884057971014496, 'weighted avg_support': 116.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2938, 'epoch': 2}]}
Best model updated: current epoch macro f1 = 0.31884057971014496
{'micro_f1': 0.8271211378126533, 'precision': 0.8271211378126533, 'Flag_Waving_precision': 0.26373626373626374, 'Flag_Waving_recall': 0.2553191489361702, 'Flag_Waving_f1-score': 0.2594594594594594, 'Flag_Waving_support': 94.0, 'micro avg_precision': 0.26373626373626374, 'micro avg_recall': 0.2553191489361702, 'micro avg_f1-score': 0.2594594594594594, 'micro avg_support': 94.0, 'macro avg_precision': 0.26373626373626374, 'macro avg_recall': 0.2553191489361702, 'macro avg_f1-score': 0.2594594594594594, 'macro avg_support': 94.0, 'weighted avg_precision': 0.26373626373626374, 'weighted avg_recall': 0.2553191489361702, 'weighted avg_f1-score': 0.2594594594594594, 'weighted avg_support': 94.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2938, 'epoch': 3}
{'results': [{'micro_f1': 0.820990681706719, 'precision': 0.820990681706719, 'Flag_Waving_precision': 0.15384615384615385, 'Flag_Waving_recall': 0.10526315789473684, 'Flag_Waving_f1-score': 0.125, 'Flag_Waving_support': 133.0, 'micro avg_precision': 0.15384615384615385, 'micro avg_recall': 0.10526315789473684, 'micro avg_f1-score': 0.125, 'micro avg_support': 133.0, 'macro avg_precision': 0.15384615384615385, 'macro avg_recall': 0.10526315789473684, 'macro avg_f1-score': 0.125, 'macro avg_support': 133.0, 'weighted avg_precision': 0.15384615384615385, 'weighted avg_recall': 0.10526315789473684, 'weighted avg_f1-score': 0.125, 'weighted avg_support': 133.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2938, 'epoch': 0}, {'micro_f1': 0.8523786169691026, 'precision': 0.8523786169691026, 'Flag_Waving_precision': 0.2087912087912088, 'Flag_Waving_recall': 0.16666666666666666, 'Flag_Waving_f1-score': 0.18536585365853658, 'Flag_Waving_support': 114.0, 'micro avg_precision': 0.2087912087912088, 'micro avg_recall': 0.16666666666666666, 'micro avg_f1-score': 0.18536585365853658, 'micro avg_support': 114.0, 'macro avg_precision': 0.2087912087912088, 'macro avg_recall': 0.16666666666666666, 'macro avg_f1-score': 0.18536585365853658, 'macro avg_support': 114.0, 'weighted avg_precision': 0.2087912087912088, 'weighted avg_recall': 0.16666666666666666, 'weighted avg_f1-score': 0.18536585365853658, 'weighted avg_support': 114.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2938, 'epoch': 1}, {'micro_f1': 0.8452672878862187, 'precision': 0.8452672878862187, 'Flag_Waving_precision': 0.3626373626373626, 'Flag_Waving_recall': 0.28448275862068967, 'Flag_Waving_f1-score': 0.31884057971014496, 'Flag_Waving_support': 116.0, 'micro avg_precision': 0.3626373626373626, 'micro avg_recall': 0.28448275862068967, 'micro avg_f1-score': 0.31884057971014496, 'micro avg_support': 116.0, 'macro avg_precision': 0.3626373626373626, 'macro avg_recall': 0.28448275862068967, 'macro avg_f1-score': 0.31884057971014496, 'macro avg_support': 116.0, 'weighted avg_precision': 0.3626373626373626, 'weighted avg_recall': 0.28448275862068967, 'weighted avg_f1-score': 0.31884057971014496, 'weighted avg_support': 116.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2938, 'epoch': 2}, {'micro_f1': 0.8271211378126533, 'precision': 0.8271211378126533, 'Flag_Waving_precision': 0.26373626373626374, 'Flag_Waving_recall': 0.2553191489361702, 'Flag_Waving_f1-score': 0.2594594594594594, 'Flag_Waving_support': 94.0, 'micro avg_precision': 0.26373626373626374, 'micro avg_recall': 0.2553191489361702, 'micro avg_f1-score': 0.2594594594594594, 'micro avg_support': 94.0, 'macro avg_precision': 0.26373626373626374, 'macro avg_recall': 0.2553191489361702, 'macro avg_f1-score': 0.2594594594594594, 'macro avg_support': 94.0, 'weighted avg_precision': 0.26373626373626374, 'weighted avg_recall': 0.2553191489361702, 'weighted avg_f1-score': 0.2594594594594594, 'weighted avg_support': 94.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2938, 'epoch': 3}]}
{'micro_f1': 0.8376655223148602, 'precision': 0.8376655223148602, 'Flag_Waving_precision': 0.38461538461538464, 'Flag_Waving_recall': 0.25735294117647056, 'Flag_Waving_f1-score': 0.30837004405286345, 'Flag_Waving_support': 136.0, 'micro avg_precision': 0.38461538461538464, 'micro avg_recall': 0.25735294117647056, 'micro avg_f1-score': 0.30837004405286345, 'micro avg_support': 136.0, 'macro avg_precision': 0.38461538461538464, 'macro avg_recall': 0.25735294117647056, 'macro avg_f1-score': 0.30837004405286345, 'macro avg_support': 136.0, 'weighted avg_precision': 0.38461538461538464, 'weighted avg_recall': 0.25735294117647056, 'weighted avg_f1-score': 0.30837004405286345, 'weighted avg_support': 136.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2938, 'epoch': 4}
{'results': [{'micro_f1': 0.820990681706719, 'precision': 0.820990681706719, 'Flag_Waving_precision': 0.15384615384615385, 'Flag_Waving_recall': 0.10526315789473684, 'Flag_Waving_f1-score': 0.125, 'Flag_Waving_support': 133.0, 'micro avg_precision': 0.15384615384615385, 'micro avg_recall': 0.10526315789473684, 'micro avg_f1-score': 0.125, 'micro avg_support': 133.0, 'macro avg_precision': 0.15384615384615385, 'macro avg_recall': 0.10526315789473684, 'macro avg_f1-score': 0.125, 'macro avg_support': 133.0, 'weighted avg_precision': 0.15384615384615385, 'weighted avg_recall': 0.10526315789473684, 'weighted avg_f1-score': 0.125, 'weighted avg_support': 133.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2938, 'epoch': 0}, {'micro_f1': 0.8523786169691026, 'precision': 0.8523786169691026, 'Flag_Waving_precision': 0.2087912087912088, 'Flag_Waving_recall': 0.16666666666666666, 'Flag_Waving_f1-score': 0.18536585365853658, 'Flag_Waving_support': 114.0, 'micro avg_precision': 0.2087912087912088, 'micro avg_recall': 0.16666666666666666, 'micro avg_f1-score': 0.18536585365853658, 'micro avg_support': 114.0, 'macro avg_precision': 0.2087912087912088, 'macro avg_recall': 0.16666666666666666, 'macro avg_f1-score': 0.18536585365853658, 'macro avg_support': 114.0, 'weighted avg_precision': 0.2087912087912088, 'weighted avg_recall': 0.16666666666666666, 'weighted avg_f1-score': 0.18536585365853658, 'weighted avg_support': 114.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2938, 'epoch': 1}, {'micro_f1': 0.8452672878862187, 'precision': 0.8452672878862187, 'Flag_Waving_precision': 0.3626373626373626, 'Flag_Waving_recall': 0.28448275862068967, 'Flag_Waving_f1-score': 0.31884057971014496, 'Flag_Waving_support': 116.0, 'micro avg_precision': 0.3626373626373626, 'micro avg_recall': 0.28448275862068967, 'micro avg_f1-score': 0.31884057971014496, 'micro avg_support': 116.0, 'macro avg_precision': 0.3626373626373626, 'macro avg_recall': 0.28448275862068967, 'macro avg_f1-score': 0.31884057971014496, 'macro avg_support': 116.0, 'weighted avg_precision': 0.3626373626373626, 'weighted avg_recall': 0.28448275862068967, 'weighted avg_f1-score': 0.31884057971014496, 'weighted avg_support': 116.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2938, 'epoch': 2}, {'micro_f1': 0.8271211378126533, 'precision': 0.8271211378126533, 'Flag_Waving_precision': 0.26373626373626374, 'Flag_Waving_recall': 0.2553191489361702, 'Flag_Waving_f1-score': 0.2594594594594594, 'Flag_Waving_support': 94.0, 'micro avg_precision': 0.26373626373626374, 'micro avg_recall': 0.2553191489361702, 'micro avg_f1-score': 0.2594594594594594, 'micro avg_support': 94.0, 'macro avg_precision': 0.26373626373626374, 'macro avg_recall': 0.2553191489361702, 'macro avg_f1-score': 0.2594594594594594, 'macro avg_support': 94.0, 'weighted avg_precision': 0.26373626373626374, 'weighted avg_recall': 0.2553191489361702, 'weighted avg_f1-score': 0.2594594594594594, 'weighted avg_support': 94.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2938, 'epoch': 3}, {'micro_f1': 0.8376655223148602, 'precision': 0.8376655223148602, 'Flag_Waving_precision': 0.38461538461538464, 'Flag_Waving_recall': 0.25735294117647056, 'Flag_Waving_f1-score': 0.30837004405286345, 'Flag_Waving_support': 136.0, 'micro avg_precision': 0.38461538461538464, 'micro avg_recall': 0.25735294117647056, 'micro avg_f1-score': 0.30837004405286345, 'micro avg_support': 136.0, 'macro avg_precision': 0.38461538461538464, 'macro avg_recall': 0.25735294117647056, 'macro avg_f1-score': 0.30837004405286345, 'macro avg_support': 136.0, 'weighted avg_precision': 0.38461538461538464, 'weighted avg_recall': 0.25735294117647056, 'weighted avg_f1-score': 0.30837004405286345, 'weighted avg_support': 136.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2938, 'epoch': 4}]}
Early stopping triggered.
Saving model to directory: ./models/M2/2024-05-13-23-08-48_aug/mdeberta-v3-base_4_ME10_target=Flag_Waving_SUBSAMPLED_2024-05-13-23-08-48
Training model no. 5 of 23 for (5, 'Causal_Oversimplification') persuasion technique...
{'micro_f1': 0.7035360678925036, 'precision': 0.7035360678925036, 'Causal_Oversimplification_precision': 0.07954545454545454, 'Causal_Oversimplification_recall': 0.040697674418604654, 'Causal_Oversimplification_f1-score': 0.05384615384615385, 'Causal_Oversimplification_support': 172.0, 'micro avg_precision': 0.07954545454545454, 'micro avg_recall': 0.040697674418604654, 'micro avg_f1-score': 0.05384615384615385, 'micro avg_support': 172.0, 'macro avg_precision': 0.07954545454545454, 'macro avg_recall': 0.040697674418604654, 'macro avg_f1-score': 0.05384615384615385, 'macro avg_support': 172.0, 'weighted avg_precision': 0.07954545454545454, 'weighted avg_recall': 0.040697674418604654, 'weighted avg_f1-score': 0.05384615384615385, 'weighted avg_support': 172.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1561, 'epoch': 0}
{'results': [{'micro_f1': 0.7035360678925036, 'precision': 0.7035360678925036, 'Causal_Oversimplification_precision': 0.07954545454545454, 'Causal_Oversimplification_recall': 0.040697674418604654, 'Causal_Oversimplification_f1-score': 0.05384615384615385, 'Causal_Oversimplification_support': 172.0, 'micro avg_precision': 0.07954545454545454, 'micro avg_recall': 0.040697674418604654, 'micro avg_f1-score': 0.05384615384615385, 'micro avg_support': 172.0, 'macro avg_precision': 0.07954545454545454, 'macro avg_recall': 0.040697674418604654, 'macro avg_f1-score': 0.05384615384615385, 'macro avg_support': 172.0, 'weighted avg_precision': 0.07954545454545454, 'weighted avg_recall': 0.040697674418604654, 'weighted avg_f1-score': 0.05384615384615385, 'weighted avg_support': 172.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1561, 'epoch': 0}]}
Best model updated: current epoch macro f1 = 0.05384615384615385
{'micro_f1': 0.65997171145686, 'precision': 0.65997171145686, 'Causal_Oversimplification_precision': 0.07954545454545454, 'Causal_Oversimplification_recall': 0.06796116504854369, 'Causal_Oversimplification_f1-score': 0.07329842931937172, 'Causal_Oversimplification_support': 103.0, 'micro avg_precision': 0.07954545454545454, 'micro avg_recall': 0.06796116504854369, 'micro avg_f1-score': 0.07329842931937172, 'micro avg_support': 103.0, 'macro avg_precision': 0.07954545454545454, 'macro avg_recall': 0.06796116504854369, 'macro avg_f1-score': 0.07329842931937172, 'macro avg_support': 103.0, 'weighted avg_precision': 0.07954545454545454, 'weighted avg_recall': 0.06796116504854369, 'weighted avg_f1-score': 0.07329842931937172, 'weighted avg_support': 103.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1561, 'epoch': 1}
{'results': [{'micro_f1': 0.7035360678925036, 'precision': 0.7035360678925036, 'Causal_Oversimplification_precision': 0.07954545454545454, 'Causal_Oversimplification_recall': 0.040697674418604654, 'Causal_Oversimplification_f1-score': 0.05384615384615385, 'Causal_Oversimplification_support': 172.0, 'micro avg_precision': 0.07954545454545454, 'micro avg_recall': 0.040697674418604654, 'micro avg_f1-score': 0.05384615384615385, 'micro avg_support': 172.0, 'macro avg_precision': 0.07954545454545454, 'macro avg_recall': 0.040697674418604654, 'macro avg_f1-score': 0.05384615384615385, 'macro avg_support': 172.0, 'weighted avg_precision': 0.07954545454545454, 'weighted avg_recall': 0.040697674418604654, 'weighted avg_f1-score': 0.05384615384615385, 'weighted avg_support': 172.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1561, 'epoch': 0}, {'micro_f1': 0.65997171145686, 'precision': 0.65997171145686, 'Causal_Oversimplification_precision': 0.07954545454545454, 'Causal_Oversimplification_recall': 0.06796116504854369, 'Causal_Oversimplification_f1-score': 0.07329842931937172, 'Causal_Oversimplification_support': 103.0, 'micro avg_precision': 0.07954545454545454, 'micro avg_recall': 0.06796116504854369, 'micro avg_f1-score': 0.07329842931937172, 'micro avg_support': 103.0, 'macro avg_precision': 0.07954545454545454, 'macro avg_recall': 0.06796116504854369, 'macro avg_f1-score': 0.07329842931937172, 'macro avg_support': 103.0, 'weighted avg_precision': 0.07954545454545454, 'weighted avg_recall': 0.06796116504854369, 'weighted avg_f1-score': 0.07329842931937172, 'weighted avg_support': 103.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1561, 'epoch': 1}]}
Best model updated: current epoch macro f1 = 0.07329842931937172
{'micro_f1': 0.8144271570014144, 'precision': 0.8144271570014144, 'Causal_Oversimplification_precision': 0.36363636363636365, 'Causal_Oversimplification_recall': 0.22377622377622378, 'Causal_Oversimplification_f1-score': 0.27705627705627706, 'Causal_Oversimplification_support': 143.0, 'micro avg_precision': 0.36363636363636365, 'micro avg_recall': 0.22377622377622378, 'micro avg_f1-score': 0.27705627705627706, 'micro avg_support': 143.0, 'macro avg_precision': 0.36363636363636365, 'macro avg_recall': 0.22377622377622378, 'macro avg_f1-score': 0.27705627705627706, 'macro avg_support': 143.0, 'weighted avg_precision': 0.36363636363636365, 'weighted avg_recall': 0.22377622377622378, 'weighted avg_f1-score': 0.27705627705627706, 'weighted avg_support': 143.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1561, 'epoch': 2}
{'results': [{'micro_f1': 0.7035360678925036, 'precision': 0.7035360678925036, 'Causal_Oversimplification_precision': 0.07954545454545454, 'Causal_Oversimplification_recall': 0.040697674418604654, 'Causal_Oversimplification_f1-score': 0.05384615384615385, 'Causal_Oversimplification_support': 172.0, 'micro avg_precision': 0.07954545454545454, 'micro avg_recall': 0.040697674418604654, 'micro avg_f1-score': 0.05384615384615385, 'micro avg_support': 172.0, 'macro avg_precision': 0.07954545454545454, 'macro avg_recall': 0.040697674418604654, 'macro avg_f1-score': 0.05384615384615385, 'macro avg_support': 172.0, 'weighted avg_precision': 0.07954545454545454, 'weighted avg_recall': 0.040697674418604654, 'weighted avg_f1-score': 0.05384615384615385, 'weighted avg_support': 172.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1561, 'epoch': 0}, {'micro_f1': 0.65997171145686, 'precision': 0.65997171145686, 'Causal_Oversimplification_precision': 0.07954545454545454, 'Causal_Oversimplification_recall': 0.06796116504854369, 'Causal_Oversimplification_f1-score': 0.07329842931937172, 'Causal_Oversimplification_support': 103.0, 'micro avg_precision': 0.07954545454545454, 'micro avg_recall': 0.06796116504854369, 'micro avg_f1-score': 0.07329842931937172, 'micro avg_support': 103.0, 'macro avg_precision': 0.07954545454545454, 'macro avg_recall': 0.06796116504854369, 'macro avg_f1-score': 0.07329842931937172, 'macro avg_support': 103.0, 'weighted avg_precision': 0.07954545454545454, 'weighted avg_recall': 0.06796116504854369, 'weighted avg_f1-score': 0.07329842931937172, 'weighted avg_support': 103.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1561, 'epoch': 1}, {'micro_f1': 0.8144271570014144, 'precision': 0.8144271570014144, 'Causal_Oversimplification_precision': 0.36363636363636365, 'Causal_Oversimplification_recall': 0.22377622377622378, 'Causal_Oversimplification_f1-score': 0.27705627705627706, 'Causal_Oversimplification_support': 143.0, 'micro avg_precision': 0.36363636363636365, 'micro avg_recall': 0.22377622377622378, 'micro avg_f1-score': 0.27705627705627706, 'micro avg_support': 143.0, 'macro avg_precision': 0.36363636363636365, 'macro avg_recall': 0.22377622377622378, 'macro avg_f1-score': 0.27705627705627706, 'macro avg_support': 143.0, 'weighted avg_precision': 0.36363636363636365, 'weighted avg_recall': 0.22377622377622378, 'weighted avg_f1-score': 0.27705627705627706, 'weighted avg_support': 143.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1561, 'epoch': 2}]}
Best model updated: current epoch macro f1 = 0.27705627705627706
{'micro_f1': 0.8087694483734088, 'precision': 0.8087694483734088, 'Causal_Oversimplification_precision': 0.375, 'Causal_Oversimplification_recall': 0.3113207547169811, 'Causal_Oversimplification_f1-score': 0.34020618556701027, 'Causal_Oversimplification_support': 106.0, 'micro avg_precision': 0.375, 'micro avg_recall': 0.3113207547169811, 'micro avg_f1-score': 0.34020618556701027, 'micro avg_support': 106.0, 'macro avg_precision': 0.375, 'macro avg_recall': 0.3113207547169811, 'macro avg_f1-score': 0.34020618556701027, 'macro avg_support': 106.0, 'weighted avg_precision': 0.375, 'weighted avg_recall': 0.3113207547169811, 'weighted avg_f1-score': 0.34020618556701027, 'weighted avg_support': 106.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1561, 'epoch': 3}
{'results': [{'micro_f1': 0.7035360678925036, 'precision': 0.7035360678925036, 'Causal_Oversimplification_precision': 0.07954545454545454, 'Causal_Oversimplification_recall': 0.040697674418604654, 'Causal_Oversimplification_f1-score': 0.05384615384615385, 'Causal_Oversimplification_support': 172.0, 'micro avg_precision': 0.07954545454545454, 'micro avg_recall': 0.040697674418604654, 'micro avg_f1-score': 0.05384615384615385, 'micro avg_support': 172.0, 'macro avg_precision': 0.07954545454545454, 'macro avg_recall': 0.040697674418604654, 'macro avg_f1-score': 0.05384615384615385, 'macro avg_support': 172.0, 'weighted avg_precision': 0.07954545454545454, 'weighted avg_recall': 0.040697674418604654, 'weighted avg_f1-score': 0.05384615384615385, 'weighted avg_support': 172.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1561, 'epoch': 0}, {'micro_f1': 0.65997171145686, 'precision': 0.65997171145686, 'Causal_Oversimplification_precision': 0.07954545454545454, 'Causal_Oversimplification_recall': 0.06796116504854369, 'Causal_Oversimplification_f1-score': 0.07329842931937172, 'Causal_Oversimplification_support': 103.0, 'micro avg_precision': 0.07954545454545454, 'micro avg_recall': 0.06796116504854369, 'micro avg_f1-score': 0.07329842931937172, 'micro avg_support': 103.0, 'macro avg_precision': 0.07954545454545454, 'macro avg_recall': 0.06796116504854369, 'macro avg_f1-score': 0.07329842931937172, 'macro avg_support': 103.0, 'weighted avg_precision': 0.07954545454545454, 'weighted avg_recall': 0.06796116504854369, 'weighted avg_f1-score': 0.07329842931937172, 'weighted avg_support': 103.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1561, 'epoch': 1}, {'micro_f1': 0.8144271570014144, 'precision': 0.8144271570014144, 'Causal_Oversimplification_precision': 0.36363636363636365, 'Causal_Oversimplification_recall': 0.22377622377622378, 'Causal_Oversimplification_f1-score': 0.27705627705627706, 'Causal_Oversimplification_support': 143.0, 'micro avg_precision': 0.36363636363636365, 'micro avg_recall': 0.22377622377622378, 'micro avg_f1-score': 0.27705627705627706, 'micro avg_support': 143.0, 'macro avg_precision': 0.36363636363636365, 'macro avg_recall': 0.22377622377622378, 'macro avg_f1-score': 0.27705627705627706, 'macro avg_support': 143.0, 'weighted avg_precision': 0.36363636363636365, 'weighted avg_recall': 0.22377622377622378, 'weighted avg_f1-score': 0.27705627705627706, 'weighted avg_support': 143.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1561, 'epoch': 2}, {'micro_f1': 0.8087694483734088, 'precision': 0.8087694483734088, 'Causal_Oversimplification_precision': 0.375, 'Causal_Oversimplification_recall': 0.3113207547169811, 'Causal_Oversimplification_f1-score': 0.34020618556701027, 'Causal_Oversimplification_support': 106.0, 'micro avg_precision': 0.375, 'micro avg_recall': 0.3113207547169811, 'micro avg_f1-score': 0.34020618556701027, 'micro avg_support': 106.0, 'macro avg_precision': 0.375, 'macro avg_recall': 0.3113207547169811, 'macro avg_f1-score': 0.34020618556701027, 'macro avg_support': 106.0, 'weighted avg_precision': 0.375, 'weighted avg_recall': 0.3113207547169811, 'weighted avg_f1-score': 0.34020618556701027, 'weighted avg_support': 106.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1561, 'epoch': 3}]}
Best model updated: current epoch macro f1 = 0.34020618556701027
{'micro_f1': 0.8132956152758133, 'precision': 0.8132956152758133, 'Causal_Oversimplification_precision': 0.4772727272727273, 'Causal_Oversimplification_recall': 0.375, 'Causal_Oversimplification_f1-score': 0.42, 'Causal_Oversimplification_support': 112.0, 'micro avg_precision': 0.4772727272727273, 'micro avg_recall': 0.375, 'micro avg_f1-score': 0.42, 'micro avg_support': 112.0, 'macro avg_precision': 0.4772727272727273, 'macro avg_recall': 0.375, 'macro avg_f1-score': 0.42, 'macro avg_support': 112.0, 'weighted avg_precision': 0.47727272727272724, 'weighted avg_recall': 0.375, 'weighted avg_f1-score': 0.42, 'weighted avg_support': 112.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1561, 'epoch': 4}
{'results': [{'micro_f1': 0.7035360678925036, 'precision': 0.7035360678925036, 'Causal_Oversimplification_precision': 0.07954545454545454, 'Causal_Oversimplification_recall': 0.040697674418604654, 'Causal_Oversimplification_f1-score': 0.05384615384615385, 'Causal_Oversimplification_support': 172.0, 'micro avg_precision': 0.07954545454545454, 'micro avg_recall': 0.040697674418604654, 'micro avg_f1-score': 0.05384615384615385, 'micro avg_support': 172.0, 'macro avg_precision': 0.07954545454545454, 'macro avg_recall': 0.040697674418604654, 'macro avg_f1-score': 0.05384615384615385, 'macro avg_support': 172.0, 'weighted avg_precision': 0.07954545454545454, 'weighted avg_recall': 0.040697674418604654, 'weighted avg_f1-score': 0.05384615384615385, 'weighted avg_support': 172.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1561, 'epoch': 0}, {'micro_f1': 0.65997171145686, 'precision': 0.65997171145686, 'Causal_Oversimplification_precision': 0.07954545454545454, 'Causal_Oversimplification_recall': 0.06796116504854369, 'Causal_Oversimplification_f1-score': 0.07329842931937172, 'Causal_Oversimplification_support': 103.0, 'micro avg_precision': 0.07954545454545454, 'micro avg_recall': 0.06796116504854369, 'micro avg_f1-score': 0.07329842931937172, 'micro avg_support': 103.0, 'macro avg_precision': 0.07954545454545454, 'macro avg_recall': 0.06796116504854369, 'macro avg_f1-score': 0.07329842931937172, 'macro avg_support': 103.0, 'weighted avg_precision': 0.07954545454545454, 'weighted avg_recall': 0.06796116504854369, 'weighted avg_f1-score': 0.07329842931937172, 'weighted avg_support': 103.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1561, 'epoch': 1}, {'micro_f1': 0.8144271570014144, 'precision': 0.8144271570014144, 'Causal_Oversimplification_precision': 0.36363636363636365, 'Causal_Oversimplification_recall': 0.22377622377622378, 'Causal_Oversimplification_f1-score': 0.27705627705627706, 'Causal_Oversimplification_support': 143.0, 'micro avg_precision': 0.36363636363636365, 'micro avg_recall': 0.22377622377622378, 'micro avg_f1-score': 0.27705627705627706, 'micro avg_support': 143.0, 'macro avg_precision': 0.36363636363636365, 'macro avg_recall': 0.22377622377622378, 'macro avg_f1-score': 0.27705627705627706, 'macro avg_support': 143.0, 'weighted avg_precision': 0.36363636363636365, 'weighted avg_recall': 0.22377622377622378, 'weighted avg_f1-score': 0.27705627705627706, 'weighted avg_support': 143.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1561, 'epoch': 2}, {'micro_f1': 0.8087694483734088, 'precision': 0.8087694483734088, 'Causal_Oversimplification_precision': 0.375, 'Causal_Oversimplification_recall': 0.3113207547169811, 'Causal_Oversimplification_f1-score': 0.34020618556701027, 'Causal_Oversimplification_support': 106.0, 'micro avg_precision': 0.375, 'micro avg_recall': 0.3113207547169811, 'micro avg_f1-score': 0.34020618556701027, 'micro avg_support': 106.0, 'macro avg_precision': 0.375, 'macro avg_recall': 0.3113207547169811, 'macro avg_f1-score': 0.34020618556701027, 'macro avg_support': 106.0, 'weighted avg_precision': 0.375, 'weighted avg_recall': 0.3113207547169811, 'weighted avg_f1-score': 0.34020618556701027, 'weighted avg_support': 106.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1561, 'epoch': 3}, {'micro_f1': 0.8132956152758133, 'precision': 0.8132956152758133, 'Causal_Oversimplification_precision': 0.4772727272727273, 'Causal_Oversimplification_recall': 0.375, 'Causal_Oversimplification_f1-score': 0.42, 'Causal_Oversimplification_support': 112.0, 'micro avg_precision': 0.4772727272727273, 'micro avg_recall': 0.375, 'micro avg_f1-score': 0.42, 'micro avg_support': 112.0, 'macro avg_precision': 0.4772727272727273, 'macro avg_recall': 0.375, 'macro avg_f1-score': 0.42, 'macro avg_support': 112.0, 'weighted avg_precision': 0.47727272727272724, 'weighted avg_recall': 0.375, 'weighted avg_f1-score': 0.42, 'weighted avg_support': 112.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1561, 'epoch': 4}]}
Best model updated: current epoch macro f1 = 0.42
{'micro_f1': 0.8387553041018387, 'precision': 0.8387553041018387, 'Causal_Oversimplification_precision': 0.48863636363636365, 'Causal_Oversimplification_recall': 0.3706896551724138, 'Causal_Oversimplification_f1-score': 0.42156862745098045, 'Causal_Oversimplification_support': 116.0, 'micro avg_precision': 0.48863636363636365, 'micro avg_recall': 0.3706896551724138, 'micro avg_f1-score': 0.42156862745098045, 'micro avg_support': 116.0, 'macro avg_precision': 0.48863636363636365, 'macro avg_recall': 0.3706896551724138, 'macro avg_f1-score': 0.42156862745098045, 'macro avg_support': 116.0, 'weighted avg_precision': 0.48863636363636365, 'weighted avg_recall': 0.3706896551724138, 'weighted avg_f1-score': 0.42156862745098045, 'weighted avg_support': 116.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1561, 'epoch': 5}
{'results': [{'micro_f1': 0.7035360678925036, 'precision': 0.7035360678925036, 'Causal_Oversimplification_precision': 0.07954545454545454, 'Causal_Oversimplification_recall': 0.040697674418604654, 'Causal_Oversimplification_f1-score': 0.05384615384615385, 'Causal_Oversimplification_support': 172.0, 'micro avg_precision': 0.07954545454545454, 'micro avg_recall': 0.040697674418604654, 'micro avg_f1-score': 0.05384615384615385, 'micro avg_support': 172.0, 'macro avg_precision': 0.07954545454545454, 'macro avg_recall': 0.040697674418604654, 'macro avg_f1-score': 0.05384615384615385, 'macro avg_support': 172.0, 'weighted avg_precision': 0.07954545454545454, 'weighted avg_recall': 0.040697674418604654, 'weighted avg_f1-score': 0.05384615384615385, 'weighted avg_support': 172.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1561, 'epoch': 0}, {'micro_f1': 0.65997171145686, 'precision': 0.65997171145686, 'Causal_Oversimplification_precision': 0.07954545454545454, 'Causal_Oversimplification_recall': 0.06796116504854369, 'Causal_Oversimplification_f1-score': 0.07329842931937172, 'Causal_Oversimplification_support': 103.0, 'micro avg_precision': 0.07954545454545454, 'micro avg_recall': 0.06796116504854369, 'micro avg_f1-score': 0.07329842931937172, 'micro avg_support': 103.0, 'macro avg_precision': 0.07954545454545454, 'macro avg_recall': 0.06796116504854369, 'macro avg_f1-score': 0.07329842931937172, 'macro avg_support': 103.0, 'weighted avg_precision': 0.07954545454545454, 'weighted avg_recall': 0.06796116504854369, 'weighted avg_f1-score': 0.07329842931937172, 'weighted avg_support': 103.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1561, 'epoch': 1}, {'micro_f1': 0.8144271570014144, 'precision': 0.8144271570014144, 'Causal_Oversimplification_precision': 0.36363636363636365, 'Causal_Oversimplification_recall': 0.22377622377622378, 'Causal_Oversimplification_f1-score': 0.27705627705627706, 'Causal_Oversimplification_support': 143.0, 'micro avg_precision': 0.36363636363636365, 'micro avg_recall': 0.22377622377622378, 'micro avg_f1-score': 0.27705627705627706, 'micro avg_support': 143.0, 'macro avg_precision': 0.36363636363636365, 'macro avg_recall': 0.22377622377622378, 'macro avg_f1-score': 0.27705627705627706, 'macro avg_support': 143.0, 'weighted avg_precision': 0.36363636363636365, 'weighted avg_recall': 0.22377622377622378, 'weighted avg_f1-score': 0.27705627705627706, 'weighted avg_support': 143.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1561, 'epoch': 2}, {'micro_f1': 0.8087694483734088, 'precision': 0.8087694483734088, 'Causal_Oversimplification_precision': 0.375, 'Causal_Oversimplification_recall': 0.3113207547169811, 'Causal_Oversimplification_f1-score': 0.34020618556701027, 'Causal_Oversimplification_support': 106.0, 'micro avg_precision': 0.375, 'micro avg_recall': 0.3113207547169811, 'micro avg_f1-score': 0.34020618556701027, 'micro avg_support': 106.0, 'macro avg_precision': 0.375, 'macro avg_recall': 0.3113207547169811, 'macro avg_f1-score': 0.34020618556701027, 'macro avg_support': 106.0, 'weighted avg_precision': 0.375, 'weighted avg_recall': 0.3113207547169811, 'weighted avg_f1-score': 0.34020618556701027, 'weighted avg_support': 106.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1561, 'epoch': 3}, {'micro_f1': 0.8132956152758133, 'precision': 0.8132956152758133, 'Causal_Oversimplification_precision': 0.4772727272727273, 'Causal_Oversimplification_recall': 0.375, 'Causal_Oversimplification_f1-score': 0.42, 'Causal_Oversimplification_support': 112.0, 'micro avg_precision': 0.4772727272727273, 'micro avg_recall': 0.375, 'micro avg_f1-score': 0.42, 'micro avg_support': 112.0, 'macro avg_precision': 0.4772727272727273, 'macro avg_recall': 0.375, 'macro avg_f1-score': 0.42, 'macro avg_support': 112.0, 'weighted avg_precision': 0.47727272727272724, 'weighted avg_recall': 0.375, 'weighted avg_f1-score': 0.42, 'weighted avg_support': 112.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1561, 'epoch': 4}, {'micro_f1': 0.8387553041018387, 'precision': 0.8387553041018387, 'Causal_Oversimplification_precision': 0.48863636363636365, 'Causal_Oversimplification_recall': 0.3706896551724138, 'Causal_Oversimplification_f1-score': 0.42156862745098045, 'Causal_Oversimplification_support': 116.0, 'micro avg_precision': 0.48863636363636365, 'micro avg_recall': 0.3706896551724138, 'micro avg_f1-score': 0.42156862745098045, 'micro avg_support': 116.0, 'macro avg_precision': 0.48863636363636365, 'macro avg_recall': 0.3706896551724138, 'macro avg_f1-score': 0.42156862745098045, 'macro avg_support': 116.0, 'weighted avg_precision': 0.48863636363636365, 'weighted avg_recall': 0.3706896551724138, 'weighted avg_f1-score': 0.42156862745098045, 'weighted avg_support': 116.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1561, 'epoch': 5}]}
Best model updated: current epoch macro f1 = 0.42156862745098045
{'micro_f1': 0.8353606789250354, 'precision': 0.8353606789250354, 'Causal_Oversimplification_precision': 0.48863636363636365, 'Causal_Oversimplification_recall': 0.33076923076923076, 'Causal_Oversimplification_f1-score': 0.39449541284403666, 'Causal_Oversimplification_support': 130.0, 'micro avg_precision': 0.48863636363636365, 'micro avg_recall': 0.33076923076923076, 'micro avg_f1-score': 0.39449541284403666, 'micro avg_support': 130.0, 'macro avg_precision': 0.48863636363636365, 'macro avg_recall': 0.33076923076923076, 'macro avg_f1-score': 0.39449541284403666, 'macro avg_support': 130.0, 'weighted avg_precision': 0.48863636363636365, 'weighted avg_recall': 0.33076923076923076, 'weighted avg_f1-score': 0.39449541284403666, 'weighted avg_support': 130.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1561, 'epoch': 6}
{'results': [{'micro_f1': 0.7035360678925036, 'precision': 0.7035360678925036, 'Causal_Oversimplification_precision': 0.07954545454545454, 'Causal_Oversimplification_recall': 0.040697674418604654, 'Causal_Oversimplification_f1-score': 0.05384615384615385, 'Causal_Oversimplification_support': 172.0, 'micro avg_precision': 0.07954545454545454, 'micro avg_recall': 0.040697674418604654, 'micro avg_f1-score': 0.05384615384615385, 'micro avg_support': 172.0, 'macro avg_precision': 0.07954545454545454, 'macro avg_recall': 0.040697674418604654, 'macro avg_f1-score': 0.05384615384615385, 'macro avg_support': 172.0, 'weighted avg_precision': 0.07954545454545454, 'weighted avg_recall': 0.040697674418604654, 'weighted avg_f1-score': 0.05384615384615385, 'weighted avg_support': 172.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1561, 'epoch': 0}, {'micro_f1': 0.65997171145686, 'precision': 0.65997171145686, 'Causal_Oversimplification_precision': 0.07954545454545454, 'Causal_Oversimplification_recall': 0.06796116504854369, 'Causal_Oversimplification_f1-score': 0.07329842931937172, 'Causal_Oversimplification_support': 103.0, 'micro avg_precision': 0.07954545454545454, 'micro avg_recall': 0.06796116504854369, 'micro avg_f1-score': 0.07329842931937172, 'micro avg_support': 103.0, 'macro avg_precision': 0.07954545454545454, 'macro avg_recall': 0.06796116504854369, 'macro avg_f1-score': 0.07329842931937172, 'macro avg_support': 103.0, 'weighted avg_precision': 0.07954545454545454, 'weighted avg_recall': 0.06796116504854369, 'weighted avg_f1-score': 0.07329842931937172, 'weighted avg_support': 103.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1561, 'epoch': 1}, {'micro_f1': 0.8144271570014144, 'precision': 0.8144271570014144, 'Causal_Oversimplification_precision': 0.36363636363636365, 'Causal_Oversimplification_recall': 0.22377622377622378, 'Causal_Oversimplification_f1-score': 0.27705627705627706, 'Causal_Oversimplification_support': 143.0, 'micro avg_precision': 0.36363636363636365, 'micro avg_recall': 0.22377622377622378, 'micro avg_f1-score': 0.27705627705627706, 'micro avg_support': 143.0, 'macro avg_precision': 0.36363636363636365, 'macro avg_recall': 0.22377622377622378, 'macro avg_f1-score': 0.27705627705627706, 'macro avg_support': 143.0, 'weighted avg_precision': 0.36363636363636365, 'weighted avg_recall': 0.22377622377622378, 'weighted avg_f1-score': 0.27705627705627706, 'weighted avg_support': 143.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1561, 'epoch': 2}, {'micro_f1': 0.8087694483734088, 'precision': 0.8087694483734088, 'Causal_Oversimplification_precision': 0.375, 'Causal_Oversimplification_recall': 0.3113207547169811, 'Causal_Oversimplification_f1-score': 0.34020618556701027, 'Causal_Oversimplification_support': 106.0, 'micro avg_precision': 0.375, 'micro avg_recall': 0.3113207547169811, 'micro avg_f1-score': 0.34020618556701027, 'micro avg_support': 106.0, 'macro avg_precision': 0.375, 'macro avg_recall': 0.3113207547169811, 'macro avg_f1-score': 0.34020618556701027, 'macro avg_support': 106.0, 'weighted avg_precision': 0.375, 'weighted avg_recall': 0.3113207547169811, 'weighted avg_f1-score': 0.34020618556701027, 'weighted avg_support': 106.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1561, 'epoch': 3}, {'micro_f1': 0.8132956152758133, 'precision': 0.8132956152758133, 'Causal_Oversimplification_precision': 0.4772727272727273, 'Causal_Oversimplification_recall': 0.375, 'Causal_Oversimplification_f1-score': 0.42, 'Causal_Oversimplification_support': 112.0, 'micro avg_precision': 0.4772727272727273, 'micro avg_recall': 0.375, 'micro avg_f1-score': 0.42, 'micro avg_support': 112.0, 'macro avg_precision': 0.4772727272727273, 'macro avg_recall': 0.375, 'macro avg_f1-score': 0.42, 'macro avg_support': 112.0, 'weighted avg_precision': 0.47727272727272724, 'weighted avg_recall': 0.375, 'weighted avg_f1-score': 0.42, 'weighted avg_support': 112.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1561, 'epoch': 4}, {'micro_f1': 0.8387553041018387, 'precision': 0.8387553041018387, 'Causal_Oversimplification_precision': 0.48863636363636365, 'Causal_Oversimplification_recall': 0.3706896551724138, 'Causal_Oversimplification_f1-score': 0.42156862745098045, 'Causal_Oversimplification_support': 116.0, 'micro avg_precision': 0.48863636363636365, 'micro avg_recall': 0.3706896551724138, 'micro avg_f1-score': 0.42156862745098045, 'micro avg_support': 116.0, 'macro avg_precision': 0.48863636363636365, 'macro avg_recall': 0.3706896551724138, 'macro avg_f1-score': 0.42156862745098045, 'macro avg_support': 116.0, 'weighted avg_precision': 0.48863636363636365, 'weighted avg_recall': 0.3706896551724138, 'weighted avg_f1-score': 0.42156862745098045, 'weighted avg_support': 116.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1561, 'epoch': 5}, {'micro_f1': 0.8353606789250354, 'precision': 0.8353606789250354, 'Causal_Oversimplification_precision': 0.48863636363636365, 'Causal_Oversimplification_recall': 0.33076923076923076, 'Causal_Oversimplification_f1-score': 0.39449541284403666, 'Causal_Oversimplification_support': 130.0, 'micro avg_precision': 0.48863636363636365, 'micro avg_recall': 0.33076923076923076, 'micro avg_f1-score': 0.39449541284403666, 'micro avg_support': 130.0, 'macro avg_precision': 0.48863636363636365, 'macro avg_recall': 0.33076923076923076, 'macro avg_f1-score': 0.39449541284403666, 'macro avg_support': 130.0, 'weighted avg_precision': 0.48863636363636365, 'weighted avg_recall': 0.33076923076923076, 'weighted avg_f1-score': 0.39449541284403666, 'weighted avg_support': 130.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1561, 'epoch': 6}]}
{'micro_f1': 0.813012729844413, 'precision': 0.813012729844413, 'Causal_Oversimplification_precision': 0.5, 'Causal_Oversimplification_recall': 0.32116788321167883, 'Causal_Oversimplification_f1-score': 0.3911111111111111, 'Causal_Oversimplification_support': 137.0, 'micro avg_precision': 0.5, 'micro avg_recall': 0.32116788321167883, 'micro avg_f1-score': 0.3911111111111111, 'micro avg_support': 137.0, 'macro avg_precision': 0.5, 'macro avg_recall': 0.32116788321167883, 'macro avg_f1-score': 0.3911111111111111, 'macro avg_support': 137.0, 'weighted avg_precision': 0.5, 'weighted avg_recall': 0.32116788321167883, 'weighted avg_f1-score': 0.3911111111111111, 'weighted avg_support': 137.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1561, 'epoch': 7}
{'results': [{'micro_f1': 0.7035360678925036, 'precision': 0.7035360678925036, 'Causal_Oversimplification_precision': 0.07954545454545454, 'Causal_Oversimplification_recall': 0.040697674418604654, 'Causal_Oversimplification_f1-score': 0.05384615384615385, 'Causal_Oversimplification_support': 172.0, 'micro avg_precision': 0.07954545454545454, 'micro avg_recall': 0.040697674418604654, 'micro avg_f1-score': 0.05384615384615385, 'micro avg_support': 172.0, 'macro avg_precision': 0.07954545454545454, 'macro avg_recall': 0.040697674418604654, 'macro avg_f1-score': 0.05384615384615385, 'macro avg_support': 172.0, 'weighted avg_precision': 0.07954545454545454, 'weighted avg_recall': 0.040697674418604654, 'weighted avg_f1-score': 0.05384615384615385, 'weighted avg_support': 172.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1561, 'epoch': 0}, {'micro_f1': 0.65997171145686, 'precision': 0.65997171145686, 'Causal_Oversimplification_precision': 0.07954545454545454, 'Causal_Oversimplification_recall': 0.06796116504854369, 'Causal_Oversimplification_f1-score': 0.07329842931937172, 'Causal_Oversimplification_support': 103.0, 'micro avg_precision': 0.07954545454545454, 'micro avg_recall': 0.06796116504854369, 'micro avg_f1-score': 0.07329842931937172, 'micro avg_support': 103.0, 'macro avg_precision': 0.07954545454545454, 'macro avg_recall': 0.06796116504854369, 'macro avg_f1-score': 0.07329842931937172, 'macro avg_support': 103.0, 'weighted avg_precision': 0.07954545454545454, 'weighted avg_recall': 0.06796116504854369, 'weighted avg_f1-score': 0.07329842931937172, 'weighted avg_support': 103.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1561, 'epoch': 1}, {'micro_f1': 0.8144271570014144, 'precision': 0.8144271570014144, 'Causal_Oversimplification_precision': 0.36363636363636365, 'Causal_Oversimplification_recall': 0.22377622377622378, 'Causal_Oversimplification_f1-score': 0.27705627705627706, 'Causal_Oversimplification_support': 143.0, 'micro avg_precision': 0.36363636363636365, 'micro avg_recall': 0.22377622377622378, 'micro avg_f1-score': 0.27705627705627706, 'micro avg_support': 143.0, 'macro avg_precision': 0.36363636363636365, 'macro avg_recall': 0.22377622377622378, 'macro avg_f1-score': 0.27705627705627706, 'macro avg_support': 143.0, 'weighted avg_precision': 0.36363636363636365, 'weighted avg_recall': 0.22377622377622378, 'weighted avg_f1-score': 0.27705627705627706, 'weighted avg_support': 143.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1561, 'epoch': 2}, {'micro_f1': 0.8087694483734088, 'precision': 0.8087694483734088, 'Causal_Oversimplification_precision': 0.375, 'Causal_Oversimplification_recall': 0.3113207547169811, 'Causal_Oversimplification_f1-score': 0.34020618556701027, 'Causal_Oversimplification_support': 106.0, 'micro avg_precision': 0.375, 'micro avg_recall': 0.3113207547169811, 'micro avg_f1-score': 0.34020618556701027, 'micro avg_support': 106.0, 'macro avg_precision': 0.375, 'macro avg_recall': 0.3113207547169811, 'macro avg_f1-score': 0.34020618556701027, 'macro avg_support': 106.0, 'weighted avg_precision': 0.375, 'weighted avg_recall': 0.3113207547169811, 'weighted avg_f1-score': 0.34020618556701027, 'weighted avg_support': 106.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1561, 'epoch': 3}, {'micro_f1': 0.8132956152758133, 'precision': 0.8132956152758133, 'Causal_Oversimplification_precision': 0.4772727272727273, 'Causal_Oversimplification_recall': 0.375, 'Causal_Oversimplification_f1-score': 0.42, 'Causal_Oversimplification_support': 112.0, 'micro avg_precision': 0.4772727272727273, 'micro avg_recall': 0.375, 'micro avg_f1-score': 0.42, 'micro avg_support': 112.0, 'macro avg_precision': 0.4772727272727273, 'macro avg_recall': 0.375, 'macro avg_f1-score': 0.42, 'macro avg_support': 112.0, 'weighted avg_precision': 0.47727272727272724, 'weighted avg_recall': 0.375, 'weighted avg_f1-score': 0.42, 'weighted avg_support': 112.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1561, 'epoch': 4}, {'micro_f1': 0.8387553041018387, 'precision': 0.8387553041018387, 'Causal_Oversimplification_precision': 0.48863636363636365, 'Causal_Oversimplification_recall': 0.3706896551724138, 'Causal_Oversimplification_f1-score': 0.42156862745098045, 'Causal_Oversimplification_support': 116.0, 'micro avg_precision': 0.48863636363636365, 'micro avg_recall': 0.3706896551724138, 'micro avg_f1-score': 0.42156862745098045, 'micro avg_support': 116.0, 'macro avg_precision': 0.48863636363636365, 'macro avg_recall': 0.3706896551724138, 'macro avg_f1-score': 0.42156862745098045, 'macro avg_support': 116.0, 'weighted avg_precision': 0.48863636363636365, 'weighted avg_recall': 0.3706896551724138, 'weighted avg_f1-score': 0.42156862745098045, 'weighted avg_support': 116.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1561, 'epoch': 5}, {'micro_f1': 0.8353606789250354, 'precision': 0.8353606789250354, 'Causal_Oversimplification_precision': 0.48863636363636365, 'Causal_Oversimplification_recall': 0.33076923076923076, 'Causal_Oversimplification_f1-score': 0.39449541284403666, 'Causal_Oversimplification_support': 130.0, 'micro avg_precision': 0.48863636363636365, 'micro avg_recall': 0.33076923076923076, 'micro avg_f1-score': 0.39449541284403666, 'micro avg_support': 130.0, 'macro avg_precision': 0.48863636363636365, 'macro avg_recall': 0.33076923076923076, 'macro avg_f1-score': 0.39449541284403666, 'macro avg_support': 130.0, 'weighted avg_precision': 0.48863636363636365, 'weighted avg_recall': 0.33076923076923076, 'weighted avg_f1-score': 0.39449541284403666, 'weighted avg_support': 130.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1561, 'epoch': 6}, {'micro_f1': 0.813012729844413, 'precision': 0.813012729844413, 'Causal_Oversimplification_precision': 0.5, 'Causal_Oversimplification_recall': 0.32116788321167883, 'Causal_Oversimplification_f1-score': 0.3911111111111111, 'Causal_Oversimplification_support': 137.0, 'micro avg_precision': 0.5, 'micro avg_recall': 0.32116788321167883, 'micro avg_f1-score': 0.3911111111111111, 'micro avg_support': 137.0, 'macro avg_precision': 0.5, 'macro avg_recall': 0.32116788321167883, 'macro avg_f1-score': 0.3911111111111111, 'macro avg_support': 137.0, 'weighted avg_precision': 0.5, 'weighted avg_recall': 0.32116788321167883, 'weighted avg_f1-score': 0.3911111111111111, 'weighted avg_support': 137.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1561, 'epoch': 7}]}
Early stopping triggered.
Saving model to directory: ./models/M2/2024-05-13-23-08-48_aug/mdeberta-v3-base_5_ME10_target=Causal_Oversimplification_SUBSAMPLED_2024-05-13-23-08-48
Training model no. 6 of 23 for (6, 'False_Dilemma-No_Choice') persuasion technique...
{'micro_f1': 0.7919224555735055, 'precision': 0.7919224555735056, 'False_Dilemma-No_Choice_precision': 0.20238095238095238, 'False_Dilemma-No_Choice_recall': 0.1650485436893204, 'False_Dilemma-No_Choice_f1-score': 0.18181818181818185, 'False_Dilemma-No_Choice_support': 103.0, 'micro avg_precision': 0.20238095238095238, 'micro avg_recall': 0.1650485436893204, 'micro avg_f1-score': 0.18181818181818185, 'micro avg_support': 103.0, 'macro avg_precision': 0.20238095238095238, 'macro avg_recall': 0.1650485436893204, 'macro avg_f1-score': 0.18181818181818185, 'macro avg_support': 103.0, 'weighted avg_precision': 0.20238095238095238, 'weighted avg_recall': 0.1650485436893204, 'weighted avg_f1-score': 0.18181818181818185, 'weighted avg_support': 103.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 1667, 'epoch': 0}
{'results': [{'micro_f1': 0.7919224555735055, 'precision': 0.7919224555735056, 'False_Dilemma-No_Choice_precision': 0.20238095238095238, 'False_Dilemma-No_Choice_recall': 0.1650485436893204, 'False_Dilemma-No_Choice_f1-score': 0.18181818181818185, 'False_Dilemma-No_Choice_support': 103.0, 'micro avg_precision': 0.20238095238095238, 'micro avg_recall': 0.1650485436893204, 'micro avg_f1-score': 0.18181818181818185, 'micro avg_support': 103.0, 'macro avg_precision': 0.20238095238095238, 'macro avg_recall': 0.1650485436893204, 'macro avg_f1-score': 0.18181818181818185, 'macro avg_support': 103.0, 'weighted avg_precision': 0.20238095238095238, 'weighted avg_recall': 0.1650485436893204, 'weighted avg_f1-score': 0.18181818181818185, 'weighted avg_support': 103.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 1667, 'epoch': 0}]}
Best model updated: current epoch macro f1 = 0.18181818181818185
{'micro_f1': 0.8410339256865913, 'precision': 0.8410339256865913, 'False_Dilemma-No_Choice_precision': 0.34523809523809523, 'False_Dilemma-No_Choice_recall': 0.25663716814159293, 'False_Dilemma-No_Choice_f1-score': 0.2944162436548223, 'False_Dilemma-No_Choice_support': 113.0, 'micro avg_precision': 0.34523809523809523, 'micro avg_recall': 0.25663716814159293, 'micro avg_f1-score': 0.2944162436548223, 'micro avg_support': 113.0, 'macro avg_precision': 0.34523809523809523, 'macro avg_recall': 0.25663716814159293, 'macro avg_f1-score': 0.2944162436548223, 'macro avg_support': 113.0, 'weighted avg_precision': 0.34523809523809523, 'weighted avg_recall': 0.25663716814159293, 'weighted avg_f1-score': 0.2944162436548223, 'weighted avg_support': 113.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 1667, 'epoch': 1}
{'results': [{'micro_f1': 0.7919224555735055, 'precision': 0.7919224555735056, 'False_Dilemma-No_Choice_precision': 0.20238095238095238, 'False_Dilemma-No_Choice_recall': 0.1650485436893204, 'False_Dilemma-No_Choice_f1-score': 0.18181818181818185, 'False_Dilemma-No_Choice_support': 103.0, 'micro avg_precision': 0.20238095238095238, 'micro avg_recall': 0.1650485436893204, 'micro avg_f1-score': 0.18181818181818185, 'micro avg_support': 103.0, 'macro avg_precision': 0.20238095238095238, 'macro avg_recall': 0.1650485436893204, 'macro avg_f1-score': 0.18181818181818185, 'macro avg_support': 103.0, 'weighted avg_precision': 0.20238095238095238, 'weighted avg_recall': 0.1650485436893204, 'weighted avg_f1-score': 0.18181818181818185, 'weighted avg_support': 103.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 1667, 'epoch': 0}, {'micro_f1': 0.8410339256865913, 'precision': 0.8410339256865913, 'False_Dilemma-No_Choice_precision': 0.34523809523809523, 'False_Dilemma-No_Choice_recall': 0.25663716814159293, 'False_Dilemma-No_Choice_f1-score': 0.2944162436548223, 'False_Dilemma-No_Choice_support': 113.0, 'micro avg_precision': 0.34523809523809523, 'micro avg_recall': 0.25663716814159293, 'micro avg_f1-score': 0.2944162436548223, 'micro avg_support': 113.0, 'macro avg_precision': 0.34523809523809523, 'macro avg_recall': 0.25663716814159293, 'macro avg_f1-score': 0.2944162436548223, 'macro avg_support': 113.0, 'weighted avg_precision': 0.34523809523809523, 'weighted avg_recall': 0.25663716814159293, 'weighted avg_f1-score': 0.2944162436548223, 'weighted avg_support': 113.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 1667, 'epoch': 1}]}
Best model updated: current epoch macro f1 = 0.2944162436548223
{'micro_f1': 0.84297253634895, 'precision': 0.84297253634895, 'False_Dilemma-No_Choice_precision': 0.34523809523809523, 'False_Dilemma-No_Choice_recall': 0.23577235772357724, 'False_Dilemma-No_Choice_f1-score': 0.28019323671497587, 'False_Dilemma-No_Choice_support': 123.0, 'micro avg_precision': 0.34523809523809523, 'micro avg_recall': 0.23577235772357724, 'micro avg_f1-score': 0.28019323671497587, 'micro avg_support': 123.0, 'macro avg_precision': 0.34523809523809523, 'macro avg_recall': 0.23577235772357724, 'macro avg_f1-score': 0.28019323671497587, 'macro avg_support': 123.0, 'weighted avg_precision': 0.34523809523809523, 'weighted avg_recall': 0.23577235772357724, 'weighted avg_f1-score': 0.28019323671497587, 'weighted avg_support': 123.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 1667, 'epoch': 2}
{'results': [{'micro_f1': 0.7919224555735055, 'precision': 0.7919224555735056, 'False_Dilemma-No_Choice_precision': 0.20238095238095238, 'False_Dilemma-No_Choice_recall': 0.1650485436893204, 'False_Dilemma-No_Choice_f1-score': 0.18181818181818185, 'False_Dilemma-No_Choice_support': 103.0, 'micro avg_precision': 0.20238095238095238, 'micro avg_recall': 0.1650485436893204, 'micro avg_f1-score': 0.18181818181818185, 'micro avg_support': 103.0, 'macro avg_precision': 0.20238095238095238, 'macro avg_recall': 0.1650485436893204, 'macro avg_f1-score': 0.18181818181818185, 'macro avg_support': 103.0, 'weighted avg_precision': 0.20238095238095238, 'weighted avg_recall': 0.1650485436893204, 'weighted avg_f1-score': 0.18181818181818185, 'weighted avg_support': 103.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 1667, 'epoch': 0}, {'micro_f1': 0.8410339256865913, 'precision': 0.8410339256865913, 'False_Dilemma-No_Choice_precision': 0.34523809523809523, 'False_Dilemma-No_Choice_recall': 0.25663716814159293, 'False_Dilemma-No_Choice_f1-score': 0.2944162436548223, 'False_Dilemma-No_Choice_support': 113.0, 'micro avg_precision': 0.34523809523809523, 'micro avg_recall': 0.25663716814159293, 'micro avg_f1-score': 0.2944162436548223, 'micro avg_support': 113.0, 'macro avg_precision': 0.34523809523809523, 'macro avg_recall': 0.25663716814159293, 'macro avg_f1-score': 0.2944162436548223, 'macro avg_support': 113.0, 'weighted avg_precision': 0.34523809523809523, 'weighted avg_recall': 0.25663716814159293, 'weighted avg_f1-score': 0.2944162436548223, 'weighted avg_support': 113.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 1667, 'epoch': 1}, {'micro_f1': 0.84297253634895, 'precision': 0.84297253634895, 'False_Dilemma-No_Choice_precision': 0.34523809523809523, 'False_Dilemma-No_Choice_recall': 0.23577235772357724, 'False_Dilemma-No_Choice_f1-score': 0.28019323671497587, 'False_Dilemma-No_Choice_support': 123.0, 'micro avg_precision': 0.34523809523809523, 'micro avg_recall': 0.23577235772357724, 'micro avg_f1-score': 0.28019323671497587, 'micro avg_support': 123.0, 'macro avg_precision': 0.34523809523809523, 'macro avg_recall': 0.23577235772357724, 'macro avg_f1-score': 0.28019323671497587, 'macro avg_support': 123.0, 'weighted avg_precision': 0.34523809523809523, 'weighted avg_recall': 0.23577235772357724, 'weighted avg_f1-score': 0.28019323671497587, 'weighted avg_support': 123.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 1667, 'epoch': 2}]}
{'micro_f1': 0.848465266558966, 'precision': 0.848465266558966, 'False_Dilemma-No_Choice_precision': 0.3333333333333333, 'False_Dilemma-No_Choice_recall': 0.25925925925925924, 'False_Dilemma-No_Choice_f1-score': 0.2916666666666667, 'False_Dilemma-No_Choice_support': 108.0, 'micro avg_precision': 0.3333333333333333, 'micro avg_recall': 0.25925925925925924, 'micro avg_f1-score': 0.2916666666666667, 'micro avg_support': 108.0, 'macro avg_precision': 0.3333333333333333, 'macro avg_recall': 0.25925925925925924, 'macro avg_f1-score': 0.2916666666666667, 'macro avg_support': 108.0, 'weighted avg_precision': 0.3333333333333333, 'weighted avg_recall': 0.25925925925925924, 'weighted avg_f1-score': 0.2916666666666667, 'weighted avg_support': 108.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 1667, 'epoch': 3}
{'results': [{'micro_f1': 0.7919224555735055, 'precision': 0.7919224555735056, 'False_Dilemma-No_Choice_precision': 0.20238095238095238, 'False_Dilemma-No_Choice_recall': 0.1650485436893204, 'False_Dilemma-No_Choice_f1-score': 0.18181818181818185, 'False_Dilemma-No_Choice_support': 103.0, 'micro avg_precision': 0.20238095238095238, 'micro avg_recall': 0.1650485436893204, 'micro avg_f1-score': 0.18181818181818185, 'micro avg_support': 103.0, 'macro avg_precision': 0.20238095238095238, 'macro avg_recall': 0.1650485436893204, 'macro avg_f1-score': 0.18181818181818185, 'macro avg_support': 103.0, 'weighted avg_precision': 0.20238095238095238, 'weighted avg_recall': 0.1650485436893204, 'weighted avg_f1-score': 0.18181818181818185, 'weighted avg_support': 103.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 1667, 'epoch': 0}, {'micro_f1': 0.8410339256865913, 'precision': 0.8410339256865913, 'False_Dilemma-No_Choice_precision': 0.34523809523809523, 'False_Dilemma-No_Choice_recall': 0.25663716814159293, 'False_Dilemma-No_Choice_f1-score': 0.2944162436548223, 'False_Dilemma-No_Choice_support': 113.0, 'micro avg_precision': 0.34523809523809523, 'micro avg_recall': 0.25663716814159293, 'micro avg_f1-score': 0.2944162436548223, 'micro avg_support': 113.0, 'macro avg_precision': 0.34523809523809523, 'macro avg_recall': 0.25663716814159293, 'macro avg_f1-score': 0.2944162436548223, 'macro avg_support': 113.0, 'weighted avg_precision': 0.34523809523809523, 'weighted avg_recall': 0.25663716814159293, 'weighted avg_f1-score': 0.2944162436548223, 'weighted avg_support': 113.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 1667, 'epoch': 1}, {'micro_f1': 0.84297253634895, 'precision': 0.84297253634895, 'False_Dilemma-No_Choice_precision': 0.34523809523809523, 'False_Dilemma-No_Choice_recall': 0.23577235772357724, 'False_Dilemma-No_Choice_f1-score': 0.28019323671497587, 'False_Dilemma-No_Choice_support': 123.0, 'micro avg_precision': 0.34523809523809523, 'micro avg_recall': 0.23577235772357724, 'micro avg_f1-score': 0.28019323671497587, 'micro avg_support': 123.0, 'macro avg_precision': 0.34523809523809523, 'macro avg_recall': 0.23577235772357724, 'macro avg_f1-score': 0.28019323671497587, 'macro avg_support': 123.0, 'weighted avg_precision': 0.34523809523809523, 'weighted avg_recall': 0.23577235772357724, 'weighted avg_f1-score': 0.28019323671497587, 'weighted avg_support': 123.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 1667, 'epoch': 2}, {'micro_f1': 0.848465266558966, 'precision': 0.848465266558966, 'False_Dilemma-No_Choice_precision': 0.3333333333333333, 'False_Dilemma-No_Choice_recall': 0.25925925925925924, 'False_Dilemma-No_Choice_f1-score': 0.2916666666666667, 'False_Dilemma-No_Choice_support': 108.0, 'micro avg_precision': 0.3333333333333333, 'micro avg_recall': 0.25925925925925924, 'micro avg_f1-score': 0.2916666666666667, 'micro avg_support': 108.0, 'macro avg_precision': 0.3333333333333333, 'macro avg_recall': 0.25925925925925924, 'macro avg_f1-score': 0.2916666666666667, 'macro avg_support': 108.0, 'weighted avg_precision': 0.3333333333333333, 'weighted avg_recall': 0.25925925925925924, 'weighted avg_f1-score': 0.2916666666666667, 'weighted avg_support': 108.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 1667, 'epoch': 3}]}
Early stopping triggered.
Saving model to directory: ./models/M2/2024-05-13-23-08-48_aug/mdeberta-v3-base_6_ME10_target=False_Dilemma-No_Choice_SUBSAMPLED_2024-05-13-23-08-48
Training model no. 7 of 23 for (7, 'Consequential_Oversimplification') persuasion technique...
{'micro_f1': 0.841296928327645, 'precision': 0.841296928327645, 'Consequential_Oversimplification_precision': 0.0392156862745098, 'Consequential_Oversimplification_recall': 0.02247191011235955, 'Consequential_Oversimplification_f1-score': 0.02857142857142857, 'Consequential_Oversimplification_support': 89.0, 'micro avg_precision': 0.0392156862745098, 'micro avg_recall': 0.02247191011235955, 'micro avg_f1-score': 0.02857142857142857, 'micro avg_support': 89.0, 'macro avg_precision': 0.0392156862745098, 'macro avg_recall': 0.02247191011235955, 'macro avg_f1-score': 0.02857142857142857, 'macro avg_support': 89.0, 'weighted avg_precision': 0.0392156862745098, 'weighted avg_recall': 0.02247191011235955, 'weighted avg_f1-score': 0.02857142857142857, 'weighted avg_support': 89.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 0}
{'results': [{'micro_f1': 0.841296928327645, 'precision': 0.841296928327645, 'Consequential_Oversimplification_precision': 0.0392156862745098, 'Consequential_Oversimplification_recall': 0.02247191011235955, 'Consequential_Oversimplification_f1-score': 0.02857142857142857, 'Consequential_Oversimplification_support': 89.0, 'micro avg_precision': 0.0392156862745098, 'micro avg_recall': 0.02247191011235955, 'micro avg_f1-score': 0.02857142857142857, 'micro avg_support': 89.0, 'macro avg_precision': 0.0392156862745098, 'macro avg_recall': 0.02247191011235955, 'macro avg_f1-score': 0.02857142857142857, 'macro avg_support': 89.0, 'weighted avg_precision': 0.0392156862745098, 'weighted avg_recall': 0.02247191011235955, 'weighted avg_f1-score': 0.02857142857142857, 'weighted avg_support': 89.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 0}]}
Best model updated: current epoch macro f1 = 0.02857142857142857
{'micro_f1': 0.7721843003412968, 'precision': 0.7721843003412969, 'Consequential_Oversimplification_precision': 0.058823529411764705, 'Consequential_Oversimplification_recall': 0.023809523809523808, 'Consequential_Oversimplification_f1-score': 0.033898305084745756, 'Consequential_Oversimplification_support': 126.0, 'micro avg_precision': 0.058823529411764705, 'micro avg_recall': 0.023809523809523808, 'micro avg_f1-score': 0.033898305084745756, 'micro avg_support': 126.0, 'macro avg_precision': 0.058823529411764705, 'macro avg_recall': 0.023809523809523808, 'macro avg_f1-score': 0.033898305084745756, 'macro avg_support': 126.0, 'weighted avg_precision': 0.058823529411764705, 'weighted avg_recall': 0.023809523809523808, 'weighted avg_f1-score': 0.033898305084745756, 'weighted avg_support': 126.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 1}
{'results': [{'micro_f1': 0.841296928327645, 'precision': 0.841296928327645, 'Consequential_Oversimplification_precision': 0.0392156862745098, 'Consequential_Oversimplification_recall': 0.02247191011235955, 'Consequential_Oversimplification_f1-score': 0.02857142857142857, 'Consequential_Oversimplification_support': 89.0, 'micro avg_precision': 0.0392156862745098, 'micro avg_recall': 0.02247191011235955, 'micro avg_f1-score': 0.02857142857142857, 'micro avg_support': 89.0, 'macro avg_precision': 0.0392156862745098, 'macro avg_recall': 0.02247191011235955, 'macro avg_f1-score': 0.02857142857142857, 'macro avg_support': 89.0, 'weighted avg_precision': 0.0392156862745098, 'weighted avg_recall': 0.02247191011235955, 'weighted avg_f1-score': 0.02857142857142857, 'weighted avg_support': 89.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 0}, {'micro_f1': 0.7721843003412968, 'precision': 0.7721843003412969, 'Consequential_Oversimplification_precision': 0.058823529411764705, 'Consequential_Oversimplification_recall': 0.023809523809523808, 'Consequential_Oversimplification_f1-score': 0.033898305084745756, 'Consequential_Oversimplification_support': 126.0, 'micro avg_precision': 0.058823529411764705, 'micro avg_recall': 0.023809523809523808, 'micro avg_f1-score': 0.033898305084745756, 'micro avg_support': 126.0, 'macro avg_precision': 0.058823529411764705, 'macro avg_recall': 0.023809523809523808, 'macro avg_f1-score': 0.033898305084745756, 'macro avg_support': 126.0, 'weighted avg_precision': 0.058823529411764705, 'weighted avg_recall': 0.023809523809523808, 'weighted avg_f1-score': 0.033898305084745756, 'weighted avg_support': 126.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 1}]}
Best model updated: current epoch macro f1 = 0.033898305084745756
{'micro_f1': 0.8549488054607508, 'precision': 0.8549488054607508, 'Consequential_Oversimplification_precision': 0.3137254901960784, 'Consequential_Oversimplification_recall': 0.19753086419753085, 'Consequential_Oversimplification_f1-score': 0.24242424242424243, 'Consequential_Oversimplification_support': 81.0, 'micro avg_precision': 0.3137254901960784, 'micro avg_recall': 0.19753086419753085, 'micro avg_f1-score': 0.24242424242424243, 'micro avg_support': 81.0, 'macro avg_precision': 0.3137254901960784, 'macro avg_recall': 0.19753086419753085, 'macro avg_f1-score': 0.24242424242424243, 'macro avg_support': 81.0, 'weighted avg_precision': 0.3137254901960784, 'weighted avg_recall': 0.19753086419753085, 'weighted avg_f1-score': 0.24242424242424243, 'weighted avg_support': 81.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 2}
{'results': [{'micro_f1': 0.841296928327645, 'precision': 0.841296928327645, 'Consequential_Oversimplification_precision': 0.0392156862745098, 'Consequential_Oversimplification_recall': 0.02247191011235955, 'Consequential_Oversimplification_f1-score': 0.02857142857142857, 'Consequential_Oversimplification_support': 89.0, 'micro avg_precision': 0.0392156862745098, 'micro avg_recall': 0.02247191011235955, 'micro avg_f1-score': 0.02857142857142857, 'micro avg_support': 89.0, 'macro avg_precision': 0.0392156862745098, 'macro avg_recall': 0.02247191011235955, 'macro avg_f1-score': 0.02857142857142857, 'macro avg_support': 89.0, 'weighted avg_precision': 0.0392156862745098, 'weighted avg_recall': 0.02247191011235955, 'weighted avg_f1-score': 0.02857142857142857, 'weighted avg_support': 89.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 0}, {'micro_f1': 0.7721843003412968, 'precision': 0.7721843003412969, 'Consequential_Oversimplification_precision': 0.058823529411764705, 'Consequential_Oversimplification_recall': 0.023809523809523808, 'Consequential_Oversimplification_f1-score': 0.033898305084745756, 'Consequential_Oversimplification_support': 126.0, 'micro avg_precision': 0.058823529411764705, 'micro avg_recall': 0.023809523809523808, 'micro avg_f1-score': 0.033898305084745756, 'micro avg_support': 126.0, 'macro avg_precision': 0.058823529411764705, 'macro avg_recall': 0.023809523809523808, 'macro avg_f1-score': 0.033898305084745756, 'macro avg_support': 126.0, 'weighted avg_precision': 0.058823529411764705, 'weighted avg_recall': 0.023809523809523808, 'weighted avg_f1-score': 0.033898305084745756, 'weighted avg_support': 126.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 1}, {'micro_f1': 0.8549488054607508, 'precision': 0.8549488054607508, 'Consequential_Oversimplification_precision': 0.3137254901960784, 'Consequential_Oversimplification_recall': 0.19753086419753085, 'Consequential_Oversimplification_f1-score': 0.24242424242424243, 'Consequential_Oversimplification_support': 81.0, 'micro avg_precision': 0.3137254901960784, 'micro avg_recall': 0.19753086419753085, 'micro avg_f1-score': 0.24242424242424243, 'micro avg_support': 81.0, 'macro avg_precision': 0.3137254901960784, 'macro avg_recall': 0.19753086419753085, 'macro avg_f1-score': 0.24242424242424243, 'macro avg_support': 81.0, 'weighted avg_precision': 0.3137254901960784, 'weighted avg_recall': 0.19753086419753085, 'weighted avg_f1-score': 0.24242424242424243, 'weighted avg_support': 81.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 2}]}
Best model updated: current epoch macro f1 = 0.24242424242424243
{'micro_f1': 0.8771331058020477, 'precision': 0.8771331058020477, 'Consequential_Oversimplification_precision': 0.2549019607843137, 'Consequential_Oversimplification_recall': 0.1625, 'Consequential_Oversimplification_f1-score': 0.19847328244274812, 'Consequential_Oversimplification_support': 80.0, 'micro avg_precision': 0.2549019607843137, 'micro avg_recall': 0.1625, 'micro avg_f1-score': 0.19847328244274812, 'micro avg_support': 80.0, 'macro avg_precision': 0.2549019607843137, 'macro avg_recall': 0.1625, 'macro avg_f1-score': 0.19847328244274812, 'macro avg_support': 80.0, 'weighted avg_precision': 0.2549019607843137, 'weighted avg_recall': 0.1625, 'weighted avg_f1-score': 0.19847328244274812, 'weighted avg_support': 80.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 3}
{'results': [{'micro_f1': 0.841296928327645, 'precision': 0.841296928327645, 'Consequential_Oversimplification_precision': 0.0392156862745098, 'Consequential_Oversimplification_recall': 0.02247191011235955, 'Consequential_Oversimplification_f1-score': 0.02857142857142857, 'Consequential_Oversimplification_support': 89.0, 'micro avg_precision': 0.0392156862745098, 'micro avg_recall': 0.02247191011235955, 'micro avg_f1-score': 0.02857142857142857, 'micro avg_support': 89.0, 'macro avg_precision': 0.0392156862745098, 'macro avg_recall': 0.02247191011235955, 'macro avg_f1-score': 0.02857142857142857, 'macro avg_support': 89.0, 'weighted avg_precision': 0.0392156862745098, 'weighted avg_recall': 0.02247191011235955, 'weighted avg_f1-score': 0.02857142857142857, 'weighted avg_support': 89.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 0}, {'micro_f1': 0.7721843003412968, 'precision': 0.7721843003412969, 'Consequential_Oversimplification_precision': 0.058823529411764705, 'Consequential_Oversimplification_recall': 0.023809523809523808, 'Consequential_Oversimplification_f1-score': 0.033898305084745756, 'Consequential_Oversimplification_support': 126.0, 'micro avg_precision': 0.058823529411764705, 'micro avg_recall': 0.023809523809523808, 'micro avg_f1-score': 0.033898305084745756, 'micro avg_support': 126.0, 'macro avg_precision': 0.058823529411764705, 'macro avg_recall': 0.023809523809523808, 'macro avg_f1-score': 0.033898305084745756, 'macro avg_support': 126.0, 'weighted avg_precision': 0.058823529411764705, 'weighted avg_recall': 0.023809523809523808, 'weighted avg_f1-score': 0.033898305084745756, 'weighted avg_support': 126.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 1}, {'micro_f1': 0.8549488054607508, 'precision': 0.8549488054607508, 'Consequential_Oversimplification_precision': 0.3137254901960784, 'Consequential_Oversimplification_recall': 0.19753086419753085, 'Consequential_Oversimplification_f1-score': 0.24242424242424243, 'Consequential_Oversimplification_support': 81.0, 'micro avg_precision': 0.3137254901960784, 'micro avg_recall': 0.19753086419753085, 'micro avg_f1-score': 0.24242424242424243, 'micro avg_support': 81.0, 'macro avg_precision': 0.3137254901960784, 'macro avg_recall': 0.19753086419753085, 'macro avg_f1-score': 0.24242424242424243, 'macro avg_support': 81.0, 'weighted avg_precision': 0.3137254901960784, 'weighted avg_recall': 0.19753086419753085, 'weighted avg_f1-score': 0.24242424242424243, 'weighted avg_support': 81.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 2}, {'micro_f1': 0.8771331058020477, 'precision': 0.8771331058020477, 'Consequential_Oversimplification_precision': 0.2549019607843137, 'Consequential_Oversimplification_recall': 0.1625, 'Consequential_Oversimplification_f1-score': 0.19847328244274812, 'Consequential_Oversimplification_support': 80.0, 'micro avg_precision': 0.2549019607843137, 'micro avg_recall': 0.1625, 'micro avg_f1-score': 0.19847328244274812, 'micro avg_support': 80.0, 'macro avg_precision': 0.2549019607843137, 'macro avg_recall': 0.1625, 'macro avg_f1-score': 0.19847328244274812, 'macro avg_support': 80.0, 'weighted avg_precision': 0.2549019607843137, 'weighted avg_recall': 0.1625, 'weighted avg_f1-score': 0.19847328244274812, 'weighted avg_support': 80.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 3}]}
{'micro_f1': 0.8515358361774744, 'precision': 0.8515358361774744, 'Consequential_Oversimplification_precision': 0.37254901960784315, 'Consequential_Oversimplification_recall': 0.2111111111111111, 'Consequential_Oversimplification_f1-score': 0.2695035460992908, 'Consequential_Oversimplification_support': 90.0, 'micro avg_precision': 0.37254901960784315, 'micro avg_recall': 0.2111111111111111, 'micro avg_f1-score': 0.2695035460992908, 'micro avg_support': 90.0, 'macro avg_precision': 0.37254901960784315, 'macro avg_recall': 0.2111111111111111, 'macro avg_f1-score': 0.2695035460992908, 'macro avg_support': 90.0, 'weighted avg_precision': 0.37254901960784315, 'weighted avg_recall': 0.2111111111111111, 'weighted avg_f1-score': 0.2695035460992908, 'weighted avg_support': 90.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 4}
{'results': [{'micro_f1': 0.841296928327645, 'precision': 0.841296928327645, 'Consequential_Oversimplification_precision': 0.0392156862745098, 'Consequential_Oversimplification_recall': 0.02247191011235955, 'Consequential_Oversimplification_f1-score': 0.02857142857142857, 'Consequential_Oversimplification_support': 89.0, 'micro avg_precision': 0.0392156862745098, 'micro avg_recall': 0.02247191011235955, 'micro avg_f1-score': 0.02857142857142857, 'micro avg_support': 89.0, 'macro avg_precision': 0.0392156862745098, 'macro avg_recall': 0.02247191011235955, 'macro avg_f1-score': 0.02857142857142857, 'macro avg_support': 89.0, 'weighted avg_precision': 0.0392156862745098, 'weighted avg_recall': 0.02247191011235955, 'weighted avg_f1-score': 0.02857142857142857, 'weighted avg_support': 89.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 0}, {'micro_f1': 0.7721843003412968, 'precision': 0.7721843003412969, 'Consequential_Oversimplification_precision': 0.058823529411764705, 'Consequential_Oversimplification_recall': 0.023809523809523808, 'Consequential_Oversimplification_f1-score': 0.033898305084745756, 'Consequential_Oversimplification_support': 126.0, 'micro avg_precision': 0.058823529411764705, 'micro avg_recall': 0.023809523809523808, 'micro avg_f1-score': 0.033898305084745756, 'micro avg_support': 126.0, 'macro avg_precision': 0.058823529411764705, 'macro avg_recall': 0.023809523809523808, 'macro avg_f1-score': 0.033898305084745756, 'macro avg_support': 126.0, 'weighted avg_precision': 0.058823529411764705, 'weighted avg_recall': 0.023809523809523808, 'weighted avg_f1-score': 0.033898305084745756, 'weighted avg_support': 126.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 1}, {'micro_f1': 0.8549488054607508, 'precision': 0.8549488054607508, 'Consequential_Oversimplification_precision': 0.3137254901960784, 'Consequential_Oversimplification_recall': 0.19753086419753085, 'Consequential_Oversimplification_f1-score': 0.24242424242424243, 'Consequential_Oversimplification_support': 81.0, 'micro avg_precision': 0.3137254901960784, 'micro avg_recall': 0.19753086419753085, 'micro avg_f1-score': 0.24242424242424243, 'micro avg_support': 81.0, 'macro avg_precision': 0.3137254901960784, 'macro avg_recall': 0.19753086419753085, 'macro avg_f1-score': 0.24242424242424243, 'macro avg_support': 81.0, 'weighted avg_precision': 0.3137254901960784, 'weighted avg_recall': 0.19753086419753085, 'weighted avg_f1-score': 0.24242424242424243, 'weighted avg_support': 81.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 2}, {'micro_f1': 0.8771331058020477, 'precision': 0.8771331058020477, 'Consequential_Oversimplification_precision': 0.2549019607843137, 'Consequential_Oversimplification_recall': 0.1625, 'Consequential_Oversimplification_f1-score': 0.19847328244274812, 'Consequential_Oversimplification_support': 80.0, 'micro avg_precision': 0.2549019607843137, 'micro avg_recall': 0.1625, 'micro avg_f1-score': 0.19847328244274812, 'micro avg_support': 80.0, 'macro avg_precision': 0.2549019607843137, 'macro avg_recall': 0.1625, 'macro avg_f1-score': 0.19847328244274812, 'macro avg_support': 80.0, 'weighted avg_precision': 0.2549019607843137, 'weighted avg_recall': 0.1625, 'weighted avg_f1-score': 0.19847328244274812, 'weighted avg_support': 80.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 3}, {'micro_f1': 0.8515358361774744, 'precision': 0.8515358361774744, 'Consequential_Oversimplification_precision': 0.37254901960784315, 'Consequential_Oversimplification_recall': 0.2111111111111111, 'Consequential_Oversimplification_f1-score': 0.2695035460992908, 'Consequential_Oversimplification_support': 90.0, 'micro avg_precision': 0.37254901960784315, 'micro avg_recall': 0.2111111111111111, 'micro avg_f1-score': 0.2695035460992908, 'micro avg_support': 90.0, 'macro avg_precision': 0.37254901960784315, 'macro avg_recall': 0.2111111111111111, 'macro avg_f1-score': 0.2695035460992908, 'macro avg_support': 90.0, 'weighted avg_precision': 0.37254901960784315, 'weighted avg_recall': 0.2111111111111111, 'weighted avg_f1-score': 0.2695035460992908, 'weighted avg_support': 90.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 4}]}
Best model updated: current epoch macro f1 = 0.2695035460992908
{'micro_f1': 0.8553754266211604, 'precision': 0.8553754266211604, 'Consequential_Oversimplification_precision': 0.43137254901960786, 'Consequential_Oversimplification_recall': 0.2619047619047619, 'Consequential_Oversimplification_f1-score': 0.32592592592592595, 'Consequential_Oversimplification_support': 84.0, 'micro avg_precision': 0.43137254901960786, 'micro avg_recall': 0.2619047619047619, 'micro avg_f1-score': 0.32592592592592595, 'micro avg_support': 84.0, 'macro avg_precision': 0.43137254901960786, 'macro avg_recall': 0.2619047619047619, 'macro avg_f1-score': 0.32592592592592595, 'macro avg_support': 84.0, 'weighted avg_precision': 0.4313725490196078, 'weighted avg_recall': 0.2619047619047619, 'weighted avg_f1-score': 0.32592592592592595, 'weighted avg_support': 84.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 5}
{'results': [{'micro_f1': 0.841296928327645, 'precision': 0.841296928327645, 'Consequential_Oversimplification_precision': 0.0392156862745098, 'Consequential_Oversimplification_recall': 0.02247191011235955, 'Consequential_Oversimplification_f1-score': 0.02857142857142857, 'Consequential_Oversimplification_support': 89.0, 'micro avg_precision': 0.0392156862745098, 'micro avg_recall': 0.02247191011235955, 'micro avg_f1-score': 0.02857142857142857, 'micro avg_support': 89.0, 'macro avg_precision': 0.0392156862745098, 'macro avg_recall': 0.02247191011235955, 'macro avg_f1-score': 0.02857142857142857, 'macro avg_support': 89.0, 'weighted avg_precision': 0.0392156862745098, 'weighted avg_recall': 0.02247191011235955, 'weighted avg_f1-score': 0.02857142857142857, 'weighted avg_support': 89.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 0}, {'micro_f1': 0.7721843003412968, 'precision': 0.7721843003412969, 'Consequential_Oversimplification_precision': 0.058823529411764705, 'Consequential_Oversimplification_recall': 0.023809523809523808, 'Consequential_Oversimplification_f1-score': 0.033898305084745756, 'Consequential_Oversimplification_support': 126.0, 'micro avg_precision': 0.058823529411764705, 'micro avg_recall': 0.023809523809523808, 'micro avg_f1-score': 0.033898305084745756, 'micro avg_support': 126.0, 'macro avg_precision': 0.058823529411764705, 'macro avg_recall': 0.023809523809523808, 'macro avg_f1-score': 0.033898305084745756, 'macro avg_support': 126.0, 'weighted avg_precision': 0.058823529411764705, 'weighted avg_recall': 0.023809523809523808, 'weighted avg_f1-score': 0.033898305084745756, 'weighted avg_support': 126.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 1}, {'micro_f1': 0.8549488054607508, 'precision': 0.8549488054607508, 'Consequential_Oversimplification_precision': 0.3137254901960784, 'Consequential_Oversimplification_recall': 0.19753086419753085, 'Consequential_Oversimplification_f1-score': 0.24242424242424243, 'Consequential_Oversimplification_support': 81.0, 'micro avg_precision': 0.3137254901960784, 'micro avg_recall': 0.19753086419753085, 'micro avg_f1-score': 0.24242424242424243, 'micro avg_support': 81.0, 'macro avg_precision': 0.3137254901960784, 'macro avg_recall': 0.19753086419753085, 'macro avg_f1-score': 0.24242424242424243, 'macro avg_support': 81.0, 'weighted avg_precision': 0.3137254901960784, 'weighted avg_recall': 0.19753086419753085, 'weighted avg_f1-score': 0.24242424242424243, 'weighted avg_support': 81.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 2}, {'micro_f1': 0.8771331058020477, 'precision': 0.8771331058020477, 'Consequential_Oversimplification_precision': 0.2549019607843137, 'Consequential_Oversimplification_recall': 0.1625, 'Consequential_Oversimplification_f1-score': 0.19847328244274812, 'Consequential_Oversimplification_support': 80.0, 'micro avg_precision': 0.2549019607843137, 'micro avg_recall': 0.1625, 'micro avg_f1-score': 0.19847328244274812, 'micro avg_support': 80.0, 'macro avg_precision': 0.2549019607843137, 'macro avg_recall': 0.1625, 'macro avg_f1-score': 0.19847328244274812, 'macro avg_support': 80.0, 'weighted avg_precision': 0.2549019607843137, 'weighted avg_recall': 0.1625, 'weighted avg_f1-score': 0.19847328244274812, 'weighted avg_support': 80.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 3}, {'micro_f1': 0.8515358361774744, 'precision': 0.8515358361774744, 'Consequential_Oversimplification_precision': 0.37254901960784315, 'Consequential_Oversimplification_recall': 0.2111111111111111, 'Consequential_Oversimplification_f1-score': 0.2695035460992908, 'Consequential_Oversimplification_support': 90.0, 'micro avg_precision': 0.37254901960784315, 'micro avg_recall': 0.2111111111111111, 'micro avg_f1-score': 0.2695035460992908, 'micro avg_support': 90.0, 'macro avg_precision': 0.37254901960784315, 'macro avg_recall': 0.2111111111111111, 'macro avg_f1-score': 0.2695035460992908, 'macro avg_support': 90.0, 'weighted avg_precision': 0.37254901960784315, 'weighted avg_recall': 0.2111111111111111, 'weighted avg_f1-score': 0.2695035460992908, 'weighted avg_support': 90.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 4}, {'micro_f1': 0.8553754266211604, 'precision': 0.8553754266211604, 'Consequential_Oversimplification_precision': 0.43137254901960786, 'Consequential_Oversimplification_recall': 0.2619047619047619, 'Consequential_Oversimplification_f1-score': 0.32592592592592595, 'Consequential_Oversimplification_support': 84.0, 'micro avg_precision': 0.43137254901960786, 'micro avg_recall': 0.2619047619047619, 'micro avg_f1-score': 0.32592592592592595, 'micro avg_support': 84.0, 'macro avg_precision': 0.43137254901960786, 'macro avg_recall': 0.2619047619047619, 'macro avg_f1-score': 0.32592592592592595, 'macro avg_support': 84.0, 'weighted avg_precision': 0.4313725490196078, 'weighted avg_recall': 0.2619047619047619, 'weighted avg_f1-score': 0.32592592592592595, 'weighted avg_support': 84.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 5}]}
Best model updated: current epoch macro f1 = 0.32592592592592595
{'micro_f1': 0.8720136518771331, 'precision': 0.8720136518771331, 'Consequential_Oversimplification_precision': 0.4117647058823529, 'Consequential_Oversimplification_recall': 0.2413793103448276, 'Consequential_Oversimplification_f1-score': 0.3043478260869565, 'Consequential_Oversimplification_support': 87.0, 'micro avg_precision': 0.4117647058823529, 'micro avg_recall': 0.2413793103448276, 'micro avg_f1-score': 0.3043478260869565, 'micro avg_support': 87.0, 'macro avg_precision': 0.4117647058823529, 'macro avg_recall': 0.2413793103448276, 'macro avg_f1-score': 0.3043478260869565, 'macro avg_support': 87.0, 'weighted avg_precision': 0.4117647058823529, 'weighted avg_recall': 0.2413793103448276, 'weighted avg_f1-score': 0.3043478260869565, 'weighted avg_support': 87.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 6}
{'results': [{'micro_f1': 0.841296928327645, 'precision': 0.841296928327645, 'Consequential_Oversimplification_precision': 0.0392156862745098, 'Consequential_Oversimplification_recall': 0.02247191011235955, 'Consequential_Oversimplification_f1-score': 0.02857142857142857, 'Consequential_Oversimplification_support': 89.0, 'micro avg_precision': 0.0392156862745098, 'micro avg_recall': 0.02247191011235955, 'micro avg_f1-score': 0.02857142857142857, 'micro avg_support': 89.0, 'macro avg_precision': 0.0392156862745098, 'macro avg_recall': 0.02247191011235955, 'macro avg_f1-score': 0.02857142857142857, 'macro avg_support': 89.0, 'weighted avg_precision': 0.0392156862745098, 'weighted avg_recall': 0.02247191011235955, 'weighted avg_f1-score': 0.02857142857142857, 'weighted avg_support': 89.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 0}, {'micro_f1': 0.7721843003412968, 'precision': 0.7721843003412969, 'Consequential_Oversimplification_precision': 0.058823529411764705, 'Consequential_Oversimplification_recall': 0.023809523809523808, 'Consequential_Oversimplification_f1-score': 0.033898305084745756, 'Consequential_Oversimplification_support': 126.0, 'micro avg_precision': 0.058823529411764705, 'micro avg_recall': 0.023809523809523808, 'micro avg_f1-score': 0.033898305084745756, 'micro avg_support': 126.0, 'macro avg_precision': 0.058823529411764705, 'macro avg_recall': 0.023809523809523808, 'macro avg_f1-score': 0.033898305084745756, 'macro avg_support': 126.0, 'weighted avg_precision': 0.058823529411764705, 'weighted avg_recall': 0.023809523809523808, 'weighted avg_f1-score': 0.033898305084745756, 'weighted avg_support': 126.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 1}, {'micro_f1': 0.8549488054607508, 'precision': 0.8549488054607508, 'Consequential_Oversimplification_precision': 0.3137254901960784, 'Consequential_Oversimplification_recall': 0.19753086419753085, 'Consequential_Oversimplification_f1-score': 0.24242424242424243, 'Consequential_Oversimplification_support': 81.0, 'micro avg_precision': 0.3137254901960784, 'micro avg_recall': 0.19753086419753085, 'micro avg_f1-score': 0.24242424242424243, 'micro avg_support': 81.0, 'macro avg_precision': 0.3137254901960784, 'macro avg_recall': 0.19753086419753085, 'macro avg_f1-score': 0.24242424242424243, 'macro avg_support': 81.0, 'weighted avg_precision': 0.3137254901960784, 'weighted avg_recall': 0.19753086419753085, 'weighted avg_f1-score': 0.24242424242424243, 'weighted avg_support': 81.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 2}, {'micro_f1': 0.8771331058020477, 'precision': 0.8771331058020477, 'Consequential_Oversimplification_precision': 0.2549019607843137, 'Consequential_Oversimplification_recall': 0.1625, 'Consequential_Oversimplification_f1-score': 0.19847328244274812, 'Consequential_Oversimplification_support': 80.0, 'micro avg_precision': 0.2549019607843137, 'micro avg_recall': 0.1625, 'micro avg_f1-score': 0.19847328244274812, 'micro avg_support': 80.0, 'macro avg_precision': 0.2549019607843137, 'macro avg_recall': 0.1625, 'macro avg_f1-score': 0.19847328244274812, 'macro avg_support': 80.0, 'weighted avg_precision': 0.2549019607843137, 'weighted avg_recall': 0.1625, 'weighted avg_f1-score': 0.19847328244274812, 'weighted avg_support': 80.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 3}, {'micro_f1': 0.8515358361774744, 'precision': 0.8515358361774744, 'Consequential_Oversimplification_precision': 0.37254901960784315, 'Consequential_Oversimplification_recall': 0.2111111111111111, 'Consequential_Oversimplification_f1-score': 0.2695035460992908, 'Consequential_Oversimplification_support': 90.0, 'micro avg_precision': 0.37254901960784315, 'micro avg_recall': 0.2111111111111111, 'micro avg_f1-score': 0.2695035460992908, 'micro avg_support': 90.0, 'macro avg_precision': 0.37254901960784315, 'macro avg_recall': 0.2111111111111111, 'macro avg_f1-score': 0.2695035460992908, 'macro avg_support': 90.0, 'weighted avg_precision': 0.37254901960784315, 'weighted avg_recall': 0.2111111111111111, 'weighted avg_f1-score': 0.2695035460992908, 'weighted avg_support': 90.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 4}, {'micro_f1': 0.8553754266211604, 'precision': 0.8553754266211604, 'Consequential_Oversimplification_precision': 0.43137254901960786, 'Consequential_Oversimplification_recall': 0.2619047619047619, 'Consequential_Oversimplification_f1-score': 0.32592592592592595, 'Consequential_Oversimplification_support': 84.0, 'micro avg_precision': 0.43137254901960786, 'micro avg_recall': 0.2619047619047619, 'micro avg_f1-score': 0.32592592592592595, 'micro avg_support': 84.0, 'macro avg_precision': 0.43137254901960786, 'macro avg_recall': 0.2619047619047619, 'macro avg_f1-score': 0.32592592592592595, 'macro avg_support': 84.0, 'weighted avg_precision': 0.4313725490196078, 'weighted avg_recall': 0.2619047619047619, 'weighted avg_f1-score': 0.32592592592592595, 'weighted avg_support': 84.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 5}, {'micro_f1': 0.8720136518771331, 'precision': 0.8720136518771331, 'Consequential_Oversimplification_precision': 0.4117647058823529, 'Consequential_Oversimplification_recall': 0.2413793103448276, 'Consequential_Oversimplification_f1-score': 0.3043478260869565, 'Consequential_Oversimplification_support': 87.0, 'micro avg_precision': 0.4117647058823529, 'micro avg_recall': 0.2413793103448276, 'micro avg_f1-score': 0.3043478260869565, 'micro avg_support': 87.0, 'macro avg_precision': 0.4117647058823529, 'macro avg_recall': 0.2413793103448276, 'macro avg_f1-score': 0.3043478260869565, 'macro avg_support': 87.0, 'weighted avg_precision': 0.4117647058823529, 'weighted avg_recall': 0.2413793103448276, 'weighted avg_f1-score': 0.3043478260869565, 'weighted avg_support': 87.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 6}]}
{'micro_f1': 0.8784129692832765, 'precision': 0.8784129692832765, 'Consequential_Oversimplification_precision': 0.43137254901960786, 'Consequential_Oversimplification_recall': 0.27848101265822783, 'Consequential_Oversimplification_f1-score': 0.3384615384615385, 'Consequential_Oversimplification_support': 79.0, 'micro avg_precision': 0.43137254901960786, 'micro avg_recall': 0.27848101265822783, 'micro avg_f1-score': 0.3384615384615385, 'micro avg_support': 79.0, 'macro avg_precision': 0.43137254901960786, 'macro avg_recall': 0.27848101265822783, 'macro avg_f1-score': 0.3384615384615385, 'macro avg_support': 79.0, 'weighted avg_precision': 0.43137254901960786, 'weighted avg_recall': 0.27848101265822783, 'weighted avg_f1-score': 0.3384615384615385, 'weighted avg_support': 79.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 7}
{'results': [{'micro_f1': 0.841296928327645, 'precision': 0.841296928327645, 'Consequential_Oversimplification_precision': 0.0392156862745098, 'Consequential_Oversimplification_recall': 0.02247191011235955, 'Consequential_Oversimplification_f1-score': 0.02857142857142857, 'Consequential_Oversimplification_support': 89.0, 'micro avg_precision': 0.0392156862745098, 'micro avg_recall': 0.02247191011235955, 'micro avg_f1-score': 0.02857142857142857, 'micro avg_support': 89.0, 'macro avg_precision': 0.0392156862745098, 'macro avg_recall': 0.02247191011235955, 'macro avg_f1-score': 0.02857142857142857, 'macro avg_support': 89.0, 'weighted avg_precision': 0.0392156862745098, 'weighted avg_recall': 0.02247191011235955, 'weighted avg_f1-score': 0.02857142857142857, 'weighted avg_support': 89.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 0}, {'micro_f1': 0.7721843003412968, 'precision': 0.7721843003412969, 'Consequential_Oversimplification_precision': 0.058823529411764705, 'Consequential_Oversimplification_recall': 0.023809523809523808, 'Consequential_Oversimplification_f1-score': 0.033898305084745756, 'Consequential_Oversimplification_support': 126.0, 'micro avg_precision': 0.058823529411764705, 'micro avg_recall': 0.023809523809523808, 'micro avg_f1-score': 0.033898305084745756, 'micro avg_support': 126.0, 'macro avg_precision': 0.058823529411764705, 'macro avg_recall': 0.023809523809523808, 'macro avg_f1-score': 0.033898305084745756, 'macro avg_support': 126.0, 'weighted avg_precision': 0.058823529411764705, 'weighted avg_recall': 0.023809523809523808, 'weighted avg_f1-score': 0.033898305084745756, 'weighted avg_support': 126.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 1}, {'micro_f1': 0.8549488054607508, 'precision': 0.8549488054607508, 'Consequential_Oversimplification_precision': 0.3137254901960784, 'Consequential_Oversimplification_recall': 0.19753086419753085, 'Consequential_Oversimplification_f1-score': 0.24242424242424243, 'Consequential_Oversimplification_support': 81.0, 'micro avg_precision': 0.3137254901960784, 'micro avg_recall': 0.19753086419753085, 'micro avg_f1-score': 0.24242424242424243, 'micro avg_support': 81.0, 'macro avg_precision': 0.3137254901960784, 'macro avg_recall': 0.19753086419753085, 'macro avg_f1-score': 0.24242424242424243, 'macro avg_support': 81.0, 'weighted avg_precision': 0.3137254901960784, 'weighted avg_recall': 0.19753086419753085, 'weighted avg_f1-score': 0.24242424242424243, 'weighted avg_support': 81.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 2}, {'micro_f1': 0.8771331058020477, 'precision': 0.8771331058020477, 'Consequential_Oversimplification_precision': 0.2549019607843137, 'Consequential_Oversimplification_recall': 0.1625, 'Consequential_Oversimplification_f1-score': 0.19847328244274812, 'Consequential_Oversimplification_support': 80.0, 'micro avg_precision': 0.2549019607843137, 'micro avg_recall': 0.1625, 'micro avg_f1-score': 0.19847328244274812, 'micro avg_support': 80.0, 'macro avg_precision': 0.2549019607843137, 'macro avg_recall': 0.1625, 'macro avg_f1-score': 0.19847328244274812, 'macro avg_support': 80.0, 'weighted avg_precision': 0.2549019607843137, 'weighted avg_recall': 0.1625, 'weighted avg_f1-score': 0.19847328244274812, 'weighted avg_support': 80.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 3}, {'micro_f1': 0.8515358361774744, 'precision': 0.8515358361774744, 'Consequential_Oversimplification_precision': 0.37254901960784315, 'Consequential_Oversimplification_recall': 0.2111111111111111, 'Consequential_Oversimplification_f1-score': 0.2695035460992908, 'Consequential_Oversimplification_support': 90.0, 'micro avg_precision': 0.37254901960784315, 'micro avg_recall': 0.2111111111111111, 'micro avg_f1-score': 0.2695035460992908, 'micro avg_support': 90.0, 'macro avg_precision': 0.37254901960784315, 'macro avg_recall': 0.2111111111111111, 'macro avg_f1-score': 0.2695035460992908, 'macro avg_support': 90.0, 'weighted avg_precision': 0.37254901960784315, 'weighted avg_recall': 0.2111111111111111, 'weighted avg_f1-score': 0.2695035460992908, 'weighted avg_support': 90.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 4}, {'micro_f1': 0.8553754266211604, 'precision': 0.8553754266211604, 'Consequential_Oversimplification_precision': 0.43137254901960786, 'Consequential_Oversimplification_recall': 0.2619047619047619, 'Consequential_Oversimplification_f1-score': 0.32592592592592595, 'Consequential_Oversimplification_support': 84.0, 'micro avg_precision': 0.43137254901960786, 'micro avg_recall': 0.2619047619047619, 'micro avg_f1-score': 0.32592592592592595, 'micro avg_support': 84.0, 'macro avg_precision': 0.43137254901960786, 'macro avg_recall': 0.2619047619047619, 'macro avg_f1-score': 0.32592592592592595, 'macro avg_support': 84.0, 'weighted avg_precision': 0.4313725490196078, 'weighted avg_recall': 0.2619047619047619, 'weighted avg_f1-score': 0.32592592592592595, 'weighted avg_support': 84.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 5}, {'micro_f1': 0.8720136518771331, 'precision': 0.8720136518771331, 'Consequential_Oversimplification_precision': 0.4117647058823529, 'Consequential_Oversimplification_recall': 0.2413793103448276, 'Consequential_Oversimplification_f1-score': 0.3043478260869565, 'Consequential_Oversimplification_support': 87.0, 'micro avg_precision': 0.4117647058823529, 'micro avg_recall': 0.2413793103448276, 'micro avg_f1-score': 0.3043478260869565, 'micro avg_support': 87.0, 'macro avg_precision': 0.4117647058823529, 'macro avg_recall': 0.2413793103448276, 'macro avg_f1-score': 0.3043478260869565, 'macro avg_support': 87.0, 'weighted avg_precision': 0.4117647058823529, 'weighted avg_recall': 0.2413793103448276, 'weighted avg_f1-score': 0.3043478260869565, 'weighted avg_support': 87.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 6}, {'micro_f1': 0.8784129692832765, 'precision': 0.8784129692832765, 'Consequential_Oversimplification_precision': 0.43137254901960786, 'Consequential_Oversimplification_recall': 0.27848101265822783, 'Consequential_Oversimplification_f1-score': 0.3384615384615385, 'Consequential_Oversimplification_support': 79.0, 'micro avg_precision': 0.43137254901960786, 'micro avg_recall': 0.27848101265822783, 'micro avg_f1-score': 0.3384615384615385, 'micro avg_support': 79.0, 'macro avg_precision': 0.43137254901960786, 'macro avg_recall': 0.27848101265822783, 'macro avg_f1-score': 0.3384615384615385, 'macro avg_support': 79.0, 'weighted avg_precision': 0.43137254901960786, 'weighted avg_recall': 0.27848101265822783, 'weighted avg_f1-score': 0.3384615384615385, 'weighted avg_support': 79.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 7}]}
Best model updated: current epoch macro f1 = 0.3384615384615385
{'micro_f1': 0.8745733788395904, 'precision': 0.8745733788395904, 'Consequential_Oversimplification_precision': 0.4117647058823529, 'Consequential_Oversimplification_recall': 0.25925925925925924, 'Consequential_Oversimplification_f1-score': 0.3181818181818182, 'Consequential_Oversimplification_support': 81.0, 'micro avg_precision': 0.4117647058823529, 'micro avg_recall': 0.25925925925925924, 'micro avg_f1-score': 0.3181818181818182, 'micro avg_support': 81.0, 'macro avg_precision': 0.4117647058823529, 'macro avg_recall': 0.25925925925925924, 'macro avg_f1-score': 0.3181818181818182, 'macro avg_support': 81.0, 'weighted avg_precision': 0.4117647058823529, 'weighted avg_recall': 0.25925925925925924, 'weighted avg_f1-score': 0.3181818181818182, 'weighted avg_support': 81.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 8}
{'results': [{'micro_f1': 0.841296928327645, 'precision': 0.841296928327645, 'Consequential_Oversimplification_precision': 0.0392156862745098, 'Consequential_Oversimplification_recall': 0.02247191011235955, 'Consequential_Oversimplification_f1-score': 0.02857142857142857, 'Consequential_Oversimplification_support': 89.0, 'micro avg_precision': 0.0392156862745098, 'micro avg_recall': 0.02247191011235955, 'micro avg_f1-score': 0.02857142857142857, 'micro avg_support': 89.0, 'macro avg_precision': 0.0392156862745098, 'macro avg_recall': 0.02247191011235955, 'macro avg_f1-score': 0.02857142857142857, 'macro avg_support': 89.0, 'weighted avg_precision': 0.0392156862745098, 'weighted avg_recall': 0.02247191011235955, 'weighted avg_f1-score': 0.02857142857142857, 'weighted avg_support': 89.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 0}, {'micro_f1': 0.7721843003412968, 'precision': 0.7721843003412969, 'Consequential_Oversimplification_precision': 0.058823529411764705, 'Consequential_Oversimplification_recall': 0.023809523809523808, 'Consequential_Oversimplification_f1-score': 0.033898305084745756, 'Consequential_Oversimplification_support': 126.0, 'micro avg_precision': 0.058823529411764705, 'micro avg_recall': 0.023809523809523808, 'micro avg_f1-score': 0.033898305084745756, 'micro avg_support': 126.0, 'macro avg_precision': 0.058823529411764705, 'macro avg_recall': 0.023809523809523808, 'macro avg_f1-score': 0.033898305084745756, 'macro avg_support': 126.0, 'weighted avg_precision': 0.058823529411764705, 'weighted avg_recall': 0.023809523809523808, 'weighted avg_f1-score': 0.033898305084745756, 'weighted avg_support': 126.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 1}, {'micro_f1': 0.8549488054607508, 'precision': 0.8549488054607508, 'Consequential_Oversimplification_precision': 0.3137254901960784, 'Consequential_Oversimplification_recall': 0.19753086419753085, 'Consequential_Oversimplification_f1-score': 0.24242424242424243, 'Consequential_Oversimplification_support': 81.0, 'micro avg_precision': 0.3137254901960784, 'micro avg_recall': 0.19753086419753085, 'micro avg_f1-score': 0.24242424242424243, 'micro avg_support': 81.0, 'macro avg_precision': 0.3137254901960784, 'macro avg_recall': 0.19753086419753085, 'macro avg_f1-score': 0.24242424242424243, 'macro avg_support': 81.0, 'weighted avg_precision': 0.3137254901960784, 'weighted avg_recall': 0.19753086419753085, 'weighted avg_f1-score': 0.24242424242424243, 'weighted avg_support': 81.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 2}, {'micro_f1': 0.8771331058020477, 'precision': 0.8771331058020477, 'Consequential_Oversimplification_precision': 0.2549019607843137, 'Consequential_Oversimplification_recall': 0.1625, 'Consequential_Oversimplification_f1-score': 0.19847328244274812, 'Consequential_Oversimplification_support': 80.0, 'micro avg_precision': 0.2549019607843137, 'micro avg_recall': 0.1625, 'micro avg_f1-score': 0.19847328244274812, 'micro avg_support': 80.0, 'macro avg_precision': 0.2549019607843137, 'macro avg_recall': 0.1625, 'macro avg_f1-score': 0.19847328244274812, 'macro avg_support': 80.0, 'weighted avg_precision': 0.2549019607843137, 'weighted avg_recall': 0.1625, 'weighted avg_f1-score': 0.19847328244274812, 'weighted avg_support': 80.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 3}, {'micro_f1': 0.8515358361774744, 'precision': 0.8515358361774744, 'Consequential_Oversimplification_precision': 0.37254901960784315, 'Consequential_Oversimplification_recall': 0.2111111111111111, 'Consequential_Oversimplification_f1-score': 0.2695035460992908, 'Consequential_Oversimplification_support': 90.0, 'micro avg_precision': 0.37254901960784315, 'micro avg_recall': 0.2111111111111111, 'micro avg_f1-score': 0.2695035460992908, 'micro avg_support': 90.0, 'macro avg_precision': 0.37254901960784315, 'macro avg_recall': 0.2111111111111111, 'macro avg_f1-score': 0.2695035460992908, 'macro avg_support': 90.0, 'weighted avg_precision': 0.37254901960784315, 'weighted avg_recall': 0.2111111111111111, 'weighted avg_f1-score': 0.2695035460992908, 'weighted avg_support': 90.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 4}, {'micro_f1': 0.8553754266211604, 'precision': 0.8553754266211604, 'Consequential_Oversimplification_precision': 0.43137254901960786, 'Consequential_Oversimplification_recall': 0.2619047619047619, 'Consequential_Oversimplification_f1-score': 0.32592592592592595, 'Consequential_Oversimplification_support': 84.0, 'micro avg_precision': 0.43137254901960786, 'micro avg_recall': 0.2619047619047619, 'micro avg_f1-score': 0.32592592592592595, 'micro avg_support': 84.0, 'macro avg_precision': 0.43137254901960786, 'macro avg_recall': 0.2619047619047619, 'macro avg_f1-score': 0.32592592592592595, 'macro avg_support': 84.0, 'weighted avg_precision': 0.4313725490196078, 'weighted avg_recall': 0.2619047619047619, 'weighted avg_f1-score': 0.32592592592592595, 'weighted avg_support': 84.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 5}, {'micro_f1': 0.8720136518771331, 'precision': 0.8720136518771331, 'Consequential_Oversimplification_precision': 0.4117647058823529, 'Consequential_Oversimplification_recall': 0.2413793103448276, 'Consequential_Oversimplification_f1-score': 0.3043478260869565, 'Consequential_Oversimplification_support': 87.0, 'micro avg_precision': 0.4117647058823529, 'micro avg_recall': 0.2413793103448276, 'micro avg_f1-score': 0.3043478260869565, 'micro avg_support': 87.0, 'macro avg_precision': 0.4117647058823529, 'macro avg_recall': 0.2413793103448276, 'macro avg_f1-score': 0.3043478260869565, 'macro avg_support': 87.0, 'weighted avg_precision': 0.4117647058823529, 'weighted avg_recall': 0.2413793103448276, 'weighted avg_f1-score': 0.3043478260869565, 'weighted avg_support': 87.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 6}, {'micro_f1': 0.8784129692832765, 'precision': 0.8784129692832765, 'Consequential_Oversimplification_precision': 0.43137254901960786, 'Consequential_Oversimplification_recall': 0.27848101265822783, 'Consequential_Oversimplification_f1-score': 0.3384615384615385, 'Consequential_Oversimplification_support': 79.0, 'micro avg_precision': 0.43137254901960786, 'micro avg_recall': 0.27848101265822783, 'micro avg_f1-score': 0.3384615384615385, 'micro avg_support': 79.0, 'macro avg_precision': 0.43137254901960786, 'macro avg_recall': 0.27848101265822783, 'macro avg_f1-score': 0.3384615384615385, 'macro avg_support': 79.0, 'weighted avg_precision': 0.43137254901960786, 'weighted avg_recall': 0.27848101265822783, 'weighted avg_f1-score': 0.3384615384615385, 'weighted avg_support': 79.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 7}, {'micro_f1': 0.8745733788395904, 'precision': 0.8745733788395904, 'Consequential_Oversimplification_precision': 0.4117647058823529, 'Consequential_Oversimplification_recall': 0.25925925925925924, 'Consequential_Oversimplification_f1-score': 0.3181818181818182, 'Consequential_Oversimplification_support': 81.0, 'micro avg_precision': 0.4117647058823529, 'micro avg_recall': 0.25925925925925924, 'micro avg_f1-score': 0.3181818181818182, 'micro avg_support': 81.0, 'macro avg_precision': 0.4117647058823529, 'macro avg_recall': 0.25925925925925924, 'macro avg_f1-score': 0.3181818181818182, 'macro avg_support': 81.0, 'weighted avg_precision': 0.4117647058823529, 'weighted avg_recall': 0.25925925925925924, 'weighted avg_f1-score': 0.3181818181818182, 'weighted avg_support': 81.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 8}]}
{'micro_f1': 0.867320819112628, 'precision': 0.867320819112628, 'Consequential_Oversimplification_precision': 0.45098039215686275, 'Consequential_Oversimplification_recall': 0.2875, 'Consequential_Oversimplification_f1-score': 0.35114503816793885, 'Consequential_Oversimplification_support': 80.0, 'micro avg_precision': 0.45098039215686275, 'micro avg_recall': 0.2875, 'micro avg_f1-score': 0.35114503816793885, 'micro avg_support': 80.0, 'macro avg_precision': 0.45098039215686275, 'macro avg_recall': 0.2875, 'macro avg_f1-score': 0.35114503816793885, 'macro avg_support': 80.0, 'weighted avg_precision': 0.45098039215686275, 'weighted avg_recall': 0.2875, 'weighted avg_f1-score': 0.35114503816793885, 'weighted avg_support': 80.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 9}
{'results': [{'micro_f1': 0.841296928327645, 'precision': 0.841296928327645, 'Consequential_Oversimplification_precision': 0.0392156862745098, 'Consequential_Oversimplification_recall': 0.02247191011235955, 'Consequential_Oversimplification_f1-score': 0.02857142857142857, 'Consequential_Oversimplification_support': 89.0, 'micro avg_precision': 0.0392156862745098, 'micro avg_recall': 0.02247191011235955, 'micro avg_f1-score': 0.02857142857142857, 'micro avg_support': 89.0, 'macro avg_precision': 0.0392156862745098, 'macro avg_recall': 0.02247191011235955, 'macro avg_f1-score': 0.02857142857142857, 'macro avg_support': 89.0, 'weighted avg_precision': 0.0392156862745098, 'weighted avg_recall': 0.02247191011235955, 'weighted avg_f1-score': 0.02857142857142857, 'weighted avg_support': 89.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 0}, {'micro_f1': 0.7721843003412968, 'precision': 0.7721843003412969, 'Consequential_Oversimplification_precision': 0.058823529411764705, 'Consequential_Oversimplification_recall': 0.023809523809523808, 'Consequential_Oversimplification_f1-score': 0.033898305084745756, 'Consequential_Oversimplification_support': 126.0, 'micro avg_precision': 0.058823529411764705, 'micro avg_recall': 0.023809523809523808, 'micro avg_f1-score': 0.033898305084745756, 'micro avg_support': 126.0, 'macro avg_precision': 0.058823529411764705, 'macro avg_recall': 0.023809523809523808, 'macro avg_f1-score': 0.033898305084745756, 'macro avg_support': 126.0, 'weighted avg_precision': 0.058823529411764705, 'weighted avg_recall': 0.023809523809523808, 'weighted avg_f1-score': 0.033898305084745756, 'weighted avg_support': 126.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 1}, {'micro_f1': 0.8549488054607508, 'precision': 0.8549488054607508, 'Consequential_Oversimplification_precision': 0.3137254901960784, 'Consequential_Oversimplification_recall': 0.19753086419753085, 'Consequential_Oversimplification_f1-score': 0.24242424242424243, 'Consequential_Oversimplification_support': 81.0, 'micro avg_precision': 0.3137254901960784, 'micro avg_recall': 0.19753086419753085, 'micro avg_f1-score': 0.24242424242424243, 'micro avg_support': 81.0, 'macro avg_precision': 0.3137254901960784, 'macro avg_recall': 0.19753086419753085, 'macro avg_f1-score': 0.24242424242424243, 'macro avg_support': 81.0, 'weighted avg_precision': 0.3137254901960784, 'weighted avg_recall': 0.19753086419753085, 'weighted avg_f1-score': 0.24242424242424243, 'weighted avg_support': 81.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 2}, {'micro_f1': 0.8771331058020477, 'precision': 0.8771331058020477, 'Consequential_Oversimplification_precision': 0.2549019607843137, 'Consequential_Oversimplification_recall': 0.1625, 'Consequential_Oversimplification_f1-score': 0.19847328244274812, 'Consequential_Oversimplification_support': 80.0, 'micro avg_precision': 0.2549019607843137, 'micro avg_recall': 0.1625, 'micro avg_f1-score': 0.19847328244274812, 'micro avg_support': 80.0, 'macro avg_precision': 0.2549019607843137, 'macro avg_recall': 0.1625, 'macro avg_f1-score': 0.19847328244274812, 'macro avg_support': 80.0, 'weighted avg_precision': 0.2549019607843137, 'weighted avg_recall': 0.1625, 'weighted avg_f1-score': 0.19847328244274812, 'weighted avg_support': 80.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 3}, {'micro_f1': 0.8515358361774744, 'precision': 0.8515358361774744, 'Consequential_Oversimplification_precision': 0.37254901960784315, 'Consequential_Oversimplification_recall': 0.2111111111111111, 'Consequential_Oversimplification_f1-score': 0.2695035460992908, 'Consequential_Oversimplification_support': 90.0, 'micro avg_precision': 0.37254901960784315, 'micro avg_recall': 0.2111111111111111, 'micro avg_f1-score': 0.2695035460992908, 'micro avg_support': 90.0, 'macro avg_precision': 0.37254901960784315, 'macro avg_recall': 0.2111111111111111, 'macro avg_f1-score': 0.2695035460992908, 'macro avg_support': 90.0, 'weighted avg_precision': 0.37254901960784315, 'weighted avg_recall': 0.2111111111111111, 'weighted avg_f1-score': 0.2695035460992908, 'weighted avg_support': 90.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 4}, {'micro_f1': 0.8553754266211604, 'precision': 0.8553754266211604, 'Consequential_Oversimplification_precision': 0.43137254901960786, 'Consequential_Oversimplification_recall': 0.2619047619047619, 'Consequential_Oversimplification_f1-score': 0.32592592592592595, 'Consequential_Oversimplification_support': 84.0, 'micro avg_precision': 0.43137254901960786, 'micro avg_recall': 0.2619047619047619, 'micro avg_f1-score': 0.32592592592592595, 'micro avg_support': 84.0, 'macro avg_precision': 0.43137254901960786, 'macro avg_recall': 0.2619047619047619, 'macro avg_f1-score': 0.32592592592592595, 'macro avg_support': 84.0, 'weighted avg_precision': 0.4313725490196078, 'weighted avg_recall': 0.2619047619047619, 'weighted avg_f1-score': 0.32592592592592595, 'weighted avg_support': 84.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 5}, {'micro_f1': 0.8720136518771331, 'precision': 0.8720136518771331, 'Consequential_Oversimplification_precision': 0.4117647058823529, 'Consequential_Oversimplification_recall': 0.2413793103448276, 'Consequential_Oversimplification_f1-score': 0.3043478260869565, 'Consequential_Oversimplification_support': 87.0, 'micro avg_precision': 0.4117647058823529, 'micro avg_recall': 0.2413793103448276, 'micro avg_f1-score': 0.3043478260869565, 'micro avg_support': 87.0, 'macro avg_precision': 0.4117647058823529, 'macro avg_recall': 0.2413793103448276, 'macro avg_f1-score': 0.3043478260869565, 'macro avg_support': 87.0, 'weighted avg_precision': 0.4117647058823529, 'weighted avg_recall': 0.2413793103448276, 'weighted avg_f1-score': 0.3043478260869565, 'weighted avg_support': 87.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 6}, {'micro_f1': 0.8784129692832765, 'precision': 0.8784129692832765, 'Consequential_Oversimplification_precision': 0.43137254901960786, 'Consequential_Oversimplification_recall': 0.27848101265822783, 'Consequential_Oversimplification_f1-score': 0.3384615384615385, 'Consequential_Oversimplification_support': 79.0, 'micro avg_precision': 0.43137254901960786, 'micro avg_recall': 0.27848101265822783, 'micro avg_f1-score': 0.3384615384615385, 'micro avg_support': 79.0, 'macro avg_precision': 0.43137254901960786, 'macro avg_recall': 0.27848101265822783, 'macro avg_f1-score': 0.3384615384615385, 'macro avg_support': 79.0, 'weighted avg_precision': 0.43137254901960786, 'weighted avg_recall': 0.27848101265822783, 'weighted avg_f1-score': 0.3384615384615385, 'weighted avg_support': 79.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 7}, {'micro_f1': 0.8745733788395904, 'precision': 0.8745733788395904, 'Consequential_Oversimplification_precision': 0.4117647058823529, 'Consequential_Oversimplification_recall': 0.25925925925925924, 'Consequential_Oversimplification_f1-score': 0.3181818181818182, 'Consequential_Oversimplification_support': 81.0, 'micro avg_precision': 0.4117647058823529, 'micro avg_recall': 0.25925925925925924, 'micro avg_f1-score': 0.3181818181818182, 'micro avg_support': 81.0, 'macro avg_precision': 0.4117647058823529, 'macro avg_recall': 0.25925925925925924, 'macro avg_f1-score': 0.3181818181818182, 'macro avg_support': 81.0, 'weighted avg_precision': 0.4117647058823529, 'weighted avg_recall': 0.25925925925925924, 'weighted avg_f1-score': 0.3181818181818182, 'weighted avg_support': 81.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 8}, {'micro_f1': 0.867320819112628, 'precision': 0.867320819112628, 'Consequential_Oversimplification_precision': 0.45098039215686275, 'Consequential_Oversimplification_recall': 0.2875, 'Consequential_Oversimplification_f1-score': 0.35114503816793885, 'Consequential_Oversimplification_support': 80.0, 'micro avg_precision': 0.45098039215686275, 'micro avg_recall': 0.2875, 'micro avg_f1-score': 0.35114503816793885, 'micro avg_support': 80.0, 'macro avg_precision': 0.45098039215686275, 'macro avg_recall': 0.2875, 'macro avg_f1-score': 0.35114503816793885, 'macro avg_support': 80.0, 'weighted avg_precision': 0.45098039215686275, 'weighted avg_recall': 0.2875, 'weighted avg_f1-score': 0.35114503816793885, 'weighted avg_support': 80.0, 'O_support': 993, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 9}]}
Best model updated: current epoch macro f1 = 0.35114503816793885
Saving model to directory: ./models/M2/2024-05-13-23-08-48_aug/mdeberta-v3-base_7_ME10_target=Consequential_Oversimplification_SUBSAMPLED_2024-05-13-23-08-48
Training model no. 8 of 23 for (8, 'Straw_Man') persuasion technique...
{'micro_f1': 0.7539813289401428, 'precision': 0.7539813289401428, 'Straw_Man_precision': 0.044444444444444446, 'Straw_Man_recall': 0.0196078431372549, 'Straw_Man_f1-score': 0.0272108843537415, 'Straw_Man_support': 102.0, 'micro avg_precision': 0.044444444444444446, 'micro avg_recall': 0.0196078431372549, 'micro avg_f1-score': 0.0272108843537415, 'micro avg_support': 102.0, 'macro avg_precision': 0.044444444444444446, 'macro avg_recall': 0.0196078431372549, 'macro avg_f1-score': 0.0272108843537415, 'macro avg_support': 102.0, 'weighted avg_precision': 0.044444444444444446, 'weighted avg_recall': 0.0196078431372549, 'weighted avg_f1-score': 0.0272108843537415, 'weighted avg_support': 102.0, 'O_support': 1048, 'B-Straw_Man_support': 45, 'I-Straw_Man_support': 728, 'epoch': 0}
{'results': [{'micro_f1': 0.7539813289401428, 'precision': 0.7539813289401428, 'Straw_Man_precision': 0.044444444444444446, 'Straw_Man_recall': 0.0196078431372549, 'Straw_Man_f1-score': 0.0272108843537415, 'Straw_Man_support': 102.0, 'micro avg_precision': 0.044444444444444446, 'micro avg_recall': 0.0196078431372549, 'micro avg_f1-score': 0.0272108843537415, 'micro avg_support': 102.0, 'macro avg_precision': 0.044444444444444446, 'macro avg_recall': 0.0196078431372549, 'macro avg_f1-score': 0.0272108843537415, 'macro avg_support': 102.0, 'weighted avg_precision': 0.044444444444444446, 'weighted avg_recall': 0.0196078431372549, 'weighted avg_f1-score': 0.0272108843537415, 'weighted avg_support': 102.0, 'O_support': 1048, 'B-Straw_Man_support': 45, 'I-Straw_Man_support': 728, 'epoch': 0}]}
Best model updated: current epoch macro f1 = 0.0272108843537415
{'micro_f1': 0.7226798462383306, 'precision': 0.7226798462383306, 'Straw_Man_precision': 0.08888888888888889, 'Straw_Man_recall': 0.038834951456310676, 'Straw_Man_f1-score': 0.05405405405405406, 'Straw_Man_support': 103.0, 'micro avg_precision': 0.08888888888888889, 'micro avg_recall': 0.038834951456310676, 'micro avg_f1-score': 0.05405405405405406, 'micro avg_support': 103.0, 'macro avg_precision': 0.08888888888888889, 'macro avg_recall': 0.038834951456310676, 'macro avg_f1-score': 0.05405405405405406, 'macro avg_support': 103.0, 'weighted avg_precision': 0.0888888888888889, 'weighted avg_recall': 0.038834951456310676, 'weighted avg_f1-score': 0.05405405405405406, 'weighted avg_support': 103.0, 'O_support': 1048, 'B-Straw_Man_support': 45, 'I-Straw_Man_support': 728, 'epoch': 1}
{'results': [{'micro_f1': 0.7539813289401428, 'precision': 0.7539813289401428, 'Straw_Man_precision': 0.044444444444444446, 'Straw_Man_recall': 0.0196078431372549, 'Straw_Man_f1-score': 0.0272108843537415, 'Straw_Man_support': 102.0, 'micro avg_precision': 0.044444444444444446, 'micro avg_recall': 0.0196078431372549, 'micro avg_f1-score': 0.0272108843537415, 'micro avg_support': 102.0, 'macro avg_precision': 0.044444444444444446, 'macro avg_recall': 0.0196078431372549, 'macro avg_f1-score': 0.0272108843537415, 'macro avg_support': 102.0, 'weighted avg_precision': 0.044444444444444446, 'weighted avg_recall': 0.0196078431372549, 'weighted avg_f1-score': 0.0272108843537415, 'weighted avg_support': 102.0, 'O_support': 1048, 'B-Straw_Man_support': 45, 'I-Straw_Man_support': 728, 'epoch': 0}, {'micro_f1': 0.7226798462383306, 'precision': 0.7226798462383306, 'Straw_Man_precision': 0.08888888888888889, 'Straw_Man_recall': 0.038834951456310676, 'Straw_Man_f1-score': 0.05405405405405406, 'Straw_Man_support': 103.0, 'micro avg_precision': 0.08888888888888889, 'micro avg_recall': 0.038834951456310676, 'micro avg_f1-score': 0.05405405405405406, 'micro avg_support': 103.0, 'macro avg_precision': 0.08888888888888889, 'macro avg_recall': 0.038834951456310676, 'macro avg_f1-score': 0.05405405405405406, 'macro avg_support': 103.0, 'weighted avg_precision': 0.0888888888888889, 'weighted avg_recall': 0.038834951456310676, 'weighted avg_f1-score': 0.05405405405405406, 'weighted avg_support': 103.0, 'O_support': 1048, 'B-Straw_Man_support': 45, 'I-Straw_Man_support': 728, 'epoch': 1}]}
Best model updated: current epoch macro f1 = 0.05405405405405406
{'micro_f1': 0.7869302580999451, 'precision': 0.7869302580999451, 'Straw_Man_precision': 0.2, 'Straw_Man_recall': 0.10843373493975904, 'Straw_Man_f1-score': 0.140625, 'Straw_Man_support': 83.0, 'micro avg_precision': 0.2, 'micro avg_recall': 0.10843373493975904, 'micro avg_f1-score': 0.140625, 'micro avg_support': 83.0, 'macro avg_precision': 0.2, 'macro avg_recall': 0.10843373493975904, 'macro avg_f1-score': 0.140625, 'macro avg_support': 83.0, 'weighted avg_precision': 0.2, 'weighted avg_recall': 0.10843373493975904, 'weighted avg_f1-score': 0.140625, 'weighted avg_support': 83.0, 'O_support': 1048, 'B-Straw_Man_support': 45, 'I-Straw_Man_support': 728, 'epoch': 2}
{'results': [{'micro_f1': 0.7539813289401428, 'precision': 0.7539813289401428, 'Straw_Man_precision': 0.044444444444444446, 'Straw_Man_recall': 0.0196078431372549, 'Straw_Man_f1-score': 0.0272108843537415, 'Straw_Man_support': 102.0, 'micro avg_precision': 0.044444444444444446, 'micro avg_recall': 0.0196078431372549, 'micro avg_f1-score': 0.0272108843537415, 'micro avg_support': 102.0, 'macro avg_precision': 0.044444444444444446, 'macro avg_recall': 0.0196078431372549, 'macro avg_f1-score': 0.0272108843537415, 'macro avg_support': 102.0, 'weighted avg_precision': 0.044444444444444446, 'weighted avg_recall': 0.0196078431372549, 'weighted avg_f1-score': 0.0272108843537415, 'weighted avg_support': 102.0, 'O_support': 1048, 'B-Straw_Man_support': 45, 'I-Straw_Man_support': 728, 'epoch': 0}, {'micro_f1': 0.7226798462383306, 'precision': 0.7226798462383306, 'Straw_Man_precision': 0.08888888888888889, 'Straw_Man_recall': 0.038834951456310676, 'Straw_Man_f1-score': 0.05405405405405406, 'Straw_Man_support': 103.0, 'micro avg_precision': 0.08888888888888889, 'micro avg_recall': 0.038834951456310676, 'micro avg_f1-score': 0.05405405405405406, 'micro avg_support': 103.0, 'macro avg_precision': 0.08888888888888889, 'macro avg_recall': 0.038834951456310676, 'macro avg_f1-score': 0.05405405405405406, 'macro avg_support': 103.0, 'weighted avg_precision': 0.0888888888888889, 'weighted avg_recall': 0.038834951456310676, 'weighted avg_f1-score': 0.05405405405405406, 'weighted avg_support': 103.0, 'O_support': 1048, 'B-Straw_Man_support': 45, 'I-Straw_Man_support': 728, 'epoch': 1}, {'micro_f1': 0.7869302580999451, 'precision': 0.7869302580999451, 'Straw_Man_precision': 0.2, 'Straw_Man_recall': 0.10843373493975904, 'Straw_Man_f1-score': 0.140625, 'Straw_Man_support': 83.0, 'micro avg_precision': 0.2, 'micro avg_recall': 0.10843373493975904, 'micro avg_f1-score': 0.140625, 'micro avg_support': 83.0, 'macro avg_precision': 0.2, 'macro avg_recall': 0.10843373493975904, 'macro avg_f1-score': 0.140625, 'macro avg_support': 83.0, 'weighted avg_precision': 0.2, 'weighted avg_recall': 0.10843373493975904, 'weighted avg_f1-score': 0.140625, 'weighted avg_support': 83.0, 'O_support': 1048, 'B-Straw_Man_support': 45, 'I-Straw_Man_support': 728, 'epoch': 2}]}
Best model updated: current epoch macro f1 = 0.140625
{'micro_f1': 0.7764964305326744, 'precision': 0.7764964305326744, 'Straw_Man_precision': 0.06666666666666667, 'Straw_Man_recall': 0.0379746835443038, 'Straw_Man_f1-score': 0.048387096774193554, 'Straw_Man_support': 79.0, 'micro avg_precision': 0.06666666666666667, 'micro avg_recall': 0.0379746835443038, 'micro avg_f1-score': 0.048387096774193554, 'micro avg_support': 79.0, 'macro avg_precision': 0.06666666666666667, 'macro avg_recall': 0.0379746835443038, 'macro avg_f1-score': 0.048387096774193554, 'macro avg_support': 79.0, 'weighted avg_precision': 0.06666666666666667, 'weighted avg_recall': 0.0379746835443038, 'weighted avg_f1-score': 0.048387096774193554, 'weighted avg_support': 79.0, 'O_support': 1048, 'B-Straw_Man_support': 45, 'I-Straw_Man_support': 728, 'epoch': 3}
{'results': [{'micro_f1': 0.7539813289401428, 'precision': 0.7539813289401428, 'Straw_Man_precision': 0.044444444444444446, 'Straw_Man_recall': 0.0196078431372549, 'Straw_Man_f1-score': 0.0272108843537415, 'Straw_Man_support': 102.0, 'micro avg_precision': 0.044444444444444446, 'micro avg_recall': 0.0196078431372549, 'micro avg_f1-score': 0.0272108843537415, 'micro avg_support': 102.0, 'macro avg_precision': 0.044444444444444446, 'macro avg_recall': 0.0196078431372549, 'macro avg_f1-score': 0.0272108843537415, 'macro avg_support': 102.0, 'weighted avg_precision': 0.044444444444444446, 'weighted avg_recall': 0.0196078431372549, 'weighted avg_f1-score': 0.0272108843537415, 'weighted avg_support': 102.0, 'O_support': 1048, 'B-Straw_Man_support': 45, 'I-Straw_Man_support': 728, 'epoch': 0}, {'micro_f1': 0.7226798462383306, 'precision': 0.7226798462383306, 'Straw_Man_precision': 0.08888888888888889, 'Straw_Man_recall': 0.038834951456310676, 'Straw_Man_f1-score': 0.05405405405405406, 'Straw_Man_support': 103.0, 'micro avg_precision': 0.08888888888888889, 'micro avg_recall': 0.038834951456310676, 'micro avg_f1-score': 0.05405405405405406, 'micro avg_support': 103.0, 'macro avg_precision': 0.08888888888888889, 'macro avg_recall': 0.038834951456310676, 'macro avg_f1-score': 0.05405405405405406, 'macro avg_support': 103.0, 'weighted avg_precision': 0.0888888888888889, 'weighted avg_recall': 0.038834951456310676, 'weighted avg_f1-score': 0.05405405405405406, 'weighted avg_support': 103.0, 'O_support': 1048, 'B-Straw_Man_support': 45, 'I-Straw_Man_support': 728, 'epoch': 1}, {'micro_f1': 0.7869302580999451, 'precision': 0.7869302580999451, 'Straw_Man_precision': 0.2, 'Straw_Man_recall': 0.10843373493975904, 'Straw_Man_f1-score': 0.140625, 'Straw_Man_support': 83.0, 'micro avg_precision': 0.2, 'micro avg_recall': 0.10843373493975904, 'micro avg_f1-score': 0.140625, 'micro avg_support': 83.0, 'macro avg_precision': 0.2, 'macro avg_recall': 0.10843373493975904, 'macro avg_f1-score': 0.140625, 'macro avg_support': 83.0, 'weighted avg_precision': 0.2, 'weighted avg_recall': 0.10843373493975904, 'weighted avg_f1-score': 0.140625, 'weighted avg_support': 83.0, 'O_support': 1048, 'B-Straw_Man_support': 45, 'I-Straw_Man_support': 728, 'epoch': 2}, {'micro_f1': 0.7764964305326744, 'precision': 0.7764964305326744, 'Straw_Man_precision': 0.06666666666666667, 'Straw_Man_recall': 0.0379746835443038, 'Straw_Man_f1-score': 0.048387096774193554, 'Straw_Man_support': 79.0, 'micro avg_precision': 0.06666666666666667, 'micro avg_recall': 0.0379746835443038, 'micro avg_f1-score': 0.048387096774193554, 'micro avg_support': 79.0, 'macro avg_precision': 0.06666666666666667, 'macro avg_recall': 0.0379746835443038, 'macro avg_f1-score': 0.048387096774193554, 'macro avg_support': 79.0, 'weighted avg_precision': 0.06666666666666667, 'weighted avg_recall': 0.0379746835443038, 'weighted avg_f1-score': 0.048387096774193554, 'weighted avg_support': 79.0, 'O_support': 1048, 'B-Straw_Man_support': 45, 'I-Straw_Man_support': 728, 'epoch': 3}]}
{'micro_f1': 0.7199341021416804, 'precision': 0.7199341021416804, 'Straw_Man_precision': 0.15555555555555556, 'Straw_Man_recall': 0.08860759493670886, 'Straw_Man_f1-score': 0.11290322580645161, 'Straw_Man_support': 79.0, 'micro avg_precision': 0.15555555555555556, 'micro avg_recall': 0.08860759493670886, 'micro avg_f1-score': 0.11290322580645161, 'micro avg_support': 79.0, 'macro avg_precision': 0.15555555555555556, 'macro avg_recall': 0.08860759493670886, 'macro avg_f1-score': 0.11290322580645161, 'macro avg_support': 79.0, 'weighted avg_precision': 0.15555555555555556, 'weighted avg_recall': 0.08860759493670886, 'weighted avg_f1-score': 0.11290322580645162, 'weighted avg_support': 79.0, 'O_support': 1048, 'B-Straw_Man_support': 45, 'I-Straw_Man_support': 728, 'epoch': 4}
{'results': [{'micro_f1': 0.7539813289401428, 'precision': 0.7539813289401428, 'Straw_Man_precision': 0.044444444444444446, 'Straw_Man_recall': 0.0196078431372549, 'Straw_Man_f1-score': 0.0272108843537415, 'Straw_Man_support': 102.0, 'micro avg_precision': 0.044444444444444446, 'micro avg_recall': 0.0196078431372549, 'micro avg_f1-score': 0.0272108843537415, 'micro avg_support': 102.0, 'macro avg_precision': 0.044444444444444446, 'macro avg_recall': 0.0196078431372549, 'macro avg_f1-score': 0.0272108843537415, 'macro avg_support': 102.0, 'weighted avg_precision': 0.044444444444444446, 'weighted avg_recall': 0.0196078431372549, 'weighted avg_f1-score': 0.0272108843537415, 'weighted avg_support': 102.0, 'O_support': 1048, 'B-Straw_Man_support': 45, 'I-Straw_Man_support': 728, 'epoch': 0}, {'micro_f1': 0.7226798462383306, 'precision': 0.7226798462383306, 'Straw_Man_precision': 0.08888888888888889, 'Straw_Man_recall': 0.038834951456310676, 'Straw_Man_f1-score': 0.05405405405405406, 'Straw_Man_support': 103.0, 'micro avg_precision': 0.08888888888888889, 'micro avg_recall': 0.038834951456310676, 'micro avg_f1-score': 0.05405405405405406, 'micro avg_support': 103.0, 'macro avg_precision': 0.08888888888888889, 'macro avg_recall': 0.038834951456310676, 'macro avg_f1-score': 0.05405405405405406, 'macro avg_support': 103.0, 'weighted avg_precision': 0.0888888888888889, 'weighted avg_recall': 0.038834951456310676, 'weighted avg_f1-score': 0.05405405405405406, 'weighted avg_support': 103.0, 'O_support': 1048, 'B-Straw_Man_support': 45, 'I-Straw_Man_support': 728, 'epoch': 1}, {'micro_f1': 0.7869302580999451, 'precision': 0.7869302580999451, 'Straw_Man_precision': 0.2, 'Straw_Man_recall': 0.10843373493975904, 'Straw_Man_f1-score': 0.140625, 'Straw_Man_support': 83.0, 'micro avg_precision': 0.2, 'micro avg_recall': 0.10843373493975904, 'micro avg_f1-score': 0.140625, 'micro avg_support': 83.0, 'macro avg_precision': 0.2, 'macro avg_recall': 0.10843373493975904, 'macro avg_f1-score': 0.140625, 'macro avg_support': 83.0, 'weighted avg_precision': 0.2, 'weighted avg_recall': 0.10843373493975904, 'weighted avg_f1-score': 0.140625, 'weighted avg_support': 83.0, 'O_support': 1048, 'B-Straw_Man_support': 45, 'I-Straw_Man_support': 728, 'epoch': 2}, {'micro_f1': 0.7764964305326744, 'precision': 0.7764964305326744, 'Straw_Man_precision': 0.06666666666666667, 'Straw_Man_recall': 0.0379746835443038, 'Straw_Man_f1-score': 0.048387096774193554, 'Straw_Man_support': 79.0, 'micro avg_precision': 0.06666666666666667, 'micro avg_recall': 0.0379746835443038, 'micro avg_f1-score': 0.048387096774193554, 'micro avg_support': 79.0, 'macro avg_precision': 0.06666666666666667, 'macro avg_recall': 0.0379746835443038, 'macro avg_f1-score': 0.048387096774193554, 'macro avg_support': 79.0, 'weighted avg_precision': 0.06666666666666667, 'weighted avg_recall': 0.0379746835443038, 'weighted avg_f1-score': 0.048387096774193554, 'weighted avg_support': 79.0, 'O_support': 1048, 'B-Straw_Man_support': 45, 'I-Straw_Man_support': 728, 'epoch': 3}, {'micro_f1': 0.7199341021416804, 'precision': 0.7199341021416804, 'Straw_Man_precision': 0.15555555555555556, 'Straw_Man_recall': 0.08860759493670886, 'Straw_Man_f1-score': 0.11290322580645161, 'Straw_Man_support': 79.0, 'micro avg_precision': 0.15555555555555556, 'micro avg_recall': 0.08860759493670886, 'micro avg_f1-score': 0.11290322580645161, 'micro avg_support': 79.0, 'macro avg_precision': 0.15555555555555556, 'macro avg_recall': 0.08860759493670886, 'macro avg_f1-score': 0.11290322580645161, 'macro avg_support': 79.0, 'weighted avg_precision': 0.15555555555555556, 'weighted avg_recall': 0.08860759493670886, 'weighted avg_f1-score': 0.11290322580645162, 'weighted avg_support': 79.0, 'O_support': 1048, 'B-Straw_Man_support': 45, 'I-Straw_Man_support': 728, 'epoch': 4}]}
Early stopping triggered.
Saving model to directory: ./models/M2/2024-05-13-23-08-48_aug/mdeberta-v3-base_8_ME10_target=Straw_Man_SUBSAMPLED_2024-05-13-23-08-48
Training model no. 9 of 23 for (9, 'Red_Herring') persuasion technique...
{'micro_f1': 0.6686340640809444, 'precision': 0.6686340640809444, 'Red_Herring_precision': 0.0, 'Red_Herring_recall': 0.0, 'Red_Herring_f1-score': 0.0, 'Red_Herring_support': 3.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 3.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 3.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 3.0, 'O_support': 790, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 0}
{'results': [{'micro_f1': 0.6686340640809444, 'precision': 0.6686340640809444, 'Red_Herring_precision': 0.0, 'Red_Herring_recall': 0.0, 'Red_Herring_f1-score': 0.0, 'Red_Herring_support': 3.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 3.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 3.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 3.0, 'O_support': 790, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 0}]}
{'micro_f1': 0.760539629005059, 'precision': 0.760539629005059, 'Red_Herring_precision': 0.043478260869565216, 'Red_Herring_recall': 0.020833333333333332, 'Red_Herring_f1-score': 0.028169014084507043, 'Red_Herring_support': 48.0, 'micro avg_precision': 0.043478260869565216, 'micro avg_recall': 0.020833333333333332, 'micro avg_f1-score': 0.028169014084507043, 'micro avg_support': 48.0, 'macro avg_precision': 0.043478260869565216, 'macro avg_recall': 0.020833333333333332, 'macro avg_f1-score': 0.028169014084507043, 'macro avg_support': 48.0, 'weighted avg_precision': 0.043478260869565216, 'weighted avg_recall': 0.020833333333333332, 'weighted avg_f1-score': 0.028169014084507043, 'weighted avg_support': 48.0, 'O_support': 790, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 1}
{'results': [{'micro_f1': 0.6686340640809444, 'precision': 0.6686340640809444, 'Red_Herring_precision': 0.0, 'Red_Herring_recall': 0.0, 'Red_Herring_f1-score': 0.0, 'Red_Herring_support': 3.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 3.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 3.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 3.0, 'O_support': 790, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 0}, {'micro_f1': 0.760539629005059, 'precision': 0.760539629005059, 'Red_Herring_precision': 0.043478260869565216, 'Red_Herring_recall': 0.020833333333333332, 'Red_Herring_f1-score': 0.028169014084507043, 'Red_Herring_support': 48.0, 'micro avg_precision': 0.043478260869565216, 'micro avg_recall': 0.020833333333333332, 'micro avg_f1-score': 0.028169014084507043, 'micro avg_support': 48.0, 'macro avg_precision': 0.043478260869565216, 'macro avg_recall': 0.020833333333333332, 'macro avg_f1-score': 0.028169014084507043, 'macro avg_support': 48.0, 'weighted avg_precision': 0.043478260869565216, 'weighted avg_recall': 0.020833333333333332, 'weighted avg_f1-score': 0.028169014084507043, 'weighted avg_support': 48.0, 'O_support': 790, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 1}]}
Best model updated: current epoch macro f1 = 0.028169014084507043
{'micro_f1': 0.7731871838111298, 'precision': 0.7731871838111298, 'Red_Herring_precision': 0.13043478260869565, 'Red_Herring_recall': 0.08333333333333333, 'Red_Herring_f1-score': 0.10169491525423728, 'Red_Herring_support': 36.0, 'micro avg_precision': 0.13043478260869565, 'micro avg_recall': 0.08333333333333333, 'micro avg_f1-score': 0.10169491525423728, 'micro avg_support': 36.0, 'macro avg_precision': 0.13043478260869565, 'macro avg_recall': 0.08333333333333333, 'macro avg_f1-score': 0.10169491525423728, 'macro avg_support': 36.0, 'weighted avg_precision': 0.13043478260869565, 'weighted avg_recall': 0.08333333333333333, 'weighted avg_f1-score': 0.10169491525423728, 'weighted avg_support': 36.0, 'O_support': 790, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 2}
{'results': [{'micro_f1': 0.6686340640809444, 'precision': 0.6686340640809444, 'Red_Herring_precision': 0.0, 'Red_Herring_recall': 0.0, 'Red_Herring_f1-score': 0.0, 'Red_Herring_support': 3.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 3.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 3.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 3.0, 'O_support': 790, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 0}, {'micro_f1': 0.760539629005059, 'precision': 0.760539629005059, 'Red_Herring_precision': 0.043478260869565216, 'Red_Herring_recall': 0.020833333333333332, 'Red_Herring_f1-score': 0.028169014084507043, 'Red_Herring_support': 48.0, 'micro avg_precision': 0.043478260869565216, 'micro avg_recall': 0.020833333333333332, 'micro avg_f1-score': 0.028169014084507043, 'micro avg_support': 48.0, 'macro avg_precision': 0.043478260869565216, 'macro avg_recall': 0.020833333333333332, 'macro avg_f1-score': 0.028169014084507043, 'macro avg_support': 48.0, 'weighted avg_precision': 0.043478260869565216, 'weighted avg_recall': 0.020833333333333332, 'weighted avg_f1-score': 0.028169014084507043, 'weighted avg_support': 48.0, 'O_support': 790, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 1}, {'micro_f1': 0.7731871838111298, 'precision': 0.7731871838111298, 'Red_Herring_precision': 0.13043478260869565, 'Red_Herring_recall': 0.08333333333333333, 'Red_Herring_f1-score': 0.10169491525423728, 'Red_Herring_support': 36.0, 'micro avg_precision': 0.13043478260869565, 'micro avg_recall': 0.08333333333333333, 'micro avg_f1-score': 0.10169491525423728, 'micro avg_support': 36.0, 'macro avg_precision': 0.13043478260869565, 'macro avg_recall': 0.08333333333333333, 'macro avg_f1-score': 0.10169491525423728, 'macro avg_support': 36.0, 'weighted avg_precision': 0.13043478260869565, 'weighted avg_recall': 0.08333333333333333, 'weighted avg_f1-score': 0.10169491525423728, 'weighted avg_support': 36.0, 'O_support': 790, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 2}]}
Best model updated: current epoch macro f1 = 0.10169491525423728
{'micro_f1': 0.7655986509274875, 'precision': 0.7655986509274874, 'Red_Herring_precision': 0.4782608695652174, 'Red_Herring_recall': 0.1896551724137931, 'Red_Herring_f1-score': 0.271604938271605, 'Red_Herring_support': 58.0, 'micro avg_precision': 0.4782608695652174, 'micro avg_recall': 0.1896551724137931, 'micro avg_f1-score': 0.271604938271605, 'micro avg_support': 58.0, 'macro avg_precision': 0.4782608695652174, 'macro avg_recall': 0.1896551724137931, 'macro avg_f1-score': 0.271604938271605, 'macro avg_support': 58.0, 'weighted avg_precision': 0.4782608695652174, 'weighted avg_recall': 0.1896551724137931, 'weighted avg_f1-score': 0.271604938271605, 'weighted avg_support': 58.0, 'O_support': 790, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 3}
{'results': [{'micro_f1': 0.6686340640809444, 'precision': 0.6686340640809444, 'Red_Herring_precision': 0.0, 'Red_Herring_recall': 0.0, 'Red_Herring_f1-score': 0.0, 'Red_Herring_support': 3.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 3.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 3.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 3.0, 'O_support': 790, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 0}, {'micro_f1': 0.760539629005059, 'precision': 0.760539629005059, 'Red_Herring_precision': 0.043478260869565216, 'Red_Herring_recall': 0.020833333333333332, 'Red_Herring_f1-score': 0.028169014084507043, 'Red_Herring_support': 48.0, 'micro avg_precision': 0.043478260869565216, 'micro avg_recall': 0.020833333333333332, 'micro avg_f1-score': 0.028169014084507043, 'micro avg_support': 48.0, 'macro avg_precision': 0.043478260869565216, 'macro avg_recall': 0.020833333333333332, 'macro avg_f1-score': 0.028169014084507043, 'macro avg_support': 48.0, 'weighted avg_precision': 0.043478260869565216, 'weighted avg_recall': 0.020833333333333332, 'weighted avg_f1-score': 0.028169014084507043, 'weighted avg_support': 48.0, 'O_support': 790, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 1}, {'micro_f1': 0.7731871838111298, 'precision': 0.7731871838111298, 'Red_Herring_precision': 0.13043478260869565, 'Red_Herring_recall': 0.08333333333333333, 'Red_Herring_f1-score': 0.10169491525423728, 'Red_Herring_support': 36.0, 'micro avg_precision': 0.13043478260869565, 'micro avg_recall': 0.08333333333333333, 'micro avg_f1-score': 0.10169491525423728, 'micro avg_support': 36.0, 'macro avg_precision': 0.13043478260869565, 'macro avg_recall': 0.08333333333333333, 'macro avg_f1-score': 0.10169491525423728, 'macro avg_support': 36.0, 'weighted avg_precision': 0.13043478260869565, 'weighted avg_recall': 0.08333333333333333, 'weighted avg_f1-score': 0.10169491525423728, 'weighted avg_support': 36.0, 'O_support': 790, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 2}, {'micro_f1': 0.7655986509274875, 'precision': 0.7655986509274874, 'Red_Herring_precision': 0.4782608695652174, 'Red_Herring_recall': 0.1896551724137931, 'Red_Herring_f1-score': 0.271604938271605, 'Red_Herring_support': 58.0, 'micro avg_precision': 0.4782608695652174, 'micro avg_recall': 0.1896551724137931, 'micro avg_f1-score': 0.271604938271605, 'micro avg_support': 58.0, 'macro avg_precision': 0.4782608695652174, 'macro avg_recall': 0.1896551724137931, 'macro avg_f1-score': 0.271604938271605, 'macro avg_support': 58.0, 'weighted avg_precision': 0.4782608695652174, 'weighted avg_recall': 0.1896551724137931, 'weighted avg_f1-score': 0.271604938271605, 'weighted avg_support': 58.0, 'O_support': 790, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 3}]}
Best model updated: current epoch macro f1 = 0.271604938271605
{'micro_f1': 0.8145025295109612, 'precision': 0.8145025295109612, 'Red_Herring_precision': 0.391304347826087, 'Red_Herring_recall': 0.15517241379310345, 'Red_Herring_f1-score': 0.2222222222222222, 'Red_Herring_support': 58.0, 'micro avg_precision': 0.391304347826087, 'micro avg_recall': 0.15517241379310345, 'micro avg_f1-score': 0.2222222222222222, 'micro avg_support': 58.0, 'macro avg_precision': 0.391304347826087, 'macro avg_recall': 0.15517241379310345, 'macro avg_f1-score': 0.2222222222222222, 'macro avg_support': 58.0, 'weighted avg_precision': 0.391304347826087, 'weighted avg_recall': 0.15517241379310345, 'weighted avg_f1-score': 0.2222222222222222, 'weighted avg_support': 58.0, 'O_support': 790, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 4}
{'results': [{'micro_f1': 0.6686340640809444, 'precision': 0.6686340640809444, 'Red_Herring_precision': 0.0, 'Red_Herring_recall': 0.0, 'Red_Herring_f1-score': 0.0, 'Red_Herring_support': 3.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 3.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 3.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 3.0, 'O_support': 790, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 0}, {'micro_f1': 0.760539629005059, 'precision': 0.760539629005059, 'Red_Herring_precision': 0.043478260869565216, 'Red_Herring_recall': 0.020833333333333332, 'Red_Herring_f1-score': 0.028169014084507043, 'Red_Herring_support': 48.0, 'micro avg_precision': 0.043478260869565216, 'micro avg_recall': 0.020833333333333332, 'micro avg_f1-score': 0.028169014084507043, 'micro avg_support': 48.0, 'macro avg_precision': 0.043478260869565216, 'macro avg_recall': 0.020833333333333332, 'macro avg_f1-score': 0.028169014084507043, 'macro avg_support': 48.0, 'weighted avg_precision': 0.043478260869565216, 'weighted avg_recall': 0.020833333333333332, 'weighted avg_f1-score': 0.028169014084507043, 'weighted avg_support': 48.0, 'O_support': 790, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 1}, {'micro_f1': 0.7731871838111298, 'precision': 0.7731871838111298, 'Red_Herring_precision': 0.13043478260869565, 'Red_Herring_recall': 0.08333333333333333, 'Red_Herring_f1-score': 0.10169491525423728, 'Red_Herring_support': 36.0, 'micro avg_precision': 0.13043478260869565, 'micro avg_recall': 0.08333333333333333, 'micro avg_f1-score': 0.10169491525423728, 'micro avg_support': 36.0, 'macro avg_precision': 0.13043478260869565, 'macro avg_recall': 0.08333333333333333, 'macro avg_f1-score': 0.10169491525423728, 'macro avg_support': 36.0, 'weighted avg_precision': 0.13043478260869565, 'weighted avg_recall': 0.08333333333333333, 'weighted avg_f1-score': 0.10169491525423728, 'weighted avg_support': 36.0, 'O_support': 790, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 2}, {'micro_f1': 0.7655986509274875, 'precision': 0.7655986509274874, 'Red_Herring_precision': 0.4782608695652174, 'Red_Herring_recall': 0.1896551724137931, 'Red_Herring_f1-score': 0.271604938271605, 'Red_Herring_support': 58.0, 'micro avg_precision': 0.4782608695652174, 'micro avg_recall': 0.1896551724137931, 'micro avg_f1-score': 0.271604938271605, 'micro avg_support': 58.0, 'macro avg_precision': 0.4782608695652174, 'macro avg_recall': 0.1896551724137931, 'macro avg_f1-score': 0.271604938271605, 'macro avg_support': 58.0, 'weighted avg_precision': 0.4782608695652174, 'weighted avg_recall': 0.1896551724137931, 'weighted avg_f1-score': 0.271604938271605, 'weighted avg_support': 58.0, 'O_support': 790, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 3}, {'micro_f1': 0.8145025295109612, 'precision': 0.8145025295109612, 'Red_Herring_precision': 0.391304347826087, 'Red_Herring_recall': 0.15517241379310345, 'Red_Herring_f1-score': 0.2222222222222222, 'Red_Herring_support': 58.0, 'micro avg_precision': 0.391304347826087, 'micro avg_recall': 0.15517241379310345, 'micro avg_f1-score': 0.2222222222222222, 'micro avg_support': 58.0, 'macro avg_precision': 0.391304347826087, 'macro avg_recall': 0.15517241379310345, 'macro avg_f1-score': 0.2222222222222222, 'macro avg_support': 58.0, 'weighted avg_precision': 0.391304347826087, 'weighted avg_recall': 0.15517241379310345, 'weighted avg_f1-score': 0.2222222222222222, 'weighted avg_support': 58.0, 'O_support': 790, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 4}]}
{'micro_f1': 0.7959527824620573, 'precision': 0.7959527824620574, 'Red_Herring_precision': 0.34782608695652173, 'Red_Herring_recall': 0.2222222222222222, 'Red_Herring_f1-score': 0.2711864406779661, 'Red_Herring_support': 36.0, 'micro avg_precision': 0.34782608695652173, 'micro avg_recall': 0.2222222222222222, 'micro avg_f1-score': 0.2711864406779661, 'micro avg_support': 36.0, 'macro avg_precision': 0.34782608695652173, 'macro avg_recall': 0.2222222222222222, 'macro avg_f1-score': 0.2711864406779661, 'macro avg_support': 36.0, 'weighted avg_precision': 0.34782608695652173, 'weighted avg_recall': 0.2222222222222222, 'weighted avg_f1-score': 0.2711864406779661, 'weighted avg_support': 36.0, 'O_support': 790, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 5}
{'results': [{'micro_f1': 0.6686340640809444, 'precision': 0.6686340640809444, 'Red_Herring_precision': 0.0, 'Red_Herring_recall': 0.0, 'Red_Herring_f1-score': 0.0, 'Red_Herring_support': 3.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 3.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 3.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 3.0, 'O_support': 790, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 0}, {'micro_f1': 0.760539629005059, 'precision': 0.760539629005059, 'Red_Herring_precision': 0.043478260869565216, 'Red_Herring_recall': 0.020833333333333332, 'Red_Herring_f1-score': 0.028169014084507043, 'Red_Herring_support': 48.0, 'micro avg_precision': 0.043478260869565216, 'micro avg_recall': 0.020833333333333332, 'micro avg_f1-score': 0.028169014084507043, 'micro avg_support': 48.0, 'macro avg_precision': 0.043478260869565216, 'macro avg_recall': 0.020833333333333332, 'macro avg_f1-score': 0.028169014084507043, 'macro avg_support': 48.0, 'weighted avg_precision': 0.043478260869565216, 'weighted avg_recall': 0.020833333333333332, 'weighted avg_f1-score': 0.028169014084507043, 'weighted avg_support': 48.0, 'O_support': 790, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 1}, {'micro_f1': 0.7731871838111298, 'precision': 0.7731871838111298, 'Red_Herring_precision': 0.13043478260869565, 'Red_Herring_recall': 0.08333333333333333, 'Red_Herring_f1-score': 0.10169491525423728, 'Red_Herring_support': 36.0, 'micro avg_precision': 0.13043478260869565, 'micro avg_recall': 0.08333333333333333, 'micro avg_f1-score': 0.10169491525423728, 'micro avg_support': 36.0, 'macro avg_precision': 0.13043478260869565, 'macro avg_recall': 0.08333333333333333, 'macro avg_f1-score': 0.10169491525423728, 'macro avg_support': 36.0, 'weighted avg_precision': 0.13043478260869565, 'weighted avg_recall': 0.08333333333333333, 'weighted avg_f1-score': 0.10169491525423728, 'weighted avg_support': 36.0, 'O_support': 790, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 2}, {'micro_f1': 0.7655986509274875, 'precision': 0.7655986509274874, 'Red_Herring_precision': 0.4782608695652174, 'Red_Herring_recall': 0.1896551724137931, 'Red_Herring_f1-score': 0.271604938271605, 'Red_Herring_support': 58.0, 'micro avg_precision': 0.4782608695652174, 'micro avg_recall': 0.1896551724137931, 'micro avg_f1-score': 0.271604938271605, 'micro avg_support': 58.0, 'macro avg_precision': 0.4782608695652174, 'macro avg_recall': 0.1896551724137931, 'macro avg_f1-score': 0.271604938271605, 'macro avg_support': 58.0, 'weighted avg_precision': 0.4782608695652174, 'weighted avg_recall': 0.1896551724137931, 'weighted avg_f1-score': 0.271604938271605, 'weighted avg_support': 58.0, 'O_support': 790, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 3}, {'micro_f1': 0.8145025295109612, 'precision': 0.8145025295109612, 'Red_Herring_precision': 0.391304347826087, 'Red_Herring_recall': 0.15517241379310345, 'Red_Herring_f1-score': 0.2222222222222222, 'Red_Herring_support': 58.0, 'micro avg_precision': 0.391304347826087, 'micro avg_recall': 0.15517241379310345, 'micro avg_f1-score': 0.2222222222222222, 'micro avg_support': 58.0, 'macro avg_precision': 0.391304347826087, 'macro avg_recall': 0.15517241379310345, 'macro avg_f1-score': 0.2222222222222222, 'macro avg_support': 58.0, 'weighted avg_precision': 0.391304347826087, 'weighted avg_recall': 0.15517241379310345, 'weighted avg_f1-score': 0.2222222222222222, 'weighted avg_support': 58.0, 'O_support': 790, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 4}, {'micro_f1': 0.7959527824620573, 'precision': 0.7959527824620574, 'Red_Herring_precision': 0.34782608695652173, 'Red_Herring_recall': 0.2222222222222222, 'Red_Herring_f1-score': 0.2711864406779661, 'Red_Herring_support': 36.0, 'micro avg_precision': 0.34782608695652173, 'micro avg_recall': 0.2222222222222222, 'micro avg_f1-score': 0.2711864406779661, 'micro avg_support': 36.0, 'macro avg_precision': 0.34782608695652173, 'macro avg_recall': 0.2222222222222222, 'macro avg_f1-score': 0.2711864406779661, 'macro avg_support': 36.0, 'weighted avg_precision': 0.34782608695652173, 'weighted avg_recall': 0.2222222222222222, 'weighted avg_f1-score': 0.2711864406779661, 'weighted avg_support': 36.0, 'O_support': 790, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 5}]}
Early stopping triggered.
Saving model to directory: ./models/M2/2024-05-13-23-08-48_aug/mdeberta-v3-base_9_ME10_target=Red_Herring_SUBSAMPLED_2024-05-13-23-08-48
Training model no. 10 of 23 for (10, 'Whataboutism') persuasion technique...
{'micro_f1': 0.765490943755958, 'precision': 0.765490943755958, 'Whataboutism_precision': 0.0, 'Whataboutism_recall': 0.0, 'Whataboutism_f1-score': 0.0, 'Whataboutism_support': 97.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 97.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 97.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 97.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 433, 'epoch': 0}
{'results': [{'micro_f1': 0.765490943755958, 'precision': 0.765490943755958, 'Whataboutism_precision': 0.0, 'Whataboutism_recall': 0.0, 'Whataboutism_f1-score': 0.0, 'Whataboutism_support': 97.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 97.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 97.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 97.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 433, 'epoch': 0}]}
{'micro_f1': 0.47664442326024786, 'precision': 0.47664442326024786, 'Whataboutism_precision': 0.0, 'Whataboutism_recall': 0.0, 'Whataboutism_f1-score': 0.0, 'Whataboutism_support': 35.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 35.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 35.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 35.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 433, 'epoch': 1}
{'results': [{'micro_f1': 0.765490943755958, 'precision': 0.765490943755958, 'Whataboutism_precision': 0.0, 'Whataboutism_recall': 0.0, 'Whataboutism_f1-score': 0.0, 'Whataboutism_support': 97.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 97.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 97.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 97.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 433, 'epoch': 0}, {'micro_f1': 0.47664442326024786, 'precision': 0.47664442326024786, 'Whataboutism_precision': 0.0, 'Whataboutism_recall': 0.0, 'Whataboutism_f1-score': 0.0, 'Whataboutism_support': 35.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 35.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 35.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 35.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 433, 'epoch': 1}]}
Early stopping triggered.
Saving model to directory: ./models/M2/2024-05-13-23-08-48_aug/mdeberta-v3-base_10_ME10_target=Whataboutism_SUBSAMPLED_2024-05-13-23-08-48
Training model no. 11 of 23 for (11, 'Slogans') persuasion technique...
{'micro_f1': 0.8888888888888888, 'precision': 0.8888888888888888, 'Slogans_precision': 0.28865979381443296, 'Slogans_recall': 0.1794871794871795, 'Slogans_f1-score': 0.22134387351778653, 'Slogans_support': 156.0, 'micro avg_precision': 0.28865979381443296, 'micro avg_recall': 0.1794871794871795, 'micro avg_f1-score': 0.22134387351778653, 'micro avg_support': 156.0, 'macro avg_precision': 0.28865979381443296, 'macro avg_recall': 0.1794871794871795, 'macro avg_f1-score': 0.22134387351778653, 'macro avg_support': 156.0, 'weighted avg_precision': 0.28865979381443296, 'weighted avg_recall': 0.1794871794871795, 'weighted avg_f1-score': 0.2213438735177865, 'weighted avg_support': 156.0, 'O_support': 3016, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 0}
{'results': [{'micro_f1': 0.8888888888888888, 'precision': 0.8888888888888888, 'Slogans_precision': 0.28865979381443296, 'Slogans_recall': 0.1794871794871795, 'Slogans_f1-score': 0.22134387351778653, 'Slogans_support': 156.0, 'micro avg_precision': 0.28865979381443296, 'micro avg_recall': 0.1794871794871795, 'micro avg_f1-score': 0.22134387351778653, 'micro avg_support': 156.0, 'macro avg_precision': 0.28865979381443296, 'macro avg_recall': 0.1794871794871795, 'macro avg_f1-score': 0.22134387351778653, 'macro avg_support': 156.0, 'weighted avg_precision': 0.28865979381443296, 'weighted avg_recall': 0.1794871794871795, 'weighted avg_f1-score': 0.2213438735177865, 'weighted avg_support': 156.0, 'O_support': 3016, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 0}]}
Best model updated: current epoch macro f1 = 0.22134387351778653
{'micro_f1': 0.9264705882352942, 'precision': 0.9264705882352942, 'Slogans_precision': 0.4020618556701031, 'Slogans_recall': 0.38235294117647056, 'Slogans_f1-score': 0.3919597989949749, 'Slogans_support': 102.0, 'micro avg_precision': 0.4020618556701031, 'micro avg_recall': 0.38235294117647056, 'micro avg_f1-score': 0.3919597989949749, 'micro avg_support': 102.0, 'macro avg_precision': 0.4020618556701031, 'macro avg_recall': 0.38235294117647056, 'macro avg_f1-score': 0.3919597989949749, 'macro avg_support': 102.0, 'weighted avg_precision': 0.4020618556701031, 'weighted avg_recall': 0.38235294117647056, 'weighted avg_f1-score': 0.39195979899497485, 'weighted avg_support': 102.0, 'O_support': 3016, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 1}
{'results': [{'micro_f1': 0.8888888888888888, 'precision': 0.8888888888888888, 'Slogans_precision': 0.28865979381443296, 'Slogans_recall': 0.1794871794871795, 'Slogans_f1-score': 0.22134387351778653, 'Slogans_support': 156.0, 'micro avg_precision': 0.28865979381443296, 'micro avg_recall': 0.1794871794871795, 'micro avg_f1-score': 0.22134387351778653, 'micro avg_support': 156.0, 'macro avg_precision': 0.28865979381443296, 'macro avg_recall': 0.1794871794871795, 'macro avg_f1-score': 0.22134387351778653, 'macro avg_support': 156.0, 'weighted avg_precision': 0.28865979381443296, 'weighted avg_recall': 0.1794871794871795, 'weighted avg_f1-score': 0.2213438735177865, 'weighted avg_support': 156.0, 'O_support': 3016, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 0}, {'micro_f1': 0.9264705882352942, 'precision': 0.9264705882352942, 'Slogans_precision': 0.4020618556701031, 'Slogans_recall': 0.38235294117647056, 'Slogans_f1-score': 0.3919597989949749, 'Slogans_support': 102.0, 'micro avg_precision': 0.4020618556701031, 'micro avg_recall': 0.38235294117647056, 'micro avg_f1-score': 0.3919597989949749, 'micro avg_support': 102.0, 'macro avg_precision': 0.4020618556701031, 'macro avg_recall': 0.38235294117647056, 'macro avg_f1-score': 0.3919597989949749, 'macro avg_support': 102.0, 'weighted avg_precision': 0.4020618556701031, 'weighted avg_recall': 0.38235294117647056, 'weighted avg_f1-score': 0.39195979899497485, 'weighted avg_support': 102.0, 'O_support': 3016, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 1}]}
Best model updated: current epoch macro f1 = 0.3919597989949749
{'micro_f1': 0.9240196078431373, 'precision': 0.9240196078431373, 'Slogans_precision': 0.38144329896907214, 'Slogans_recall': 0.3333333333333333, 'Slogans_f1-score': 0.3557692307692308, 'Slogans_support': 111.0, 'micro avg_precision': 0.38144329896907214, 'micro avg_recall': 0.3333333333333333, 'micro avg_f1-score': 0.3557692307692308, 'micro avg_support': 111.0, 'macro avg_precision': 0.38144329896907214, 'macro avg_recall': 0.3333333333333333, 'macro avg_f1-score': 0.3557692307692308, 'macro avg_support': 111.0, 'weighted avg_precision': 0.38144329896907214, 'weighted avg_recall': 0.3333333333333333, 'weighted avg_f1-score': 0.35576923076923084, 'weighted avg_support': 111.0, 'O_support': 3016, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 2}
{'results': [{'micro_f1': 0.8888888888888888, 'precision': 0.8888888888888888, 'Slogans_precision': 0.28865979381443296, 'Slogans_recall': 0.1794871794871795, 'Slogans_f1-score': 0.22134387351778653, 'Slogans_support': 156.0, 'micro avg_precision': 0.28865979381443296, 'micro avg_recall': 0.1794871794871795, 'micro avg_f1-score': 0.22134387351778653, 'micro avg_support': 156.0, 'macro avg_precision': 0.28865979381443296, 'macro avg_recall': 0.1794871794871795, 'macro avg_f1-score': 0.22134387351778653, 'macro avg_support': 156.0, 'weighted avg_precision': 0.28865979381443296, 'weighted avg_recall': 0.1794871794871795, 'weighted avg_f1-score': 0.2213438735177865, 'weighted avg_support': 156.0, 'O_support': 3016, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 0}, {'micro_f1': 0.9264705882352942, 'precision': 0.9264705882352942, 'Slogans_precision': 0.4020618556701031, 'Slogans_recall': 0.38235294117647056, 'Slogans_f1-score': 0.3919597989949749, 'Slogans_support': 102.0, 'micro avg_precision': 0.4020618556701031, 'micro avg_recall': 0.38235294117647056, 'micro avg_f1-score': 0.3919597989949749, 'micro avg_support': 102.0, 'macro avg_precision': 0.4020618556701031, 'macro avg_recall': 0.38235294117647056, 'macro avg_f1-score': 0.3919597989949749, 'macro avg_support': 102.0, 'weighted avg_precision': 0.4020618556701031, 'weighted avg_recall': 0.38235294117647056, 'weighted avg_f1-score': 0.39195979899497485, 'weighted avg_support': 102.0, 'O_support': 3016, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 1}, {'micro_f1': 0.9240196078431373, 'precision': 0.9240196078431373, 'Slogans_precision': 0.38144329896907214, 'Slogans_recall': 0.3333333333333333, 'Slogans_f1-score': 0.3557692307692308, 'Slogans_support': 111.0, 'micro avg_precision': 0.38144329896907214, 'micro avg_recall': 0.3333333333333333, 'micro avg_f1-score': 0.3557692307692308, 'micro avg_support': 111.0, 'macro avg_precision': 0.38144329896907214, 'macro avg_recall': 0.3333333333333333, 'macro avg_f1-score': 0.3557692307692308, 'macro avg_support': 111.0, 'weighted avg_precision': 0.38144329896907214, 'weighted avg_recall': 0.3333333333333333, 'weighted avg_f1-score': 0.35576923076923084, 'weighted avg_support': 111.0, 'O_support': 3016, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 2}]}
{'micro_f1': 0.9193899782135075, 'precision': 0.9193899782135077, 'Slogans_precision': 0.3917525773195876, 'Slogans_recall': 0.3275862068965517, 'Slogans_f1-score': 0.35680751173708913, 'Slogans_support': 116.0, 'micro avg_precision': 0.3917525773195876, 'micro avg_recall': 0.3275862068965517, 'micro avg_f1-score': 0.35680751173708913, 'micro avg_support': 116.0, 'macro avg_precision': 0.3917525773195876, 'macro avg_recall': 0.3275862068965517, 'macro avg_f1-score': 0.35680751173708913, 'macro avg_support': 116.0, 'weighted avg_precision': 0.3917525773195876, 'weighted avg_recall': 0.3275862068965517, 'weighted avg_f1-score': 0.35680751173708913, 'weighted avg_support': 116.0, 'O_support': 3016, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 3}
{'results': [{'micro_f1': 0.8888888888888888, 'precision': 0.8888888888888888, 'Slogans_precision': 0.28865979381443296, 'Slogans_recall': 0.1794871794871795, 'Slogans_f1-score': 0.22134387351778653, 'Slogans_support': 156.0, 'micro avg_precision': 0.28865979381443296, 'micro avg_recall': 0.1794871794871795, 'micro avg_f1-score': 0.22134387351778653, 'micro avg_support': 156.0, 'macro avg_precision': 0.28865979381443296, 'macro avg_recall': 0.1794871794871795, 'macro avg_f1-score': 0.22134387351778653, 'macro avg_support': 156.0, 'weighted avg_precision': 0.28865979381443296, 'weighted avg_recall': 0.1794871794871795, 'weighted avg_f1-score': 0.2213438735177865, 'weighted avg_support': 156.0, 'O_support': 3016, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 0}, {'micro_f1': 0.9264705882352942, 'precision': 0.9264705882352942, 'Slogans_precision': 0.4020618556701031, 'Slogans_recall': 0.38235294117647056, 'Slogans_f1-score': 0.3919597989949749, 'Slogans_support': 102.0, 'micro avg_precision': 0.4020618556701031, 'micro avg_recall': 0.38235294117647056, 'micro avg_f1-score': 0.3919597989949749, 'micro avg_support': 102.0, 'macro avg_precision': 0.4020618556701031, 'macro avg_recall': 0.38235294117647056, 'macro avg_f1-score': 0.3919597989949749, 'macro avg_support': 102.0, 'weighted avg_precision': 0.4020618556701031, 'weighted avg_recall': 0.38235294117647056, 'weighted avg_f1-score': 0.39195979899497485, 'weighted avg_support': 102.0, 'O_support': 3016, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 1}, {'micro_f1': 0.9240196078431373, 'precision': 0.9240196078431373, 'Slogans_precision': 0.38144329896907214, 'Slogans_recall': 0.3333333333333333, 'Slogans_f1-score': 0.3557692307692308, 'Slogans_support': 111.0, 'micro avg_precision': 0.38144329896907214, 'micro avg_recall': 0.3333333333333333, 'micro avg_f1-score': 0.3557692307692308, 'micro avg_support': 111.0, 'macro avg_precision': 0.38144329896907214, 'macro avg_recall': 0.3333333333333333, 'macro avg_f1-score': 0.3557692307692308, 'macro avg_support': 111.0, 'weighted avg_precision': 0.38144329896907214, 'weighted avg_recall': 0.3333333333333333, 'weighted avg_f1-score': 0.35576923076923084, 'weighted avg_support': 111.0, 'O_support': 3016, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 2}, {'micro_f1': 0.9193899782135075, 'precision': 0.9193899782135077, 'Slogans_precision': 0.3917525773195876, 'Slogans_recall': 0.3275862068965517, 'Slogans_f1-score': 0.35680751173708913, 'Slogans_support': 116.0, 'micro avg_precision': 0.3917525773195876, 'micro avg_recall': 0.3275862068965517, 'micro avg_f1-score': 0.35680751173708913, 'micro avg_support': 116.0, 'macro avg_precision': 0.3917525773195876, 'macro avg_recall': 0.3275862068965517, 'macro avg_f1-score': 0.35680751173708913, 'macro avg_support': 116.0, 'weighted avg_precision': 0.3917525773195876, 'weighted avg_recall': 0.3275862068965517, 'weighted avg_f1-score': 0.35680751173708913, 'weighted avg_support': 116.0, 'O_support': 3016, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 3}]}
Early stopping triggered.
Saving model to directory: ./models/M2/2024-05-13-23-08-48_aug/mdeberta-v3-base_11_ME10_target=Slogans_SUBSAMPLED_2024-05-13-23-08-48
Training model no. 12 of 23 for (12, 'Appeal_to_Time') persuasion technique...
{'micro_f1': 0.6857463524130191, 'precision': 0.6857463524130191, 'Appeal_to_Time_precision': 0.037037037037037035, 'Appeal_to_Time_recall': 0.015384615384615385, 'Appeal_to_Time_f1-score': 0.021739130434782608, 'Appeal_to_Time_support': 65.0, 'micro avg_precision': 0.037037037037037035, 'micro avg_recall': 0.015384615384615385, 'micro avg_f1-score': 0.021739130434782608, 'micro avg_support': 65.0, 'macro avg_precision': 0.037037037037037035, 'macro avg_recall': 0.015384615384615385, 'macro avg_f1-score': 0.021739130434782608, 'macro avg_support': 65.0, 'weighted avg_precision': 0.037037037037037035, 'weighted avg_recall': 0.015384615384615385, 'weighted avg_f1-score': 0.021739130434782608, 'weighted avg_support': 65.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 0}
{'results': [{'micro_f1': 0.6857463524130191, 'precision': 0.6857463524130191, 'Appeal_to_Time_precision': 0.037037037037037035, 'Appeal_to_Time_recall': 0.015384615384615385, 'Appeal_to_Time_f1-score': 0.021739130434782608, 'Appeal_to_Time_support': 65.0, 'micro avg_precision': 0.037037037037037035, 'micro avg_recall': 0.015384615384615385, 'micro avg_f1-score': 0.021739130434782608, 'micro avg_support': 65.0, 'macro avg_precision': 0.037037037037037035, 'macro avg_recall': 0.015384615384615385, 'macro avg_f1-score': 0.021739130434782608, 'macro avg_support': 65.0, 'weighted avg_precision': 0.037037037037037035, 'weighted avg_recall': 0.015384615384615385, 'weighted avg_f1-score': 0.021739130434782608, 'weighted avg_support': 65.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 0}]}
Best model updated: current epoch macro f1 = 0.021739130434782608
{'micro_f1': 0.7306397306397306, 'precision': 0.7306397306397306, 'Appeal_to_Time_precision': 0.07407407407407407, 'Appeal_to_Time_recall': 0.0273972602739726, 'Appeal_to_Time_f1-score': 0.04, 'Appeal_to_Time_support': 73.0, 'micro avg_precision': 0.07407407407407407, 'micro avg_recall': 0.0273972602739726, 'micro avg_f1-score': 0.04, 'micro avg_support': 73.0, 'macro avg_precision': 0.07407407407407407, 'macro avg_recall': 0.0273972602739726, 'macro avg_f1-score': 0.04, 'macro avg_support': 73.0, 'weighted avg_precision': 0.07407407407407407, 'weighted avg_recall': 0.0273972602739726, 'weighted avg_f1-score': 0.04, 'weighted avg_support': 73.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 1}
{'results': [{'micro_f1': 0.6857463524130191, 'precision': 0.6857463524130191, 'Appeal_to_Time_precision': 0.037037037037037035, 'Appeal_to_Time_recall': 0.015384615384615385, 'Appeal_to_Time_f1-score': 0.021739130434782608, 'Appeal_to_Time_support': 65.0, 'micro avg_precision': 0.037037037037037035, 'micro avg_recall': 0.015384615384615385, 'micro avg_f1-score': 0.021739130434782608, 'micro avg_support': 65.0, 'macro avg_precision': 0.037037037037037035, 'macro avg_recall': 0.015384615384615385, 'macro avg_f1-score': 0.021739130434782608, 'macro avg_support': 65.0, 'weighted avg_precision': 0.037037037037037035, 'weighted avg_recall': 0.015384615384615385, 'weighted avg_f1-score': 0.021739130434782608, 'weighted avg_support': 65.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 0}, {'micro_f1': 0.7306397306397306, 'precision': 0.7306397306397306, 'Appeal_to_Time_precision': 0.07407407407407407, 'Appeal_to_Time_recall': 0.0273972602739726, 'Appeal_to_Time_f1-score': 0.04, 'Appeal_to_Time_support': 73.0, 'micro avg_precision': 0.07407407407407407, 'micro avg_recall': 0.0273972602739726, 'micro avg_f1-score': 0.04, 'micro avg_support': 73.0, 'macro avg_precision': 0.07407407407407407, 'macro avg_recall': 0.0273972602739726, 'macro avg_f1-score': 0.04, 'macro avg_support': 73.0, 'weighted avg_precision': 0.07407407407407407, 'weighted avg_recall': 0.0273972602739726, 'weighted avg_f1-score': 0.04, 'weighted avg_support': 73.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 1}]}
Best model updated: current epoch macro f1 = 0.04
{'micro_f1': 0.7586980920314254, 'precision': 0.7586980920314254, 'Appeal_to_Time_precision': 0.2222222222222222, 'Appeal_to_Time_recall': 0.10526315789473684, 'Appeal_to_Time_f1-score': 0.14285714285714285, 'Appeal_to_Time_support': 57.0, 'micro avg_precision': 0.2222222222222222, 'micro avg_recall': 0.10526315789473684, 'micro avg_f1-score': 0.14285714285714285, 'micro avg_support': 57.0, 'macro avg_precision': 0.2222222222222222, 'macro avg_recall': 0.10526315789473684, 'macro avg_f1-score': 0.14285714285714285, 'macro avg_support': 57.0, 'weighted avg_precision': 0.2222222222222222, 'weighted avg_recall': 0.10526315789473684, 'weighted avg_f1-score': 0.14285714285714285, 'weighted avg_support': 57.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 2}
{'results': [{'micro_f1': 0.6857463524130191, 'precision': 0.6857463524130191, 'Appeal_to_Time_precision': 0.037037037037037035, 'Appeal_to_Time_recall': 0.015384615384615385, 'Appeal_to_Time_f1-score': 0.021739130434782608, 'Appeal_to_Time_support': 65.0, 'micro avg_precision': 0.037037037037037035, 'micro avg_recall': 0.015384615384615385, 'micro avg_f1-score': 0.021739130434782608, 'micro avg_support': 65.0, 'macro avg_precision': 0.037037037037037035, 'macro avg_recall': 0.015384615384615385, 'macro avg_f1-score': 0.021739130434782608, 'macro avg_support': 65.0, 'weighted avg_precision': 0.037037037037037035, 'weighted avg_recall': 0.015384615384615385, 'weighted avg_f1-score': 0.021739130434782608, 'weighted avg_support': 65.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 0}, {'micro_f1': 0.7306397306397306, 'precision': 0.7306397306397306, 'Appeal_to_Time_precision': 0.07407407407407407, 'Appeal_to_Time_recall': 0.0273972602739726, 'Appeal_to_Time_f1-score': 0.04, 'Appeal_to_Time_support': 73.0, 'micro avg_precision': 0.07407407407407407, 'micro avg_recall': 0.0273972602739726, 'micro avg_f1-score': 0.04, 'micro avg_support': 73.0, 'macro avg_precision': 0.07407407407407407, 'macro avg_recall': 0.0273972602739726, 'macro avg_f1-score': 0.04, 'macro avg_support': 73.0, 'weighted avg_precision': 0.07407407407407407, 'weighted avg_recall': 0.0273972602739726, 'weighted avg_f1-score': 0.04, 'weighted avg_support': 73.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 1}, {'micro_f1': 0.7586980920314254, 'precision': 0.7586980920314254, 'Appeal_to_Time_precision': 0.2222222222222222, 'Appeal_to_Time_recall': 0.10526315789473684, 'Appeal_to_Time_f1-score': 0.14285714285714285, 'Appeal_to_Time_support': 57.0, 'micro avg_precision': 0.2222222222222222, 'micro avg_recall': 0.10526315789473684, 'micro avg_f1-score': 0.14285714285714285, 'micro avg_support': 57.0, 'macro avg_precision': 0.2222222222222222, 'macro avg_recall': 0.10526315789473684, 'macro avg_f1-score': 0.14285714285714285, 'macro avg_support': 57.0, 'weighted avg_precision': 0.2222222222222222, 'weighted avg_recall': 0.10526315789473684, 'weighted avg_f1-score': 0.14285714285714285, 'weighted avg_support': 57.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 2}]}
Best model updated: current epoch macro f1 = 0.14285714285714285
{'micro_f1': 0.7575757575757576, 'precision': 0.7575757575757576, 'Appeal_to_Time_precision': 0.14814814814814814, 'Appeal_to_Time_recall': 0.07272727272727272, 'Appeal_to_Time_f1-score': 0.09756097560975609, 'Appeal_to_Time_support': 55.0, 'micro avg_precision': 0.14814814814814814, 'micro avg_recall': 0.07272727272727272, 'micro avg_f1-score': 0.09756097560975609, 'micro avg_support': 55.0, 'macro avg_precision': 0.14814814814814814, 'macro avg_recall': 0.07272727272727272, 'macro avg_f1-score': 0.09756097560975609, 'macro avg_support': 55.0, 'weighted avg_precision': 0.14814814814814814, 'weighted avg_recall': 0.07272727272727272, 'weighted avg_f1-score': 0.09756097560975609, 'weighted avg_support': 55.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 3}
{'results': [{'micro_f1': 0.6857463524130191, 'precision': 0.6857463524130191, 'Appeal_to_Time_precision': 0.037037037037037035, 'Appeal_to_Time_recall': 0.015384615384615385, 'Appeal_to_Time_f1-score': 0.021739130434782608, 'Appeal_to_Time_support': 65.0, 'micro avg_precision': 0.037037037037037035, 'micro avg_recall': 0.015384615384615385, 'micro avg_f1-score': 0.021739130434782608, 'micro avg_support': 65.0, 'macro avg_precision': 0.037037037037037035, 'macro avg_recall': 0.015384615384615385, 'macro avg_f1-score': 0.021739130434782608, 'macro avg_support': 65.0, 'weighted avg_precision': 0.037037037037037035, 'weighted avg_recall': 0.015384615384615385, 'weighted avg_f1-score': 0.021739130434782608, 'weighted avg_support': 65.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 0}, {'micro_f1': 0.7306397306397306, 'precision': 0.7306397306397306, 'Appeal_to_Time_precision': 0.07407407407407407, 'Appeal_to_Time_recall': 0.0273972602739726, 'Appeal_to_Time_f1-score': 0.04, 'Appeal_to_Time_support': 73.0, 'micro avg_precision': 0.07407407407407407, 'micro avg_recall': 0.0273972602739726, 'micro avg_f1-score': 0.04, 'micro avg_support': 73.0, 'macro avg_precision': 0.07407407407407407, 'macro avg_recall': 0.0273972602739726, 'macro avg_f1-score': 0.04, 'macro avg_support': 73.0, 'weighted avg_precision': 0.07407407407407407, 'weighted avg_recall': 0.0273972602739726, 'weighted avg_f1-score': 0.04, 'weighted avg_support': 73.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 1}, {'micro_f1': 0.7586980920314254, 'precision': 0.7586980920314254, 'Appeal_to_Time_precision': 0.2222222222222222, 'Appeal_to_Time_recall': 0.10526315789473684, 'Appeal_to_Time_f1-score': 0.14285714285714285, 'Appeal_to_Time_support': 57.0, 'micro avg_precision': 0.2222222222222222, 'micro avg_recall': 0.10526315789473684, 'micro avg_f1-score': 0.14285714285714285, 'micro avg_support': 57.0, 'macro avg_precision': 0.2222222222222222, 'macro avg_recall': 0.10526315789473684, 'macro avg_f1-score': 0.14285714285714285, 'macro avg_support': 57.0, 'weighted avg_precision': 0.2222222222222222, 'weighted avg_recall': 0.10526315789473684, 'weighted avg_f1-score': 0.14285714285714285, 'weighted avg_support': 57.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 2}, {'micro_f1': 0.7575757575757576, 'precision': 0.7575757575757576, 'Appeal_to_Time_precision': 0.14814814814814814, 'Appeal_to_Time_recall': 0.07272727272727272, 'Appeal_to_Time_f1-score': 0.09756097560975609, 'Appeal_to_Time_support': 55.0, 'micro avg_precision': 0.14814814814814814, 'micro avg_recall': 0.07272727272727272, 'micro avg_f1-score': 0.09756097560975609, 'micro avg_support': 55.0, 'macro avg_precision': 0.14814814814814814, 'macro avg_recall': 0.07272727272727272, 'macro avg_f1-score': 0.09756097560975609, 'macro avg_support': 55.0, 'weighted avg_precision': 0.14814814814814814, 'weighted avg_recall': 0.07272727272727272, 'weighted avg_f1-score': 0.09756097560975609, 'weighted avg_support': 55.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 3}]}
{'micro_f1': 0.7575757575757576, 'precision': 0.7575757575757576, 'Appeal_to_Time_precision': 0.25925925925925924, 'Appeal_to_Time_recall': 0.1320754716981132, 'Appeal_to_Time_f1-score': 0.17499999999999996, 'Appeal_to_Time_support': 53.0, 'micro avg_precision': 0.25925925925925924, 'micro avg_recall': 0.1320754716981132, 'micro avg_f1-score': 0.17499999999999996, 'micro avg_support': 53.0, 'macro avg_precision': 0.25925925925925924, 'macro avg_recall': 0.1320754716981132, 'macro avg_f1-score': 0.17499999999999996, 'macro avg_support': 53.0, 'weighted avg_precision': 0.25925925925925924, 'weighted avg_recall': 0.1320754716981132, 'weighted avg_f1-score': 0.17499999999999996, 'weighted avg_support': 53.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 4}
{'results': [{'micro_f1': 0.6857463524130191, 'precision': 0.6857463524130191, 'Appeal_to_Time_precision': 0.037037037037037035, 'Appeal_to_Time_recall': 0.015384615384615385, 'Appeal_to_Time_f1-score': 0.021739130434782608, 'Appeal_to_Time_support': 65.0, 'micro avg_precision': 0.037037037037037035, 'micro avg_recall': 0.015384615384615385, 'micro avg_f1-score': 0.021739130434782608, 'micro avg_support': 65.0, 'macro avg_precision': 0.037037037037037035, 'macro avg_recall': 0.015384615384615385, 'macro avg_f1-score': 0.021739130434782608, 'macro avg_support': 65.0, 'weighted avg_precision': 0.037037037037037035, 'weighted avg_recall': 0.015384615384615385, 'weighted avg_f1-score': 0.021739130434782608, 'weighted avg_support': 65.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 0}, {'micro_f1': 0.7306397306397306, 'precision': 0.7306397306397306, 'Appeal_to_Time_precision': 0.07407407407407407, 'Appeal_to_Time_recall': 0.0273972602739726, 'Appeal_to_Time_f1-score': 0.04, 'Appeal_to_Time_support': 73.0, 'micro avg_precision': 0.07407407407407407, 'micro avg_recall': 0.0273972602739726, 'micro avg_f1-score': 0.04, 'micro avg_support': 73.0, 'macro avg_precision': 0.07407407407407407, 'macro avg_recall': 0.0273972602739726, 'macro avg_f1-score': 0.04, 'macro avg_support': 73.0, 'weighted avg_precision': 0.07407407407407407, 'weighted avg_recall': 0.0273972602739726, 'weighted avg_f1-score': 0.04, 'weighted avg_support': 73.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 1}, {'micro_f1': 0.7586980920314254, 'precision': 0.7586980920314254, 'Appeal_to_Time_precision': 0.2222222222222222, 'Appeal_to_Time_recall': 0.10526315789473684, 'Appeal_to_Time_f1-score': 0.14285714285714285, 'Appeal_to_Time_support': 57.0, 'micro avg_precision': 0.2222222222222222, 'micro avg_recall': 0.10526315789473684, 'micro avg_f1-score': 0.14285714285714285, 'micro avg_support': 57.0, 'macro avg_precision': 0.2222222222222222, 'macro avg_recall': 0.10526315789473684, 'macro avg_f1-score': 0.14285714285714285, 'macro avg_support': 57.0, 'weighted avg_precision': 0.2222222222222222, 'weighted avg_recall': 0.10526315789473684, 'weighted avg_f1-score': 0.14285714285714285, 'weighted avg_support': 57.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 2}, {'micro_f1': 0.7575757575757576, 'precision': 0.7575757575757576, 'Appeal_to_Time_precision': 0.14814814814814814, 'Appeal_to_Time_recall': 0.07272727272727272, 'Appeal_to_Time_f1-score': 0.09756097560975609, 'Appeal_to_Time_support': 55.0, 'micro avg_precision': 0.14814814814814814, 'micro avg_recall': 0.07272727272727272, 'micro avg_f1-score': 0.09756097560975609, 'micro avg_support': 55.0, 'macro avg_precision': 0.14814814814814814, 'macro avg_recall': 0.07272727272727272, 'macro avg_f1-score': 0.09756097560975609, 'macro avg_support': 55.0, 'weighted avg_precision': 0.14814814814814814, 'weighted avg_recall': 0.07272727272727272, 'weighted avg_f1-score': 0.09756097560975609, 'weighted avg_support': 55.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 3}, {'micro_f1': 0.7575757575757576, 'precision': 0.7575757575757576, 'Appeal_to_Time_precision': 0.25925925925925924, 'Appeal_to_Time_recall': 0.1320754716981132, 'Appeal_to_Time_f1-score': 0.17499999999999996, 'Appeal_to_Time_support': 53.0, 'micro avg_precision': 0.25925925925925924, 'micro avg_recall': 0.1320754716981132, 'micro avg_f1-score': 0.17499999999999996, 'micro avg_support': 53.0, 'macro avg_precision': 0.25925925925925924, 'macro avg_recall': 0.1320754716981132, 'macro avg_f1-score': 0.17499999999999996, 'macro avg_support': 53.0, 'weighted avg_precision': 0.25925925925925924, 'weighted avg_recall': 0.1320754716981132, 'weighted avg_f1-score': 0.17499999999999996, 'weighted avg_support': 53.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 4}]}
Best model updated: current epoch macro f1 = 0.17499999999999996
{'micro_f1': 0.7643097643097643, 'precision': 0.7643097643097643, 'Appeal_to_Time_precision': 0.2962962962962963, 'Appeal_to_Time_recall': 0.17777777777777778, 'Appeal_to_Time_f1-score': 0.2222222222222222, 'Appeal_to_Time_support': 45.0, 'micro avg_precision': 0.2962962962962963, 'micro avg_recall': 0.17777777777777778, 'micro avg_f1-score': 0.2222222222222222, 'micro avg_support': 45.0, 'macro avg_precision': 0.2962962962962963, 'macro avg_recall': 0.17777777777777778, 'macro avg_f1-score': 0.2222222222222222, 'macro avg_support': 45.0, 'weighted avg_precision': 0.2962962962962963, 'weighted avg_recall': 0.17777777777777778, 'weighted avg_f1-score': 0.2222222222222222, 'weighted avg_support': 45.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 5}
{'results': [{'micro_f1': 0.6857463524130191, 'precision': 0.6857463524130191, 'Appeal_to_Time_precision': 0.037037037037037035, 'Appeal_to_Time_recall': 0.015384615384615385, 'Appeal_to_Time_f1-score': 0.021739130434782608, 'Appeal_to_Time_support': 65.0, 'micro avg_precision': 0.037037037037037035, 'micro avg_recall': 0.015384615384615385, 'micro avg_f1-score': 0.021739130434782608, 'micro avg_support': 65.0, 'macro avg_precision': 0.037037037037037035, 'macro avg_recall': 0.015384615384615385, 'macro avg_f1-score': 0.021739130434782608, 'macro avg_support': 65.0, 'weighted avg_precision': 0.037037037037037035, 'weighted avg_recall': 0.015384615384615385, 'weighted avg_f1-score': 0.021739130434782608, 'weighted avg_support': 65.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 0}, {'micro_f1': 0.7306397306397306, 'precision': 0.7306397306397306, 'Appeal_to_Time_precision': 0.07407407407407407, 'Appeal_to_Time_recall': 0.0273972602739726, 'Appeal_to_Time_f1-score': 0.04, 'Appeal_to_Time_support': 73.0, 'micro avg_precision': 0.07407407407407407, 'micro avg_recall': 0.0273972602739726, 'micro avg_f1-score': 0.04, 'micro avg_support': 73.0, 'macro avg_precision': 0.07407407407407407, 'macro avg_recall': 0.0273972602739726, 'macro avg_f1-score': 0.04, 'macro avg_support': 73.0, 'weighted avg_precision': 0.07407407407407407, 'weighted avg_recall': 0.0273972602739726, 'weighted avg_f1-score': 0.04, 'weighted avg_support': 73.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 1}, {'micro_f1': 0.7586980920314254, 'precision': 0.7586980920314254, 'Appeal_to_Time_precision': 0.2222222222222222, 'Appeal_to_Time_recall': 0.10526315789473684, 'Appeal_to_Time_f1-score': 0.14285714285714285, 'Appeal_to_Time_support': 57.0, 'micro avg_precision': 0.2222222222222222, 'micro avg_recall': 0.10526315789473684, 'micro avg_f1-score': 0.14285714285714285, 'micro avg_support': 57.0, 'macro avg_precision': 0.2222222222222222, 'macro avg_recall': 0.10526315789473684, 'macro avg_f1-score': 0.14285714285714285, 'macro avg_support': 57.0, 'weighted avg_precision': 0.2222222222222222, 'weighted avg_recall': 0.10526315789473684, 'weighted avg_f1-score': 0.14285714285714285, 'weighted avg_support': 57.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 2}, {'micro_f1': 0.7575757575757576, 'precision': 0.7575757575757576, 'Appeal_to_Time_precision': 0.14814814814814814, 'Appeal_to_Time_recall': 0.07272727272727272, 'Appeal_to_Time_f1-score': 0.09756097560975609, 'Appeal_to_Time_support': 55.0, 'micro avg_precision': 0.14814814814814814, 'micro avg_recall': 0.07272727272727272, 'micro avg_f1-score': 0.09756097560975609, 'micro avg_support': 55.0, 'macro avg_precision': 0.14814814814814814, 'macro avg_recall': 0.07272727272727272, 'macro avg_f1-score': 0.09756097560975609, 'macro avg_support': 55.0, 'weighted avg_precision': 0.14814814814814814, 'weighted avg_recall': 0.07272727272727272, 'weighted avg_f1-score': 0.09756097560975609, 'weighted avg_support': 55.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 3}, {'micro_f1': 0.7575757575757576, 'precision': 0.7575757575757576, 'Appeal_to_Time_precision': 0.25925925925925924, 'Appeal_to_Time_recall': 0.1320754716981132, 'Appeal_to_Time_f1-score': 0.17499999999999996, 'Appeal_to_Time_support': 53.0, 'micro avg_precision': 0.25925925925925924, 'micro avg_recall': 0.1320754716981132, 'micro avg_f1-score': 0.17499999999999996, 'micro avg_support': 53.0, 'macro avg_precision': 0.25925925925925924, 'macro avg_recall': 0.1320754716981132, 'macro avg_f1-score': 0.17499999999999996, 'macro avg_support': 53.0, 'weighted avg_precision': 0.25925925925925924, 'weighted avg_recall': 0.1320754716981132, 'weighted avg_f1-score': 0.17499999999999996, 'weighted avg_support': 53.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 4}, {'micro_f1': 0.7643097643097643, 'precision': 0.7643097643097643, 'Appeal_to_Time_precision': 0.2962962962962963, 'Appeal_to_Time_recall': 0.17777777777777778, 'Appeal_to_Time_f1-score': 0.2222222222222222, 'Appeal_to_Time_support': 45.0, 'micro avg_precision': 0.2962962962962963, 'micro avg_recall': 0.17777777777777778, 'micro avg_f1-score': 0.2222222222222222, 'micro avg_support': 45.0, 'macro avg_precision': 0.2962962962962963, 'macro avg_recall': 0.17777777777777778, 'macro avg_f1-score': 0.2222222222222222, 'macro avg_support': 45.0, 'weighted avg_precision': 0.2962962962962963, 'weighted avg_recall': 0.17777777777777778, 'weighted avg_f1-score': 0.2222222222222222, 'weighted avg_support': 45.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 5}]}
Best model updated: current epoch macro f1 = 0.2222222222222222
{'micro_f1': 0.7643097643097643, 'precision': 0.7643097643097643, 'Appeal_to_Time_precision': 0.14814814814814814, 'Appeal_to_Time_recall': 0.08333333333333333, 'Appeal_to_Time_f1-score': 0.10666666666666667, 'Appeal_to_Time_support': 48.0, 'micro avg_precision': 0.14814814814814814, 'micro avg_recall': 0.08333333333333333, 'micro avg_f1-score': 0.10666666666666667, 'micro avg_support': 48.0, 'macro avg_precision': 0.14814814814814814, 'macro avg_recall': 0.08333333333333333, 'macro avg_f1-score': 0.10666666666666667, 'macro avg_support': 48.0, 'weighted avg_precision': 0.14814814814814814, 'weighted avg_recall': 0.08333333333333333, 'weighted avg_f1-score': 0.10666666666666667, 'weighted avg_support': 48.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 6}
{'results': [{'micro_f1': 0.6857463524130191, 'precision': 0.6857463524130191, 'Appeal_to_Time_precision': 0.037037037037037035, 'Appeal_to_Time_recall': 0.015384615384615385, 'Appeal_to_Time_f1-score': 0.021739130434782608, 'Appeal_to_Time_support': 65.0, 'micro avg_precision': 0.037037037037037035, 'micro avg_recall': 0.015384615384615385, 'micro avg_f1-score': 0.021739130434782608, 'micro avg_support': 65.0, 'macro avg_precision': 0.037037037037037035, 'macro avg_recall': 0.015384615384615385, 'macro avg_f1-score': 0.021739130434782608, 'macro avg_support': 65.0, 'weighted avg_precision': 0.037037037037037035, 'weighted avg_recall': 0.015384615384615385, 'weighted avg_f1-score': 0.021739130434782608, 'weighted avg_support': 65.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 0}, {'micro_f1': 0.7306397306397306, 'precision': 0.7306397306397306, 'Appeal_to_Time_precision': 0.07407407407407407, 'Appeal_to_Time_recall': 0.0273972602739726, 'Appeal_to_Time_f1-score': 0.04, 'Appeal_to_Time_support': 73.0, 'micro avg_precision': 0.07407407407407407, 'micro avg_recall': 0.0273972602739726, 'micro avg_f1-score': 0.04, 'micro avg_support': 73.0, 'macro avg_precision': 0.07407407407407407, 'macro avg_recall': 0.0273972602739726, 'macro avg_f1-score': 0.04, 'macro avg_support': 73.0, 'weighted avg_precision': 0.07407407407407407, 'weighted avg_recall': 0.0273972602739726, 'weighted avg_f1-score': 0.04, 'weighted avg_support': 73.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 1}, {'micro_f1': 0.7586980920314254, 'precision': 0.7586980920314254, 'Appeal_to_Time_precision': 0.2222222222222222, 'Appeal_to_Time_recall': 0.10526315789473684, 'Appeal_to_Time_f1-score': 0.14285714285714285, 'Appeal_to_Time_support': 57.0, 'micro avg_precision': 0.2222222222222222, 'micro avg_recall': 0.10526315789473684, 'micro avg_f1-score': 0.14285714285714285, 'micro avg_support': 57.0, 'macro avg_precision': 0.2222222222222222, 'macro avg_recall': 0.10526315789473684, 'macro avg_f1-score': 0.14285714285714285, 'macro avg_support': 57.0, 'weighted avg_precision': 0.2222222222222222, 'weighted avg_recall': 0.10526315789473684, 'weighted avg_f1-score': 0.14285714285714285, 'weighted avg_support': 57.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 2}, {'micro_f1': 0.7575757575757576, 'precision': 0.7575757575757576, 'Appeal_to_Time_precision': 0.14814814814814814, 'Appeal_to_Time_recall': 0.07272727272727272, 'Appeal_to_Time_f1-score': 0.09756097560975609, 'Appeal_to_Time_support': 55.0, 'micro avg_precision': 0.14814814814814814, 'micro avg_recall': 0.07272727272727272, 'micro avg_f1-score': 0.09756097560975609, 'micro avg_support': 55.0, 'macro avg_precision': 0.14814814814814814, 'macro avg_recall': 0.07272727272727272, 'macro avg_f1-score': 0.09756097560975609, 'macro avg_support': 55.0, 'weighted avg_precision': 0.14814814814814814, 'weighted avg_recall': 0.07272727272727272, 'weighted avg_f1-score': 0.09756097560975609, 'weighted avg_support': 55.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 3}, {'micro_f1': 0.7575757575757576, 'precision': 0.7575757575757576, 'Appeal_to_Time_precision': 0.25925925925925924, 'Appeal_to_Time_recall': 0.1320754716981132, 'Appeal_to_Time_f1-score': 0.17499999999999996, 'Appeal_to_Time_support': 53.0, 'micro avg_precision': 0.25925925925925924, 'micro avg_recall': 0.1320754716981132, 'micro avg_f1-score': 0.17499999999999996, 'micro avg_support': 53.0, 'macro avg_precision': 0.25925925925925924, 'macro avg_recall': 0.1320754716981132, 'macro avg_f1-score': 0.17499999999999996, 'macro avg_support': 53.0, 'weighted avg_precision': 0.25925925925925924, 'weighted avg_recall': 0.1320754716981132, 'weighted avg_f1-score': 0.17499999999999996, 'weighted avg_support': 53.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 4}, {'micro_f1': 0.7643097643097643, 'precision': 0.7643097643097643, 'Appeal_to_Time_precision': 0.2962962962962963, 'Appeal_to_Time_recall': 0.17777777777777778, 'Appeal_to_Time_f1-score': 0.2222222222222222, 'Appeal_to_Time_support': 45.0, 'micro avg_precision': 0.2962962962962963, 'micro avg_recall': 0.17777777777777778, 'micro avg_f1-score': 0.2222222222222222, 'micro avg_support': 45.0, 'macro avg_precision': 0.2962962962962963, 'macro avg_recall': 0.17777777777777778, 'macro avg_f1-score': 0.2222222222222222, 'macro avg_support': 45.0, 'weighted avg_precision': 0.2962962962962963, 'weighted avg_recall': 0.17777777777777778, 'weighted avg_f1-score': 0.2222222222222222, 'weighted avg_support': 45.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 5}, {'micro_f1': 0.7643097643097643, 'precision': 0.7643097643097643, 'Appeal_to_Time_precision': 0.14814814814814814, 'Appeal_to_Time_recall': 0.08333333333333333, 'Appeal_to_Time_f1-score': 0.10666666666666667, 'Appeal_to_Time_support': 48.0, 'micro avg_precision': 0.14814814814814814, 'micro avg_recall': 0.08333333333333333, 'micro avg_f1-score': 0.10666666666666667, 'micro avg_support': 48.0, 'macro avg_precision': 0.14814814814814814, 'macro avg_recall': 0.08333333333333333, 'macro avg_f1-score': 0.10666666666666667, 'macro avg_support': 48.0, 'weighted avg_precision': 0.14814814814814814, 'weighted avg_recall': 0.08333333333333333, 'weighted avg_f1-score': 0.10666666666666667, 'weighted avg_support': 48.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 6}]}
{'micro_f1': 0.7407407407407407, 'precision': 0.7407407407407407, 'Appeal_to_Time_precision': 0.18518518518518517, 'Appeal_to_Time_recall': 0.10869565217391304, 'Appeal_to_Time_f1-score': 0.13698630136986303, 'Appeal_to_Time_support': 46.0, 'micro avg_precision': 0.18518518518518517, 'micro avg_recall': 0.10869565217391304, 'micro avg_f1-score': 0.13698630136986303, 'micro avg_support': 46.0, 'macro avg_precision': 0.18518518518518517, 'macro avg_recall': 0.10869565217391304, 'macro avg_f1-score': 0.13698630136986303, 'macro avg_support': 46.0, 'weighted avg_precision': 0.18518518518518515, 'weighted avg_recall': 0.10869565217391304, 'weighted avg_f1-score': 0.13698630136986303, 'weighted avg_support': 46.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 7}
{'results': [{'micro_f1': 0.6857463524130191, 'precision': 0.6857463524130191, 'Appeal_to_Time_precision': 0.037037037037037035, 'Appeal_to_Time_recall': 0.015384615384615385, 'Appeal_to_Time_f1-score': 0.021739130434782608, 'Appeal_to_Time_support': 65.0, 'micro avg_precision': 0.037037037037037035, 'micro avg_recall': 0.015384615384615385, 'micro avg_f1-score': 0.021739130434782608, 'micro avg_support': 65.0, 'macro avg_precision': 0.037037037037037035, 'macro avg_recall': 0.015384615384615385, 'macro avg_f1-score': 0.021739130434782608, 'macro avg_support': 65.0, 'weighted avg_precision': 0.037037037037037035, 'weighted avg_recall': 0.015384615384615385, 'weighted avg_f1-score': 0.021739130434782608, 'weighted avg_support': 65.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 0}, {'micro_f1': 0.7306397306397306, 'precision': 0.7306397306397306, 'Appeal_to_Time_precision': 0.07407407407407407, 'Appeal_to_Time_recall': 0.0273972602739726, 'Appeal_to_Time_f1-score': 0.04, 'Appeal_to_Time_support': 73.0, 'micro avg_precision': 0.07407407407407407, 'micro avg_recall': 0.0273972602739726, 'micro avg_f1-score': 0.04, 'micro avg_support': 73.0, 'macro avg_precision': 0.07407407407407407, 'macro avg_recall': 0.0273972602739726, 'macro avg_f1-score': 0.04, 'macro avg_support': 73.0, 'weighted avg_precision': 0.07407407407407407, 'weighted avg_recall': 0.0273972602739726, 'weighted avg_f1-score': 0.04, 'weighted avg_support': 73.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 1}, {'micro_f1': 0.7586980920314254, 'precision': 0.7586980920314254, 'Appeal_to_Time_precision': 0.2222222222222222, 'Appeal_to_Time_recall': 0.10526315789473684, 'Appeal_to_Time_f1-score': 0.14285714285714285, 'Appeal_to_Time_support': 57.0, 'micro avg_precision': 0.2222222222222222, 'micro avg_recall': 0.10526315789473684, 'micro avg_f1-score': 0.14285714285714285, 'micro avg_support': 57.0, 'macro avg_precision': 0.2222222222222222, 'macro avg_recall': 0.10526315789473684, 'macro avg_f1-score': 0.14285714285714285, 'macro avg_support': 57.0, 'weighted avg_precision': 0.2222222222222222, 'weighted avg_recall': 0.10526315789473684, 'weighted avg_f1-score': 0.14285714285714285, 'weighted avg_support': 57.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 2}, {'micro_f1': 0.7575757575757576, 'precision': 0.7575757575757576, 'Appeal_to_Time_precision': 0.14814814814814814, 'Appeal_to_Time_recall': 0.07272727272727272, 'Appeal_to_Time_f1-score': 0.09756097560975609, 'Appeal_to_Time_support': 55.0, 'micro avg_precision': 0.14814814814814814, 'micro avg_recall': 0.07272727272727272, 'micro avg_f1-score': 0.09756097560975609, 'micro avg_support': 55.0, 'macro avg_precision': 0.14814814814814814, 'macro avg_recall': 0.07272727272727272, 'macro avg_f1-score': 0.09756097560975609, 'macro avg_support': 55.0, 'weighted avg_precision': 0.14814814814814814, 'weighted avg_recall': 0.07272727272727272, 'weighted avg_f1-score': 0.09756097560975609, 'weighted avg_support': 55.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 3}, {'micro_f1': 0.7575757575757576, 'precision': 0.7575757575757576, 'Appeal_to_Time_precision': 0.25925925925925924, 'Appeal_to_Time_recall': 0.1320754716981132, 'Appeal_to_Time_f1-score': 0.17499999999999996, 'Appeal_to_Time_support': 53.0, 'micro avg_precision': 0.25925925925925924, 'micro avg_recall': 0.1320754716981132, 'micro avg_f1-score': 0.17499999999999996, 'micro avg_support': 53.0, 'macro avg_precision': 0.25925925925925924, 'macro avg_recall': 0.1320754716981132, 'macro avg_f1-score': 0.17499999999999996, 'macro avg_support': 53.0, 'weighted avg_precision': 0.25925925925925924, 'weighted avg_recall': 0.1320754716981132, 'weighted avg_f1-score': 0.17499999999999996, 'weighted avg_support': 53.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 4}, {'micro_f1': 0.7643097643097643, 'precision': 0.7643097643097643, 'Appeal_to_Time_precision': 0.2962962962962963, 'Appeal_to_Time_recall': 0.17777777777777778, 'Appeal_to_Time_f1-score': 0.2222222222222222, 'Appeal_to_Time_support': 45.0, 'micro avg_precision': 0.2962962962962963, 'micro avg_recall': 0.17777777777777778, 'micro avg_f1-score': 0.2222222222222222, 'micro avg_support': 45.0, 'macro avg_precision': 0.2962962962962963, 'macro avg_recall': 0.17777777777777778, 'macro avg_f1-score': 0.2222222222222222, 'macro avg_support': 45.0, 'weighted avg_precision': 0.2962962962962963, 'weighted avg_recall': 0.17777777777777778, 'weighted avg_f1-score': 0.2222222222222222, 'weighted avg_support': 45.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 5}, {'micro_f1': 0.7643097643097643, 'precision': 0.7643097643097643, 'Appeal_to_Time_precision': 0.14814814814814814, 'Appeal_to_Time_recall': 0.08333333333333333, 'Appeal_to_Time_f1-score': 0.10666666666666667, 'Appeal_to_Time_support': 48.0, 'micro avg_precision': 0.14814814814814814, 'micro avg_recall': 0.08333333333333333, 'micro avg_f1-score': 0.10666666666666667, 'micro avg_support': 48.0, 'macro avg_precision': 0.14814814814814814, 'macro avg_recall': 0.08333333333333333, 'macro avg_f1-score': 0.10666666666666667, 'macro avg_support': 48.0, 'weighted avg_precision': 0.14814814814814814, 'weighted avg_recall': 0.08333333333333333, 'weighted avg_f1-score': 0.10666666666666667, 'weighted avg_support': 48.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 6}, {'micro_f1': 0.7407407407407407, 'precision': 0.7407407407407407, 'Appeal_to_Time_precision': 0.18518518518518517, 'Appeal_to_Time_recall': 0.10869565217391304, 'Appeal_to_Time_f1-score': 0.13698630136986303, 'Appeal_to_Time_support': 46.0, 'micro avg_precision': 0.18518518518518517, 'micro avg_recall': 0.10869565217391304, 'micro avg_f1-score': 0.13698630136986303, 'micro avg_support': 46.0, 'macro avg_precision': 0.18518518518518517, 'macro avg_recall': 0.10869565217391304, 'macro avg_f1-score': 0.13698630136986303, 'macro avg_support': 46.0, 'weighted avg_precision': 0.18518518518518515, 'weighted avg_recall': 0.10869565217391304, 'weighted avg_f1-score': 0.13698630136986303, 'weighted avg_support': 46.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 7}]}
Early stopping triggered.
Saving model to directory: ./models/M2/2024-05-13-23-08-48_aug/mdeberta-v3-base_12_ME10_target=Appeal_to_Time_SUBSAMPLED_2024-05-13-23-08-48
Training model no. 13 of 23 for (13, 'Conversation_Killer') persuasion technique...
{'micro_f1': 0.8024835988753515, 'precision': 0.8024835988753515, 'Conversation_Killer_precision': 0.17687074829931973, 'Conversation_Killer_recall': 0.15757575757575756, 'Conversation_Killer_f1-score': 0.16666666666666666, 'Conversation_Killer_support': 165.0, 'micro avg_precision': 0.17687074829931973, 'micro avg_recall': 0.15757575757575756, 'micro avg_f1-score': 0.16666666666666666, 'micro avg_support': 165.0, 'macro avg_precision': 0.17687074829931973, 'macro avg_recall': 0.15757575757575756, 'macro avg_f1-score': 0.16666666666666666, 'macro avg_support': 165.0, 'weighted avg_precision': 0.17687074829931973, 'weighted avg_recall': 0.15757575757575756, 'weighted avg_f1-score': 0.16666666666666666, 'weighted avg_support': 165.0, 'O_support': 3083, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 0}
{'results': [{'micro_f1': 0.8024835988753515, 'precision': 0.8024835988753515, 'Conversation_Killer_precision': 0.17687074829931973, 'Conversation_Killer_recall': 0.15757575757575756, 'Conversation_Killer_f1-score': 0.16666666666666666, 'Conversation_Killer_support': 165.0, 'micro avg_precision': 0.17687074829931973, 'micro avg_recall': 0.15757575757575756, 'micro avg_f1-score': 0.16666666666666666, 'micro avg_support': 165.0, 'macro avg_precision': 0.17687074829931973, 'macro avg_recall': 0.15757575757575756, 'macro avg_f1-score': 0.16666666666666666, 'macro avg_support': 165.0, 'weighted avg_precision': 0.17687074829931973, 'weighted avg_recall': 0.15757575757575756, 'weighted avg_f1-score': 0.16666666666666666, 'weighted avg_support': 165.0, 'O_support': 3083, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 0}]}
Best model updated: current epoch macro f1 = 0.16666666666666666
{'micro_f1': 0.8263823805060918, 'precision': 0.8263823805060918, 'Conversation_Killer_precision': 0.2653061224489796, 'Conversation_Killer_recall': 0.23636363636363636, 'Conversation_Killer_f1-score': 0.25, 'Conversation_Killer_support': 165.0, 'micro avg_precision': 0.2653061224489796, 'micro avg_recall': 0.23636363636363636, 'micro avg_f1-score': 0.25, 'micro avg_support': 165.0, 'macro avg_precision': 0.2653061224489796, 'macro avg_recall': 0.23636363636363636, 'macro avg_f1-score': 0.25, 'macro avg_support': 165.0, 'weighted avg_precision': 0.2653061224489796, 'weighted avg_recall': 0.23636363636363636, 'weighted avg_f1-score': 0.25, 'weighted avg_support': 165.0, 'O_support': 3083, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 1}
{'results': [{'micro_f1': 0.8024835988753515, 'precision': 0.8024835988753515, 'Conversation_Killer_precision': 0.17687074829931973, 'Conversation_Killer_recall': 0.15757575757575756, 'Conversation_Killer_f1-score': 0.16666666666666666, 'Conversation_Killer_support': 165.0, 'micro avg_precision': 0.17687074829931973, 'micro avg_recall': 0.15757575757575756, 'micro avg_f1-score': 0.16666666666666666, 'micro avg_support': 165.0, 'macro avg_precision': 0.17687074829931973, 'macro avg_recall': 0.15757575757575756, 'macro avg_f1-score': 0.16666666666666666, 'macro avg_support': 165.0, 'weighted avg_precision': 0.17687074829931973, 'weighted avg_recall': 0.15757575757575756, 'weighted avg_f1-score': 0.16666666666666666, 'weighted avg_support': 165.0, 'O_support': 3083, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 0}, {'micro_f1': 0.8263823805060918, 'precision': 0.8263823805060918, 'Conversation_Killer_precision': 0.2653061224489796, 'Conversation_Killer_recall': 0.23636363636363636, 'Conversation_Killer_f1-score': 0.25, 'Conversation_Killer_support': 165.0, 'micro avg_precision': 0.2653061224489796, 'micro avg_recall': 0.23636363636363636, 'micro avg_f1-score': 0.25, 'micro avg_support': 165.0, 'macro avg_precision': 0.2653061224489796, 'macro avg_recall': 0.23636363636363636, 'macro avg_f1-score': 0.25, 'macro avg_support': 165.0, 'weighted avg_precision': 0.2653061224489796, 'weighted avg_recall': 0.23636363636363636, 'weighted avg_f1-score': 0.25, 'weighted avg_support': 165.0, 'O_support': 3083, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 1}]}
Best model updated: current epoch macro f1 = 0.25
{'micro_f1': 0.8160731021555764, 'precision': 0.8160731021555764, 'Conversation_Killer_precision': 0.3401360544217687, 'Conversation_Killer_recall': 0.33783783783783783, 'Conversation_Killer_f1-score': 0.3389830508474576, 'Conversation_Killer_support': 148.0, 'micro avg_precision': 0.3401360544217687, 'micro avg_recall': 0.33783783783783783, 'micro avg_f1-score': 0.3389830508474576, 'micro avg_support': 148.0, 'macro avg_precision': 0.3401360544217687, 'macro avg_recall': 0.33783783783783783, 'macro avg_f1-score': 0.3389830508474576, 'macro avg_support': 148.0, 'weighted avg_precision': 0.3401360544217687, 'weighted avg_recall': 0.33783783783783783, 'weighted avg_f1-score': 0.3389830508474576, 'weighted avg_support': 148.0, 'O_support': 3083, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 2}
{'results': [{'micro_f1': 0.8024835988753515, 'precision': 0.8024835988753515, 'Conversation_Killer_precision': 0.17687074829931973, 'Conversation_Killer_recall': 0.15757575757575756, 'Conversation_Killer_f1-score': 0.16666666666666666, 'Conversation_Killer_support': 165.0, 'micro avg_precision': 0.17687074829931973, 'micro avg_recall': 0.15757575757575756, 'micro avg_f1-score': 0.16666666666666666, 'micro avg_support': 165.0, 'macro avg_precision': 0.17687074829931973, 'macro avg_recall': 0.15757575757575756, 'macro avg_f1-score': 0.16666666666666666, 'macro avg_support': 165.0, 'weighted avg_precision': 0.17687074829931973, 'weighted avg_recall': 0.15757575757575756, 'weighted avg_f1-score': 0.16666666666666666, 'weighted avg_support': 165.0, 'O_support': 3083, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 0}, {'micro_f1': 0.8263823805060918, 'precision': 0.8263823805060918, 'Conversation_Killer_precision': 0.2653061224489796, 'Conversation_Killer_recall': 0.23636363636363636, 'Conversation_Killer_f1-score': 0.25, 'Conversation_Killer_support': 165.0, 'micro avg_precision': 0.2653061224489796, 'micro avg_recall': 0.23636363636363636, 'micro avg_f1-score': 0.25, 'micro avg_support': 165.0, 'macro avg_precision': 0.2653061224489796, 'macro avg_recall': 0.23636363636363636, 'macro avg_f1-score': 0.25, 'macro avg_support': 165.0, 'weighted avg_precision': 0.2653061224489796, 'weighted avg_recall': 0.23636363636363636, 'weighted avg_f1-score': 0.25, 'weighted avg_support': 165.0, 'O_support': 3083, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 1}, {'micro_f1': 0.8160731021555764, 'precision': 0.8160731021555764, 'Conversation_Killer_precision': 0.3401360544217687, 'Conversation_Killer_recall': 0.33783783783783783, 'Conversation_Killer_f1-score': 0.3389830508474576, 'Conversation_Killer_support': 148.0, 'micro avg_precision': 0.3401360544217687, 'micro avg_recall': 0.33783783783783783, 'micro avg_f1-score': 0.3389830508474576, 'micro avg_support': 148.0, 'macro avg_precision': 0.3401360544217687, 'macro avg_recall': 0.33783783783783783, 'macro avg_f1-score': 0.3389830508474576, 'macro avg_support': 148.0, 'weighted avg_precision': 0.3401360544217687, 'weighted avg_recall': 0.33783783783783783, 'weighted avg_f1-score': 0.3389830508474576, 'weighted avg_support': 148.0, 'O_support': 3083, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 2}]}
Best model updated: current epoch macro f1 = 0.3389830508474576
{'micro_f1': 0.8081068416119962, 'precision': 0.8081068416119962, 'Conversation_Killer_precision': 0.38095238095238093, 'Conversation_Killer_recall': 0.27860696517412936, 'Conversation_Killer_f1-score': 0.3218390804597701, 'Conversation_Killer_support': 201.0, 'micro avg_precision': 0.38095238095238093, 'micro avg_recall': 0.27860696517412936, 'micro avg_f1-score': 0.3218390804597701, 'micro avg_support': 201.0, 'macro avg_precision': 0.38095238095238093, 'macro avg_recall': 0.27860696517412936, 'macro avg_f1-score': 0.3218390804597701, 'macro avg_support': 201.0, 'weighted avg_precision': 0.38095238095238093, 'weighted avg_recall': 0.27860696517412936, 'weighted avg_f1-score': 0.3218390804597701, 'weighted avg_support': 201.0, 'O_support': 3083, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 3}
{'results': [{'micro_f1': 0.8024835988753515, 'precision': 0.8024835988753515, 'Conversation_Killer_precision': 0.17687074829931973, 'Conversation_Killer_recall': 0.15757575757575756, 'Conversation_Killer_f1-score': 0.16666666666666666, 'Conversation_Killer_support': 165.0, 'micro avg_precision': 0.17687074829931973, 'micro avg_recall': 0.15757575757575756, 'micro avg_f1-score': 0.16666666666666666, 'micro avg_support': 165.0, 'macro avg_precision': 0.17687074829931973, 'macro avg_recall': 0.15757575757575756, 'macro avg_f1-score': 0.16666666666666666, 'macro avg_support': 165.0, 'weighted avg_precision': 0.17687074829931973, 'weighted avg_recall': 0.15757575757575756, 'weighted avg_f1-score': 0.16666666666666666, 'weighted avg_support': 165.0, 'O_support': 3083, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 0}, {'micro_f1': 0.8263823805060918, 'precision': 0.8263823805060918, 'Conversation_Killer_precision': 0.2653061224489796, 'Conversation_Killer_recall': 0.23636363636363636, 'Conversation_Killer_f1-score': 0.25, 'Conversation_Killer_support': 165.0, 'micro avg_precision': 0.2653061224489796, 'micro avg_recall': 0.23636363636363636, 'micro avg_f1-score': 0.25, 'micro avg_support': 165.0, 'macro avg_precision': 0.2653061224489796, 'macro avg_recall': 0.23636363636363636, 'macro avg_f1-score': 0.25, 'macro avg_support': 165.0, 'weighted avg_precision': 0.2653061224489796, 'weighted avg_recall': 0.23636363636363636, 'weighted avg_f1-score': 0.25, 'weighted avg_support': 165.0, 'O_support': 3083, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 1}, {'micro_f1': 0.8160731021555764, 'precision': 0.8160731021555764, 'Conversation_Killer_precision': 0.3401360544217687, 'Conversation_Killer_recall': 0.33783783783783783, 'Conversation_Killer_f1-score': 0.3389830508474576, 'Conversation_Killer_support': 148.0, 'micro avg_precision': 0.3401360544217687, 'micro avg_recall': 0.33783783783783783, 'micro avg_f1-score': 0.3389830508474576, 'micro avg_support': 148.0, 'macro avg_precision': 0.3401360544217687, 'macro avg_recall': 0.33783783783783783, 'macro avg_f1-score': 0.3389830508474576, 'macro avg_support': 148.0, 'weighted avg_precision': 0.3401360544217687, 'weighted avg_recall': 0.33783783783783783, 'weighted avg_f1-score': 0.3389830508474576, 'weighted avg_support': 148.0, 'O_support': 3083, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 2}, {'micro_f1': 0.8081068416119962, 'precision': 0.8081068416119962, 'Conversation_Killer_precision': 0.38095238095238093, 'Conversation_Killer_recall': 0.27860696517412936, 'Conversation_Killer_f1-score': 0.3218390804597701, 'Conversation_Killer_support': 201.0, 'micro avg_precision': 0.38095238095238093, 'micro avg_recall': 0.27860696517412936, 'micro avg_f1-score': 0.3218390804597701, 'micro avg_support': 201.0, 'macro avg_precision': 0.38095238095238093, 'macro avg_recall': 0.27860696517412936, 'macro avg_f1-score': 0.3218390804597701, 'macro avg_support': 201.0, 'weighted avg_precision': 0.38095238095238093, 'weighted avg_recall': 0.27860696517412936, 'weighted avg_f1-score': 0.3218390804597701, 'weighted avg_support': 201.0, 'O_support': 3083, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 3}]}
{'micro_f1': 0.8362230552952202, 'precision': 0.8362230552952202, 'Conversation_Killer_precision': 0.3945578231292517, 'Conversation_Killer_recall': 0.35802469135802467, 'Conversation_Killer_f1-score': 0.3754045307443365, 'Conversation_Killer_support': 162.0, 'micro avg_precision': 0.3945578231292517, 'micro avg_recall': 0.35802469135802467, 'micro avg_f1-score': 0.3754045307443365, 'micro avg_support': 162.0, 'macro avg_precision': 0.3945578231292517, 'macro avg_recall': 0.35802469135802467, 'macro avg_f1-score': 0.3754045307443365, 'macro avg_support': 162.0, 'weighted avg_precision': 0.3945578231292517, 'weighted avg_recall': 0.35802469135802467, 'weighted avg_f1-score': 0.3754045307443365, 'weighted avg_support': 162.0, 'O_support': 3083, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 4}
{'results': [{'micro_f1': 0.8024835988753515, 'precision': 0.8024835988753515, 'Conversation_Killer_precision': 0.17687074829931973, 'Conversation_Killer_recall': 0.15757575757575756, 'Conversation_Killer_f1-score': 0.16666666666666666, 'Conversation_Killer_support': 165.0, 'micro avg_precision': 0.17687074829931973, 'micro avg_recall': 0.15757575757575756, 'micro avg_f1-score': 0.16666666666666666, 'micro avg_support': 165.0, 'macro avg_precision': 0.17687074829931973, 'macro avg_recall': 0.15757575757575756, 'macro avg_f1-score': 0.16666666666666666, 'macro avg_support': 165.0, 'weighted avg_precision': 0.17687074829931973, 'weighted avg_recall': 0.15757575757575756, 'weighted avg_f1-score': 0.16666666666666666, 'weighted avg_support': 165.0, 'O_support': 3083, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 0}, {'micro_f1': 0.8263823805060918, 'precision': 0.8263823805060918, 'Conversation_Killer_precision': 0.2653061224489796, 'Conversation_Killer_recall': 0.23636363636363636, 'Conversation_Killer_f1-score': 0.25, 'Conversation_Killer_support': 165.0, 'micro avg_precision': 0.2653061224489796, 'micro avg_recall': 0.23636363636363636, 'micro avg_f1-score': 0.25, 'micro avg_support': 165.0, 'macro avg_precision': 0.2653061224489796, 'macro avg_recall': 0.23636363636363636, 'macro avg_f1-score': 0.25, 'macro avg_support': 165.0, 'weighted avg_precision': 0.2653061224489796, 'weighted avg_recall': 0.23636363636363636, 'weighted avg_f1-score': 0.25, 'weighted avg_support': 165.0, 'O_support': 3083, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 1}, {'micro_f1': 0.8160731021555764, 'precision': 0.8160731021555764, 'Conversation_Killer_precision': 0.3401360544217687, 'Conversation_Killer_recall': 0.33783783783783783, 'Conversation_Killer_f1-score': 0.3389830508474576, 'Conversation_Killer_support': 148.0, 'micro avg_precision': 0.3401360544217687, 'micro avg_recall': 0.33783783783783783, 'micro avg_f1-score': 0.3389830508474576, 'micro avg_support': 148.0, 'macro avg_precision': 0.3401360544217687, 'macro avg_recall': 0.33783783783783783, 'macro avg_f1-score': 0.3389830508474576, 'macro avg_support': 148.0, 'weighted avg_precision': 0.3401360544217687, 'weighted avg_recall': 0.33783783783783783, 'weighted avg_f1-score': 0.3389830508474576, 'weighted avg_support': 148.0, 'O_support': 3083, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 2}, {'micro_f1': 0.8081068416119962, 'precision': 0.8081068416119962, 'Conversation_Killer_precision': 0.38095238095238093, 'Conversation_Killer_recall': 0.27860696517412936, 'Conversation_Killer_f1-score': 0.3218390804597701, 'Conversation_Killer_support': 201.0, 'micro avg_precision': 0.38095238095238093, 'micro avg_recall': 0.27860696517412936, 'micro avg_f1-score': 0.3218390804597701, 'micro avg_support': 201.0, 'macro avg_precision': 0.38095238095238093, 'macro avg_recall': 0.27860696517412936, 'macro avg_f1-score': 0.3218390804597701, 'macro avg_support': 201.0, 'weighted avg_precision': 0.38095238095238093, 'weighted avg_recall': 0.27860696517412936, 'weighted avg_f1-score': 0.3218390804597701, 'weighted avg_support': 201.0, 'O_support': 3083, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 3}, {'micro_f1': 0.8362230552952202, 'precision': 0.8362230552952202, 'Conversation_Killer_precision': 0.3945578231292517, 'Conversation_Killer_recall': 0.35802469135802467, 'Conversation_Killer_f1-score': 0.3754045307443365, 'Conversation_Killer_support': 162.0, 'micro avg_precision': 0.3945578231292517, 'micro avg_recall': 0.35802469135802467, 'micro avg_f1-score': 0.3754045307443365, 'micro avg_support': 162.0, 'macro avg_precision': 0.3945578231292517, 'macro avg_recall': 0.35802469135802467, 'macro avg_f1-score': 0.3754045307443365, 'macro avg_support': 162.0, 'weighted avg_precision': 0.3945578231292517, 'weighted avg_recall': 0.35802469135802467, 'weighted avg_f1-score': 0.3754045307443365, 'weighted avg_support': 162.0, 'O_support': 3083, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 4}]}
Best model updated: current epoch macro f1 = 0.3754045307443365
{'micro_f1': 0.8334114339268979, 'precision': 0.8334114339268979, 'Conversation_Killer_precision': 0.41496598639455784, 'Conversation_Killer_recall': 0.3961038961038961, 'Conversation_Killer_f1-score': 0.40531561461794025, 'Conversation_Killer_support': 154.0, 'micro avg_precision': 0.41496598639455784, 'micro avg_recall': 0.3961038961038961, 'micro avg_f1-score': 0.40531561461794025, 'micro avg_support': 154.0, 'macro avg_precision': 0.41496598639455784, 'macro avg_recall': 0.3961038961038961, 'macro avg_f1-score': 0.40531561461794025, 'macro avg_support': 154.0, 'weighted avg_precision': 0.41496598639455784, 'weighted avg_recall': 0.3961038961038961, 'weighted avg_f1-score': 0.40531561461794025, 'weighted avg_support': 154.0, 'O_support': 3083, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 5}
{'results': [{'micro_f1': 0.8024835988753515, 'precision': 0.8024835988753515, 'Conversation_Killer_precision': 0.17687074829931973, 'Conversation_Killer_recall': 0.15757575757575756, 'Conversation_Killer_f1-score': 0.16666666666666666, 'Conversation_Killer_support': 165.0, 'micro avg_precision': 0.17687074829931973, 'micro avg_recall': 0.15757575757575756, 'micro avg_f1-score': 0.16666666666666666, 'micro avg_support': 165.0, 'macro avg_precision': 0.17687074829931973, 'macro avg_recall': 0.15757575757575756, 'macro avg_f1-score': 0.16666666666666666, 'macro avg_support': 165.0, 'weighted avg_precision': 0.17687074829931973, 'weighted avg_recall': 0.15757575757575756, 'weighted avg_f1-score': 0.16666666666666666, 'weighted avg_support': 165.0, 'O_support': 3083, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 0}, {'micro_f1': 0.8263823805060918, 'precision': 0.8263823805060918, 'Conversation_Killer_precision': 0.2653061224489796, 'Conversation_Killer_recall': 0.23636363636363636, 'Conversation_Killer_f1-score': 0.25, 'Conversation_Killer_support': 165.0, 'micro avg_precision': 0.2653061224489796, 'micro avg_recall': 0.23636363636363636, 'micro avg_f1-score': 0.25, 'micro avg_support': 165.0, 'macro avg_precision': 0.2653061224489796, 'macro avg_recall': 0.23636363636363636, 'macro avg_f1-score': 0.25, 'macro avg_support': 165.0, 'weighted avg_precision': 0.2653061224489796, 'weighted avg_recall': 0.23636363636363636, 'weighted avg_f1-score': 0.25, 'weighted avg_support': 165.0, 'O_support': 3083, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 1}, {'micro_f1': 0.8160731021555764, 'precision': 0.8160731021555764, 'Conversation_Killer_precision': 0.3401360544217687, 'Conversation_Killer_recall': 0.33783783783783783, 'Conversation_Killer_f1-score': 0.3389830508474576, 'Conversation_Killer_support': 148.0, 'micro avg_precision': 0.3401360544217687, 'micro avg_recall': 0.33783783783783783, 'micro avg_f1-score': 0.3389830508474576, 'micro avg_support': 148.0, 'macro avg_precision': 0.3401360544217687, 'macro avg_recall': 0.33783783783783783, 'macro avg_f1-score': 0.3389830508474576, 'macro avg_support': 148.0, 'weighted avg_precision': 0.3401360544217687, 'weighted avg_recall': 0.33783783783783783, 'weighted avg_f1-score': 0.3389830508474576, 'weighted avg_support': 148.0, 'O_support': 3083, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 2}, {'micro_f1': 0.8081068416119962, 'precision': 0.8081068416119962, 'Conversation_Killer_precision': 0.38095238095238093, 'Conversation_Killer_recall': 0.27860696517412936, 'Conversation_Killer_f1-score': 0.3218390804597701, 'Conversation_Killer_support': 201.0, 'micro avg_precision': 0.38095238095238093, 'micro avg_recall': 0.27860696517412936, 'micro avg_f1-score': 0.3218390804597701, 'micro avg_support': 201.0, 'macro avg_precision': 0.38095238095238093, 'macro avg_recall': 0.27860696517412936, 'macro avg_f1-score': 0.3218390804597701, 'macro avg_support': 201.0, 'weighted avg_precision': 0.38095238095238093, 'weighted avg_recall': 0.27860696517412936, 'weighted avg_f1-score': 0.3218390804597701, 'weighted avg_support': 201.0, 'O_support': 3083, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 3}, {'micro_f1': 0.8362230552952202, 'precision': 0.8362230552952202, 'Conversation_Killer_precision': 0.3945578231292517, 'Conversation_Killer_recall': 0.35802469135802467, 'Conversation_Killer_f1-score': 0.3754045307443365, 'Conversation_Killer_support': 162.0, 'micro avg_precision': 0.3945578231292517, 'micro avg_recall': 0.35802469135802467, 'micro avg_f1-score': 0.3754045307443365, 'micro avg_support': 162.0, 'macro avg_precision': 0.3945578231292517, 'macro avg_recall': 0.35802469135802467, 'macro avg_f1-score': 0.3754045307443365, 'macro avg_support': 162.0, 'weighted avg_precision': 0.3945578231292517, 'weighted avg_recall': 0.35802469135802467, 'weighted avg_f1-score': 0.3754045307443365, 'weighted avg_support': 162.0, 'O_support': 3083, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 4}, {'micro_f1': 0.8334114339268979, 'precision': 0.8334114339268979, 'Conversation_Killer_precision': 0.41496598639455784, 'Conversation_Killer_recall': 0.3961038961038961, 'Conversation_Killer_f1-score': 0.40531561461794025, 'Conversation_Killer_support': 154.0, 'micro avg_precision': 0.41496598639455784, 'micro avg_recall': 0.3961038961038961, 'micro avg_f1-score': 0.40531561461794025, 'micro avg_support': 154.0, 'macro avg_precision': 0.41496598639455784, 'macro avg_recall': 0.3961038961038961, 'macro avg_f1-score': 0.40531561461794025, 'macro avg_support': 154.0, 'weighted avg_precision': 0.41496598639455784, 'weighted avg_recall': 0.3961038961038961, 'weighted avg_f1-score': 0.40531561461794025, 'weighted avg_support': 154.0, 'O_support': 3083, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 5}]}
Best model updated: current epoch macro f1 = 0.40531561461794025
{'micro_f1': 0.8289597000937207, 'precision': 0.8289597000937207, 'Conversation_Killer_precision': 0.4421768707482993, 'Conversation_Killer_recall': 0.42207792207792205, 'Conversation_Killer_f1-score': 0.43189368770764114, 'Conversation_Killer_support': 154.0, 'micro avg_precision': 0.4421768707482993, 'micro avg_recall': 0.42207792207792205, 'micro avg_f1-score': 0.43189368770764114, 'micro avg_support': 154.0, 'macro avg_precision': 0.4421768707482993, 'macro avg_recall': 0.42207792207792205, 'macro avg_f1-score': 0.43189368770764114, 'macro avg_support': 154.0, 'weighted avg_precision': 0.44217687074829926, 'weighted avg_recall': 0.42207792207792205, 'weighted avg_f1-score': 0.4318936877076412, 'weighted avg_support': 154.0, 'O_support': 3083, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 6}
{'results': [{'micro_f1': 0.8024835988753515, 'precision': 0.8024835988753515, 'Conversation_Killer_precision': 0.17687074829931973, 'Conversation_Killer_recall': 0.15757575757575756, 'Conversation_Killer_f1-score': 0.16666666666666666, 'Conversation_Killer_support': 165.0, 'micro avg_precision': 0.17687074829931973, 'micro avg_recall': 0.15757575757575756, 'micro avg_f1-score': 0.16666666666666666, 'micro avg_support': 165.0, 'macro avg_precision': 0.17687074829931973, 'macro avg_recall': 0.15757575757575756, 'macro avg_f1-score': 0.16666666666666666, 'macro avg_support': 165.0, 'weighted avg_precision': 0.17687074829931973, 'weighted avg_recall': 0.15757575757575756, 'weighted avg_f1-score': 0.16666666666666666, 'weighted avg_support': 165.0, 'O_support': 3083, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 0}, {'micro_f1': 0.8263823805060918, 'precision': 0.8263823805060918, 'Conversation_Killer_precision': 0.2653061224489796, 'Conversation_Killer_recall': 0.23636363636363636, 'Conversation_Killer_f1-score': 0.25, 'Conversation_Killer_support': 165.0, 'micro avg_precision': 0.2653061224489796, 'micro avg_recall': 0.23636363636363636, 'micro avg_f1-score': 0.25, 'micro avg_support': 165.0, 'macro avg_precision': 0.2653061224489796, 'macro avg_recall': 0.23636363636363636, 'macro avg_f1-score': 0.25, 'macro avg_support': 165.0, 'weighted avg_precision': 0.2653061224489796, 'weighted avg_recall': 0.23636363636363636, 'weighted avg_f1-score': 0.25, 'weighted avg_support': 165.0, 'O_support': 3083, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 1}, {'micro_f1': 0.8160731021555764, 'precision': 0.8160731021555764, 'Conversation_Killer_precision': 0.3401360544217687, 'Conversation_Killer_recall': 0.33783783783783783, 'Conversation_Killer_f1-score': 0.3389830508474576, 'Conversation_Killer_support': 148.0, 'micro avg_precision': 0.3401360544217687, 'micro avg_recall': 0.33783783783783783, 'micro avg_f1-score': 0.3389830508474576, 'micro avg_support': 148.0, 'macro avg_precision': 0.3401360544217687, 'macro avg_recall': 0.33783783783783783, 'macro avg_f1-score': 0.3389830508474576, 'macro avg_support': 148.0, 'weighted avg_precision': 0.3401360544217687, 'weighted avg_recall': 0.33783783783783783, 'weighted avg_f1-score': 0.3389830508474576, 'weighted avg_support': 148.0, 'O_support': 3083, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 2}, {'micro_f1': 0.8081068416119962, 'precision': 0.8081068416119962, 'Conversation_Killer_precision': 0.38095238095238093, 'Conversation_Killer_recall': 0.27860696517412936, 'Conversation_Killer_f1-score': 0.3218390804597701, 'Conversation_Killer_support': 201.0, 'micro avg_precision': 0.38095238095238093, 'micro avg_recall': 0.27860696517412936, 'micro avg_f1-score': 0.3218390804597701, 'micro avg_support': 201.0, 'macro avg_precision': 0.38095238095238093, 'macro avg_recall': 0.27860696517412936, 'macro avg_f1-score': 0.3218390804597701, 'macro avg_support': 201.0, 'weighted avg_precision': 0.38095238095238093, 'weighted avg_recall': 0.27860696517412936, 'weighted avg_f1-score': 0.3218390804597701, 'weighted avg_support': 201.0, 'O_support': 3083, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 3}, {'micro_f1': 0.8362230552952202, 'precision': 0.8362230552952202, 'Conversation_Killer_precision': 0.3945578231292517, 'Conversation_Killer_recall': 0.35802469135802467, 'Conversation_Killer_f1-score': 0.3754045307443365, 'Conversation_Killer_support': 162.0, 'micro avg_precision': 0.3945578231292517, 'micro avg_recall': 0.35802469135802467, 'micro avg_f1-score': 0.3754045307443365, 'micro avg_support': 162.0, 'macro avg_precision': 0.3945578231292517, 'macro avg_recall': 0.35802469135802467, 'macro avg_f1-score': 0.3754045307443365, 'macro avg_support': 162.0, 'weighted avg_precision': 0.3945578231292517, 'weighted avg_recall': 0.35802469135802467, 'weighted avg_f1-score': 0.3754045307443365, 'weighted avg_support': 162.0, 'O_support': 3083, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 4}, {'micro_f1': 0.8334114339268979, 'precision': 0.8334114339268979, 'Conversation_Killer_precision': 0.41496598639455784, 'Conversation_Killer_recall': 0.3961038961038961, 'Conversation_Killer_f1-score': 0.40531561461794025, 'Conversation_Killer_support': 154.0, 'micro avg_precision': 0.41496598639455784, 'micro avg_recall': 0.3961038961038961, 'micro avg_f1-score': 0.40531561461794025, 'micro avg_support': 154.0, 'macro avg_precision': 0.41496598639455784, 'macro avg_recall': 0.3961038961038961, 'macro avg_f1-score': 0.40531561461794025, 'macro avg_support': 154.0, 'weighted avg_precision': 0.41496598639455784, 'weighted avg_recall': 0.3961038961038961, 'weighted avg_f1-score': 0.40531561461794025, 'weighted avg_support': 154.0, 'O_support': 3083, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 5}, {'micro_f1': 0.8289597000937207, 'precision': 0.8289597000937207, 'Conversation_Killer_precision': 0.4421768707482993, 'Conversation_Killer_recall': 0.42207792207792205, 'Conversation_Killer_f1-score': 0.43189368770764114, 'Conversation_Killer_support': 154.0, 'micro avg_precision': 0.4421768707482993, 'micro avg_recall': 0.42207792207792205, 'micro avg_f1-score': 0.43189368770764114, 'micro avg_support': 154.0, 'macro avg_precision': 0.4421768707482993, 'macro avg_recall': 0.42207792207792205, 'macro avg_f1-score': 0.43189368770764114, 'macro avg_support': 154.0, 'weighted avg_precision': 0.44217687074829926, 'weighted avg_recall': 0.42207792207792205, 'weighted avg_f1-score': 0.4318936877076412, 'weighted avg_support': 154.0, 'O_support': 3083, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 6}]}
Best model updated: current epoch macro f1 = 0.43189368770764114
{'micro_f1': 0.837394564198688, 'precision': 0.837394564198688, 'Conversation_Killer_precision': 0.3741496598639456, 'Conversation_Killer_recall': 0.41353383458646614, 'Conversation_Killer_f1-score': 0.39285714285714285, 'Conversation_Killer_support': 133.0, 'micro avg_precision': 0.3741496598639456, 'micro avg_recall': 0.41353383458646614, 'micro avg_f1-score': 0.39285714285714285, 'micro avg_support': 133.0, 'macro avg_precision': 0.3741496598639456, 'macro avg_recall': 0.41353383458646614, 'macro avg_f1-score': 0.39285714285714285, 'macro avg_support': 133.0, 'weighted avg_precision': 0.3741496598639456, 'weighted avg_recall': 0.41353383458646614, 'weighted avg_f1-score': 0.39285714285714285, 'weighted avg_support': 133.0, 'O_support': 3083, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 7}
{'results': [{'micro_f1': 0.8024835988753515, 'precision': 0.8024835988753515, 'Conversation_Killer_precision': 0.17687074829931973, 'Conversation_Killer_recall': 0.15757575757575756, 'Conversation_Killer_f1-score': 0.16666666666666666, 'Conversation_Killer_support': 165.0, 'micro avg_precision': 0.17687074829931973, 'micro avg_recall': 0.15757575757575756, 'micro avg_f1-score': 0.16666666666666666, 'micro avg_support': 165.0, 'macro avg_precision': 0.17687074829931973, 'macro avg_recall': 0.15757575757575756, 'macro avg_f1-score': 0.16666666666666666, 'macro avg_support': 165.0, 'weighted avg_precision': 0.17687074829931973, 'weighted avg_recall': 0.15757575757575756, 'weighted avg_f1-score': 0.16666666666666666, 'weighted avg_support': 165.0, 'O_support': 3083, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 0}, {'micro_f1': 0.8263823805060918, 'precision': 0.8263823805060918, 'Conversation_Killer_precision': 0.2653061224489796, 'Conversation_Killer_recall': 0.23636363636363636, 'Conversation_Killer_f1-score': 0.25, 'Conversation_Killer_support': 165.0, 'micro avg_precision': 0.2653061224489796, 'micro avg_recall': 0.23636363636363636, 'micro avg_f1-score': 0.25, 'micro avg_support': 165.0, 'macro avg_precision': 0.2653061224489796, 'macro avg_recall': 0.23636363636363636, 'macro avg_f1-score': 0.25, 'macro avg_support': 165.0, 'weighted avg_precision': 0.2653061224489796, 'weighted avg_recall': 0.23636363636363636, 'weighted avg_f1-score': 0.25, 'weighted avg_support': 165.0, 'O_support': 3083, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 1}, {'micro_f1': 0.8160731021555764, 'precision': 0.8160731021555764, 'Conversation_Killer_precision': 0.3401360544217687, 'Conversation_Killer_recall': 0.33783783783783783, 'Conversation_Killer_f1-score': 0.3389830508474576, 'Conversation_Killer_support': 148.0, 'micro avg_precision': 0.3401360544217687, 'micro avg_recall': 0.33783783783783783, 'micro avg_f1-score': 0.3389830508474576, 'micro avg_support': 148.0, 'macro avg_precision': 0.3401360544217687, 'macro avg_recall': 0.33783783783783783, 'macro avg_f1-score': 0.3389830508474576, 'macro avg_support': 148.0, 'weighted avg_precision': 0.3401360544217687, 'weighted avg_recall': 0.33783783783783783, 'weighted avg_f1-score': 0.3389830508474576, 'weighted avg_support': 148.0, 'O_support': 3083, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 2}, {'micro_f1': 0.8081068416119962, 'precision': 0.8081068416119962, 'Conversation_Killer_precision': 0.38095238095238093, 'Conversation_Killer_recall': 0.27860696517412936, 'Conversation_Killer_f1-score': 0.3218390804597701, 'Conversation_Killer_support': 201.0, 'micro avg_precision': 0.38095238095238093, 'micro avg_recall': 0.27860696517412936, 'micro avg_f1-score': 0.3218390804597701, 'micro avg_support': 201.0, 'macro avg_precision': 0.38095238095238093, 'macro avg_recall': 0.27860696517412936, 'macro avg_f1-score': 0.3218390804597701, 'macro avg_support': 201.0, 'weighted avg_precision': 0.38095238095238093, 'weighted avg_recall': 0.27860696517412936, 'weighted avg_f1-score': 0.3218390804597701, 'weighted avg_support': 201.0, 'O_support': 3083, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 3}, {'micro_f1': 0.8362230552952202, 'precision': 0.8362230552952202, 'Conversation_Killer_precision': 0.3945578231292517, 'Conversation_Killer_recall': 0.35802469135802467, 'Conversation_Killer_f1-score': 0.3754045307443365, 'Conversation_Killer_support': 162.0, 'micro avg_precision': 0.3945578231292517, 'micro avg_recall': 0.35802469135802467, 'micro avg_f1-score': 0.3754045307443365, 'micro avg_support': 162.0, 'macro avg_precision': 0.3945578231292517, 'macro avg_recall': 0.35802469135802467, 'macro avg_f1-score': 0.3754045307443365, 'macro avg_support': 162.0, 'weighted avg_precision': 0.3945578231292517, 'weighted avg_recall': 0.35802469135802467, 'weighted avg_f1-score': 0.3754045307443365, 'weighted avg_support': 162.0, 'O_support': 3083, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 4}, {'micro_f1': 0.8334114339268979, 'precision': 0.8334114339268979, 'Conversation_Killer_precision': 0.41496598639455784, 'Conversation_Killer_recall': 0.3961038961038961, 'Conversation_Killer_f1-score': 0.40531561461794025, 'Conversation_Killer_support': 154.0, 'micro avg_precision': 0.41496598639455784, 'micro avg_recall': 0.3961038961038961, 'micro avg_f1-score': 0.40531561461794025, 'micro avg_support': 154.0, 'macro avg_precision': 0.41496598639455784, 'macro avg_recall': 0.3961038961038961, 'macro avg_f1-score': 0.40531561461794025, 'macro avg_support': 154.0, 'weighted avg_precision': 0.41496598639455784, 'weighted avg_recall': 0.3961038961038961, 'weighted avg_f1-score': 0.40531561461794025, 'weighted avg_support': 154.0, 'O_support': 3083, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 5}, {'micro_f1': 0.8289597000937207, 'precision': 0.8289597000937207, 'Conversation_Killer_precision': 0.4421768707482993, 'Conversation_Killer_recall': 0.42207792207792205, 'Conversation_Killer_f1-score': 0.43189368770764114, 'Conversation_Killer_support': 154.0, 'micro avg_precision': 0.4421768707482993, 'micro avg_recall': 0.42207792207792205, 'micro avg_f1-score': 0.43189368770764114, 'micro avg_support': 154.0, 'macro avg_precision': 0.4421768707482993, 'macro avg_recall': 0.42207792207792205, 'macro avg_f1-score': 0.43189368770764114, 'macro avg_support': 154.0, 'weighted avg_precision': 0.44217687074829926, 'weighted avg_recall': 0.42207792207792205, 'weighted avg_f1-score': 0.4318936877076412, 'weighted avg_support': 154.0, 'O_support': 3083, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 6}, {'micro_f1': 0.837394564198688, 'precision': 0.837394564198688, 'Conversation_Killer_precision': 0.3741496598639456, 'Conversation_Killer_recall': 0.41353383458646614, 'Conversation_Killer_f1-score': 0.39285714285714285, 'Conversation_Killer_support': 133.0, 'micro avg_precision': 0.3741496598639456, 'micro avg_recall': 0.41353383458646614, 'micro avg_f1-score': 0.39285714285714285, 'micro avg_support': 133.0, 'macro avg_precision': 0.3741496598639456, 'macro avg_recall': 0.41353383458646614, 'macro avg_f1-score': 0.39285714285714285, 'macro avg_support': 133.0, 'weighted avg_precision': 0.3741496598639456, 'weighted avg_recall': 0.41353383458646614, 'weighted avg_f1-score': 0.39285714285714285, 'weighted avg_support': 133.0, 'O_support': 3083, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 7}]}
{'micro_f1': 0.8338800374882849, 'precision': 0.8338800374882849, 'Conversation_Killer_precision': 0.4217687074829932, 'Conversation_Killer_recall': 0.37575757575757573, 'Conversation_Killer_f1-score': 0.3974358974358974, 'Conversation_Killer_support': 165.0, 'micro avg_precision': 0.4217687074829932, 'micro avg_recall': 0.37575757575757573, 'micro avg_f1-score': 0.3974358974358974, 'micro avg_support': 165.0, 'macro avg_precision': 0.4217687074829932, 'macro avg_recall': 0.37575757575757573, 'macro avg_f1-score': 0.3974358974358974, 'macro avg_support': 165.0, 'weighted avg_precision': 0.4217687074829932, 'weighted avg_recall': 0.37575757575757573, 'weighted avg_f1-score': 0.39743589743589736, 'weighted avg_support': 165.0, 'O_support': 3083, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 8}
{'results': [{'micro_f1': 0.8024835988753515, 'precision': 0.8024835988753515, 'Conversation_Killer_precision': 0.17687074829931973, 'Conversation_Killer_recall': 0.15757575757575756, 'Conversation_Killer_f1-score': 0.16666666666666666, 'Conversation_Killer_support': 165.0, 'micro avg_precision': 0.17687074829931973, 'micro avg_recall': 0.15757575757575756, 'micro avg_f1-score': 0.16666666666666666, 'micro avg_support': 165.0, 'macro avg_precision': 0.17687074829931973, 'macro avg_recall': 0.15757575757575756, 'macro avg_f1-score': 0.16666666666666666, 'macro avg_support': 165.0, 'weighted avg_precision': 0.17687074829931973, 'weighted avg_recall': 0.15757575757575756, 'weighted avg_f1-score': 0.16666666666666666, 'weighted avg_support': 165.0, 'O_support': 3083, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 0}, {'micro_f1': 0.8263823805060918, 'precision': 0.8263823805060918, 'Conversation_Killer_precision': 0.2653061224489796, 'Conversation_Killer_recall': 0.23636363636363636, 'Conversation_Killer_f1-score': 0.25, 'Conversation_Killer_support': 165.0, 'micro avg_precision': 0.2653061224489796, 'micro avg_recall': 0.23636363636363636, 'micro avg_f1-score': 0.25, 'micro avg_support': 165.0, 'macro avg_precision': 0.2653061224489796, 'macro avg_recall': 0.23636363636363636, 'macro avg_f1-score': 0.25, 'macro avg_support': 165.0, 'weighted avg_precision': 0.2653061224489796, 'weighted avg_recall': 0.23636363636363636, 'weighted avg_f1-score': 0.25, 'weighted avg_support': 165.0, 'O_support': 3083, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 1}, {'micro_f1': 0.8160731021555764, 'precision': 0.8160731021555764, 'Conversation_Killer_precision': 0.3401360544217687, 'Conversation_Killer_recall': 0.33783783783783783, 'Conversation_Killer_f1-score': 0.3389830508474576, 'Conversation_Killer_support': 148.0, 'micro avg_precision': 0.3401360544217687, 'micro avg_recall': 0.33783783783783783, 'micro avg_f1-score': 0.3389830508474576, 'micro avg_support': 148.0, 'macro avg_precision': 0.3401360544217687, 'macro avg_recall': 0.33783783783783783, 'macro avg_f1-score': 0.3389830508474576, 'macro avg_support': 148.0, 'weighted avg_precision': 0.3401360544217687, 'weighted avg_recall': 0.33783783783783783, 'weighted avg_f1-score': 0.3389830508474576, 'weighted avg_support': 148.0, 'O_support': 3083, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 2}, {'micro_f1': 0.8081068416119962, 'precision': 0.8081068416119962, 'Conversation_Killer_precision': 0.38095238095238093, 'Conversation_Killer_recall': 0.27860696517412936, 'Conversation_Killer_f1-score': 0.3218390804597701, 'Conversation_Killer_support': 201.0, 'micro avg_precision': 0.38095238095238093, 'micro avg_recall': 0.27860696517412936, 'micro avg_f1-score': 0.3218390804597701, 'micro avg_support': 201.0, 'macro avg_precision': 0.38095238095238093, 'macro avg_recall': 0.27860696517412936, 'macro avg_f1-score': 0.3218390804597701, 'macro avg_support': 201.0, 'weighted avg_precision': 0.38095238095238093, 'weighted avg_recall': 0.27860696517412936, 'weighted avg_f1-score': 0.3218390804597701, 'weighted avg_support': 201.0, 'O_support': 3083, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 3}, {'micro_f1': 0.8362230552952202, 'precision': 0.8362230552952202, 'Conversation_Killer_precision': 0.3945578231292517, 'Conversation_Killer_recall': 0.35802469135802467, 'Conversation_Killer_f1-score': 0.3754045307443365, 'Conversation_Killer_support': 162.0, 'micro avg_precision': 0.3945578231292517, 'micro avg_recall': 0.35802469135802467, 'micro avg_f1-score': 0.3754045307443365, 'micro avg_support': 162.0, 'macro avg_precision': 0.3945578231292517, 'macro avg_recall': 0.35802469135802467, 'macro avg_f1-score': 0.3754045307443365, 'macro avg_support': 162.0, 'weighted avg_precision': 0.3945578231292517, 'weighted avg_recall': 0.35802469135802467, 'weighted avg_f1-score': 0.3754045307443365, 'weighted avg_support': 162.0, 'O_support': 3083, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 4}, {'micro_f1': 0.8334114339268979, 'precision': 0.8334114339268979, 'Conversation_Killer_precision': 0.41496598639455784, 'Conversation_Killer_recall': 0.3961038961038961, 'Conversation_Killer_f1-score': 0.40531561461794025, 'Conversation_Killer_support': 154.0, 'micro avg_precision': 0.41496598639455784, 'micro avg_recall': 0.3961038961038961, 'micro avg_f1-score': 0.40531561461794025, 'micro avg_support': 154.0, 'macro avg_precision': 0.41496598639455784, 'macro avg_recall': 0.3961038961038961, 'macro avg_f1-score': 0.40531561461794025, 'macro avg_support': 154.0, 'weighted avg_precision': 0.41496598639455784, 'weighted avg_recall': 0.3961038961038961, 'weighted avg_f1-score': 0.40531561461794025, 'weighted avg_support': 154.0, 'O_support': 3083, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 5}, {'micro_f1': 0.8289597000937207, 'precision': 0.8289597000937207, 'Conversation_Killer_precision': 0.4421768707482993, 'Conversation_Killer_recall': 0.42207792207792205, 'Conversation_Killer_f1-score': 0.43189368770764114, 'Conversation_Killer_support': 154.0, 'micro avg_precision': 0.4421768707482993, 'micro avg_recall': 0.42207792207792205, 'micro avg_f1-score': 0.43189368770764114, 'micro avg_support': 154.0, 'macro avg_precision': 0.4421768707482993, 'macro avg_recall': 0.42207792207792205, 'macro avg_f1-score': 0.43189368770764114, 'macro avg_support': 154.0, 'weighted avg_precision': 0.44217687074829926, 'weighted avg_recall': 0.42207792207792205, 'weighted avg_f1-score': 0.4318936877076412, 'weighted avg_support': 154.0, 'O_support': 3083, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 6}, {'micro_f1': 0.837394564198688, 'precision': 0.837394564198688, 'Conversation_Killer_precision': 0.3741496598639456, 'Conversation_Killer_recall': 0.41353383458646614, 'Conversation_Killer_f1-score': 0.39285714285714285, 'Conversation_Killer_support': 133.0, 'micro avg_precision': 0.3741496598639456, 'micro avg_recall': 0.41353383458646614, 'micro avg_f1-score': 0.39285714285714285, 'micro avg_support': 133.0, 'macro avg_precision': 0.3741496598639456, 'macro avg_recall': 0.41353383458646614, 'macro avg_f1-score': 0.39285714285714285, 'macro avg_support': 133.0, 'weighted avg_precision': 0.3741496598639456, 'weighted avg_recall': 0.41353383458646614, 'weighted avg_f1-score': 0.39285714285714285, 'weighted avg_support': 133.0, 'O_support': 3083, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 7}, {'micro_f1': 0.8338800374882849, 'precision': 0.8338800374882849, 'Conversation_Killer_precision': 0.4217687074829932, 'Conversation_Killer_recall': 0.37575757575757573, 'Conversation_Killer_f1-score': 0.3974358974358974, 'Conversation_Killer_support': 165.0, 'micro avg_precision': 0.4217687074829932, 'micro avg_recall': 0.37575757575757573, 'micro avg_f1-score': 0.3974358974358974, 'micro avg_support': 165.0, 'macro avg_precision': 0.4217687074829932, 'macro avg_recall': 0.37575757575757573, 'macro avg_f1-score': 0.3974358974358974, 'macro avg_support': 165.0, 'weighted avg_precision': 0.4217687074829932, 'weighted avg_recall': 0.37575757575757573, 'weighted avg_f1-score': 0.39743589743589736, 'weighted avg_support': 165.0, 'O_support': 3083, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 8}]}
Early stopping triggered.
Saving model to directory: ./models/M2/2024-05-13-23-08-48_aug/mdeberta-v3-base_13_ME10_target=Conversation_Killer_SUBSAMPLED_2024-05-13-23-08-48
Training model no. 14 of 23 for (14, 'Loaded_Language') persuasion technique...
{'micro_f1': 0.9056764140443185, 'precision': 0.9056764140443185, 'Loaded_Language_precision': 0.09138381201044386, 'Loaded_Language_recall': 0.1958955223880597, 'Loaded_Language_f1-score': 0.12462908011869436, 'Loaded_Language_support': 536.0, 'micro avg_precision': 0.09138381201044386, 'micro avg_recall': 0.1958955223880597, 'micro avg_f1-score': 0.12462908011869436, 'micro avg_support': 536.0, 'macro avg_precision': 0.09138381201044386, 'macro avg_recall': 0.1958955223880597, 'macro avg_f1-score': 0.12462908011869436, 'macro avg_support': 536.0, 'weighted avg_precision': 0.09138381201044386, 'weighted avg_recall': 0.1958955223880597, 'weighted avg_f1-score': 0.12462908011869436, 'weighted avg_support': 536.0, 'O_support': 43792, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 0}
{'results': [{'micro_f1': 0.9056764140443185, 'precision': 0.9056764140443185, 'Loaded_Language_precision': 0.09138381201044386, 'Loaded_Language_recall': 0.1958955223880597, 'Loaded_Language_f1-score': 0.12462908011869436, 'Loaded_Language_support': 536.0, 'micro avg_precision': 0.09138381201044386, 'micro avg_recall': 0.1958955223880597, 'micro avg_f1-score': 0.12462908011869436, 'micro avg_support': 536.0, 'macro avg_precision': 0.09138381201044386, 'macro avg_recall': 0.1958955223880597, 'macro avg_f1-score': 0.12462908011869436, 'macro avg_support': 536.0, 'weighted avg_precision': 0.09138381201044386, 'weighted avg_recall': 0.1958955223880597, 'weighted avg_f1-score': 0.12462908011869436, 'weighted avg_support': 536.0, 'O_support': 43792, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 0}]}
Best model updated: current epoch macro f1 = 0.12462908011869436
{'micro_f1': 0.9118688657290297, 'precision': 0.9118688657290297, 'Loaded_Language_precision': 0.1462140992167102, 'Loaded_Language_recall': 0.30324909747292417, 'Loaded_Language_f1-score': 0.19729888432178508, 'Loaded_Language_support': 554.0, 'micro avg_precision': 0.1462140992167102, 'micro avg_recall': 0.30324909747292417, 'micro avg_f1-score': 0.19729888432178508, 'micro avg_support': 554.0, 'macro avg_precision': 0.1462140992167102, 'macro avg_recall': 0.30324909747292417, 'macro avg_f1-score': 0.19729888432178508, 'macro avg_support': 554.0, 'weighted avg_precision': 0.1462140992167102, 'weighted avg_recall': 0.30324909747292417, 'weighted avg_f1-score': 0.19729888432178508, 'weighted avg_support': 554.0, 'O_support': 43792, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 1}
{'results': [{'micro_f1': 0.9056764140443185, 'precision': 0.9056764140443185, 'Loaded_Language_precision': 0.09138381201044386, 'Loaded_Language_recall': 0.1958955223880597, 'Loaded_Language_f1-score': 0.12462908011869436, 'Loaded_Language_support': 536.0, 'micro avg_precision': 0.09138381201044386, 'micro avg_recall': 0.1958955223880597, 'micro avg_f1-score': 0.12462908011869436, 'micro avg_support': 536.0, 'macro avg_precision': 0.09138381201044386, 'macro avg_recall': 0.1958955223880597, 'macro avg_f1-score': 0.12462908011869436, 'macro avg_support': 536.0, 'weighted avg_precision': 0.09138381201044386, 'weighted avg_recall': 0.1958955223880597, 'weighted avg_f1-score': 0.12462908011869436, 'weighted avg_support': 536.0, 'O_support': 43792, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 0}, {'micro_f1': 0.9118688657290297, 'precision': 0.9118688657290297, 'Loaded_Language_precision': 0.1462140992167102, 'Loaded_Language_recall': 0.30324909747292417, 'Loaded_Language_f1-score': 0.19729888432178508, 'Loaded_Language_support': 554.0, 'micro avg_precision': 0.1462140992167102, 'micro avg_recall': 0.30324909747292417, 'micro avg_f1-score': 0.19729888432178508, 'micro avg_support': 554.0, 'macro avg_precision': 0.1462140992167102, 'macro avg_recall': 0.30324909747292417, 'macro avg_f1-score': 0.19729888432178508, 'macro avg_support': 554.0, 'weighted avg_precision': 0.1462140992167102, 'weighted avg_recall': 0.30324909747292417, 'weighted avg_f1-score': 0.19729888432178508, 'weighted avg_support': 554.0, 'O_support': 43792, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 1}]}
Best model updated: current epoch macro f1 = 0.19729888432178508
{'micro_f1': 0.9195386016391783, 'precision': 0.9195386016391783, 'Loaded_Language_precision': 0.2515230635335074, 'Loaded_Language_recall': 0.3087606837606838, 'Loaded_Language_f1-score': 0.2772182254196643, 'Loaded_Language_support': 936.0, 'micro avg_precision': 0.2515230635335074, 'micro avg_recall': 0.3087606837606838, 'micro avg_f1-score': 0.2772182254196643, 'micro avg_support': 936.0, 'macro avg_precision': 0.2515230635335074, 'macro avg_recall': 0.3087606837606838, 'macro avg_f1-score': 0.2772182254196643, 'macro avg_support': 936.0, 'weighted avg_precision': 0.2515230635335074, 'weighted avg_recall': 0.3087606837606838, 'weighted avg_f1-score': 0.2772182254196643, 'weighted avg_support': 936.0, 'O_support': 43792, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 2}
{'results': [{'micro_f1': 0.9056764140443185, 'precision': 0.9056764140443185, 'Loaded_Language_precision': 0.09138381201044386, 'Loaded_Language_recall': 0.1958955223880597, 'Loaded_Language_f1-score': 0.12462908011869436, 'Loaded_Language_support': 536.0, 'micro avg_precision': 0.09138381201044386, 'micro avg_recall': 0.1958955223880597, 'micro avg_f1-score': 0.12462908011869436, 'micro avg_support': 536.0, 'macro avg_precision': 0.09138381201044386, 'macro avg_recall': 0.1958955223880597, 'macro avg_f1-score': 0.12462908011869436, 'macro avg_support': 536.0, 'weighted avg_precision': 0.09138381201044386, 'weighted avg_recall': 0.1958955223880597, 'weighted avg_f1-score': 0.12462908011869436, 'weighted avg_support': 536.0, 'O_support': 43792, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 0}, {'micro_f1': 0.9118688657290297, 'precision': 0.9118688657290297, 'Loaded_Language_precision': 0.1462140992167102, 'Loaded_Language_recall': 0.30324909747292417, 'Loaded_Language_f1-score': 0.19729888432178508, 'Loaded_Language_support': 554.0, 'micro avg_precision': 0.1462140992167102, 'micro avg_recall': 0.30324909747292417, 'micro avg_f1-score': 0.19729888432178508, 'micro avg_support': 554.0, 'macro avg_precision': 0.1462140992167102, 'macro avg_recall': 0.30324909747292417, 'macro avg_f1-score': 0.19729888432178508, 'macro avg_support': 554.0, 'weighted avg_precision': 0.1462140992167102, 'weighted avg_recall': 0.30324909747292417, 'weighted avg_f1-score': 0.19729888432178508, 'weighted avg_support': 554.0, 'O_support': 43792, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 1}, {'micro_f1': 0.9195386016391783, 'precision': 0.9195386016391783, 'Loaded_Language_precision': 0.2515230635335074, 'Loaded_Language_recall': 0.3087606837606838, 'Loaded_Language_f1-score': 0.2772182254196643, 'Loaded_Language_support': 936.0, 'micro avg_precision': 0.2515230635335074, 'micro avg_recall': 0.3087606837606838, 'micro avg_f1-score': 0.2772182254196643, 'micro avg_support': 936.0, 'macro avg_precision': 0.2515230635335074, 'macro avg_recall': 0.3087606837606838, 'macro avg_f1-score': 0.2772182254196643, 'macro avg_support': 936.0, 'weighted avg_precision': 0.2515230635335074, 'weighted avg_recall': 0.3087606837606838, 'weighted avg_f1-score': 0.2772182254196643, 'weighted avg_support': 936.0, 'O_support': 43792, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 2}]}
Best model updated: current epoch macro f1 = 0.2772182254196643
{'micro_f1': 0.922128908226247, 'precision': 0.922128908226247, 'Loaded_Language_precision': 0.2959094865100087, 'Loaded_Language_recall': 0.3640256959314775, 'Loaded_Language_f1-score': 0.32645223235717713, 'Loaded_Language_support': 934.0, 'micro avg_precision': 0.2959094865100087, 'micro avg_recall': 0.3640256959314775, 'micro avg_f1-score': 0.32645223235717713, 'micro avg_support': 934.0, 'macro avg_precision': 0.2959094865100087, 'macro avg_recall': 0.3640256959314775, 'macro avg_f1-score': 0.32645223235717713, 'macro avg_support': 934.0, 'weighted avg_precision': 0.2959094865100087, 'weighted avg_recall': 0.3640256959314775, 'weighted avg_f1-score': 0.32645223235717713, 'weighted avg_support': 934.0, 'O_support': 43792, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 3}
{'results': [{'micro_f1': 0.9056764140443185, 'precision': 0.9056764140443185, 'Loaded_Language_precision': 0.09138381201044386, 'Loaded_Language_recall': 0.1958955223880597, 'Loaded_Language_f1-score': 0.12462908011869436, 'Loaded_Language_support': 536.0, 'micro avg_precision': 0.09138381201044386, 'micro avg_recall': 0.1958955223880597, 'micro avg_f1-score': 0.12462908011869436, 'micro avg_support': 536.0, 'macro avg_precision': 0.09138381201044386, 'macro avg_recall': 0.1958955223880597, 'macro avg_f1-score': 0.12462908011869436, 'macro avg_support': 536.0, 'weighted avg_precision': 0.09138381201044386, 'weighted avg_recall': 0.1958955223880597, 'weighted avg_f1-score': 0.12462908011869436, 'weighted avg_support': 536.0, 'O_support': 43792, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 0}, {'micro_f1': 0.9118688657290297, 'precision': 0.9118688657290297, 'Loaded_Language_precision': 0.1462140992167102, 'Loaded_Language_recall': 0.30324909747292417, 'Loaded_Language_f1-score': 0.19729888432178508, 'Loaded_Language_support': 554.0, 'micro avg_precision': 0.1462140992167102, 'micro avg_recall': 0.30324909747292417, 'micro avg_f1-score': 0.19729888432178508, 'micro avg_support': 554.0, 'macro avg_precision': 0.1462140992167102, 'macro avg_recall': 0.30324909747292417, 'macro avg_f1-score': 0.19729888432178508, 'macro avg_support': 554.0, 'weighted avg_precision': 0.1462140992167102, 'weighted avg_recall': 0.30324909747292417, 'weighted avg_f1-score': 0.19729888432178508, 'weighted avg_support': 554.0, 'O_support': 43792, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 1}, {'micro_f1': 0.9195386016391783, 'precision': 0.9195386016391783, 'Loaded_Language_precision': 0.2515230635335074, 'Loaded_Language_recall': 0.3087606837606838, 'Loaded_Language_f1-score': 0.2772182254196643, 'Loaded_Language_support': 936.0, 'micro avg_precision': 0.2515230635335074, 'micro avg_recall': 0.3087606837606838, 'micro avg_f1-score': 0.2772182254196643, 'micro avg_support': 936.0, 'macro avg_precision': 0.2515230635335074, 'macro avg_recall': 0.3087606837606838, 'macro avg_f1-score': 0.2772182254196643, 'macro avg_support': 936.0, 'weighted avg_precision': 0.2515230635335074, 'weighted avg_recall': 0.3087606837606838, 'weighted avg_f1-score': 0.2772182254196643, 'weighted avg_support': 936.0, 'O_support': 43792, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 2}, {'micro_f1': 0.922128908226247, 'precision': 0.922128908226247, 'Loaded_Language_precision': 0.2959094865100087, 'Loaded_Language_recall': 0.3640256959314775, 'Loaded_Language_f1-score': 0.32645223235717713, 'Loaded_Language_support': 934.0, 'micro avg_precision': 0.2959094865100087, 'micro avg_recall': 0.3640256959314775, 'micro avg_f1-score': 0.32645223235717713, 'micro avg_support': 934.0, 'macro avg_precision': 0.2959094865100087, 'macro avg_recall': 0.3640256959314775, 'macro avg_f1-score': 0.32645223235717713, 'macro avg_support': 934.0, 'weighted avg_precision': 0.2959094865100087, 'weighted avg_recall': 0.3640256959314775, 'weighted avg_f1-score': 0.32645223235717713, 'weighted avg_support': 934.0, 'O_support': 43792, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 3}]}
Best model updated: current epoch macro f1 = 0.32645223235717713
{'micro_f1': 0.9210765961752504, 'precision': 0.9210765961752504, 'Loaded_Language_precision': 0.350739773716275, 'Loaded_Language_recall': 0.3510452961672474, 'Loaded_Language_f1-score': 0.3508924684370919, 'Loaded_Language_support': 1148.0, 'micro avg_precision': 0.350739773716275, 'micro avg_recall': 0.3510452961672474, 'micro avg_f1-score': 0.3508924684370919, 'micro avg_support': 1148.0, 'macro avg_precision': 0.350739773716275, 'macro avg_recall': 0.3510452961672474, 'macro avg_f1-score': 0.3508924684370919, 'macro avg_support': 1148.0, 'weighted avg_precision': 0.350739773716275, 'weighted avg_recall': 0.3510452961672474, 'weighted avg_f1-score': 0.3508924684370919, 'weighted avg_support': 1148.0, 'O_support': 43792, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 4}
{'results': [{'micro_f1': 0.9056764140443185, 'precision': 0.9056764140443185, 'Loaded_Language_precision': 0.09138381201044386, 'Loaded_Language_recall': 0.1958955223880597, 'Loaded_Language_f1-score': 0.12462908011869436, 'Loaded_Language_support': 536.0, 'micro avg_precision': 0.09138381201044386, 'micro avg_recall': 0.1958955223880597, 'micro avg_f1-score': 0.12462908011869436, 'micro avg_support': 536.0, 'macro avg_precision': 0.09138381201044386, 'macro avg_recall': 0.1958955223880597, 'macro avg_f1-score': 0.12462908011869436, 'macro avg_support': 536.0, 'weighted avg_precision': 0.09138381201044386, 'weighted avg_recall': 0.1958955223880597, 'weighted avg_f1-score': 0.12462908011869436, 'weighted avg_support': 536.0, 'O_support': 43792, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 0}, {'micro_f1': 0.9118688657290297, 'precision': 0.9118688657290297, 'Loaded_Language_precision': 0.1462140992167102, 'Loaded_Language_recall': 0.30324909747292417, 'Loaded_Language_f1-score': 0.19729888432178508, 'Loaded_Language_support': 554.0, 'micro avg_precision': 0.1462140992167102, 'micro avg_recall': 0.30324909747292417, 'micro avg_f1-score': 0.19729888432178508, 'micro avg_support': 554.0, 'macro avg_precision': 0.1462140992167102, 'macro avg_recall': 0.30324909747292417, 'macro avg_f1-score': 0.19729888432178508, 'macro avg_support': 554.0, 'weighted avg_precision': 0.1462140992167102, 'weighted avg_recall': 0.30324909747292417, 'weighted avg_f1-score': 0.19729888432178508, 'weighted avg_support': 554.0, 'O_support': 43792, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 1}, {'micro_f1': 0.9195386016391783, 'precision': 0.9195386016391783, 'Loaded_Language_precision': 0.2515230635335074, 'Loaded_Language_recall': 0.3087606837606838, 'Loaded_Language_f1-score': 0.2772182254196643, 'Loaded_Language_support': 936.0, 'micro avg_precision': 0.2515230635335074, 'micro avg_recall': 0.3087606837606838, 'micro avg_f1-score': 0.2772182254196643, 'micro avg_support': 936.0, 'macro avg_precision': 0.2515230635335074, 'macro avg_recall': 0.3087606837606838, 'macro avg_f1-score': 0.2772182254196643, 'macro avg_support': 936.0, 'weighted avg_precision': 0.2515230635335074, 'weighted avg_recall': 0.3087606837606838, 'weighted avg_f1-score': 0.2772182254196643, 'weighted avg_support': 936.0, 'O_support': 43792, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 2}, {'micro_f1': 0.922128908226247, 'precision': 0.922128908226247, 'Loaded_Language_precision': 0.2959094865100087, 'Loaded_Language_recall': 0.3640256959314775, 'Loaded_Language_f1-score': 0.32645223235717713, 'Loaded_Language_support': 934.0, 'micro avg_precision': 0.2959094865100087, 'micro avg_recall': 0.3640256959314775, 'micro avg_f1-score': 0.32645223235717713, 'micro avg_support': 934.0, 'macro avg_precision': 0.2959094865100087, 'macro avg_recall': 0.3640256959314775, 'macro avg_f1-score': 0.32645223235717713, 'macro avg_support': 934.0, 'weighted avg_precision': 0.2959094865100087, 'weighted avg_recall': 0.3640256959314775, 'weighted avg_f1-score': 0.32645223235717713, 'weighted avg_support': 934.0, 'O_support': 43792, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 3}, {'micro_f1': 0.9210765961752504, 'precision': 0.9210765961752504, 'Loaded_Language_precision': 0.350739773716275, 'Loaded_Language_recall': 0.3510452961672474, 'Loaded_Language_f1-score': 0.3508924684370919, 'Loaded_Language_support': 1148.0, 'micro avg_precision': 0.350739773716275, 'micro avg_recall': 0.3510452961672474, 'micro avg_f1-score': 0.3508924684370919, 'micro avg_support': 1148.0, 'macro avg_precision': 0.350739773716275, 'macro avg_recall': 0.3510452961672474, 'macro avg_f1-score': 0.3508924684370919, 'macro avg_support': 1148.0, 'weighted avg_precision': 0.350739773716275, 'weighted avg_recall': 0.3510452961672474, 'weighted avg_f1-score': 0.3508924684370919, 'weighted avg_support': 1148.0, 'O_support': 43792, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 4}]}
Best model updated: current epoch macro f1 = 0.3508924684370919
{'micro_f1': 0.921440858039057, 'precision': 0.921440858039057, 'Loaded_Language_precision': 0.31505657093124456, 'Loaded_Language_recall': 0.40492170022371365, 'Loaded_Language_f1-score': 0.3543808125305922, 'Loaded_Language_support': 894.0, 'micro avg_precision': 0.31505657093124456, 'micro avg_recall': 0.40492170022371365, 'micro avg_f1-score': 0.3543808125305922, 'micro avg_support': 894.0, 'macro avg_precision': 0.31505657093124456, 'macro avg_recall': 0.40492170022371365, 'macro avg_f1-score': 0.3543808125305922, 'macro avg_support': 894.0, 'weighted avg_precision': 0.31505657093124456, 'weighted avg_recall': 0.40492170022371365, 'weighted avg_f1-score': 0.3543808125305922, 'weighted avg_support': 894.0, 'O_support': 43792, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 5}
{'results': [{'micro_f1': 0.9056764140443185, 'precision': 0.9056764140443185, 'Loaded_Language_precision': 0.09138381201044386, 'Loaded_Language_recall': 0.1958955223880597, 'Loaded_Language_f1-score': 0.12462908011869436, 'Loaded_Language_support': 536.0, 'micro avg_precision': 0.09138381201044386, 'micro avg_recall': 0.1958955223880597, 'micro avg_f1-score': 0.12462908011869436, 'micro avg_support': 536.0, 'macro avg_precision': 0.09138381201044386, 'macro avg_recall': 0.1958955223880597, 'macro avg_f1-score': 0.12462908011869436, 'macro avg_support': 536.0, 'weighted avg_precision': 0.09138381201044386, 'weighted avg_recall': 0.1958955223880597, 'weighted avg_f1-score': 0.12462908011869436, 'weighted avg_support': 536.0, 'O_support': 43792, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 0}, {'micro_f1': 0.9118688657290297, 'precision': 0.9118688657290297, 'Loaded_Language_precision': 0.1462140992167102, 'Loaded_Language_recall': 0.30324909747292417, 'Loaded_Language_f1-score': 0.19729888432178508, 'Loaded_Language_support': 554.0, 'micro avg_precision': 0.1462140992167102, 'micro avg_recall': 0.30324909747292417, 'micro avg_f1-score': 0.19729888432178508, 'micro avg_support': 554.0, 'macro avg_precision': 0.1462140992167102, 'macro avg_recall': 0.30324909747292417, 'macro avg_f1-score': 0.19729888432178508, 'macro avg_support': 554.0, 'weighted avg_precision': 0.1462140992167102, 'weighted avg_recall': 0.30324909747292417, 'weighted avg_f1-score': 0.19729888432178508, 'weighted avg_support': 554.0, 'O_support': 43792, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 1}, {'micro_f1': 0.9195386016391783, 'precision': 0.9195386016391783, 'Loaded_Language_precision': 0.2515230635335074, 'Loaded_Language_recall': 0.3087606837606838, 'Loaded_Language_f1-score': 0.2772182254196643, 'Loaded_Language_support': 936.0, 'micro avg_precision': 0.2515230635335074, 'micro avg_recall': 0.3087606837606838, 'micro avg_f1-score': 0.2772182254196643, 'micro avg_support': 936.0, 'macro avg_precision': 0.2515230635335074, 'macro avg_recall': 0.3087606837606838, 'macro avg_f1-score': 0.2772182254196643, 'macro avg_support': 936.0, 'weighted avg_precision': 0.2515230635335074, 'weighted avg_recall': 0.3087606837606838, 'weighted avg_f1-score': 0.2772182254196643, 'weighted avg_support': 936.0, 'O_support': 43792, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 2}, {'micro_f1': 0.922128908226247, 'precision': 0.922128908226247, 'Loaded_Language_precision': 0.2959094865100087, 'Loaded_Language_recall': 0.3640256959314775, 'Loaded_Language_f1-score': 0.32645223235717713, 'Loaded_Language_support': 934.0, 'micro avg_precision': 0.2959094865100087, 'micro avg_recall': 0.3640256959314775, 'micro avg_f1-score': 0.32645223235717713, 'micro avg_support': 934.0, 'macro avg_precision': 0.2959094865100087, 'macro avg_recall': 0.3640256959314775, 'macro avg_f1-score': 0.32645223235717713, 'macro avg_support': 934.0, 'weighted avg_precision': 0.2959094865100087, 'weighted avg_recall': 0.3640256959314775, 'weighted avg_f1-score': 0.32645223235717713, 'weighted avg_support': 934.0, 'O_support': 43792, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 3}, {'micro_f1': 0.9210765961752504, 'precision': 0.9210765961752504, 'Loaded_Language_precision': 0.350739773716275, 'Loaded_Language_recall': 0.3510452961672474, 'Loaded_Language_f1-score': 0.3508924684370919, 'Loaded_Language_support': 1148.0, 'micro avg_precision': 0.350739773716275, 'micro avg_recall': 0.3510452961672474, 'micro avg_f1-score': 0.3508924684370919, 'micro avg_support': 1148.0, 'macro avg_precision': 0.350739773716275, 'macro avg_recall': 0.3510452961672474, 'macro avg_f1-score': 0.3508924684370919, 'macro avg_support': 1148.0, 'weighted avg_precision': 0.350739773716275, 'weighted avg_recall': 0.3510452961672474, 'weighted avg_f1-score': 0.3508924684370919, 'weighted avg_support': 1148.0, 'O_support': 43792, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 4}, {'micro_f1': 0.921440858039057, 'precision': 0.921440858039057, 'Loaded_Language_precision': 0.31505657093124456, 'Loaded_Language_recall': 0.40492170022371365, 'Loaded_Language_f1-score': 0.3543808125305922, 'Loaded_Language_support': 894.0, 'micro avg_precision': 0.31505657093124456, 'micro avg_recall': 0.40492170022371365, 'micro avg_f1-score': 0.3543808125305922, 'micro avg_support': 894.0, 'macro avg_precision': 0.31505657093124456, 'macro avg_recall': 0.40492170022371365, 'macro avg_f1-score': 0.3543808125305922, 'macro avg_support': 894.0, 'weighted avg_precision': 0.31505657093124456, 'weighted avg_recall': 0.40492170022371365, 'weighted avg_f1-score': 0.3543808125305922, 'weighted avg_support': 894.0, 'O_support': 43792, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 5}]}
Best model updated: current epoch macro f1 = 0.3543808125305922
{'micro_f1': 0.9223312759283618, 'precision': 0.9223312759283618, 'Loaded_Language_precision': 0.3733681462140992, 'Loaded_Language_recall': 0.4047169811320755, 'Loaded_Language_f1-score': 0.3884110457220462, 'Loaded_Language_support': 1060.0, 'micro avg_precision': 0.3733681462140992, 'micro avg_recall': 0.4047169811320755, 'micro avg_f1-score': 0.3884110457220462, 'micro avg_support': 1060.0, 'macro avg_precision': 0.3733681462140992, 'macro avg_recall': 0.4047169811320755, 'macro avg_f1-score': 0.3884110457220462, 'macro avg_support': 1060.0, 'weighted avg_precision': 0.3733681462140992, 'weighted avg_recall': 0.4047169811320755, 'weighted avg_f1-score': 0.3884110457220462, 'weighted avg_support': 1060.0, 'O_support': 43792, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 6}
{'results': [{'micro_f1': 0.9056764140443185, 'precision': 0.9056764140443185, 'Loaded_Language_precision': 0.09138381201044386, 'Loaded_Language_recall': 0.1958955223880597, 'Loaded_Language_f1-score': 0.12462908011869436, 'Loaded_Language_support': 536.0, 'micro avg_precision': 0.09138381201044386, 'micro avg_recall': 0.1958955223880597, 'micro avg_f1-score': 0.12462908011869436, 'micro avg_support': 536.0, 'macro avg_precision': 0.09138381201044386, 'macro avg_recall': 0.1958955223880597, 'macro avg_f1-score': 0.12462908011869436, 'macro avg_support': 536.0, 'weighted avg_precision': 0.09138381201044386, 'weighted avg_recall': 0.1958955223880597, 'weighted avg_f1-score': 0.12462908011869436, 'weighted avg_support': 536.0, 'O_support': 43792, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 0}, {'micro_f1': 0.9118688657290297, 'precision': 0.9118688657290297, 'Loaded_Language_precision': 0.1462140992167102, 'Loaded_Language_recall': 0.30324909747292417, 'Loaded_Language_f1-score': 0.19729888432178508, 'Loaded_Language_support': 554.0, 'micro avg_precision': 0.1462140992167102, 'micro avg_recall': 0.30324909747292417, 'micro avg_f1-score': 0.19729888432178508, 'micro avg_support': 554.0, 'macro avg_precision': 0.1462140992167102, 'macro avg_recall': 0.30324909747292417, 'macro avg_f1-score': 0.19729888432178508, 'macro avg_support': 554.0, 'weighted avg_precision': 0.1462140992167102, 'weighted avg_recall': 0.30324909747292417, 'weighted avg_f1-score': 0.19729888432178508, 'weighted avg_support': 554.0, 'O_support': 43792, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 1}, {'micro_f1': 0.9195386016391783, 'precision': 0.9195386016391783, 'Loaded_Language_precision': 0.2515230635335074, 'Loaded_Language_recall': 0.3087606837606838, 'Loaded_Language_f1-score': 0.2772182254196643, 'Loaded_Language_support': 936.0, 'micro avg_precision': 0.2515230635335074, 'micro avg_recall': 0.3087606837606838, 'micro avg_f1-score': 0.2772182254196643, 'micro avg_support': 936.0, 'macro avg_precision': 0.2515230635335074, 'macro avg_recall': 0.3087606837606838, 'macro avg_f1-score': 0.2772182254196643, 'macro avg_support': 936.0, 'weighted avg_precision': 0.2515230635335074, 'weighted avg_recall': 0.3087606837606838, 'weighted avg_f1-score': 0.2772182254196643, 'weighted avg_support': 936.0, 'O_support': 43792, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 2}, {'micro_f1': 0.922128908226247, 'precision': 0.922128908226247, 'Loaded_Language_precision': 0.2959094865100087, 'Loaded_Language_recall': 0.3640256959314775, 'Loaded_Language_f1-score': 0.32645223235717713, 'Loaded_Language_support': 934.0, 'micro avg_precision': 0.2959094865100087, 'micro avg_recall': 0.3640256959314775, 'micro avg_f1-score': 0.32645223235717713, 'micro avg_support': 934.0, 'macro avg_precision': 0.2959094865100087, 'macro avg_recall': 0.3640256959314775, 'macro avg_f1-score': 0.32645223235717713, 'macro avg_support': 934.0, 'weighted avg_precision': 0.2959094865100087, 'weighted avg_recall': 0.3640256959314775, 'weighted avg_f1-score': 0.32645223235717713, 'weighted avg_support': 934.0, 'O_support': 43792, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 3}, {'micro_f1': 0.9210765961752504, 'precision': 0.9210765961752504, 'Loaded_Language_precision': 0.350739773716275, 'Loaded_Language_recall': 0.3510452961672474, 'Loaded_Language_f1-score': 0.3508924684370919, 'Loaded_Language_support': 1148.0, 'micro avg_precision': 0.350739773716275, 'micro avg_recall': 0.3510452961672474, 'micro avg_f1-score': 0.3508924684370919, 'micro avg_support': 1148.0, 'macro avg_precision': 0.350739773716275, 'macro avg_recall': 0.3510452961672474, 'macro avg_f1-score': 0.3508924684370919, 'macro avg_support': 1148.0, 'weighted avg_precision': 0.350739773716275, 'weighted avg_recall': 0.3510452961672474, 'weighted avg_f1-score': 0.3508924684370919, 'weighted avg_support': 1148.0, 'O_support': 43792, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 4}, {'micro_f1': 0.921440858039057, 'precision': 0.921440858039057, 'Loaded_Language_precision': 0.31505657093124456, 'Loaded_Language_recall': 0.40492170022371365, 'Loaded_Language_f1-score': 0.3543808125305922, 'Loaded_Language_support': 894.0, 'micro avg_precision': 0.31505657093124456, 'micro avg_recall': 0.40492170022371365, 'micro avg_f1-score': 0.3543808125305922, 'micro avg_support': 894.0, 'macro avg_precision': 0.31505657093124456, 'macro avg_recall': 0.40492170022371365, 'macro avg_f1-score': 0.3543808125305922, 'macro avg_support': 894.0, 'weighted avg_precision': 0.31505657093124456, 'weighted avg_recall': 0.40492170022371365, 'weighted avg_f1-score': 0.3543808125305922, 'weighted avg_support': 894.0, 'O_support': 43792, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 5}, {'micro_f1': 0.9223312759283618, 'precision': 0.9223312759283618, 'Loaded_Language_precision': 0.3733681462140992, 'Loaded_Language_recall': 0.4047169811320755, 'Loaded_Language_f1-score': 0.3884110457220462, 'Loaded_Language_support': 1060.0, 'micro avg_precision': 0.3733681462140992, 'micro avg_recall': 0.4047169811320755, 'micro avg_f1-score': 0.3884110457220462, 'micro avg_support': 1060.0, 'macro avg_precision': 0.3733681462140992, 'macro avg_recall': 0.4047169811320755, 'macro avg_f1-score': 0.3884110457220462, 'macro avg_support': 1060.0, 'weighted avg_precision': 0.3733681462140992, 'weighted avg_recall': 0.4047169811320755, 'weighted avg_f1-score': 0.3884110457220462, 'weighted avg_support': 1060.0, 'O_support': 43792, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 6}]}
Best model updated: current epoch macro f1 = 0.3884110457220462
{'micro_f1': 0.9206111504603866, 'precision': 0.9206111504603866, 'Loaded_Language_precision': 0.308964316797215, 'Loaded_Language_recall': 0.41813898704358066, 'Loaded_Language_f1-score': 0.35535535535535534, 'Loaded_Language_support': 849.0, 'micro avg_precision': 0.308964316797215, 'micro avg_recall': 0.41813898704358066, 'micro avg_f1-score': 0.35535535535535534, 'micro avg_support': 849.0, 'macro avg_precision': 0.308964316797215, 'macro avg_recall': 0.41813898704358066, 'macro avg_f1-score': 0.35535535535535534, 'macro avg_support': 849.0, 'weighted avg_precision': 0.308964316797215, 'weighted avg_recall': 0.41813898704358066, 'weighted avg_f1-score': 0.35535535535535534, 'weighted avg_support': 849.0, 'O_support': 43792, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 7}
{'results': [{'micro_f1': 0.9056764140443185, 'precision': 0.9056764140443185, 'Loaded_Language_precision': 0.09138381201044386, 'Loaded_Language_recall': 0.1958955223880597, 'Loaded_Language_f1-score': 0.12462908011869436, 'Loaded_Language_support': 536.0, 'micro avg_precision': 0.09138381201044386, 'micro avg_recall': 0.1958955223880597, 'micro avg_f1-score': 0.12462908011869436, 'micro avg_support': 536.0, 'macro avg_precision': 0.09138381201044386, 'macro avg_recall': 0.1958955223880597, 'macro avg_f1-score': 0.12462908011869436, 'macro avg_support': 536.0, 'weighted avg_precision': 0.09138381201044386, 'weighted avg_recall': 0.1958955223880597, 'weighted avg_f1-score': 0.12462908011869436, 'weighted avg_support': 536.0, 'O_support': 43792, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 0}, {'micro_f1': 0.9118688657290297, 'precision': 0.9118688657290297, 'Loaded_Language_precision': 0.1462140992167102, 'Loaded_Language_recall': 0.30324909747292417, 'Loaded_Language_f1-score': 0.19729888432178508, 'Loaded_Language_support': 554.0, 'micro avg_precision': 0.1462140992167102, 'micro avg_recall': 0.30324909747292417, 'micro avg_f1-score': 0.19729888432178508, 'micro avg_support': 554.0, 'macro avg_precision': 0.1462140992167102, 'macro avg_recall': 0.30324909747292417, 'macro avg_f1-score': 0.19729888432178508, 'macro avg_support': 554.0, 'weighted avg_precision': 0.1462140992167102, 'weighted avg_recall': 0.30324909747292417, 'weighted avg_f1-score': 0.19729888432178508, 'weighted avg_support': 554.0, 'O_support': 43792, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 1}, {'micro_f1': 0.9195386016391783, 'precision': 0.9195386016391783, 'Loaded_Language_precision': 0.2515230635335074, 'Loaded_Language_recall': 0.3087606837606838, 'Loaded_Language_f1-score': 0.2772182254196643, 'Loaded_Language_support': 936.0, 'micro avg_precision': 0.2515230635335074, 'micro avg_recall': 0.3087606837606838, 'micro avg_f1-score': 0.2772182254196643, 'micro avg_support': 936.0, 'macro avg_precision': 0.2515230635335074, 'macro avg_recall': 0.3087606837606838, 'macro avg_f1-score': 0.2772182254196643, 'macro avg_support': 936.0, 'weighted avg_precision': 0.2515230635335074, 'weighted avg_recall': 0.3087606837606838, 'weighted avg_f1-score': 0.2772182254196643, 'weighted avg_support': 936.0, 'O_support': 43792, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 2}, {'micro_f1': 0.922128908226247, 'precision': 0.922128908226247, 'Loaded_Language_precision': 0.2959094865100087, 'Loaded_Language_recall': 0.3640256959314775, 'Loaded_Language_f1-score': 0.32645223235717713, 'Loaded_Language_support': 934.0, 'micro avg_precision': 0.2959094865100087, 'micro avg_recall': 0.3640256959314775, 'micro avg_f1-score': 0.32645223235717713, 'micro avg_support': 934.0, 'macro avg_precision': 0.2959094865100087, 'macro avg_recall': 0.3640256959314775, 'macro avg_f1-score': 0.32645223235717713, 'macro avg_support': 934.0, 'weighted avg_precision': 0.2959094865100087, 'weighted avg_recall': 0.3640256959314775, 'weighted avg_f1-score': 0.32645223235717713, 'weighted avg_support': 934.0, 'O_support': 43792, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 3}, {'micro_f1': 0.9210765961752504, 'precision': 0.9210765961752504, 'Loaded_Language_precision': 0.350739773716275, 'Loaded_Language_recall': 0.3510452961672474, 'Loaded_Language_f1-score': 0.3508924684370919, 'Loaded_Language_support': 1148.0, 'micro avg_precision': 0.350739773716275, 'micro avg_recall': 0.3510452961672474, 'micro avg_f1-score': 0.3508924684370919, 'micro avg_support': 1148.0, 'macro avg_precision': 0.350739773716275, 'macro avg_recall': 0.3510452961672474, 'macro avg_f1-score': 0.3508924684370919, 'macro avg_support': 1148.0, 'weighted avg_precision': 0.350739773716275, 'weighted avg_recall': 0.3510452961672474, 'weighted avg_f1-score': 0.3508924684370919, 'weighted avg_support': 1148.0, 'O_support': 43792, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 4}, {'micro_f1': 0.921440858039057, 'precision': 0.921440858039057, 'Loaded_Language_precision': 0.31505657093124456, 'Loaded_Language_recall': 0.40492170022371365, 'Loaded_Language_f1-score': 0.3543808125305922, 'Loaded_Language_support': 894.0, 'micro avg_precision': 0.31505657093124456, 'micro avg_recall': 0.40492170022371365, 'micro avg_f1-score': 0.3543808125305922, 'micro avg_support': 894.0, 'macro avg_precision': 0.31505657093124456, 'macro avg_recall': 0.40492170022371365, 'macro avg_f1-score': 0.3543808125305922, 'macro avg_support': 894.0, 'weighted avg_precision': 0.31505657093124456, 'weighted avg_recall': 0.40492170022371365, 'weighted avg_f1-score': 0.3543808125305922, 'weighted avg_support': 894.0, 'O_support': 43792, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 5}, {'micro_f1': 0.9223312759283618, 'precision': 0.9223312759283618, 'Loaded_Language_precision': 0.3733681462140992, 'Loaded_Language_recall': 0.4047169811320755, 'Loaded_Language_f1-score': 0.3884110457220462, 'Loaded_Language_support': 1060.0, 'micro avg_precision': 0.3733681462140992, 'micro avg_recall': 0.4047169811320755, 'micro avg_f1-score': 0.3884110457220462, 'micro avg_support': 1060.0, 'macro avg_precision': 0.3733681462140992, 'macro avg_recall': 0.4047169811320755, 'macro avg_f1-score': 0.3884110457220462, 'macro avg_support': 1060.0, 'weighted avg_precision': 0.3733681462140992, 'weighted avg_recall': 0.4047169811320755, 'weighted avg_f1-score': 0.3884110457220462, 'weighted avg_support': 1060.0, 'O_support': 43792, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 6}, {'micro_f1': 0.9206111504603866, 'precision': 0.9206111504603866, 'Loaded_Language_precision': 0.308964316797215, 'Loaded_Language_recall': 0.41813898704358066, 'Loaded_Language_f1-score': 0.35535535535535534, 'Loaded_Language_support': 849.0, 'micro avg_precision': 0.308964316797215, 'micro avg_recall': 0.41813898704358066, 'micro avg_f1-score': 0.35535535535535534, 'micro avg_support': 849.0, 'macro avg_precision': 0.308964316797215, 'macro avg_recall': 0.41813898704358066, 'macro avg_f1-score': 0.35535535535535534, 'macro avg_support': 849.0, 'weighted avg_precision': 0.308964316797215, 'weighted avg_recall': 0.41813898704358066, 'weighted avg_f1-score': 0.35535535535535534, 'weighted avg_support': 849.0, 'O_support': 43792, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 7}]}
{'micro_f1': 0.9216634625113832, 'precision': 0.9216634625113832, 'Loaded_Language_precision': 0.3872932985204526, 'Loaded_Language_recall': 0.3723849372384937, 'Loaded_Language_f1-score': 0.37969283276450516, 'Loaded_Language_support': 1195.0, 'micro avg_precision': 0.3872932985204526, 'micro avg_recall': 0.3723849372384937, 'micro avg_f1-score': 0.37969283276450516, 'micro avg_support': 1195.0, 'macro avg_precision': 0.3872932985204526, 'macro avg_recall': 0.3723849372384937, 'macro avg_f1-score': 0.37969283276450516, 'macro avg_support': 1195.0, 'weighted avg_precision': 0.3872932985204526, 'weighted avg_recall': 0.3723849372384937, 'weighted avg_f1-score': 0.37969283276450516, 'weighted avg_support': 1195.0, 'O_support': 43792, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 8}
{'results': [{'micro_f1': 0.9056764140443185, 'precision': 0.9056764140443185, 'Loaded_Language_precision': 0.09138381201044386, 'Loaded_Language_recall': 0.1958955223880597, 'Loaded_Language_f1-score': 0.12462908011869436, 'Loaded_Language_support': 536.0, 'micro avg_precision': 0.09138381201044386, 'micro avg_recall': 0.1958955223880597, 'micro avg_f1-score': 0.12462908011869436, 'micro avg_support': 536.0, 'macro avg_precision': 0.09138381201044386, 'macro avg_recall': 0.1958955223880597, 'macro avg_f1-score': 0.12462908011869436, 'macro avg_support': 536.0, 'weighted avg_precision': 0.09138381201044386, 'weighted avg_recall': 0.1958955223880597, 'weighted avg_f1-score': 0.12462908011869436, 'weighted avg_support': 536.0, 'O_support': 43792, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 0}, {'micro_f1': 0.9118688657290297, 'precision': 0.9118688657290297, 'Loaded_Language_precision': 0.1462140992167102, 'Loaded_Language_recall': 0.30324909747292417, 'Loaded_Language_f1-score': 0.19729888432178508, 'Loaded_Language_support': 554.0, 'micro avg_precision': 0.1462140992167102, 'micro avg_recall': 0.30324909747292417, 'micro avg_f1-score': 0.19729888432178508, 'micro avg_support': 554.0, 'macro avg_precision': 0.1462140992167102, 'macro avg_recall': 0.30324909747292417, 'macro avg_f1-score': 0.19729888432178508, 'macro avg_support': 554.0, 'weighted avg_precision': 0.1462140992167102, 'weighted avg_recall': 0.30324909747292417, 'weighted avg_f1-score': 0.19729888432178508, 'weighted avg_support': 554.0, 'O_support': 43792, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 1}, {'micro_f1': 0.9195386016391783, 'precision': 0.9195386016391783, 'Loaded_Language_precision': 0.2515230635335074, 'Loaded_Language_recall': 0.3087606837606838, 'Loaded_Language_f1-score': 0.2772182254196643, 'Loaded_Language_support': 936.0, 'micro avg_precision': 0.2515230635335074, 'micro avg_recall': 0.3087606837606838, 'micro avg_f1-score': 0.2772182254196643, 'micro avg_support': 936.0, 'macro avg_precision': 0.2515230635335074, 'macro avg_recall': 0.3087606837606838, 'macro avg_f1-score': 0.2772182254196643, 'macro avg_support': 936.0, 'weighted avg_precision': 0.2515230635335074, 'weighted avg_recall': 0.3087606837606838, 'weighted avg_f1-score': 0.2772182254196643, 'weighted avg_support': 936.0, 'O_support': 43792, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 2}, {'micro_f1': 0.922128908226247, 'precision': 0.922128908226247, 'Loaded_Language_precision': 0.2959094865100087, 'Loaded_Language_recall': 0.3640256959314775, 'Loaded_Language_f1-score': 0.32645223235717713, 'Loaded_Language_support': 934.0, 'micro avg_precision': 0.2959094865100087, 'micro avg_recall': 0.3640256959314775, 'micro avg_f1-score': 0.32645223235717713, 'micro avg_support': 934.0, 'macro avg_precision': 0.2959094865100087, 'macro avg_recall': 0.3640256959314775, 'macro avg_f1-score': 0.32645223235717713, 'macro avg_support': 934.0, 'weighted avg_precision': 0.2959094865100087, 'weighted avg_recall': 0.3640256959314775, 'weighted avg_f1-score': 0.32645223235717713, 'weighted avg_support': 934.0, 'O_support': 43792, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 3}, {'micro_f1': 0.9210765961752504, 'precision': 0.9210765961752504, 'Loaded_Language_precision': 0.350739773716275, 'Loaded_Language_recall': 0.3510452961672474, 'Loaded_Language_f1-score': 0.3508924684370919, 'Loaded_Language_support': 1148.0, 'micro avg_precision': 0.350739773716275, 'micro avg_recall': 0.3510452961672474, 'micro avg_f1-score': 0.3508924684370919, 'micro avg_support': 1148.0, 'macro avg_precision': 0.350739773716275, 'macro avg_recall': 0.3510452961672474, 'macro avg_f1-score': 0.3508924684370919, 'macro avg_support': 1148.0, 'weighted avg_precision': 0.350739773716275, 'weighted avg_recall': 0.3510452961672474, 'weighted avg_f1-score': 0.3508924684370919, 'weighted avg_support': 1148.0, 'O_support': 43792, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 4}, {'micro_f1': 0.921440858039057, 'precision': 0.921440858039057, 'Loaded_Language_precision': 0.31505657093124456, 'Loaded_Language_recall': 0.40492170022371365, 'Loaded_Language_f1-score': 0.3543808125305922, 'Loaded_Language_support': 894.0, 'micro avg_precision': 0.31505657093124456, 'micro avg_recall': 0.40492170022371365, 'micro avg_f1-score': 0.3543808125305922, 'micro avg_support': 894.0, 'macro avg_precision': 0.31505657093124456, 'macro avg_recall': 0.40492170022371365, 'macro avg_f1-score': 0.3543808125305922, 'macro avg_support': 894.0, 'weighted avg_precision': 0.31505657093124456, 'weighted avg_recall': 0.40492170022371365, 'weighted avg_f1-score': 0.3543808125305922, 'weighted avg_support': 894.0, 'O_support': 43792, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 5}, {'micro_f1': 0.9223312759283618, 'precision': 0.9223312759283618, 'Loaded_Language_precision': 0.3733681462140992, 'Loaded_Language_recall': 0.4047169811320755, 'Loaded_Language_f1-score': 0.3884110457220462, 'Loaded_Language_support': 1060.0, 'micro avg_precision': 0.3733681462140992, 'micro avg_recall': 0.4047169811320755, 'micro avg_f1-score': 0.3884110457220462, 'micro avg_support': 1060.0, 'macro avg_precision': 0.3733681462140992, 'macro avg_recall': 0.4047169811320755, 'macro avg_f1-score': 0.3884110457220462, 'macro avg_support': 1060.0, 'weighted avg_precision': 0.3733681462140992, 'weighted avg_recall': 0.4047169811320755, 'weighted avg_f1-score': 0.3884110457220462, 'weighted avg_support': 1060.0, 'O_support': 43792, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 6}, {'micro_f1': 0.9206111504603866, 'precision': 0.9206111504603866, 'Loaded_Language_precision': 0.308964316797215, 'Loaded_Language_recall': 0.41813898704358066, 'Loaded_Language_f1-score': 0.35535535535535534, 'Loaded_Language_support': 849.0, 'micro avg_precision': 0.308964316797215, 'micro avg_recall': 0.41813898704358066, 'micro avg_f1-score': 0.35535535535535534, 'micro avg_support': 849.0, 'macro avg_precision': 0.308964316797215, 'macro avg_recall': 0.41813898704358066, 'macro avg_f1-score': 0.35535535535535534, 'macro avg_support': 849.0, 'weighted avg_precision': 0.308964316797215, 'weighted avg_recall': 0.41813898704358066, 'weighted avg_f1-score': 0.35535535535535534, 'weighted avg_support': 849.0, 'O_support': 43792, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 7}, {'micro_f1': 0.9216634625113832, 'precision': 0.9216634625113832, 'Loaded_Language_precision': 0.3872932985204526, 'Loaded_Language_recall': 0.3723849372384937, 'Loaded_Language_f1-score': 0.37969283276450516, 'Loaded_Language_support': 1195.0, 'micro avg_precision': 0.3872932985204526, 'micro avg_recall': 0.3723849372384937, 'micro avg_f1-score': 0.37969283276450516, 'micro avg_support': 1195.0, 'macro avg_precision': 0.3872932985204526, 'macro avg_recall': 0.3723849372384937, 'macro avg_f1-score': 0.37969283276450516, 'macro avg_support': 1195.0, 'weighted avg_precision': 0.3872932985204526, 'weighted avg_recall': 0.3723849372384937, 'weighted avg_f1-score': 0.37969283276450516, 'weighted avg_support': 1195.0, 'O_support': 43792, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 8}]}
Early stopping triggered.
Saving model to directory: ./models/M2/2024-05-13-23-08-48_aug/mdeberta-v3-base_14_ME10_target=Loaded_Language_SUBSAMPLED_2024-05-13-23-08-48
Training model no. 15 of 23 for (15, 'Repetition') persuasion technique...
{'micro_f1': 0.919447302660591, 'precision': 0.9194473026605909, 'Repetition_precision': 0.2597402597402597, 'Repetition_recall': 0.3508771929824561, 'Repetition_f1-score': 0.29850746268656714, 'Repetition_support': 114.0, 'micro avg_precision': 0.2597402597402597, 'micro avg_recall': 0.3508771929824561, 'micro avg_f1-score': 0.29850746268656714, 'micro avg_support': 114.0, 'macro avg_precision': 0.2597402597402597, 'macro avg_recall': 0.3508771929824561, 'macro avg_f1-score': 0.29850746268656714, 'macro avg_support': 114.0, 'weighted avg_precision': 0.2597402597402597, 'weighted avg_recall': 0.3508771929824561, 'weighted avg_f1-score': 0.2985074626865671, 'weighted avg_support': 114.0, 'O_support': 6058, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 0}
{'results': [{'micro_f1': 0.919447302660591, 'precision': 0.9194473026605909, 'Repetition_precision': 0.2597402597402597, 'Repetition_recall': 0.3508771929824561, 'Repetition_f1-score': 0.29850746268656714, 'Repetition_support': 114.0, 'micro avg_precision': 0.2597402597402597, 'micro avg_recall': 0.3508771929824561, 'micro avg_f1-score': 0.29850746268656714, 'micro avg_support': 114.0, 'macro avg_precision': 0.2597402597402597, 'macro avg_recall': 0.3508771929824561, 'macro avg_f1-score': 0.29850746268656714, 'macro avg_support': 114.0, 'weighted avg_precision': 0.2597402597402597, 'weighted avg_recall': 0.3508771929824561, 'weighted avg_f1-score': 0.2985074626865671, 'weighted avg_support': 114.0, 'O_support': 6058, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 0}]}
Best model updated: current epoch macro f1 = 0.29850746268656714
{'micro_f1': 0.9401734528884316, 'precision': 0.9401734528884316, 'Repetition_precision': 0.4675324675324675, 'Repetition_recall': 0.5538461538461539, 'Repetition_f1-score': 0.5070422535211268, 'Repetition_support': 130.0, 'micro avg_precision': 0.4675324675324675, 'micro avg_recall': 0.5538461538461539, 'micro avg_f1-score': 0.5070422535211268, 'micro avg_support': 130.0, 'macro avg_precision': 0.4675324675324675, 'macro avg_recall': 0.5538461538461539, 'macro avg_f1-score': 0.5070422535211268, 'macro avg_support': 130.0, 'weighted avg_precision': 0.4675324675324675, 'weighted avg_recall': 0.5538461538461539, 'weighted avg_f1-score': 0.5070422535211268, 'weighted avg_support': 130.0, 'O_support': 6058, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 1}
{'results': [{'micro_f1': 0.919447302660591, 'precision': 0.9194473026605909, 'Repetition_precision': 0.2597402597402597, 'Repetition_recall': 0.3508771929824561, 'Repetition_f1-score': 0.29850746268656714, 'Repetition_support': 114.0, 'micro avg_precision': 0.2597402597402597, 'micro avg_recall': 0.3508771929824561, 'micro avg_f1-score': 0.29850746268656714, 'micro avg_support': 114.0, 'macro avg_precision': 0.2597402597402597, 'macro avg_recall': 0.3508771929824561, 'macro avg_f1-score': 0.29850746268656714, 'macro avg_support': 114.0, 'weighted avg_precision': 0.2597402597402597, 'weighted avg_recall': 0.3508771929824561, 'weighted avg_f1-score': 0.2985074626865671, 'weighted avg_support': 114.0, 'O_support': 6058, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 0}, {'micro_f1': 0.9401734528884316, 'precision': 0.9401734528884316, 'Repetition_precision': 0.4675324675324675, 'Repetition_recall': 0.5538461538461539, 'Repetition_f1-score': 0.5070422535211268, 'Repetition_support': 130.0, 'micro avg_precision': 0.4675324675324675, 'micro avg_recall': 0.5538461538461539, 'micro avg_f1-score': 0.5070422535211268, 'micro avg_support': 130.0, 'macro avg_precision': 0.4675324675324675, 'macro avg_recall': 0.5538461538461539, 'macro avg_f1-score': 0.5070422535211268, 'macro avg_support': 130.0, 'weighted avg_precision': 0.4675324675324675, 'weighted avg_recall': 0.5538461538461539, 'weighted avg_f1-score': 0.5070422535211268, 'weighted avg_support': 130.0, 'O_support': 6058, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 1}]}
Best model updated: current epoch macro f1 = 0.5070422535211268
{'micro_f1': 0.9325297662795825, 'precision': 0.9325297662795825, 'Repetition_precision': 0.44805194805194803, 'Repetition_recall': 0.6216216216216216, 'Repetition_f1-score': 0.5207547169811321, 'Repetition_support': 111.0, 'micro avg_precision': 0.44805194805194803, 'micro avg_recall': 0.6216216216216216, 'micro avg_f1-score': 0.5207547169811321, 'micro avg_support': 111.0, 'macro avg_precision': 0.44805194805194803, 'macro avg_recall': 0.6216216216216216, 'macro avg_f1-score': 0.5207547169811321, 'macro avg_support': 111.0, 'weighted avg_precision': 0.44805194805194803, 'weighted avg_recall': 0.6216216216216216, 'weighted avg_f1-score': 0.5207547169811321, 'weighted avg_support': 111.0, 'O_support': 6058, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 2}
{'results': [{'micro_f1': 0.919447302660591, 'precision': 0.9194473026605909, 'Repetition_precision': 0.2597402597402597, 'Repetition_recall': 0.3508771929824561, 'Repetition_f1-score': 0.29850746268656714, 'Repetition_support': 114.0, 'micro avg_precision': 0.2597402597402597, 'micro avg_recall': 0.3508771929824561, 'micro avg_f1-score': 0.29850746268656714, 'micro avg_support': 114.0, 'macro avg_precision': 0.2597402597402597, 'macro avg_recall': 0.3508771929824561, 'macro avg_f1-score': 0.29850746268656714, 'macro avg_support': 114.0, 'weighted avg_precision': 0.2597402597402597, 'weighted avg_recall': 0.3508771929824561, 'weighted avg_f1-score': 0.2985074626865671, 'weighted avg_support': 114.0, 'O_support': 6058, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 0}, {'micro_f1': 0.9401734528884316, 'precision': 0.9401734528884316, 'Repetition_precision': 0.4675324675324675, 'Repetition_recall': 0.5538461538461539, 'Repetition_f1-score': 0.5070422535211268, 'Repetition_support': 130.0, 'micro avg_precision': 0.4675324675324675, 'micro avg_recall': 0.5538461538461539, 'micro avg_f1-score': 0.5070422535211268, 'micro avg_support': 130.0, 'macro avg_precision': 0.4675324675324675, 'macro avg_recall': 0.5538461538461539, 'macro avg_f1-score': 0.5070422535211268, 'macro avg_support': 130.0, 'weighted avg_precision': 0.4675324675324675, 'weighted avg_recall': 0.5538461538461539, 'weighted avg_f1-score': 0.5070422535211268, 'weighted avg_support': 130.0, 'O_support': 6058, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 1}, {'micro_f1': 0.9325297662795825, 'precision': 0.9325297662795825, 'Repetition_precision': 0.44805194805194803, 'Repetition_recall': 0.6216216216216216, 'Repetition_f1-score': 0.5207547169811321, 'Repetition_support': 111.0, 'micro avg_precision': 0.44805194805194803, 'micro avg_recall': 0.6216216216216216, 'micro avg_f1-score': 0.5207547169811321, 'micro avg_support': 111.0, 'macro avg_precision': 0.44805194805194803, 'macro avg_recall': 0.6216216216216216, 'macro avg_f1-score': 0.5207547169811321, 'macro avg_support': 111.0, 'weighted avg_precision': 0.44805194805194803, 'weighted avg_recall': 0.6216216216216216, 'weighted avg_f1-score': 0.5207547169811321, 'weighted avg_support': 111.0, 'O_support': 6058, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 2}]}
Best model updated: current epoch macro f1 = 0.5207547169811321
{'micro_f1': 0.940908422754667, 'precision': 0.940908422754667, 'Repetition_precision': 0.6103896103896104, 'Repetition_recall': 0.7175572519083969, 'Repetition_f1-score': 0.6596491228070176, 'Repetition_support': 131.0, 'micro avg_precision': 0.6103896103896104, 'micro avg_recall': 0.7175572519083969, 'micro avg_f1-score': 0.6596491228070176, 'micro avg_support': 131.0, 'macro avg_precision': 0.6103896103896104, 'macro avg_recall': 0.7175572519083969, 'macro avg_f1-score': 0.6596491228070176, 'macro avg_support': 131.0, 'weighted avg_precision': 0.6103896103896104, 'weighted avg_recall': 0.7175572519083969, 'weighted avg_f1-score': 0.6596491228070176, 'weighted avg_support': 131.0, 'O_support': 6058, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 3}
{'results': [{'micro_f1': 0.919447302660591, 'precision': 0.9194473026605909, 'Repetition_precision': 0.2597402597402597, 'Repetition_recall': 0.3508771929824561, 'Repetition_f1-score': 0.29850746268656714, 'Repetition_support': 114.0, 'micro avg_precision': 0.2597402597402597, 'micro avg_recall': 0.3508771929824561, 'micro avg_f1-score': 0.29850746268656714, 'micro avg_support': 114.0, 'macro avg_precision': 0.2597402597402597, 'macro avg_recall': 0.3508771929824561, 'macro avg_f1-score': 0.29850746268656714, 'macro avg_support': 114.0, 'weighted avg_precision': 0.2597402597402597, 'weighted avg_recall': 0.3508771929824561, 'weighted avg_f1-score': 0.2985074626865671, 'weighted avg_support': 114.0, 'O_support': 6058, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 0}, {'micro_f1': 0.9401734528884316, 'precision': 0.9401734528884316, 'Repetition_precision': 0.4675324675324675, 'Repetition_recall': 0.5538461538461539, 'Repetition_f1-score': 0.5070422535211268, 'Repetition_support': 130.0, 'micro avg_precision': 0.4675324675324675, 'micro avg_recall': 0.5538461538461539, 'micro avg_f1-score': 0.5070422535211268, 'micro avg_support': 130.0, 'macro avg_precision': 0.4675324675324675, 'macro avg_recall': 0.5538461538461539, 'macro avg_f1-score': 0.5070422535211268, 'macro avg_support': 130.0, 'weighted avg_precision': 0.4675324675324675, 'weighted avg_recall': 0.5538461538461539, 'weighted avg_f1-score': 0.5070422535211268, 'weighted avg_support': 130.0, 'O_support': 6058, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 1}, {'micro_f1': 0.9325297662795825, 'precision': 0.9325297662795825, 'Repetition_precision': 0.44805194805194803, 'Repetition_recall': 0.6216216216216216, 'Repetition_f1-score': 0.5207547169811321, 'Repetition_support': 111.0, 'micro avg_precision': 0.44805194805194803, 'micro avg_recall': 0.6216216216216216, 'micro avg_f1-score': 0.5207547169811321, 'micro avg_support': 111.0, 'macro avg_precision': 0.44805194805194803, 'macro avg_recall': 0.6216216216216216, 'macro avg_f1-score': 0.5207547169811321, 'macro avg_support': 111.0, 'weighted avg_precision': 0.44805194805194803, 'weighted avg_recall': 0.6216216216216216, 'weighted avg_f1-score': 0.5207547169811321, 'weighted avg_support': 111.0, 'O_support': 6058, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 2}, {'micro_f1': 0.940908422754667, 'precision': 0.940908422754667, 'Repetition_precision': 0.6103896103896104, 'Repetition_recall': 0.7175572519083969, 'Repetition_f1-score': 0.6596491228070176, 'Repetition_support': 131.0, 'micro avg_precision': 0.6103896103896104, 'micro avg_recall': 0.7175572519083969, 'micro avg_f1-score': 0.6596491228070176, 'micro avg_support': 131.0, 'macro avg_precision': 0.6103896103896104, 'macro avg_recall': 0.7175572519083969, 'macro avg_f1-score': 0.6596491228070176, 'macro avg_support': 131.0, 'weighted avg_precision': 0.6103896103896104, 'weighted avg_recall': 0.7175572519083969, 'weighted avg_f1-score': 0.6596491228070176, 'weighted avg_support': 131.0, 'O_support': 6058, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 3}]}
Best model updated: current epoch macro f1 = 0.6596491228070176
{'micro_f1': 0.9391444950757019, 'precision': 0.9391444950757019, 'Repetition_precision': 0.6168831168831169, 'Repetition_recall': 0.6934306569343066, 'Repetition_f1-score': 0.6529209621993127, 'Repetition_support': 137.0, 'micro avg_precision': 0.6168831168831169, 'micro avg_recall': 0.6934306569343066, 'micro avg_f1-score': 0.6529209621993127, 'micro avg_support': 137.0, 'macro avg_precision': 0.6168831168831169, 'macro avg_recall': 0.6934306569343066, 'macro avg_f1-score': 0.6529209621993127, 'macro avg_support': 137.0, 'weighted avg_precision': 0.6168831168831169, 'weighted avg_recall': 0.6934306569343066, 'weighted avg_f1-score': 0.6529209621993127, 'weighted avg_support': 137.0, 'O_support': 6058, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 4}
{'results': [{'micro_f1': 0.919447302660591, 'precision': 0.9194473026605909, 'Repetition_precision': 0.2597402597402597, 'Repetition_recall': 0.3508771929824561, 'Repetition_f1-score': 0.29850746268656714, 'Repetition_support': 114.0, 'micro avg_precision': 0.2597402597402597, 'micro avg_recall': 0.3508771929824561, 'micro avg_f1-score': 0.29850746268656714, 'micro avg_support': 114.0, 'macro avg_precision': 0.2597402597402597, 'macro avg_recall': 0.3508771929824561, 'macro avg_f1-score': 0.29850746268656714, 'macro avg_support': 114.0, 'weighted avg_precision': 0.2597402597402597, 'weighted avg_recall': 0.3508771929824561, 'weighted avg_f1-score': 0.2985074626865671, 'weighted avg_support': 114.0, 'O_support': 6058, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 0}, {'micro_f1': 0.9401734528884316, 'precision': 0.9401734528884316, 'Repetition_precision': 0.4675324675324675, 'Repetition_recall': 0.5538461538461539, 'Repetition_f1-score': 0.5070422535211268, 'Repetition_support': 130.0, 'micro avg_precision': 0.4675324675324675, 'micro avg_recall': 0.5538461538461539, 'micro avg_f1-score': 0.5070422535211268, 'micro avg_support': 130.0, 'macro avg_precision': 0.4675324675324675, 'macro avg_recall': 0.5538461538461539, 'macro avg_f1-score': 0.5070422535211268, 'macro avg_support': 130.0, 'weighted avg_precision': 0.4675324675324675, 'weighted avg_recall': 0.5538461538461539, 'weighted avg_f1-score': 0.5070422535211268, 'weighted avg_support': 130.0, 'O_support': 6058, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 1}, {'micro_f1': 0.9325297662795825, 'precision': 0.9325297662795825, 'Repetition_precision': 0.44805194805194803, 'Repetition_recall': 0.6216216216216216, 'Repetition_f1-score': 0.5207547169811321, 'Repetition_support': 111.0, 'micro avg_precision': 0.44805194805194803, 'micro avg_recall': 0.6216216216216216, 'micro avg_f1-score': 0.5207547169811321, 'micro avg_support': 111.0, 'macro avg_precision': 0.44805194805194803, 'macro avg_recall': 0.6216216216216216, 'macro avg_f1-score': 0.5207547169811321, 'macro avg_support': 111.0, 'weighted avg_precision': 0.44805194805194803, 'weighted avg_recall': 0.6216216216216216, 'weighted avg_f1-score': 0.5207547169811321, 'weighted avg_support': 111.0, 'O_support': 6058, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 2}, {'micro_f1': 0.940908422754667, 'precision': 0.940908422754667, 'Repetition_precision': 0.6103896103896104, 'Repetition_recall': 0.7175572519083969, 'Repetition_f1-score': 0.6596491228070176, 'Repetition_support': 131.0, 'micro avg_precision': 0.6103896103896104, 'micro avg_recall': 0.7175572519083969, 'micro avg_f1-score': 0.6596491228070176, 'micro avg_support': 131.0, 'macro avg_precision': 0.6103896103896104, 'macro avg_recall': 0.7175572519083969, 'macro avg_f1-score': 0.6596491228070176, 'macro avg_support': 131.0, 'weighted avg_precision': 0.6103896103896104, 'weighted avg_recall': 0.7175572519083969, 'weighted avg_f1-score': 0.6596491228070176, 'weighted avg_support': 131.0, 'O_support': 6058, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 3}, {'micro_f1': 0.9391444950757019, 'precision': 0.9391444950757019, 'Repetition_precision': 0.6168831168831169, 'Repetition_recall': 0.6934306569343066, 'Repetition_f1-score': 0.6529209621993127, 'Repetition_support': 137.0, 'micro avg_precision': 0.6168831168831169, 'micro avg_recall': 0.6934306569343066, 'micro avg_f1-score': 0.6529209621993127, 'micro avg_support': 137.0, 'macro avg_precision': 0.6168831168831169, 'macro avg_recall': 0.6934306569343066, 'macro avg_f1-score': 0.6529209621993127, 'macro avg_support': 137.0, 'weighted avg_precision': 0.6168831168831169, 'weighted avg_recall': 0.6934306569343066, 'weighted avg_f1-score': 0.6529209621993127, 'weighted avg_support': 137.0, 'O_support': 6058, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 4}]}
{'micro_f1': 0.9295898868146406, 'precision': 0.9295898868146406, 'Repetition_precision': 0.5974025974025974, 'Repetition_recall': 0.6133333333333333, 'Repetition_f1-score': 0.6052631578947367, 'Repetition_support': 150.0, 'micro avg_precision': 0.5974025974025974, 'micro avg_recall': 0.6133333333333333, 'micro avg_f1-score': 0.6052631578947367, 'micro avg_support': 150.0, 'macro avg_precision': 0.5974025974025974, 'macro avg_recall': 0.6133333333333333, 'macro avg_f1-score': 0.6052631578947367, 'macro avg_support': 150.0, 'weighted avg_precision': 0.5974025974025974, 'weighted avg_recall': 0.6133333333333333, 'weighted avg_f1-score': 0.6052631578947367, 'weighted avg_support': 150.0, 'O_support': 6058, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 5}
{'results': [{'micro_f1': 0.919447302660591, 'precision': 0.9194473026605909, 'Repetition_precision': 0.2597402597402597, 'Repetition_recall': 0.3508771929824561, 'Repetition_f1-score': 0.29850746268656714, 'Repetition_support': 114.0, 'micro avg_precision': 0.2597402597402597, 'micro avg_recall': 0.3508771929824561, 'micro avg_f1-score': 0.29850746268656714, 'micro avg_support': 114.0, 'macro avg_precision': 0.2597402597402597, 'macro avg_recall': 0.3508771929824561, 'macro avg_f1-score': 0.29850746268656714, 'macro avg_support': 114.0, 'weighted avg_precision': 0.2597402597402597, 'weighted avg_recall': 0.3508771929824561, 'weighted avg_f1-score': 0.2985074626865671, 'weighted avg_support': 114.0, 'O_support': 6058, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 0}, {'micro_f1': 0.9401734528884316, 'precision': 0.9401734528884316, 'Repetition_precision': 0.4675324675324675, 'Repetition_recall': 0.5538461538461539, 'Repetition_f1-score': 0.5070422535211268, 'Repetition_support': 130.0, 'micro avg_precision': 0.4675324675324675, 'micro avg_recall': 0.5538461538461539, 'micro avg_f1-score': 0.5070422535211268, 'micro avg_support': 130.0, 'macro avg_precision': 0.4675324675324675, 'macro avg_recall': 0.5538461538461539, 'macro avg_f1-score': 0.5070422535211268, 'macro avg_support': 130.0, 'weighted avg_precision': 0.4675324675324675, 'weighted avg_recall': 0.5538461538461539, 'weighted avg_f1-score': 0.5070422535211268, 'weighted avg_support': 130.0, 'O_support': 6058, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 1}, {'micro_f1': 0.9325297662795825, 'precision': 0.9325297662795825, 'Repetition_precision': 0.44805194805194803, 'Repetition_recall': 0.6216216216216216, 'Repetition_f1-score': 0.5207547169811321, 'Repetition_support': 111.0, 'micro avg_precision': 0.44805194805194803, 'micro avg_recall': 0.6216216216216216, 'micro avg_f1-score': 0.5207547169811321, 'micro avg_support': 111.0, 'macro avg_precision': 0.44805194805194803, 'macro avg_recall': 0.6216216216216216, 'macro avg_f1-score': 0.5207547169811321, 'macro avg_support': 111.0, 'weighted avg_precision': 0.44805194805194803, 'weighted avg_recall': 0.6216216216216216, 'weighted avg_f1-score': 0.5207547169811321, 'weighted avg_support': 111.0, 'O_support': 6058, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 2}, {'micro_f1': 0.940908422754667, 'precision': 0.940908422754667, 'Repetition_precision': 0.6103896103896104, 'Repetition_recall': 0.7175572519083969, 'Repetition_f1-score': 0.6596491228070176, 'Repetition_support': 131.0, 'micro avg_precision': 0.6103896103896104, 'micro avg_recall': 0.7175572519083969, 'micro avg_f1-score': 0.6596491228070176, 'micro avg_support': 131.0, 'macro avg_precision': 0.6103896103896104, 'macro avg_recall': 0.7175572519083969, 'macro avg_f1-score': 0.6596491228070176, 'macro avg_support': 131.0, 'weighted avg_precision': 0.6103896103896104, 'weighted avg_recall': 0.7175572519083969, 'weighted avg_f1-score': 0.6596491228070176, 'weighted avg_support': 131.0, 'O_support': 6058, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 3}, {'micro_f1': 0.9391444950757019, 'precision': 0.9391444950757019, 'Repetition_precision': 0.6168831168831169, 'Repetition_recall': 0.6934306569343066, 'Repetition_f1-score': 0.6529209621993127, 'Repetition_support': 137.0, 'micro avg_precision': 0.6168831168831169, 'micro avg_recall': 0.6934306569343066, 'micro avg_f1-score': 0.6529209621993127, 'micro avg_support': 137.0, 'macro avg_precision': 0.6168831168831169, 'macro avg_recall': 0.6934306569343066, 'macro avg_f1-score': 0.6529209621993127, 'macro avg_support': 137.0, 'weighted avg_precision': 0.6168831168831169, 'weighted avg_recall': 0.6934306569343066, 'weighted avg_f1-score': 0.6529209621993127, 'weighted avg_support': 137.0, 'O_support': 6058, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 4}, {'micro_f1': 0.9295898868146406, 'precision': 0.9295898868146406, 'Repetition_precision': 0.5974025974025974, 'Repetition_recall': 0.6133333333333333, 'Repetition_f1-score': 0.6052631578947367, 'Repetition_support': 150.0, 'micro avg_precision': 0.5974025974025974, 'micro avg_recall': 0.6133333333333333, 'micro avg_f1-score': 0.6052631578947367, 'micro avg_support': 150.0, 'macro avg_precision': 0.5974025974025974, 'macro avg_recall': 0.6133333333333333, 'macro avg_f1-score': 0.6052631578947367, 'macro avg_support': 150.0, 'weighted avg_precision': 0.5974025974025974, 'weighted avg_recall': 0.6133333333333333, 'weighted avg_f1-score': 0.6052631578947367, 'weighted avg_support': 150.0, 'O_support': 6058, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 5}]}
Early stopping triggered.
Saving model to directory: ./models/M2/2024-05-13-23-08-48_aug/mdeberta-v3-base_15_ME10_target=Repetition_SUBSAMPLED_2024-05-13-23-08-48
Training model no. 16 of 23 for (16, 'Exaggeration-Minimisation') persuasion technique...
{'micro_f1': 0.8346735284657447, 'precision': 0.8346735284657446, 'Exaggeration-Minimisation_precision': 0.07766990291262135, 'Exaggeration-Minimisation_recall': 0.12403100775193798, 'Exaggeration-Minimisation_f1-score': 0.09552238805970148, 'Exaggeration-Minimisation_support': 129.0, 'micro avg_precision': 0.07766990291262135, 'micro avg_recall': 0.12403100775193798, 'micro avg_f1-score': 0.09552238805970148, 'micro avg_support': 129.0, 'macro avg_precision': 0.07766990291262135, 'macro avg_recall': 0.12403100775193798, 'macro avg_f1-score': 0.09552238805970148, 'macro avg_support': 129.0, 'weighted avg_precision': 0.07766990291262135, 'weighted avg_recall': 0.12403100775193798, 'weighted avg_f1-score': 0.09552238805970148, 'weighted avg_support': 129.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 0}
{'results': [{'micro_f1': 0.8346735284657447, 'precision': 0.8346735284657446, 'Exaggeration-Minimisation_precision': 0.07766990291262135, 'Exaggeration-Minimisation_recall': 0.12403100775193798, 'Exaggeration-Minimisation_f1-score': 0.09552238805970148, 'Exaggeration-Minimisation_support': 129.0, 'micro avg_precision': 0.07766990291262135, 'micro avg_recall': 0.12403100775193798, 'micro avg_f1-score': 0.09552238805970148, 'micro avg_support': 129.0, 'macro avg_precision': 0.07766990291262135, 'macro avg_recall': 0.12403100775193798, 'macro avg_f1-score': 0.09552238805970148, 'macro avg_support': 129.0, 'weighted avg_precision': 0.07766990291262135, 'weighted avg_recall': 0.12403100775193798, 'weighted avg_f1-score': 0.09552238805970148, 'weighted avg_support': 129.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 0}]}
Best model updated: current epoch macro f1 = 0.09552238805970148
{'micro_f1': 0.8605124906186341, 'precision': 0.8605124906186341, 'Exaggeration-Minimisation_precision': 0.16019417475728157, 'Exaggeration-Minimisation_recall': 0.20121951219512196, 'Exaggeration-Minimisation_f1-score': 0.17837837837837842, 'Exaggeration-Minimisation_support': 164.0, 'micro avg_precision': 0.16019417475728157, 'micro avg_recall': 0.20121951219512196, 'micro avg_f1-score': 0.17837837837837842, 'micro avg_support': 164.0, 'macro avg_precision': 0.16019417475728157, 'macro avg_recall': 0.20121951219512196, 'macro avg_f1-score': 0.17837837837837842, 'macro avg_support': 164.0, 'weighted avg_precision': 0.16019417475728157, 'weighted avg_recall': 0.20121951219512196, 'weighted avg_f1-score': 0.17837837837837842, 'weighted avg_support': 164.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 1}
{'results': [{'micro_f1': 0.8346735284657447, 'precision': 0.8346735284657446, 'Exaggeration-Minimisation_precision': 0.07766990291262135, 'Exaggeration-Minimisation_recall': 0.12403100775193798, 'Exaggeration-Minimisation_f1-score': 0.09552238805970148, 'Exaggeration-Minimisation_support': 129.0, 'micro avg_precision': 0.07766990291262135, 'micro avg_recall': 0.12403100775193798, 'micro avg_f1-score': 0.09552238805970148, 'micro avg_support': 129.0, 'macro avg_precision': 0.07766990291262135, 'macro avg_recall': 0.12403100775193798, 'macro avg_f1-score': 0.09552238805970148, 'macro avg_support': 129.0, 'weighted avg_precision': 0.07766990291262135, 'weighted avg_recall': 0.12403100775193798, 'weighted avg_f1-score': 0.09552238805970148, 'weighted avg_support': 129.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 0}, {'micro_f1': 0.8605124906186341, 'precision': 0.8605124906186341, 'Exaggeration-Minimisation_precision': 0.16019417475728157, 'Exaggeration-Minimisation_recall': 0.20121951219512196, 'Exaggeration-Minimisation_f1-score': 0.17837837837837842, 'Exaggeration-Minimisation_support': 164.0, 'micro avg_precision': 0.16019417475728157, 'micro avg_recall': 0.20121951219512196, 'micro avg_f1-score': 0.17837837837837842, 'micro avg_support': 164.0, 'macro avg_precision': 0.16019417475728157, 'macro avg_recall': 0.20121951219512196, 'macro avg_f1-score': 0.17837837837837842, 'macro avg_support': 164.0, 'weighted avg_precision': 0.16019417475728157, 'weighted avg_recall': 0.20121951219512196, 'weighted avg_f1-score': 0.17837837837837842, 'weighted avg_support': 164.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 1}]}
Best model updated: current epoch macro f1 = 0.17837837837837842
{'micro_f1': 0.8656588399270934, 'precision': 0.8656588399270934, 'Exaggeration-Minimisation_precision': 0.24757281553398058, 'Exaggeration-Minimisation_recall': 0.2786885245901639, 'Exaggeration-Minimisation_f1-score': 0.2622107969151671, 'Exaggeration-Minimisation_support': 183.0, 'micro avg_precision': 0.24757281553398058, 'micro avg_recall': 0.2786885245901639, 'micro avg_f1-score': 0.2622107969151671, 'micro avg_support': 183.0, 'macro avg_precision': 0.24757281553398058, 'macro avg_recall': 0.2786885245901639, 'macro avg_f1-score': 0.2622107969151671, 'macro avg_support': 183.0, 'weighted avg_precision': 0.24757281553398058, 'weighted avg_recall': 0.2786885245901639, 'weighted avg_f1-score': 0.2622107969151671, 'weighted avg_support': 183.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 2}
{'results': [{'micro_f1': 0.8346735284657447, 'precision': 0.8346735284657446, 'Exaggeration-Minimisation_precision': 0.07766990291262135, 'Exaggeration-Minimisation_recall': 0.12403100775193798, 'Exaggeration-Minimisation_f1-score': 0.09552238805970148, 'Exaggeration-Minimisation_support': 129.0, 'micro avg_precision': 0.07766990291262135, 'micro avg_recall': 0.12403100775193798, 'micro avg_f1-score': 0.09552238805970148, 'micro avg_support': 129.0, 'macro avg_precision': 0.07766990291262135, 'macro avg_recall': 0.12403100775193798, 'macro avg_f1-score': 0.09552238805970148, 'macro avg_support': 129.0, 'weighted avg_precision': 0.07766990291262135, 'weighted avg_recall': 0.12403100775193798, 'weighted avg_f1-score': 0.09552238805970148, 'weighted avg_support': 129.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 0}, {'micro_f1': 0.8605124906186341, 'precision': 0.8605124906186341, 'Exaggeration-Minimisation_precision': 0.16019417475728157, 'Exaggeration-Minimisation_recall': 0.20121951219512196, 'Exaggeration-Minimisation_f1-score': 0.17837837837837842, 'Exaggeration-Minimisation_support': 164.0, 'micro avg_precision': 0.16019417475728157, 'micro avg_recall': 0.20121951219512196, 'micro avg_f1-score': 0.17837837837837842, 'micro avg_support': 164.0, 'macro avg_precision': 0.16019417475728157, 'macro avg_recall': 0.20121951219512196, 'macro avg_f1-score': 0.17837837837837842, 'macro avg_support': 164.0, 'weighted avg_precision': 0.16019417475728157, 'weighted avg_recall': 0.20121951219512196, 'weighted avg_f1-score': 0.17837837837837842, 'weighted avg_support': 164.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 1}, {'micro_f1': 0.8656588399270934, 'precision': 0.8656588399270934, 'Exaggeration-Minimisation_precision': 0.24757281553398058, 'Exaggeration-Minimisation_recall': 0.2786885245901639, 'Exaggeration-Minimisation_f1-score': 0.2622107969151671, 'Exaggeration-Minimisation_support': 183.0, 'micro avg_precision': 0.24757281553398058, 'micro avg_recall': 0.2786885245901639, 'micro avg_f1-score': 0.2622107969151671, 'micro avg_support': 183.0, 'macro avg_precision': 0.24757281553398058, 'macro avg_recall': 0.2786885245901639, 'macro avg_f1-score': 0.2622107969151671, 'macro avg_support': 183.0, 'weighted avg_precision': 0.24757281553398058, 'weighted avg_recall': 0.2786885245901639, 'weighted avg_f1-score': 0.2622107969151671, 'weighted avg_support': 183.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 2}]}
Best model updated: current epoch macro f1 = 0.2622107969151671
{'micro_f1': 0.8688753082448805, 'precision': 0.8688753082448805, 'Exaggeration-Minimisation_precision': 0.3592233009708738, 'Exaggeration-Minimisation_recall': 0.31759656652360513, 'Exaggeration-Minimisation_f1-score': 0.337129840546697, 'Exaggeration-Minimisation_support': 233.0, 'micro avg_precision': 0.3592233009708738, 'micro avg_recall': 0.31759656652360513, 'micro avg_f1-score': 0.337129840546697, 'micro avg_support': 233.0, 'macro avg_precision': 0.3592233009708738, 'macro avg_recall': 0.31759656652360513, 'macro avg_f1-score': 0.337129840546697, 'macro avg_support': 233.0, 'weighted avg_precision': 0.3592233009708738, 'weighted avg_recall': 0.31759656652360513, 'weighted avg_f1-score': 0.337129840546697, 'weighted avg_support': 233.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 3}
{'results': [{'micro_f1': 0.8346735284657447, 'precision': 0.8346735284657446, 'Exaggeration-Minimisation_precision': 0.07766990291262135, 'Exaggeration-Minimisation_recall': 0.12403100775193798, 'Exaggeration-Minimisation_f1-score': 0.09552238805970148, 'Exaggeration-Minimisation_support': 129.0, 'micro avg_precision': 0.07766990291262135, 'micro avg_recall': 0.12403100775193798, 'micro avg_f1-score': 0.09552238805970148, 'micro avg_support': 129.0, 'macro avg_precision': 0.07766990291262135, 'macro avg_recall': 0.12403100775193798, 'macro avg_f1-score': 0.09552238805970148, 'macro avg_support': 129.0, 'weighted avg_precision': 0.07766990291262135, 'weighted avg_recall': 0.12403100775193798, 'weighted avg_f1-score': 0.09552238805970148, 'weighted avg_support': 129.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 0}, {'micro_f1': 0.8605124906186341, 'precision': 0.8605124906186341, 'Exaggeration-Minimisation_precision': 0.16019417475728157, 'Exaggeration-Minimisation_recall': 0.20121951219512196, 'Exaggeration-Minimisation_f1-score': 0.17837837837837842, 'Exaggeration-Minimisation_support': 164.0, 'micro avg_precision': 0.16019417475728157, 'micro avg_recall': 0.20121951219512196, 'micro avg_f1-score': 0.17837837837837842, 'micro avg_support': 164.0, 'macro avg_precision': 0.16019417475728157, 'macro avg_recall': 0.20121951219512196, 'macro avg_f1-score': 0.17837837837837842, 'macro avg_support': 164.0, 'weighted avg_precision': 0.16019417475728157, 'weighted avg_recall': 0.20121951219512196, 'weighted avg_f1-score': 0.17837837837837842, 'weighted avg_support': 164.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 1}, {'micro_f1': 0.8656588399270934, 'precision': 0.8656588399270934, 'Exaggeration-Minimisation_precision': 0.24757281553398058, 'Exaggeration-Minimisation_recall': 0.2786885245901639, 'Exaggeration-Minimisation_f1-score': 0.2622107969151671, 'Exaggeration-Minimisation_support': 183.0, 'micro avg_precision': 0.24757281553398058, 'micro avg_recall': 0.2786885245901639, 'micro avg_f1-score': 0.2622107969151671, 'micro avg_support': 183.0, 'macro avg_precision': 0.24757281553398058, 'macro avg_recall': 0.2786885245901639, 'macro avg_f1-score': 0.2622107969151671, 'macro avg_support': 183.0, 'weighted avg_precision': 0.24757281553398058, 'weighted avg_recall': 0.2786885245901639, 'weighted avg_f1-score': 0.2622107969151671, 'weighted avg_support': 183.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 2}, {'micro_f1': 0.8688753082448805, 'precision': 0.8688753082448805, 'Exaggeration-Minimisation_precision': 0.3592233009708738, 'Exaggeration-Minimisation_recall': 0.31759656652360513, 'Exaggeration-Minimisation_f1-score': 0.337129840546697, 'Exaggeration-Minimisation_support': 233.0, 'micro avg_precision': 0.3592233009708738, 'micro avg_recall': 0.31759656652360513, 'micro avg_f1-score': 0.337129840546697, 'micro avg_support': 233.0, 'macro avg_precision': 0.3592233009708738, 'macro avg_recall': 0.31759656652360513, 'macro avg_f1-score': 0.337129840546697, 'macro avg_support': 233.0, 'weighted avg_precision': 0.3592233009708738, 'weighted avg_recall': 0.31759656652360513, 'weighted avg_f1-score': 0.337129840546697, 'weighted avg_support': 233.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 3}]}
Best model updated: current epoch macro f1 = 0.337129840546697
{'micro_f1': 0.8669454272542082, 'precision': 0.8669454272542082, 'Exaggeration-Minimisation_precision': 0.3737864077669903, 'Exaggeration-Minimisation_recall': 0.3031496062992126, 'Exaggeration-Minimisation_f1-score': 0.3347826086956522, 'Exaggeration-Minimisation_support': 254.0, 'micro avg_precision': 0.3737864077669903, 'micro avg_recall': 0.3031496062992126, 'micro avg_f1-score': 0.3347826086956522, 'micro avg_support': 254.0, 'macro avg_precision': 0.3737864077669903, 'macro avg_recall': 0.3031496062992126, 'macro avg_f1-score': 0.3347826086956522, 'macro avg_support': 254.0, 'weighted avg_precision': 0.3737864077669903, 'weighted avg_recall': 0.3031496062992126, 'weighted avg_f1-score': 0.3347826086956522, 'weighted avg_support': 254.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 4}
{'results': [{'micro_f1': 0.8346735284657447, 'precision': 0.8346735284657446, 'Exaggeration-Minimisation_precision': 0.07766990291262135, 'Exaggeration-Minimisation_recall': 0.12403100775193798, 'Exaggeration-Minimisation_f1-score': 0.09552238805970148, 'Exaggeration-Minimisation_support': 129.0, 'micro avg_precision': 0.07766990291262135, 'micro avg_recall': 0.12403100775193798, 'micro avg_f1-score': 0.09552238805970148, 'micro avg_support': 129.0, 'macro avg_precision': 0.07766990291262135, 'macro avg_recall': 0.12403100775193798, 'macro avg_f1-score': 0.09552238805970148, 'macro avg_support': 129.0, 'weighted avg_precision': 0.07766990291262135, 'weighted avg_recall': 0.12403100775193798, 'weighted avg_f1-score': 0.09552238805970148, 'weighted avg_support': 129.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 0}, {'micro_f1': 0.8605124906186341, 'precision': 0.8605124906186341, 'Exaggeration-Minimisation_precision': 0.16019417475728157, 'Exaggeration-Minimisation_recall': 0.20121951219512196, 'Exaggeration-Minimisation_f1-score': 0.17837837837837842, 'Exaggeration-Minimisation_support': 164.0, 'micro avg_precision': 0.16019417475728157, 'micro avg_recall': 0.20121951219512196, 'micro avg_f1-score': 0.17837837837837842, 'micro avg_support': 164.0, 'macro avg_precision': 0.16019417475728157, 'macro avg_recall': 0.20121951219512196, 'macro avg_f1-score': 0.17837837837837842, 'macro avg_support': 164.0, 'weighted avg_precision': 0.16019417475728157, 'weighted avg_recall': 0.20121951219512196, 'weighted avg_f1-score': 0.17837837837837842, 'weighted avg_support': 164.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 1}, {'micro_f1': 0.8656588399270934, 'precision': 0.8656588399270934, 'Exaggeration-Minimisation_precision': 0.24757281553398058, 'Exaggeration-Minimisation_recall': 0.2786885245901639, 'Exaggeration-Minimisation_f1-score': 0.2622107969151671, 'Exaggeration-Minimisation_support': 183.0, 'micro avg_precision': 0.24757281553398058, 'micro avg_recall': 0.2786885245901639, 'micro avg_f1-score': 0.2622107969151671, 'micro avg_support': 183.0, 'macro avg_precision': 0.24757281553398058, 'macro avg_recall': 0.2786885245901639, 'macro avg_f1-score': 0.2622107969151671, 'macro avg_support': 183.0, 'weighted avg_precision': 0.24757281553398058, 'weighted avg_recall': 0.2786885245901639, 'weighted avg_f1-score': 0.2622107969151671, 'weighted avg_support': 183.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 2}, {'micro_f1': 0.8688753082448805, 'precision': 0.8688753082448805, 'Exaggeration-Minimisation_precision': 0.3592233009708738, 'Exaggeration-Minimisation_recall': 0.31759656652360513, 'Exaggeration-Minimisation_f1-score': 0.337129840546697, 'Exaggeration-Minimisation_support': 233.0, 'micro avg_precision': 0.3592233009708738, 'micro avg_recall': 0.31759656652360513, 'micro avg_f1-score': 0.337129840546697, 'micro avg_support': 233.0, 'macro avg_precision': 0.3592233009708738, 'macro avg_recall': 0.31759656652360513, 'macro avg_f1-score': 0.337129840546697, 'macro avg_support': 233.0, 'weighted avg_precision': 0.3592233009708738, 'weighted avg_recall': 0.31759656652360513, 'weighted avg_f1-score': 0.337129840546697, 'weighted avg_support': 233.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 3}, {'micro_f1': 0.8669454272542082, 'precision': 0.8669454272542082, 'Exaggeration-Minimisation_precision': 0.3737864077669903, 'Exaggeration-Minimisation_recall': 0.3031496062992126, 'Exaggeration-Minimisation_f1-score': 0.3347826086956522, 'Exaggeration-Minimisation_support': 254.0, 'micro avg_precision': 0.3737864077669903, 'micro avg_recall': 0.3031496062992126, 'micro avg_f1-score': 0.3347826086956522, 'micro avg_support': 254.0, 'macro avg_precision': 0.3737864077669903, 'macro avg_recall': 0.3031496062992126, 'macro avg_f1-score': 0.3347826086956522, 'macro avg_support': 254.0, 'weighted avg_precision': 0.3737864077669903, 'weighted avg_recall': 0.3031496062992126, 'weighted avg_f1-score': 0.3347826086956522, 'weighted avg_support': 254.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 4}]}
{'micro_f1': 0.8746649512168971, 'precision': 0.8746649512168971, 'Exaggeration-Minimisation_precision': 0.3786407766990291, 'Exaggeration-Minimisation_recall': 0.3577981651376147, 'Exaggeration-Minimisation_f1-score': 0.36792452830188677, 'Exaggeration-Minimisation_support': 218.0, 'micro avg_precision': 0.3786407766990291, 'micro avg_recall': 0.3577981651376147, 'micro avg_f1-score': 0.36792452830188677, 'micro avg_support': 218.0, 'macro avg_precision': 0.3786407766990291, 'macro avg_recall': 0.3577981651376147, 'macro avg_f1-score': 0.36792452830188677, 'macro avg_support': 218.0, 'weighted avg_precision': 0.3786407766990291, 'weighted avg_recall': 0.3577981651376147, 'weighted avg_f1-score': 0.36792452830188677, 'weighted avg_support': 218.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 5}
{'results': [{'micro_f1': 0.8346735284657447, 'precision': 0.8346735284657446, 'Exaggeration-Minimisation_precision': 0.07766990291262135, 'Exaggeration-Minimisation_recall': 0.12403100775193798, 'Exaggeration-Minimisation_f1-score': 0.09552238805970148, 'Exaggeration-Minimisation_support': 129.0, 'micro avg_precision': 0.07766990291262135, 'micro avg_recall': 0.12403100775193798, 'micro avg_f1-score': 0.09552238805970148, 'micro avg_support': 129.0, 'macro avg_precision': 0.07766990291262135, 'macro avg_recall': 0.12403100775193798, 'macro avg_f1-score': 0.09552238805970148, 'macro avg_support': 129.0, 'weighted avg_precision': 0.07766990291262135, 'weighted avg_recall': 0.12403100775193798, 'weighted avg_f1-score': 0.09552238805970148, 'weighted avg_support': 129.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 0}, {'micro_f1': 0.8605124906186341, 'precision': 0.8605124906186341, 'Exaggeration-Minimisation_precision': 0.16019417475728157, 'Exaggeration-Minimisation_recall': 0.20121951219512196, 'Exaggeration-Minimisation_f1-score': 0.17837837837837842, 'Exaggeration-Minimisation_support': 164.0, 'micro avg_precision': 0.16019417475728157, 'micro avg_recall': 0.20121951219512196, 'micro avg_f1-score': 0.17837837837837842, 'micro avg_support': 164.0, 'macro avg_precision': 0.16019417475728157, 'macro avg_recall': 0.20121951219512196, 'macro avg_f1-score': 0.17837837837837842, 'macro avg_support': 164.0, 'weighted avg_precision': 0.16019417475728157, 'weighted avg_recall': 0.20121951219512196, 'weighted avg_f1-score': 0.17837837837837842, 'weighted avg_support': 164.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 1}, {'micro_f1': 0.8656588399270934, 'precision': 0.8656588399270934, 'Exaggeration-Minimisation_precision': 0.24757281553398058, 'Exaggeration-Minimisation_recall': 0.2786885245901639, 'Exaggeration-Minimisation_f1-score': 0.2622107969151671, 'Exaggeration-Minimisation_support': 183.0, 'micro avg_precision': 0.24757281553398058, 'micro avg_recall': 0.2786885245901639, 'micro avg_f1-score': 0.2622107969151671, 'micro avg_support': 183.0, 'macro avg_precision': 0.24757281553398058, 'macro avg_recall': 0.2786885245901639, 'macro avg_f1-score': 0.2622107969151671, 'macro avg_support': 183.0, 'weighted avg_precision': 0.24757281553398058, 'weighted avg_recall': 0.2786885245901639, 'weighted avg_f1-score': 0.2622107969151671, 'weighted avg_support': 183.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 2}, {'micro_f1': 0.8688753082448805, 'precision': 0.8688753082448805, 'Exaggeration-Minimisation_precision': 0.3592233009708738, 'Exaggeration-Minimisation_recall': 0.31759656652360513, 'Exaggeration-Minimisation_f1-score': 0.337129840546697, 'Exaggeration-Minimisation_support': 233.0, 'micro avg_precision': 0.3592233009708738, 'micro avg_recall': 0.31759656652360513, 'micro avg_f1-score': 0.337129840546697, 'micro avg_support': 233.0, 'macro avg_precision': 0.3592233009708738, 'macro avg_recall': 0.31759656652360513, 'macro avg_f1-score': 0.337129840546697, 'macro avg_support': 233.0, 'weighted avg_precision': 0.3592233009708738, 'weighted avg_recall': 0.31759656652360513, 'weighted avg_f1-score': 0.337129840546697, 'weighted avg_support': 233.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 3}, {'micro_f1': 0.8669454272542082, 'precision': 0.8669454272542082, 'Exaggeration-Minimisation_precision': 0.3737864077669903, 'Exaggeration-Minimisation_recall': 0.3031496062992126, 'Exaggeration-Minimisation_f1-score': 0.3347826086956522, 'Exaggeration-Minimisation_support': 254.0, 'micro avg_precision': 0.3737864077669903, 'micro avg_recall': 0.3031496062992126, 'micro avg_f1-score': 0.3347826086956522, 'micro avg_support': 254.0, 'macro avg_precision': 0.3737864077669903, 'macro avg_recall': 0.3031496062992126, 'macro avg_f1-score': 0.3347826086956522, 'macro avg_support': 254.0, 'weighted avg_precision': 0.3737864077669903, 'weighted avg_recall': 0.3031496062992126, 'weighted avg_f1-score': 0.3347826086956522, 'weighted avg_support': 254.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 4}, {'micro_f1': 0.8746649512168971, 'precision': 0.8746649512168971, 'Exaggeration-Minimisation_precision': 0.3786407766990291, 'Exaggeration-Minimisation_recall': 0.3577981651376147, 'Exaggeration-Minimisation_f1-score': 0.36792452830188677, 'Exaggeration-Minimisation_support': 218.0, 'micro avg_precision': 0.3786407766990291, 'micro avg_recall': 0.3577981651376147, 'micro avg_f1-score': 0.36792452830188677, 'micro avg_support': 218.0, 'macro avg_precision': 0.3786407766990291, 'macro avg_recall': 0.3577981651376147, 'macro avg_f1-score': 0.36792452830188677, 'macro avg_support': 218.0, 'weighted avg_precision': 0.3786407766990291, 'weighted avg_recall': 0.3577981651376147, 'weighted avg_f1-score': 0.36792452830188677, 'weighted avg_support': 218.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 5}]}
Best model updated: current epoch macro f1 = 0.36792452830188677
{'micro_f1': 0.8656588399270934, 'precision': 0.8656588399270934, 'Exaggeration-Minimisation_precision': 0.32524271844660196, 'Exaggeration-Minimisation_recall': 0.38285714285714284, 'Exaggeration-Minimisation_f1-score': 0.35170603674540685, 'Exaggeration-Minimisation_support': 175.0, 'micro avg_precision': 0.32524271844660196, 'micro avg_recall': 0.38285714285714284, 'micro avg_f1-score': 0.35170603674540685, 'micro avg_support': 175.0, 'macro avg_precision': 0.32524271844660196, 'macro avg_recall': 0.38285714285714284, 'macro avg_f1-score': 0.35170603674540685, 'macro avg_support': 175.0, 'weighted avg_precision': 0.32524271844660196, 'weighted avg_recall': 0.38285714285714284, 'weighted avg_f1-score': 0.35170603674540685, 'weighted avg_support': 175.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 6}
{'results': [{'micro_f1': 0.8346735284657447, 'precision': 0.8346735284657446, 'Exaggeration-Minimisation_precision': 0.07766990291262135, 'Exaggeration-Minimisation_recall': 0.12403100775193798, 'Exaggeration-Minimisation_f1-score': 0.09552238805970148, 'Exaggeration-Minimisation_support': 129.0, 'micro avg_precision': 0.07766990291262135, 'micro avg_recall': 0.12403100775193798, 'micro avg_f1-score': 0.09552238805970148, 'micro avg_support': 129.0, 'macro avg_precision': 0.07766990291262135, 'macro avg_recall': 0.12403100775193798, 'macro avg_f1-score': 0.09552238805970148, 'macro avg_support': 129.0, 'weighted avg_precision': 0.07766990291262135, 'weighted avg_recall': 0.12403100775193798, 'weighted avg_f1-score': 0.09552238805970148, 'weighted avg_support': 129.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 0}, {'micro_f1': 0.8605124906186341, 'precision': 0.8605124906186341, 'Exaggeration-Minimisation_precision': 0.16019417475728157, 'Exaggeration-Minimisation_recall': 0.20121951219512196, 'Exaggeration-Minimisation_f1-score': 0.17837837837837842, 'Exaggeration-Minimisation_support': 164.0, 'micro avg_precision': 0.16019417475728157, 'micro avg_recall': 0.20121951219512196, 'micro avg_f1-score': 0.17837837837837842, 'micro avg_support': 164.0, 'macro avg_precision': 0.16019417475728157, 'macro avg_recall': 0.20121951219512196, 'macro avg_f1-score': 0.17837837837837842, 'macro avg_support': 164.0, 'weighted avg_precision': 0.16019417475728157, 'weighted avg_recall': 0.20121951219512196, 'weighted avg_f1-score': 0.17837837837837842, 'weighted avg_support': 164.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 1}, {'micro_f1': 0.8656588399270934, 'precision': 0.8656588399270934, 'Exaggeration-Minimisation_precision': 0.24757281553398058, 'Exaggeration-Minimisation_recall': 0.2786885245901639, 'Exaggeration-Minimisation_f1-score': 0.2622107969151671, 'Exaggeration-Minimisation_support': 183.0, 'micro avg_precision': 0.24757281553398058, 'micro avg_recall': 0.2786885245901639, 'micro avg_f1-score': 0.2622107969151671, 'micro avg_support': 183.0, 'macro avg_precision': 0.24757281553398058, 'macro avg_recall': 0.2786885245901639, 'macro avg_f1-score': 0.2622107969151671, 'macro avg_support': 183.0, 'weighted avg_precision': 0.24757281553398058, 'weighted avg_recall': 0.2786885245901639, 'weighted avg_f1-score': 0.2622107969151671, 'weighted avg_support': 183.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 2}, {'micro_f1': 0.8688753082448805, 'precision': 0.8688753082448805, 'Exaggeration-Minimisation_precision': 0.3592233009708738, 'Exaggeration-Minimisation_recall': 0.31759656652360513, 'Exaggeration-Minimisation_f1-score': 0.337129840546697, 'Exaggeration-Minimisation_support': 233.0, 'micro avg_precision': 0.3592233009708738, 'micro avg_recall': 0.31759656652360513, 'micro avg_f1-score': 0.337129840546697, 'micro avg_support': 233.0, 'macro avg_precision': 0.3592233009708738, 'macro avg_recall': 0.31759656652360513, 'macro avg_f1-score': 0.337129840546697, 'macro avg_support': 233.0, 'weighted avg_precision': 0.3592233009708738, 'weighted avg_recall': 0.31759656652360513, 'weighted avg_f1-score': 0.337129840546697, 'weighted avg_support': 233.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 3}, {'micro_f1': 0.8669454272542082, 'precision': 0.8669454272542082, 'Exaggeration-Minimisation_precision': 0.3737864077669903, 'Exaggeration-Minimisation_recall': 0.3031496062992126, 'Exaggeration-Minimisation_f1-score': 0.3347826086956522, 'Exaggeration-Minimisation_support': 254.0, 'micro avg_precision': 0.3737864077669903, 'micro avg_recall': 0.3031496062992126, 'micro avg_f1-score': 0.3347826086956522, 'micro avg_support': 254.0, 'macro avg_precision': 0.3737864077669903, 'macro avg_recall': 0.3031496062992126, 'macro avg_f1-score': 0.3347826086956522, 'macro avg_support': 254.0, 'weighted avg_precision': 0.3737864077669903, 'weighted avg_recall': 0.3031496062992126, 'weighted avg_f1-score': 0.3347826086956522, 'weighted avg_support': 254.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 4}, {'micro_f1': 0.8746649512168971, 'precision': 0.8746649512168971, 'Exaggeration-Minimisation_precision': 0.3786407766990291, 'Exaggeration-Minimisation_recall': 0.3577981651376147, 'Exaggeration-Minimisation_f1-score': 0.36792452830188677, 'Exaggeration-Minimisation_support': 218.0, 'micro avg_precision': 0.3786407766990291, 'micro avg_recall': 0.3577981651376147, 'micro avg_f1-score': 0.36792452830188677, 'micro avg_support': 218.0, 'macro avg_precision': 0.3786407766990291, 'macro avg_recall': 0.3577981651376147, 'macro avg_f1-score': 0.36792452830188677, 'macro avg_support': 218.0, 'weighted avg_precision': 0.3786407766990291, 'weighted avg_recall': 0.3577981651376147, 'weighted avg_f1-score': 0.36792452830188677, 'weighted avg_support': 218.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 5}, {'micro_f1': 0.8656588399270934, 'precision': 0.8656588399270934, 'Exaggeration-Minimisation_precision': 0.32524271844660196, 'Exaggeration-Minimisation_recall': 0.38285714285714284, 'Exaggeration-Minimisation_f1-score': 0.35170603674540685, 'Exaggeration-Minimisation_support': 175.0, 'micro avg_precision': 0.32524271844660196, 'micro avg_recall': 0.38285714285714284, 'micro avg_f1-score': 0.35170603674540685, 'micro avg_support': 175.0, 'macro avg_precision': 0.32524271844660196, 'macro avg_recall': 0.38285714285714284, 'macro avg_f1-score': 0.35170603674540685, 'macro avg_support': 175.0, 'weighted avg_precision': 0.32524271844660196, 'weighted avg_recall': 0.38285714285714284, 'weighted avg_f1-score': 0.35170603674540685, 'weighted avg_support': 175.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 6}]}
{'micro_f1': 0.8651227618741288, 'precision': 0.8651227618741288, 'Exaggeration-Minimisation_precision': 0.4077669902912621, 'Exaggeration-Minimisation_recall': 0.3981042654028436, 'Exaggeration-Minimisation_f1-score': 0.40287769784172667, 'Exaggeration-Minimisation_support': 211.0, 'micro avg_precision': 0.4077669902912621, 'micro avg_recall': 0.3981042654028436, 'micro avg_f1-score': 0.40287769784172667, 'micro avg_support': 211.0, 'macro avg_precision': 0.4077669902912621, 'macro avg_recall': 0.3981042654028436, 'macro avg_f1-score': 0.40287769784172667, 'macro avg_support': 211.0, 'weighted avg_precision': 0.4077669902912621, 'weighted avg_recall': 0.3981042654028436, 'weighted avg_f1-score': 0.4028776978417266, 'weighted avg_support': 211.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 7}
{'results': [{'micro_f1': 0.8346735284657447, 'precision': 0.8346735284657446, 'Exaggeration-Minimisation_precision': 0.07766990291262135, 'Exaggeration-Minimisation_recall': 0.12403100775193798, 'Exaggeration-Minimisation_f1-score': 0.09552238805970148, 'Exaggeration-Minimisation_support': 129.0, 'micro avg_precision': 0.07766990291262135, 'micro avg_recall': 0.12403100775193798, 'micro avg_f1-score': 0.09552238805970148, 'micro avg_support': 129.0, 'macro avg_precision': 0.07766990291262135, 'macro avg_recall': 0.12403100775193798, 'macro avg_f1-score': 0.09552238805970148, 'macro avg_support': 129.0, 'weighted avg_precision': 0.07766990291262135, 'weighted avg_recall': 0.12403100775193798, 'weighted avg_f1-score': 0.09552238805970148, 'weighted avg_support': 129.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 0}, {'micro_f1': 0.8605124906186341, 'precision': 0.8605124906186341, 'Exaggeration-Minimisation_precision': 0.16019417475728157, 'Exaggeration-Minimisation_recall': 0.20121951219512196, 'Exaggeration-Minimisation_f1-score': 0.17837837837837842, 'Exaggeration-Minimisation_support': 164.0, 'micro avg_precision': 0.16019417475728157, 'micro avg_recall': 0.20121951219512196, 'micro avg_f1-score': 0.17837837837837842, 'micro avg_support': 164.0, 'macro avg_precision': 0.16019417475728157, 'macro avg_recall': 0.20121951219512196, 'macro avg_f1-score': 0.17837837837837842, 'macro avg_support': 164.0, 'weighted avg_precision': 0.16019417475728157, 'weighted avg_recall': 0.20121951219512196, 'weighted avg_f1-score': 0.17837837837837842, 'weighted avg_support': 164.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 1}, {'micro_f1': 0.8656588399270934, 'precision': 0.8656588399270934, 'Exaggeration-Minimisation_precision': 0.24757281553398058, 'Exaggeration-Minimisation_recall': 0.2786885245901639, 'Exaggeration-Minimisation_f1-score': 0.2622107969151671, 'Exaggeration-Minimisation_support': 183.0, 'micro avg_precision': 0.24757281553398058, 'micro avg_recall': 0.2786885245901639, 'micro avg_f1-score': 0.2622107969151671, 'micro avg_support': 183.0, 'macro avg_precision': 0.24757281553398058, 'macro avg_recall': 0.2786885245901639, 'macro avg_f1-score': 0.2622107969151671, 'macro avg_support': 183.0, 'weighted avg_precision': 0.24757281553398058, 'weighted avg_recall': 0.2786885245901639, 'weighted avg_f1-score': 0.2622107969151671, 'weighted avg_support': 183.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 2}, {'micro_f1': 0.8688753082448805, 'precision': 0.8688753082448805, 'Exaggeration-Minimisation_precision': 0.3592233009708738, 'Exaggeration-Minimisation_recall': 0.31759656652360513, 'Exaggeration-Minimisation_f1-score': 0.337129840546697, 'Exaggeration-Minimisation_support': 233.0, 'micro avg_precision': 0.3592233009708738, 'micro avg_recall': 0.31759656652360513, 'micro avg_f1-score': 0.337129840546697, 'micro avg_support': 233.0, 'macro avg_precision': 0.3592233009708738, 'macro avg_recall': 0.31759656652360513, 'macro avg_f1-score': 0.337129840546697, 'macro avg_support': 233.0, 'weighted avg_precision': 0.3592233009708738, 'weighted avg_recall': 0.31759656652360513, 'weighted avg_f1-score': 0.337129840546697, 'weighted avg_support': 233.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 3}, {'micro_f1': 0.8669454272542082, 'precision': 0.8669454272542082, 'Exaggeration-Minimisation_precision': 0.3737864077669903, 'Exaggeration-Minimisation_recall': 0.3031496062992126, 'Exaggeration-Minimisation_f1-score': 0.3347826086956522, 'Exaggeration-Minimisation_support': 254.0, 'micro avg_precision': 0.3737864077669903, 'micro avg_recall': 0.3031496062992126, 'micro avg_f1-score': 0.3347826086956522, 'micro avg_support': 254.0, 'macro avg_precision': 0.3737864077669903, 'macro avg_recall': 0.3031496062992126, 'macro avg_f1-score': 0.3347826086956522, 'macro avg_support': 254.0, 'weighted avg_precision': 0.3737864077669903, 'weighted avg_recall': 0.3031496062992126, 'weighted avg_f1-score': 0.3347826086956522, 'weighted avg_support': 254.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 4}, {'micro_f1': 0.8746649512168971, 'precision': 0.8746649512168971, 'Exaggeration-Minimisation_precision': 0.3786407766990291, 'Exaggeration-Minimisation_recall': 0.3577981651376147, 'Exaggeration-Minimisation_f1-score': 0.36792452830188677, 'Exaggeration-Minimisation_support': 218.0, 'micro avg_precision': 0.3786407766990291, 'micro avg_recall': 0.3577981651376147, 'micro avg_f1-score': 0.36792452830188677, 'micro avg_support': 218.0, 'macro avg_precision': 0.3786407766990291, 'macro avg_recall': 0.3577981651376147, 'macro avg_f1-score': 0.36792452830188677, 'macro avg_support': 218.0, 'weighted avg_precision': 0.3786407766990291, 'weighted avg_recall': 0.3577981651376147, 'weighted avg_f1-score': 0.36792452830188677, 'weighted avg_support': 218.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 5}, {'micro_f1': 0.8656588399270934, 'precision': 0.8656588399270934, 'Exaggeration-Minimisation_precision': 0.32524271844660196, 'Exaggeration-Minimisation_recall': 0.38285714285714284, 'Exaggeration-Minimisation_f1-score': 0.35170603674540685, 'Exaggeration-Minimisation_support': 175.0, 'micro avg_precision': 0.32524271844660196, 'micro avg_recall': 0.38285714285714284, 'micro avg_f1-score': 0.35170603674540685, 'micro avg_support': 175.0, 'macro avg_precision': 0.32524271844660196, 'macro avg_recall': 0.38285714285714284, 'macro avg_f1-score': 0.35170603674540685, 'macro avg_support': 175.0, 'weighted avg_precision': 0.32524271844660196, 'weighted avg_recall': 0.38285714285714284, 'weighted avg_f1-score': 0.35170603674540685, 'weighted avg_support': 175.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 6}, {'micro_f1': 0.8651227618741288, 'precision': 0.8651227618741288, 'Exaggeration-Minimisation_precision': 0.4077669902912621, 'Exaggeration-Minimisation_recall': 0.3981042654028436, 'Exaggeration-Minimisation_f1-score': 0.40287769784172667, 'Exaggeration-Minimisation_support': 211.0, 'micro avg_precision': 0.4077669902912621, 'micro avg_recall': 0.3981042654028436, 'micro avg_f1-score': 0.40287769784172667, 'micro avg_support': 211.0, 'macro avg_precision': 0.4077669902912621, 'macro avg_recall': 0.3981042654028436, 'macro avg_f1-score': 0.40287769784172667, 'macro avg_support': 211.0, 'weighted avg_precision': 0.4077669902912621, 'weighted avg_recall': 0.3981042654028436, 'weighted avg_f1-score': 0.4028776978417266, 'weighted avg_support': 211.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 7}]}
Best model updated: current epoch macro f1 = 0.40287769784172667
{'micro_f1': 0.8701618955719953, 'precision': 0.8701618955719953, 'Exaggeration-Minimisation_precision': 0.4029126213592233, 'Exaggeration-Minimisation_recall': 0.33739837398373984, 'Exaggeration-Minimisation_f1-score': 0.3672566371681416, 'Exaggeration-Minimisation_support': 246.0, 'micro avg_precision': 0.4029126213592233, 'micro avg_recall': 0.33739837398373984, 'micro avg_f1-score': 0.3672566371681416, 'micro avg_support': 246.0, 'macro avg_precision': 0.4029126213592233, 'macro avg_recall': 0.33739837398373984, 'macro avg_f1-score': 0.3672566371681416, 'macro avg_support': 246.0, 'weighted avg_precision': 0.4029126213592233, 'weighted avg_recall': 0.33739837398373984, 'weighted avg_f1-score': 0.3672566371681416, 'weighted avg_support': 246.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 8}
{'results': [{'micro_f1': 0.8346735284657447, 'precision': 0.8346735284657446, 'Exaggeration-Minimisation_precision': 0.07766990291262135, 'Exaggeration-Minimisation_recall': 0.12403100775193798, 'Exaggeration-Minimisation_f1-score': 0.09552238805970148, 'Exaggeration-Minimisation_support': 129.0, 'micro avg_precision': 0.07766990291262135, 'micro avg_recall': 0.12403100775193798, 'micro avg_f1-score': 0.09552238805970148, 'micro avg_support': 129.0, 'macro avg_precision': 0.07766990291262135, 'macro avg_recall': 0.12403100775193798, 'macro avg_f1-score': 0.09552238805970148, 'macro avg_support': 129.0, 'weighted avg_precision': 0.07766990291262135, 'weighted avg_recall': 0.12403100775193798, 'weighted avg_f1-score': 0.09552238805970148, 'weighted avg_support': 129.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 0}, {'micro_f1': 0.8605124906186341, 'precision': 0.8605124906186341, 'Exaggeration-Minimisation_precision': 0.16019417475728157, 'Exaggeration-Minimisation_recall': 0.20121951219512196, 'Exaggeration-Minimisation_f1-score': 0.17837837837837842, 'Exaggeration-Minimisation_support': 164.0, 'micro avg_precision': 0.16019417475728157, 'micro avg_recall': 0.20121951219512196, 'micro avg_f1-score': 0.17837837837837842, 'micro avg_support': 164.0, 'macro avg_precision': 0.16019417475728157, 'macro avg_recall': 0.20121951219512196, 'macro avg_f1-score': 0.17837837837837842, 'macro avg_support': 164.0, 'weighted avg_precision': 0.16019417475728157, 'weighted avg_recall': 0.20121951219512196, 'weighted avg_f1-score': 0.17837837837837842, 'weighted avg_support': 164.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 1}, {'micro_f1': 0.8656588399270934, 'precision': 0.8656588399270934, 'Exaggeration-Minimisation_precision': 0.24757281553398058, 'Exaggeration-Minimisation_recall': 0.2786885245901639, 'Exaggeration-Minimisation_f1-score': 0.2622107969151671, 'Exaggeration-Minimisation_support': 183.0, 'micro avg_precision': 0.24757281553398058, 'micro avg_recall': 0.2786885245901639, 'micro avg_f1-score': 0.2622107969151671, 'micro avg_support': 183.0, 'macro avg_precision': 0.24757281553398058, 'macro avg_recall': 0.2786885245901639, 'macro avg_f1-score': 0.2622107969151671, 'macro avg_support': 183.0, 'weighted avg_precision': 0.24757281553398058, 'weighted avg_recall': 0.2786885245901639, 'weighted avg_f1-score': 0.2622107969151671, 'weighted avg_support': 183.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 2}, {'micro_f1': 0.8688753082448805, 'precision': 0.8688753082448805, 'Exaggeration-Minimisation_precision': 0.3592233009708738, 'Exaggeration-Minimisation_recall': 0.31759656652360513, 'Exaggeration-Minimisation_f1-score': 0.337129840546697, 'Exaggeration-Minimisation_support': 233.0, 'micro avg_precision': 0.3592233009708738, 'micro avg_recall': 0.31759656652360513, 'micro avg_f1-score': 0.337129840546697, 'micro avg_support': 233.0, 'macro avg_precision': 0.3592233009708738, 'macro avg_recall': 0.31759656652360513, 'macro avg_f1-score': 0.337129840546697, 'macro avg_support': 233.0, 'weighted avg_precision': 0.3592233009708738, 'weighted avg_recall': 0.31759656652360513, 'weighted avg_f1-score': 0.337129840546697, 'weighted avg_support': 233.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 3}, {'micro_f1': 0.8669454272542082, 'precision': 0.8669454272542082, 'Exaggeration-Minimisation_precision': 0.3737864077669903, 'Exaggeration-Minimisation_recall': 0.3031496062992126, 'Exaggeration-Minimisation_f1-score': 0.3347826086956522, 'Exaggeration-Minimisation_support': 254.0, 'micro avg_precision': 0.3737864077669903, 'micro avg_recall': 0.3031496062992126, 'micro avg_f1-score': 0.3347826086956522, 'micro avg_support': 254.0, 'macro avg_precision': 0.3737864077669903, 'macro avg_recall': 0.3031496062992126, 'macro avg_f1-score': 0.3347826086956522, 'macro avg_support': 254.0, 'weighted avg_precision': 0.3737864077669903, 'weighted avg_recall': 0.3031496062992126, 'weighted avg_f1-score': 0.3347826086956522, 'weighted avg_support': 254.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 4}, {'micro_f1': 0.8746649512168971, 'precision': 0.8746649512168971, 'Exaggeration-Minimisation_precision': 0.3786407766990291, 'Exaggeration-Minimisation_recall': 0.3577981651376147, 'Exaggeration-Minimisation_f1-score': 0.36792452830188677, 'Exaggeration-Minimisation_support': 218.0, 'micro avg_precision': 0.3786407766990291, 'micro avg_recall': 0.3577981651376147, 'micro avg_f1-score': 0.36792452830188677, 'micro avg_support': 218.0, 'macro avg_precision': 0.3786407766990291, 'macro avg_recall': 0.3577981651376147, 'macro avg_f1-score': 0.36792452830188677, 'macro avg_support': 218.0, 'weighted avg_precision': 0.3786407766990291, 'weighted avg_recall': 0.3577981651376147, 'weighted avg_f1-score': 0.36792452830188677, 'weighted avg_support': 218.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 5}, {'micro_f1': 0.8656588399270934, 'precision': 0.8656588399270934, 'Exaggeration-Minimisation_precision': 0.32524271844660196, 'Exaggeration-Minimisation_recall': 0.38285714285714284, 'Exaggeration-Minimisation_f1-score': 0.35170603674540685, 'Exaggeration-Minimisation_support': 175.0, 'micro avg_precision': 0.32524271844660196, 'micro avg_recall': 0.38285714285714284, 'micro avg_f1-score': 0.35170603674540685, 'micro avg_support': 175.0, 'macro avg_precision': 0.32524271844660196, 'macro avg_recall': 0.38285714285714284, 'macro avg_f1-score': 0.35170603674540685, 'macro avg_support': 175.0, 'weighted avg_precision': 0.32524271844660196, 'weighted avg_recall': 0.38285714285714284, 'weighted avg_f1-score': 0.35170603674540685, 'weighted avg_support': 175.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 6}, {'micro_f1': 0.8651227618741288, 'precision': 0.8651227618741288, 'Exaggeration-Minimisation_precision': 0.4077669902912621, 'Exaggeration-Minimisation_recall': 0.3981042654028436, 'Exaggeration-Minimisation_f1-score': 0.40287769784172667, 'Exaggeration-Minimisation_support': 211.0, 'micro avg_precision': 0.4077669902912621, 'micro avg_recall': 0.3981042654028436, 'micro avg_f1-score': 0.40287769784172667, 'micro avg_support': 211.0, 'macro avg_precision': 0.4077669902912621, 'macro avg_recall': 0.3981042654028436, 'macro avg_f1-score': 0.40287769784172667, 'macro avg_support': 211.0, 'weighted avg_precision': 0.4077669902912621, 'weighted avg_recall': 0.3981042654028436, 'weighted avg_f1-score': 0.4028776978417266, 'weighted avg_support': 211.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 7}, {'micro_f1': 0.8701618955719953, 'precision': 0.8701618955719953, 'Exaggeration-Minimisation_precision': 0.4029126213592233, 'Exaggeration-Minimisation_recall': 0.33739837398373984, 'Exaggeration-Minimisation_f1-score': 0.3672566371681416, 'Exaggeration-Minimisation_support': 246.0, 'micro avg_precision': 0.4029126213592233, 'micro avg_recall': 0.33739837398373984, 'micro avg_f1-score': 0.3672566371681416, 'micro avg_support': 246.0, 'macro avg_precision': 0.4029126213592233, 'macro avg_recall': 0.33739837398373984, 'macro avg_f1-score': 0.3672566371681416, 'macro avg_support': 246.0, 'weighted avg_precision': 0.4029126213592233, 'weighted avg_recall': 0.33739837398373984, 'weighted avg_f1-score': 0.3672566371681416, 'weighted avg_support': 246.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 8}]}
{'micro_f1': 0.8709124048461456, 'precision': 0.8709124048461456, 'Exaggeration-Minimisation_precision': 0.4174757281553398, 'Exaggeration-Minimisation_recall': 0.4095238095238095, 'Exaggeration-Minimisation_f1-score': 0.4134615384615385, 'Exaggeration-Minimisation_support': 210.0, 'micro avg_precision': 0.4174757281553398, 'micro avg_recall': 0.4095238095238095, 'micro avg_f1-score': 0.4134615384615385, 'micro avg_support': 210.0, 'macro avg_precision': 0.4174757281553398, 'macro avg_recall': 0.4095238095238095, 'macro avg_f1-score': 0.4134615384615385, 'macro avg_support': 210.0, 'weighted avg_precision': 0.4174757281553398, 'weighted avg_recall': 0.4095238095238095, 'weighted avg_f1-score': 0.4134615384615385, 'weighted avg_support': 210.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 9}
{'results': [{'micro_f1': 0.8346735284657447, 'precision': 0.8346735284657446, 'Exaggeration-Minimisation_precision': 0.07766990291262135, 'Exaggeration-Minimisation_recall': 0.12403100775193798, 'Exaggeration-Minimisation_f1-score': 0.09552238805970148, 'Exaggeration-Minimisation_support': 129.0, 'micro avg_precision': 0.07766990291262135, 'micro avg_recall': 0.12403100775193798, 'micro avg_f1-score': 0.09552238805970148, 'micro avg_support': 129.0, 'macro avg_precision': 0.07766990291262135, 'macro avg_recall': 0.12403100775193798, 'macro avg_f1-score': 0.09552238805970148, 'macro avg_support': 129.0, 'weighted avg_precision': 0.07766990291262135, 'weighted avg_recall': 0.12403100775193798, 'weighted avg_f1-score': 0.09552238805970148, 'weighted avg_support': 129.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 0}, {'micro_f1': 0.8605124906186341, 'precision': 0.8605124906186341, 'Exaggeration-Minimisation_precision': 0.16019417475728157, 'Exaggeration-Minimisation_recall': 0.20121951219512196, 'Exaggeration-Minimisation_f1-score': 0.17837837837837842, 'Exaggeration-Minimisation_support': 164.0, 'micro avg_precision': 0.16019417475728157, 'micro avg_recall': 0.20121951219512196, 'micro avg_f1-score': 0.17837837837837842, 'micro avg_support': 164.0, 'macro avg_precision': 0.16019417475728157, 'macro avg_recall': 0.20121951219512196, 'macro avg_f1-score': 0.17837837837837842, 'macro avg_support': 164.0, 'weighted avg_precision': 0.16019417475728157, 'weighted avg_recall': 0.20121951219512196, 'weighted avg_f1-score': 0.17837837837837842, 'weighted avg_support': 164.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 1}, {'micro_f1': 0.8656588399270934, 'precision': 0.8656588399270934, 'Exaggeration-Minimisation_precision': 0.24757281553398058, 'Exaggeration-Minimisation_recall': 0.2786885245901639, 'Exaggeration-Minimisation_f1-score': 0.2622107969151671, 'Exaggeration-Minimisation_support': 183.0, 'micro avg_precision': 0.24757281553398058, 'micro avg_recall': 0.2786885245901639, 'micro avg_f1-score': 0.2622107969151671, 'micro avg_support': 183.0, 'macro avg_precision': 0.24757281553398058, 'macro avg_recall': 0.2786885245901639, 'macro avg_f1-score': 0.2622107969151671, 'macro avg_support': 183.0, 'weighted avg_precision': 0.24757281553398058, 'weighted avg_recall': 0.2786885245901639, 'weighted avg_f1-score': 0.2622107969151671, 'weighted avg_support': 183.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 2}, {'micro_f1': 0.8688753082448805, 'precision': 0.8688753082448805, 'Exaggeration-Minimisation_precision': 0.3592233009708738, 'Exaggeration-Minimisation_recall': 0.31759656652360513, 'Exaggeration-Minimisation_f1-score': 0.337129840546697, 'Exaggeration-Minimisation_support': 233.0, 'micro avg_precision': 0.3592233009708738, 'micro avg_recall': 0.31759656652360513, 'micro avg_f1-score': 0.337129840546697, 'micro avg_support': 233.0, 'macro avg_precision': 0.3592233009708738, 'macro avg_recall': 0.31759656652360513, 'macro avg_f1-score': 0.337129840546697, 'macro avg_support': 233.0, 'weighted avg_precision': 0.3592233009708738, 'weighted avg_recall': 0.31759656652360513, 'weighted avg_f1-score': 0.337129840546697, 'weighted avg_support': 233.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 3}, {'micro_f1': 0.8669454272542082, 'precision': 0.8669454272542082, 'Exaggeration-Minimisation_precision': 0.3737864077669903, 'Exaggeration-Minimisation_recall': 0.3031496062992126, 'Exaggeration-Minimisation_f1-score': 0.3347826086956522, 'Exaggeration-Minimisation_support': 254.0, 'micro avg_precision': 0.3737864077669903, 'micro avg_recall': 0.3031496062992126, 'micro avg_f1-score': 0.3347826086956522, 'micro avg_support': 254.0, 'macro avg_precision': 0.3737864077669903, 'macro avg_recall': 0.3031496062992126, 'macro avg_f1-score': 0.3347826086956522, 'macro avg_support': 254.0, 'weighted avg_precision': 0.3737864077669903, 'weighted avg_recall': 0.3031496062992126, 'weighted avg_f1-score': 0.3347826086956522, 'weighted avg_support': 254.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 4}, {'micro_f1': 0.8746649512168971, 'precision': 0.8746649512168971, 'Exaggeration-Minimisation_precision': 0.3786407766990291, 'Exaggeration-Minimisation_recall': 0.3577981651376147, 'Exaggeration-Minimisation_f1-score': 0.36792452830188677, 'Exaggeration-Minimisation_support': 218.0, 'micro avg_precision': 0.3786407766990291, 'micro avg_recall': 0.3577981651376147, 'micro avg_f1-score': 0.36792452830188677, 'micro avg_support': 218.0, 'macro avg_precision': 0.3786407766990291, 'macro avg_recall': 0.3577981651376147, 'macro avg_f1-score': 0.36792452830188677, 'macro avg_support': 218.0, 'weighted avg_precision': 0.3786407766990291, 'weighted avg_recall': 0.3577981651376147, 'weighted avg_f1-score': 0.36792452830188677, 'weighted avg_support': 218.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 5}, {'micro_f1': 0.8656588399270934, 'precision': 0.8656588399270934, 'Exaggeration-Minimisation_precision': 0.32524271844660196, 'Exaggeration-Minimisation_recall': 0.38285714285714284, 'Exaggeration-Minimisation_f1-score': 0.35170603674540685, 'Exaggeration-Minimisation_support': 175.0, 'micro avg_precision': 0.32524271844660196, 'micro avg_recall': 0.38285714285714284, 'micro avg_f1-score': 0.35170603674540685, 'micro avg_support': 175.0, 'macro avg_precision': 0.32524271844660196, 'macro avg_recall': 0.38285714285714284, 'macro avg_f1-score': 0.35170603674540685, 'macro avg_support': 175.0, 'weighted avg_precision': 0.32524271844660196, 'weighted avg_recall': 0.38285714285714284, 'weighted avg_f1-score': 0.35170603674540685, 'weighted avg_support': 175.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 6}, {'micro_f1': 0.8651227618741288, 'precision': 0.8651227618741288, 'Exaggeration-Minimisation_precision': 0.4077669902912621, 'Exaggeration-Minimisation_recall': 0.3981042654028436, 'Exaggeration-Minimisation_f1-score': 0.40287769784172667, 'Exaggeration-Minimisation_support': 211.0, 'micro avg_precision': 0.4077669902912621, 'micro avg_recall': 0.3981042654028436, 'micro avg_f1-score': 0.40287769784172667, 'micro avg_support': 211.0, 'macro avg_precision': 0.4077669902912621, 'macro avg_recall': 0.3981042654028436, 'macro avg_f1-score': 0.40287769784172667, 'macro avg_support': 211.0, 'weighted avg_precision': 0.4077669902912621, 'weighted avg_recall': 0.3981042654028436, 'weighted avg_f1-score': 0.4028776978417266, 'weighted avg_support': 211.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 7}, {'micro_f1': 0.8701618955719953, 'precision': 0.8701618955719953, 'Exaggeration-Minimisation_precision': 0.4029126213592233, 'Exaggeration-Minimisation_recall': 0.33739837398373984, 'Exaggeration-Minimisation_f1-score': 0.3672566371681416, 'Exaggeration-Minimisation_support': 246.0, 'micro avg_precision': 0.4029126213592233, 'micro avg_recall': 0.33739837398373984, 'micro avg_f1-score': 0.3672566371681416, 'micro avg_support': 246.0, 'macro avg_precision': 0.4029126213592233, 'macro avg_recall': 0.33739837398373984, 'macro avg_f1-score': 0.3672566371681416, 'macro avg_support': 246.0, 'weighted avg_precision': 0.4029126213592233, 'weighted avg_recall': 0.33739837398373984, 'weighted avg_f1-score': 0.3672566371681416, 'weighted avg_support': 246.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 8}, {'micro_f1': 0.8709124048461456, 'precision': 0.8709124048461456, 'Exaggeration-Minimisation_precision': 0.4174757281553398, 'Exaggeration-Minimisation_recall': 0.4095238095238095, 'Exaggeration-Minimisation_f1-score': 0.4134615384615385, 'Exaggeration-Minimisation_support': 210.0, 'micro avg_precision': 0.4174757281553398, 'micro avg_recall': 0.4095238095238095, 'micro avg_f1-score': 0.4134615384615385, 'micro avg_support': 210.0, 'macro avg_precision': 0.4174757281553398, 'macro avg_recall': 0.4095238095238095, 'macro avg_f1-score': 0.4134615384615385, 'macro avg_support': 210.0, 'weighted avg_precision': 0.4174757281553398, 'weighted avg_recall': 0.4095238095238095, 'weighted avg_f1-score': 0.4134615384615385, 'weighted avg_support': 210.0, 'O_support': 7264, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 9}]}
Best model updated: current epoch macro f1 = 0.4134615384615385
Saving model to directory: ./models/M2/2024-05-13-23-08-48_aug/mdeberta-v3-base_16_ME10_target=Exaggeration-Minimisation_SUBSAMPLED_2024-05-13-23-08-48
Training model no. 17 of 23 for (17, 'Obfuscation-Vagueness-Confusion') persuasion technique...
{'micro_f1': 0.7131544214694236, 'precision': 0.7131544214694236, 'Obfuscation-Vagueness-Confusion_precision': 0.0, 'Obfuscation-Vagueness-Confusion_recall': 0.0, 'Obfuscation-Vagueness-Confusion_f1-score': 0.0, 'Obfuscation-Vagueness-Confusion_support': 103.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 103.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 103.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 103.0, 'O_support': 1369, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 0}
{'results': [{'micro_f1': 0.7131544214694236, 'precision': 0.7131544214694236, 'Obfuscation-Vagueness-Confusion_precision': 0.0, 'Obfuscation-Vagueness-Confusion_recall': 0.0, 'Obfuscation-Vagueness-Confusion_f1-score': 0.0, 'Obfuscation-Vagueness-Confusion_support': 103.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 103.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 103.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 103.0, 'O_support': 1369, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 0}]}
{'micro_f1': 0.6827980642322922, 'precision': 0.6827980642322922, 'Obfuscation-Vagueness-Confusion_precision': 0.0425531914893617, 'Obfuscation-Vagueness-Confusion_recall': 0.012269938650306749, 'Obfuscation-Vagueness-Confusion_f1-score': 0.01904761904761905, 'Obfuscation-Vagueness-Confusion_support': 163.0, 'micro avg_precision': 0.0425531914893617, 'micro avg_recall': 0.012269938650306749, 'micro avg_f1-score': 0.01904761904761905, 'micro avg_support': 163.0, 'macro avg_precision': 0.0425531914893617, 'macro avg_recall': 0.012269938650306749, 'macro avg_f1-score': 0.01904761904761905, 'macro avg_support': 163.0, 'weighted avg_precision': 0.0425531914893617, 'weighted avg_recall': 0.012269938650306749, 'weighted avg_f1-score': 0.01904761904761905, 'weighted avg_support': 163.0, 'O_support': 1369, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 1}
{'results': [{'micro_f1': 0.7131544214694236, 'precision': 0.7131544214694236, 'Obfuscation-Vagueness-Confusion_precision': 0.0, 'Obfuscation-Vagueness-Confusion_recall': 0.0, 'Obfuscation-Vagueness-Confusion_f1-score': 0.0, 'Obfuscation-Vagueness-Confusion_support': 103.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 103.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 103.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 103.0, 'O_support': 1369, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 0}, {'micro_f1': 0.6827980642322922, 'precision': 0.6827980642322922, 'Obfuscation-Vagueness-Confusion_precision': 0.0425531914893617, 'Obfuscation-Vagueness-Confusion_recall': 0.012269938650306749, 'Obfuscation-Vagueness-Confusion_f1-score': 0.01904761904761905, 'Obfuscation-Vagueness-Confusion_support': 163.0, 'micro avg_precision': 0.0425531914893617, 'micro avg_recall': 0.012269938650306749, 'micro avg_f1-score': 0.01904761904761905, 'micro avg_support': 163.0, 'macro avg_precision': 0.0425531914893617, 'macro avg_recall': 0.012269938650306749, 'macro avg_f1-score': 0.01904761904761905, 'macro avg_support': 163.0, 'weighted avg_precision': 0.0425531914893617, 'weighted avg_recall': 0.012269938650306749, 'weighted avg_f1-score': 0.01904761904761905, 'weighted avg_support': 163.0, 'O_support': 1369, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 1}]}
Best model updated: current epoch macro f1 = 0.01904761904761905
{'micro_f1': 0.6722393312802464, 'precision': 0.6722393312802464, 'Obfuscation-Vagueness-Confusion_precision': 0.0851063829787234, 'Obfuscation-Vagueness-Confusion_recall': 0.03125, 'Obfuscation-Vagueness-Confusion_f1-score': 0.045714285714285714, 'Obfuscation-Vagueness-Confusion_support': 128.0, 'micro avg_precision': 0.0851063829787234, 'micro avg_recall': 0.03125, 'micro avg_f1-score': 0.045714285714285714, 'micro avg_support': 128.0, 'macro avg_precision': 0.0851063829787234, 'macro avg_recall': 0.03125, 'macro avg_f1-score': 0.045714285714285714, 'macro avg_support': 128.0, 'weighted avg_precision': 0.0851063829787234, 'weighted avg_recall': 0.03125, 'weighted avg_f1-score': 0.045714285714285714, 'weighted avg_support': 128.0, 'O_support': 1369, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 2}
{'results': [{'micro_f1': 0.7131544214694236, 'precision': 0.7131544214694236, 'Obfuscation-Vagueness-Confusion_precision': 0.0, 'Obfuscation-Vagueness-Confusion_recall': 0.0, 'Obfuscation-Vagueness-Confusion_f1-score': 0.0, 'Obfuscation-Vagueness-Confusion_support': 103.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 103.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 103.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 103.0, 'O_support': 1369, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 0}, {'micro_f1': 0.6827980642322922, 'precision': 0.6827980642322922, 'Obfuscation-Vagueness-Confusion_precision': 0.0425531914893617, 'Obfuscation-Vagueness-Confusion_recall': 0.012269938650306749, 'Obfuscation-Vagueness-Confusion_f1-score': 0.01904761904761905, 'Obfuscation-Vagueness-Confusion_support': 163.0, 'micro avg_precision': 0.0425531914893617, 'micro avg_recall': 0.012269938650306749, 'micro avg_f1-score': 0.01904761904761905, 'micro avg_support': 163.0, 'macro avg_precision': 0.0425531914893617, 'macro avg_recall': 0.012269938650306749, 'macro avg_f1-score': 0.01904761904761905, 'macro avg_support': 163.0, 'weighted avg_precision': 0.0425531914893617, 'weighted avg_recall': 0.012269938650306749, 'weighted avg_f1-score': 0.01904761904761905, 'weighted avg_support': 163.0, 'O_support': 1369, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 1}, {'micro_f1': 0.6722393312802464, 'precision': 0.6722393312802464, 'Obfuscation-Vagueness-Confusion_precision': 0.0851063829787234, 'Obfuscation-Vagueness-Confusion_recall': 0.03125, 'Obfuscation-Vagueness-Confusion_f1-score': 0.045714285714285714, 'Obfuscation-Vagueness-Confusion_support': 128.0, 'micro avg_precision': 0.0851063829787234, 'micro avg_recall': 0.03125, 'micro avg_f1-score': 0.045714285714285714, 'micro avg_support': 128.0, 'macro avg_precision': 0.0851063829787234, 'macro avg_recall': 0.03125, 'macro avg_f1-score': 0.045714285714285714, 'macro avg_support': 128.0, 'weighted avg_precision': 0.0851063829787234, 'weighted avg_recall': 0.03125, 'weighted avg_f1-score': 0.045714285714285714, 'weighted avg_support': 128.0, 'O_support': 1369, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 2}]}
Best model updated: current epoch macro f1 = 0.045714285714285714
{'micro_f1': 0.7179938407391113, 'precision': 0.7179938407391113, 'Obfuscation-Vagueness-Confusion_precision': 0.0851063829787234, 'Obfuscation-Vagueness-Confusion_recall': 0.037383177570093455, 'Obfuscation-Vagueness-Confusion_f1-score': 0.05194805194805195, 'Obfuscation-Vagueness-Confusion_support': 107.0, 'micro avg_precision': 0.0851063829787234, 'micro avg_recall': 0.037383177570093455, 'micro avg_f1-score': 0.05194805194805195, 'micro avg_support': 107.0, 'macro avg_precision': 0.0851063829787234, 'macro avg_recall': 0.037383177570093455, 'macro avg_f1-score': 0.05194805194805195, 'macro avg_support': 107.0, 'weighted avg_precision': 0.0851063829787234, 'weighted avg_recall': 0.037383177570093455, 'weighted avg_f1-score': 0.05194805194805195, 'weighted avg_support': 107.0, 'O_support': 1369, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 3}
{'results': [{'micro_f1': 0.7131544214694236, 'precision': 0.7131544214694236, 'Obfuscation-Vagueness-Confusion_precision': 0.0, 'Obfuscation-Vagueness-Confusion_recall': 0.0, 'Obfuscation-Vagueness-Confusion_f1-score': 0.0, 'Obfuscation-Vagueness-Confusion_support': 103.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 103.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 103.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 103.0, 'O_support': 1369, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 0}, {'micro_f1': 0.6827980642322922, 'precision': 0.6827980642322922, 'Obfuscation-Vagueness-Confusion_precision': 0.0425531914893617, 'Obfuscation-Vagueness-Confusion_recall': 0.012269938650306749, 'Obfuscation-Vagueness-Confusion_f1-score': 0.01904761904761905, 'Obfuscation-Vagueness-Confusion_support': 163.0, 'micro avg_precision': 0.0425531914893617, 'micro avg_recall': 0.012269938650306749, 'micro avg_f1-score': 0.01904761904761905, 'micro avg_support': 163.0, 'macro avg_precision': 0.0425531914893617, 'macro avg_recall': 0.012269938650306749, 'macro avg_f1-score': 0.01904761904761905, 'macro avg_support': 163.0, 'weighted avg_precision': 0.0425531914893617, 'weighted avg_recall': 0.012269938650306749, 'weighted avg_f1-score': 0.01904761904761905, 'weighted avg_support': 163.0, 'O_support': 1369, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 1}, {'micro_f1': 0.6722393312802464, 'precision': 0.6722393312802464, 'Obfuscation-Vagueness-Confusion_precision': 0.0851063829787234, 'Obfuscation-Vagueness-Confusion_recall': 0.03125, 'Obfuscation-Vagueness-Confusion_f1-score': 0.045714285714285714, 'Obfuscation-Vagueness-Confusion_support': 128.0, 'micro avg_precision': 0.0851063829787234, 'micro avg_recall': 0.03125, 'micro avg_f1-score': 0.045714285714285714, 'micro avg_support': 128.0, 'macro avg_precision': 0.0851063829787234, 'macro avg_recall': 0.03125, 'macro avg_f1-score': 0.045714285714285714, 'macro avg_support': 128.0, 'weighted avg_precision': 0.0851063829787234, 'weighted avg_recall': 0.03125, 'weighted avg_f1-score': 0.045714285714285714, 'weighted avg_support': 128.0, 'O_support': 1369, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 2}, {'micro_f1': 0.7179938407391113, 'precision': 0.7179938407391113, 'Obfuscation-Vagueness-Confusion_precision': 0.0851063829787234, 'Obfuscation-Vagueness-Confusion_recall': 0.037383177570093455, 'Obfuscation-Vagueness-Confusion_f1-score': 0.05194805194805195, 'Obfuscation-Vagueness-Confusion_support': 107.0, 'micro avg_precision': 0.0851063829787234, 'micro avg_recall': 0.037383177570093455, 'micro avg_f1-score': 0.05194805194805195, 'micro avg_support': 107.0, 'macro avg_precision': 0.0851063829787234, 'macro avg_recall': 0.037383177570093455, 'macro avg_f1-score': 0.05194805194805195, 'macro avg_support': 107.0, 'weighted avg_precision': 0.0851063829787234, 'weighted avg_recall': 0.037383177570093455, 'weighted avg_f1-score': 0.05194805194805195, 'weighted avg_support': 107.0, 'O_support': 1369, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 3}]}
Best model updated: current epoch macro f1 = 0.05194805194805195
{'micro_f1': 0.6867575890893093, 'precision': 0.6867575890893093, 'Obfuscation-Vagueness-Confusion_precision': 0.1276595744680851, 'Obfuscation-Vagueness-Confusion_recall': 0.0594059405940594, 'Obfuscation-Vagueness-Confusion_f1-score': 0.08108108108108107, 'Obfuscation-Vagueness-Confusion_support': 101.0, 'micro avg_precision': 0.1276595744680851, 'micro avg_recall': 0.0594059405940594, 'micro avg_f1-score': 0.08108108108108107, 'micro avg_support': 101.0, 'macro avg_precision': 0.1276595744680851, 'macro avg_recall': 0.0594059405940594, 'macro avg_f1-score': 0.08108108108108107, 'macro avg_support': 101.0, 'weighted avg_precision': 0.1276595744680851, 'weighted avg_recall': 0.0594059405940594, 'weighted avg_f1-score': 0.08108108108108107, 'weighted avg_support': 101.0, 'O_support': 1369, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 4}
{'results': [{'micro_f1': 0.7131544214694236, 'precision': 0.7131544214694236, 'Obfuscation-Vagueness-Confusion_precision': 0.0, 'Obfuscation-Vagueness-Confusion_recall': 0.0, 'Obfuscation-Vagueness-Confusion_f1-score': 0.0, 'Obfuscation-Vagueness-Confusion_support': 103.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 103.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 103.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 103.0, 'O_support': 1369, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 0}, {'micro_f1': 0.6827980642322922, 'precision': 0.6827980642322922, 'Obfuscation-Vagueness-Confusion_precision': 0.0425531914893617, 'Obfuscation-Vagueness-Confusion_recall': 0.012269938650306749, 'Obfuscation-Vagueness-Confusion_f1-score': 0.01904761904761905, 'Obfuscation-Vagueness-Confusion_support': 163.0, 'micro avg_precision': 0.0425531914893617, 'micro avg_recall': 0.012269938650306749, 'micro avg_f1-score': 0.01904761904761905, 'micro avg_support': 163.0, 'macro avg_precision': 0.0425531914893617, 'macro avg_recall': 0.012269938650306749, 'macro avg_f1-score': 0.01904761904761905, 'macro avg_support': 163.0, 'weighted avg_precision': 0.0425531914893617, 'weighted avg_recall': 0.012269938650306749, 'weighted avg_f1-score': 0.01904761904761905, 'weighted avg_support': 163.0, 'O_support': 1369, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 1}, {'micro_f1': 0.6722393312802464, 'precision': 0.6722393312802464, 'Obfuscation-Vagueness-Confusion_precision': 0.0851063829787234, 'Obfuscation-Vagueness-Confusion_recall': 0.03125, 'Obfuscation-Vagueness-Confusion_f1-score': 0.045714285714285714, 'Obfuscation-Vagueness-Confusion_support': 128.0, 'micro avg_precision': 0.0851063829787234, 'micro avg_recall': 0.03125, 'micro avg_f1-score': 0.045714285714285714, 'micro avg_support': 128.0, 'macro avg_precision': 0.0851063829787234, 'macro avg_recall': 0.03125, 'macro avg_f1-score': 0.045714285714285714, 'macro avg_support': 128.0, 'weighted avg_precision': 0.0851063829787234, 'weighted avg_recall': 0.03125, 'weighted avg_f1-score': 0.045714285714285714, 'weighted avg_support': 128.0, 'O_support': 1369, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 2}, {'micro_f1': 0.7179938407391113, 'precision': 0.7179938407391113, 'Obfuscation-Vagueness-Confusion_precision': 0.0851063829787234, 'Obfuscation-Vagueness-Confusion_recall': 0.037383177570093455, 'Obfuscation-Vagueness-Confusion_f1-score': 0.05194805194805195, 'Obfuscation-Vagueness-Confusion_support': 107.0, 'micro avg_precision': 0.0851063829787234, 'micro avg_recall': 0.037383177570093455, 'micro avg_f1-score': 0.05194805194805195, 'micro avg_support': 107.0, 'macro avg_precision': 0.0851063829787234, 'macro avg_recall': 0.037383177570093455, 'macro avg_f1-score': 0.05194805194805195, 'macro avg_support': 107.0, 'weighted avg_precision': 0.0851063829787234, 'weighted avg_recall': 0.037383177570093455, 'weighted avg_f1-score': 0.05194805194805195, 'weighted avg_support': 107.0, 'O_support': 1369, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 3}, {'micro_f1': 0.6867575890893093, 'precision': 0.6867575890893093, 'Obfuscation-Vagueness-Confusion_precision': 0.1276595744680851, 'Obfuscation-Vagueness-Confusion_recall': 0.0594059405940594, 'Obfuscation-Vagueness-Confusion_f1-score': 0.08108108108108107, 'Obfuscation-Vagueness-Confusion_support': 101.0, 'micro avg_precision': 0.1276595744680851, 'micro avg_recall': 0.0594059405940594, 'micro avg_f1-score': 0.08108108108108107, 'micro avg_support': 101.0, 'macro avg_precision': 0.1276595744680851, 'macro avg_recall': 0.0594059405940594, 'macro avg_f1-score': 0.08108108108108107, 'macro avg_support': 101.0, 'weighted avg_precision': 0.1276595744680851, 'weighted avg_recall': 0.0594059405940594, 'weighted avg_f1-score': 0.08108108108108107, 'weighted avg_support': 101.0, 'O_support': 1369, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 4}]}
Best model updated: current epoch macro f1 = 0.08108108108108107
{'micro_f1': 0.7135943686757588, 'precision': 0.7135943686757589, 'Obfuscation-Vagueness-Confusion_precision': 0.10638297872340426, 'Obfuscation-Vagueness-Confusion_recall': 0.06097560975609756, 'Obfuscation-Vagueness-Confusion_f1-score': 0.07751937984496125, 'Obfuscation-Vagueness-Confusion_support': 82.0, 'micro avg_precision': 0.10638297872340426, 'micro avg_recall': 0.06097560975609756, 'micro avg_f1-score': 0.07751937984496125, 'micro avg_support': 82.0, 'macro avg_precision': 0.10638297872340426, 'macro avg_recall': 0.06097560975609756, 'macro avg_f1-score': 0.07751937984496125, 'macro avg_support': 82.0, 'weighted avg_precision': 0.10638297872340426, 'weighted avg_recall': 0.06097560975609756, 'weighted avg_f1-score': 0.07751937984496125, 'weighted avg_support': 82.0, 'O_support': 1369, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 5}
{'results': [{'micro_f1': 0.7131544214694236, 'precision': 0.7131544214694236, 'Obfuscation-Vagueness-Confusion_precision': 0.0, 'Obfuscation-Vagueness-Confusion_recall': 0.0, 'Obfuscation-Vagueness-Confusion_f1-score': 0.0, 'Obfuscation-Vagueness-Confusion_support': 103.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 103.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 103.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 103.0, 'O_support': 1369, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 0}, {'micro_f1': 0.6827980642322922, 'precision': 0.6827980642322922, 'Obfuscation-Vagueness-Confusion_precision': 0.0425531914893617, 'Obfuscation-Vagueness-Confusion_recall': 0.012269938650306749, 'Obfuscation-Vagueness-Confusion_f1-score': 0.01904761904761905, 'Obfuscation-Vagueness-Confusion_support': 163.0, 'micro avg_precision': 0.0425531914893617, 'micro avg_recall': 0.012269938650306749, 'micro avg_f1-score': 0.01904761904761905, 'micro avg_support': 163.0, 'macro avg_precision': 0.0425531914893617, 'macro avg_recall': 0.012269938650306749, 'macro avg_f1-score': 0.01904761904761905, 'macro avg_support': 163.0, 'weighted avg_precision': 0.0425531914893617, 'weighted avg_recall': 0.012269938650306749, 'weighted avg_f1-score': 0.01904761904761905, 'weighted avg_support': 163.0, 'O_support': 1369, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 1}, {'micro_f1': 0.6722393312802464, 'precision': 0.6722393312802464, 'Obfuscation-Vagueness-Confusion_precision': 0.0851063829787234, 'Obfuscation-Vagueness-Confusion_recall': 0.03125, 'Obfuscation-Vagueness-Confusion_f1-score': 0.045714285714285714, 'Obfuscation-Vagueness-Confusion_support': 128.0, 'micro avg_precision': 0.0851063829787234, 'micro avg_recall': 0.03125, 'micro avg_f1-score': 0.045714285714285714, 'micro avg_support': 128.0, 'macro avg_precision': 0.0851063829787234, 'macro avg_recall': 0.03125, 'macro avg_f1-score': 0.045714285714285714, 'macro avg_support': 128.0, 'weighted avg_precision': 0.0851063829787234, 'weighted avg_recall': 0.03125, 'weighted avg_f1-score': 0.045714285714285714, 'weighted avg_support': 128.0, 'O_support': 1369, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 2}, {'micro_f1': 0.7179938407391113, 'precision': 0.7179938407391113, 'Obfuscation-Vagueness-Confusion_precision': 0.0851063829787234, 'Obfuscation-Vagueness-Confusion_recall': 0.037383177570093455, 'Obfuscation-Vagueness-Confusion_f1-score': 0.05194805194805195, 'Obfuscation-Vagueness-Confusion_support': 107.0, 'micro avg_precision': 0.0851063829787234, 'micro avg_recall': 0.037383177570093455, 'micro avg_f1-score': 0.05194805194805195, 'micro avg_support': 107.0, 'macro avg_precision': 0.0851063829787234, 'macro avg_recall': 0.037383177570093455, 'macro avg_f1-score': 0.05194805194805195, 'macro avg_support': 107.0, 'weighted avg_precision': 0.0851063829787234, 'weighted avg_recall': 0.037383177570093455, 'weighted avg_f1-score': 0.05194805194805195, 'weighted avg_support': 107.0, 'O_support': 1369, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 3}, {'micro_f1': 0.6867575890893093, 'precision': 0.6867575890893093, 'Obfuscation-Vagueness-Confusion_precision': 0.1276595744680851, 'Obfuscation-Vagueness-Confusion_recall': 0.0594059405940594, 'Obfuscation-Vagueness-Confusion_f1-score': 0.08108108108108107, 'Obfuscation-Vagueness-Confusion_support': 101.0, 'micro avg_precision': 0.1276595744680851, 'micro avg_recall': 0.0594059405940594, 'micro avg_f1-score': 0.08108108108108107, 'micro avg_support': 101.0, 'macro avg_precision': 0.1276595744680851, 'macro avg_recall': 0.0594059405940594, 'macro avg_f1-score': 0.08108108108108107, 'macro avg_support': 101.0, 'weighted avg_precision': 0.1276595744680851, 'weighted avg_recall': 0.0594059405940594, 'weighted avg_f1-score': 0.08108108108108107, 'weighted avg_support': 101.0, 'O_support': 1369, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 4}, {'micro_f1': 0.7135943686757588, 'precision': 0.7135943686757589, 'Obfuscation-Vagueness-Confusion_precision': 0.10638297872340426, 'Obfuscation-Vagueness-Confusion_recall': 0.06097560975609756, 'Obfuscation-Vagueness-Confusion_f1-score': 0.07751937984496125, 'Obfuscation-Vagueness-Confusion_support': 82.0, 'micro avg_precision': 0.10638297872340426, 'micro avg_recall': 0.06097560975609756, 'micro avg_f1-score': 0.07751937984496125, 'micro avg_support': 82.0, 'macro avg_precision': 0.10638297872340426, 'macro avg_recall': 0.06097560975609756, 'macro avg_f1-score': 0.07751937984496125, 'macro avg_support': 82.0, 'weighted avg_precision': 0.10638297872340426, 'weighted avg_recall': 0.06097560975609756, 'weighted avg_f1-score': 0.07751937984496125, 'weighted avg_support': 82.0, 'O_support': 1369, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 5}]}
{'micro_f1': 0.6823581170259568, 'precision': 0.6823581170259568, 'Obfuscation-Vagueness-Confusion_precision': 0.10638297872340426, 'Obfuscation-Vagueness-Confusion_recall': 0.04672897196261682, 'Obfuscation-Vagueness-Confusion_f1-score': 0.06493506493506494, 'Obfuscation-Vagueness-Confusion_support': 107.0, 'micro avg_precision': 0.10638297872340426, 'micro avg_recall': 0.04672897196261682, 'micro avg_f1-score': 0.06493506493506494, 'micro avg_support': 107.0, 'macro avg_precision': 0.10638297872340426, 'macro avg_recall': 0.04672897196261682, 'macro avg_f1-score': 0.06493506493506494, 'macro avg_support': 107.0, 'weighted avg_precision': 0.10638297872340426, 'weighted avg_recall': 0.04672897196261682, 'weighted avg_f1-score': 0.06493506493506494, 'weighted avg_support': 107.0, 'O_support': 1369, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 6}
{'results': [{'micro_f1': 0.7131544214694236, 'precision': 0.7131544214694236, 'Obfuscation-Vagueness-Confusion_precision': 0.0, 'Obfuscation-Vagueness-Confusion_recall': 0.0, 'Obfuscation-Vagueness-Confusion_f1-score': 0.0, 'Obfuscation-Vagueness-Confusion_support': 103.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 103.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 103.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 103.0, 'O_support': 1369, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 0}, {'micro_f1': 0.6827980642322922, 'precision': 0.6827980642322922, 'Obfuscation-Vagueness-Confusion_precision': 0.0425531914893617, 'Obfuscation-Vagueness-Confusion_recall': 0.012269938650306749, 'Obfuscation-Vagueness-Confusion_f1-score': 0.01904761904761905, 'Obfuscation-Vagueness-Confusion_support': 163.0, 'micro avg_precision': 0.0425531914893617, 'micro avg_recall': 0.012269938650306749, 'micro avg_f1-score': 0.01904761904761905, 'micro avg_support': 163.0, 'macro avg_precision': 0.0425531914893617, 'macro avg_recall': 0.012269938650306749, 'macro avg_f1-score': 0.01904761904761905, 'macro avg_support': 163.0, 'weighted avg_precision': 0.0425531914893617, 'weighted avg_recall': 0.012269938650306749, 'weighted avg_f1-score': 0.01904761904761905, 'weighted avg_support': 163.0, 'O_support': 1369, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 1}, {'micro_f1': 0.6722393312802464, 'precision': 0.6722393312802464, 'Obfuscation-Vagueness-Confusion_precision': 0.0851063829787234, 'Obfuscation-Vagueness-Confusion_recall': 0.03125, 'Obfuscation-Vagueness-Confusion_f1-score': 0.045714285714285714, 'Obfuscation-Vagueness-Confusion_support': 128.0, 'micro avg_precision': 0.0851063829787234, 'micro avg_recall': 0.03125, 'micro avg_f1-score': 0.045714285714285714, 'micro avg_support': 128.0, 'macro avg_precision': 0.0851063829787234, 'macro avg_recall': 0.03125, 'macro avg_f1-score': 0.045714285714285714, 'macro avg_support': 128.0, 'weighted avg_precision': 0.0851063829787234, 'weighted avg_recall': 0.03125, 'weighted avg_f1-score': 0.045714285714285714, 'weighted avg_support': 128.0, 'O_support': 1369, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 2}, {'micro_f1': 0.7179938407391113, 'precision': 0.7179938407391113, 'Obfuscation-Vagueness-Confusion_precision': 0.0851063829787234, 'Obfuscation-Vagueness-Confusion_recall': 0.037383177570093455, 'Obfuscation-Vagueness-Confusion_f1-score': 0.05194805194805195, 'Obfuscation-Vagueness-Confusion_support': 107.0, 'micro avg_precision': 0.0851063829787234, 'micro avg_recall': 0.037383177570093455, 'micro avg_f1-score': 0.05194805194805195, 'micro avg_support': 107.0, 'macro avg_precision': 0.0851063829787234, 'macro avg_recall': 0.037383177570093455, 'macro avg_f1-score': 0.05194805194805195, 'macro avg_support': 107.0, 'weighted avg_precision': 0.0851063829787234, 'weighted avg_recall': 0.037383177570093455, 'weighted avg_f1-score': 0.05194805194805195, 'weighted avg_support': 107.0, 'O_support': 1369, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 3}, {'micro_f1': 0.6867575890893093, 'precision': 0.6867575890893093, 'Obfuscation-Vagueness-Confusion_precision': 0.1276595744680851, 'Obfuscation-Vagueness-Confusion_recall': 0.0594059405940594, 'Obfuscation-Vagueness-Confusion_f1-score': 0.08108108108108107, 'Obfuscation-Vagueness-Confusion_support': 101.0, 'micro avg_precision': 0.1276595744680851, 'micro avg_recall': 0.0594059405940594, 'micro avg_f1-score': 0.08108108108108107, 'micro avg_support': 101.0, 'macro avg_precision': 0.1276595744680851, 'macro avg_recall': 0.0594059405940594, 'macro avg_f1-score': 0.08108108108108107, 'macro avg_support': 101.0, 'weighted avg_precision': 0.1276595744680851, 'weighted avg_recall': 0.0594059405940594, 'weighted avg_f1-score': 0.08108108108108107, 'weighted avg_support': 101.0, 'O_support': 1369, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 4}, {'micro_f1': 0.7135943686757588, 'precision': 0.7135943686757589, 'Obfuscation-Vagueness-Confusion_precision': 0.10638297872340426, 'Obfuscation-Vagueness-Confusion_recall': 0.06097560975609756, 'Obfuscation-Vagueness-Confusion_f1-score': 0.07751937984496125, 'Obfuscation-Vagueness-Confusion_support': 82.0, 'micro avg_precision': 0.10638297872340426, 'micro avg_recall': 0.06097560975609756, 'micro avg_f1-score': 0.07751937984496125, 'micro avg_support': 82.0, 'macro avg_precision': 0.10638297872340426, 'macro avg_recall': 0.06097560975609756, 'macro avg_f1-score': 0.07751937984496125, 'macro avg_support': 82.0, 'weighted avg_precision': 0.10638297872340426, 'weighted avg_recall': 0.06097560975609756, 'weighted avg_f1-score': 0.07751937984496125, 'weighted avg_support': 82.0, 'O_support': 1369, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 5}, {'micro_f1': 0.6823581170259568, 'precision': 0.6823581170259568, 'Obfuscation-Vagueness-Confusion_precision': 0.10638297872340426, 'Obfuscation-Vagueness-Confusion_recall': 0.04672897196261682, 'Obfuscation-Vagueness-Confusion_f1-score': 0.06493506493506494, 'Obfuscation-Vagueness-Confusion_support': 107.0, 'micro avg_precision': 0.10638297872340426, 'micro avg_recall': 0.04672897196261682, 'micro avg_f1-score': 0.06493506493506494, 'micro avg_support': 107.0, 'macro avg_precision': 0.10638297872340426, 'macro avg_recall': 0.04672897196261682, 'macro avg_f1-score': 0.06493506493506494, 'macro avg_support': 107.0, 'weighted avg_precision': 0.10638297872340426, 'weighted avg_recall': 0.04672897196261682, 'weighted avg_f1-score': 0.06493506493506494, 'weighted avg_support': 107.0, 'O_support': 1369, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 6}]}
Early stopping triggered.
Saving model to directory: ./models/M2/2024-05-13-23-08-48_aug/mdeberta-v3-base_17_ME10_target=Obfuscation-Vagueness-Confusion_SUBSAMPLED_2024-05-13-23-08-48
Training model no. 18 of 23 for (18, 'Name_Calling-Labeling') persuasion technique...
{'micro_f1': 0.9359066427289049, 'precision': 0.9359066427289049, 'Name_Calling-Labeling_precision': 0.10049019607843138, 'Name_Calling-Labeling_recall': 0.16565656565656567, 'Name_Calling-Labeling_f1-score': 0.12509534706331044, 'Name_Calling-Labeling_support': 495.0, 'micro avg_precision': 0.10049019607843138, 'micro avg_recall': 0.16565656565656567, 'micro avg_f1-score': 0.12509534706331044, 'micro avg_support': 495.0, 'macro avg_precision': 0.10049019607843138, 'macro avg_recall': 0.16565656565656567, 'macro avg_f1-score': 0.12509534706331044, 'macro avg_support': 495.0, 'weighted avg_precision': 0.10049019607843138, 'weighted avg_recall': 0.16565656565656567, 'weighted avg_f1-score': 0.12509534706331044, 'weighted avg_support': 495.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 0}
{'results': [{'micro_f1': 0.9359066427289049, 'precision': 0.9359066427289049, 'Name_Calling-Labeling_precision': 0.10049019607843138, 'Name_Calling-Labeling_recall': 0.16565656565656567, 'Name_Calling-Labeling_f1-score': 0.12509534706331044, 'Name_Calling-Labeling_support': 495.0, 'micro avg_precision': 0.10049019607843138, 'micro avg_recall': 0.16565656565656567, 'micro avg_f1-score': 0.12509534706331044, 'micro avg_support': 495.0, 'macro avg_precision': 0.10049019607843138, 'macro avg_recall': 0.16565656565656567, 'macro avg_f1-score': 0.12509534706331044, 'macro avg_support': 495.0, 'weighted avg_precision': 0.10049019607843138, 'weighted avg_recall': 0.16565656565656567, 'weighted avg_f1-score': 0.12509534706331044, 'weighted avg_support': 495.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 0}]}
Best model updated: current epoch macro f1 = 0.12509534706331044
{'micro_f1': 0.944524236983842, 'precision': 0.944524236983842, 'Name_Calling-Labeling_precision': 0.24509803921568626, 'Name_Calling-Labeling_recall': 0.32102728731942215, 'Name_Calling-Labeling_f1-score': 0.27797081306462823, 'Name_Calling-Labeling_support': 623.0, 'micro avg_precision': 0.24509803921568626, 'micro avg_recall': 0.32102728731942215, 'micro avg_f1-score': 0.27797081306462823, 'micro avg_support': 623.0, 'macro avg_precision': 0.24509803921568626, 'macro avg_recall': 0.32102728731942215, 'macro avg_f1-score': 0.27797081306462823, 'macro avg_support': 623.0, 'weighted avg_precision': 0.24509803921568626, 'weighted avg_recall': 0.32102728731942215, 'weighted avg_f1-score': 0.27797081306462823, 'weighted avg_support': 623.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 1}
{'results': [{'micro_f1': 0.9359066427289049, 'precision': 0.9359066427289049, 'Name_Calling-Labeling_precision': 0.10049019607843138, 'Name_Calling-Labeling_recall': 0.16565656565656567, 'Name_Calling-Labeling_f1-score': 0.12509534706331044, 'Name_Calling-Labeling_support': 495.0, 'micro avg_precision': 0.10049019607843138, 'micro avg_recall': 0.16565656565656567, 'micro avg_f1-score': 0.12509534706331044, 'micro avg_support': 495.0, 'macro avg_precision': 0.10049019607843138, 'macro avg_recall': 0.16565656565656567, 'macro avg_f1-score': 0.12509534706331044, 'macro avg_support': 495.0, 'weighted avg_precision': 0.10049019607843138, 'weighted avg_recall': 0.16565656565656567, 'weighted avg_f1-score': 0.12509534706331044, 'weighted avg_support': 495.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 0}, {'micro_f1': 0.944524236983842, 'precision': 0.944524236983842, 'Name_Calling-Labeling_precision': 0.24509803921568626, 'Name_Calling-Labeling_recall': 0.32102728731942215, 'Name_Calling-Labeling_f1-score': 0.27797081306462823, 'Name_Calling-Labeling_support': 623.0, 'micro avg_precision': 0.24509803921568626, 'micro avg_recall': 0.32102728731942215, 'micro avg_f1-score': 0.27797081306462823, 'micro avg_support': 623.0, 'macro avg_precision': 0.24509803921568626, 'macro avg_recall': 0.32102728731942215, 'macro avg_f1-score': 0.27797081306462823, 'macro avg_support': 623.0, 'weighted avg_precision': 0.24509803921568626, 'weighted avg_recall': 0.32102728731942215, 'weighted avg_f1-score': 0.27797081306462823, 'weighted avg_support': 623.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 1}]}
Best model updated: current epoch macro f1 = 0.27797081306462823
{'micro_f1': 0.9496110113704369, 'precision': 0.9496110113704369, 'Name_Calling-Labeling_precision': 0.3492647058823529, 'Name_Calling-Labeling_recall': 0.41424418604651164, 'Name_Calling-Labeling_f1-score': 0.3789893617021276, 'Name_Calling-Labeling_support': 688.0, 'micro avg_precision': 0.3492647058823529, 'micro avg_recall': 0.41424418604651164, 'micro avg_f1-score': 0.3789893617021276, 'micro avg_support': 688.0, 'macro avg_precision': 0.3492647058823529, 'macro avg_recall': 0.41424418604651164, 'macro avg_f1-score': 0.3789893617021276, 'macro avg_support': 688.0, 'weighted avg_precision': 0.3492647058823529, 'weighted avg_recall': 0.41424418604651164, 'weighted avg_f1-score': 0.3789893617021276, 'weighted avg_support': 688.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 2}
{'results': [{'micro_f1': 0.9359066427289049, 'precision': 0.9359066427289049, 'Name_Calling-Labeling_precision': 0.10049019607843138, 'Name_Calling-Labeling_recall': 0.16565656565656567, 'Name_Calling-Labeling_f1-score': 0.12509534706331044, 'Name_Calling-Labeling_support': 495.0, 'micro avg_precision': 0.10049019607843138, 'micro avg_recall': 0.16565656565656567, 'micro avg_f1-score': 0.12509534706331044, 'micro avg_support': 495.0, 'macro avg_precision': 0.10049019607843138, 'macro avg_recall': 0.16565656565656567, 'macro avg_f1-score': 0.12509534706331044, 'macro avg_support': 495.0, 'weighted avg_precision': 0.10049019607843138, 'weighted avg_recall': 0.16565656565656567, 'weighted avg_f1-score': 0.12509534706331044, 'weighted avg_support': 495.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 0}, {'micro_f1': 0.944524236983842, 'precision': 0.944524236983842, 'Name_Calling-Labeling_precision': 0.24509803921568626, 'Name_Calling-Labeling_recall': 0.32102728731942215, 'Name_Calling-Labeling_f1-score': 0.27797081306462823, 'Name_Calling-Labeling_support': 623.0, 'micro avg_precision': 0.24509803921568626, 'micro avg_recall': 0.32102728731942215, 'micro avg_f1-score': 0.27797081306462823, 'micro avg_support': 623.0, 'macro avg_precision': 0.24509803921568626, 'macro avg_recall': 0.32102728731942215, 'macro avg_f1-score': 0.27797081306462823, 'macro avg_support': 623.0, 'weighted avg_precision': 0.24509803921568626, 'weighted avg_recall': 0.32102728731942215, 'weighted avg_f1-score': 0.27797081306462823, 'weighted avg_support': 623.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 1}, {'micro_f1': 0.9496110113704369, 'precision': 0.9496110113704369, 'Name_Calling-Labeling_precision': 0.3492647058823529, 'Name_Calling-Labeling_recall': 0.41424418604651164, 'Name_Calling-Labeling_f1-score': 0.3789893617021276, 'Name_Calling-Labeling_support': 688.0, 'micro avg_precision': 0.3492647058823529, 'micro avg_recall': 0.41424418604651164, 'micro avg_f1-score': 0.3789893617021276, 'micro avg_support': 688.0, 'macro avg_precision': 0.3492647058823529, 'macro avg_recall': 0.41424418604651164, 'macro avg_f1-score': 0.3789893617021276, 'macro avg_support': 688.0, 'weighted avg_precision': 0.3492647058823529, 'weighted avg_recall': 0.41424418604651164, 'weighted avg_f1-score': 0.3789893617021276, 'weighted avg_support': 688.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 2}]}
Best model updated: current epoch macro f1 = 0.3789893617021276
{'micro_f1': 0.9460203470975463, 'precision': 0.9460203470975463, 'Name_Calling-Labeling_precision': 0.33455882352941174, 'Name_Calling-Labeling_recall': 0.4403225806451613, 'Name_Calling-Labeling_f1-score': 0.3802228412256267, 'Name_Calling-Labeling_support': 620.0, 'micro avg_precision': 0.33455882352941174, 'micro avg_recall': 0.4403225806451613, 'micro avg_f1-score': 0.3802228412256267, 'micro avg_support': 620.0, 'macro avg_precision': 0.33455882352941174, 'macro avg_recall': 0.4403225806451613, 'macro avg_f1-score': 0.3802228412256267, 'macro avg_support': 620.0, 'weighted avg_precision': 0.33455882352941174, 'weighted avg_recall': 0.4403225806451613, 'weighted avg_f1-score': 0.3802228412256267, 'weighted avg_support': 620.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 3}
{'results': [{'micro_f1': 0.9359066427289049, 'precision': 0.9359066427289049, 'Name_Calling-Labeling_precision': 0.10049019607843138, 'Name_Calling-Labeling_recall': 0.16565656565656567, 'Name_Calling-Labeling_f1-score': 0.12509534706331044, 'Name_Calling-Labeling_support': 495.0, 'micro avg_precision': 0.10049019607843138, 'micro avg_recall': 0.16565656565656567, 'micro avg_f1-score': 0.12509534706331044, 'micro avg_support': 495.0, 'macro avg_precision': 0.10049019607843138, 'macro avg_recall': 0.16565656565656567, 'macro avg_f1-score': 0.12509534706331044, 'macro avg_support': 495.0, 'weighted avg_precision': 0.10049019607843138, 'weighted avg_recall': 0.16565656565656567, 'weighted avg_f1-score': 0.12509534706331044, 'weighted avg_support': 495.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 0}, {'micro_f1': 0.944524236983842, 'precision': 0.944524236983842, 'Name_Calling-Labeling_precision': 0.24509803921568626, 'Name_Calling-Labeling_recall': 0.32102728731942215, 'Name_Calling-Labeling_f1-score': 0.27797081306462823, 'Name_Calling-Labeling_support': 623.0, 'micro avg_precision': 0.24509803921568626, 'micro avg_recall': 0.32102728731942215, 'micro avg_f1-score': 0.27797081306462823, 'micro avg_support': 623.0, 'macro avg_precision': 0.24509803921568626, 'macro avg_recall': 0.32102728731942215, 'macro avg_f1-score': 0.27797081306462823, 'macro avg_support': 623.0, 'weighted avg_precision': 0.24509803921568626, 'weighted avg_recall': 0.32102728731942215, 'weighted avg_f1-score': 0.27797081306462823, 'weighted avg_support': 623.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 1}, {'micro_f1': 0.9496110113704369, 'precision': 0.9496110113704369, 'Name_Calling-Labeling_precision': 0.3492647058823529, 'Name_Calling-Labeling_recall': 0.41424418604651164, 'Name_Calling-Labeling_f1-score': 0.3789893617021276, 'Name_Calling-Labeling_support': 688.0, 'micro avg_precision': 0.3492647058823529, 'micro avg_recall': 0.41424418604651164, 'micro avg_f1-score': 0.3789893617021276, 'micro avg_support': 688.0, 'macro avg_precision': 0.3492647058823529, 'macro avg_recall': 0.41424418604651164, 'macro avg_f1-score': 0.3789893617021276, 'macro avg_support': 688.0, 'weighted avg_precision': 0.3492647058823529, 'weighted avg_recall': 0.41424418604651164, 'weighted avg_f1-score': 0.3789893617021276, 'weighted avg_support': 688.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 2}, {'micro_f1': 0.9460203470975463, 'precision': 0.9460203470975463, 'Name_Calling-Labeling_precision': 0.33455882352941174, 'Name_Calling-Labeling_recall': 0.4403225806451613, 'Name_Calling-Labeling_f1-score': 0.3802228412256267, 'Name_Calling-Labeling_support': 620.0, 'micro avg_precision': 0.33455882352941174, 'micro avg_recall': 0.4403225806451613, 'micro avg_f1-score': 0.3802228412256267, 'micro avg_support': 620.0, 'macro avg_precision': 0.33455882352941174, 'macro avg_recall': 0.4403225806451613, 'macro avg_f1-score': 0.3802228412256267, 'macro avg_support': 620.0, 'weighted avg_precision': 0.33455882352941174, 'weighted avg_recall': 0.4403225806451613, 'weighted avg_f1-score': 0.3802228412256267, 'weighted avg_support': 620.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 3}]}
Best model updated: current epoch macro f1 = 0.3802228412256267
{'micro_f1': 0.950688210652304, 'precision': 0.950688210652304, 'Name_Calling-Labeling_precision': 0.38235294117647056, 'Name_Calling-Labeling_recall': 0.4450784593437946, 'Name_Calling-Labeling_f1-score': 0.4113381674357284, 'Name_Calling-Labeling_support': 701.0, 'micro avg_precision': 0.38235294117647056, 'micro avg_recall': 0.4450784593437946, 'micro avg_f1-score': 0.4113381674357284, 'micro avg_support': 701.0, 'macro avg_precision': 0.38235294117647056, 'macro avg_recall': 0.4450784593437946, 'macro avg_f1-score': 0.4113381674357284, 'macro avg_support': 701.0, 'weighted avg_precision': 0.38235294117647056, 'weighted avg_recall': 0.4450784593437946, 'weighted avg_f1-score': 0.4113381674357284, 'weighted avg_support': 701.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 4}
{'results': [{'micro_f1': 0.9359066427289049, 'precision': 0.9359066427289049, 'Name_Calling-Labeling_precision': 0.10049019607843138, 'Name_Calling-Labeling_recall': 0.16565656565656567, 'Name_Calling-Labeling_f1-score': 0.12509534706331044, 'Name_Calling-Labeling_support': 495.0, 'micro avg_precision': 0.10049019607843138, 'micro avg_recall': 0.16565656565656567, 'micro avg_f1-score': 0.12509534706331044, 'micro avg_support': 495.0, 'macro avg_precision': 0.10049019607843138, 'macro avg_recall': 0.16565656565656567, 'macro avg_f1-score': 0.12509534706331044, 'macro avg_support': 495.0, 'weighted avg_precision': 0.10049019607843138, 'weighted avg_recall': 0.16565656565656567, 'weighted avg_f1-score': 0.12509534706331044, 'weighted avg_support': 495.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 0}, {'micro_f1': 0.944524236983842, 'precision': 0.944524236983842, 'Name_Calling-Labeling_precision': 0.24509803921568626, 'Name_Calling-Labeling_recall': 0.32102728731942215, 'Name_Calling-Labeling_f1-score': 0.27797081306462823, 'Name_Calling-Labeling_support': 623.0, 'micro avg_precision': 0.24509803921568626, 'micro avg_recall': 0.32102728731942215, 'micro avg_f1-score': 0.27797081306462823, 'micro avg_support': 623.0, 'macro avg_precision': 0.24509803921568626, 'macro avg_recall': 0.32102728731942215, 'macro avg_f1-score': 0.27797081306462823, 'macro avg_support': 623.0, 'weighted avg_precision': 0.24509803921568626, 'weighted avg_recall': 0.32102728731942215, 'weighted avg_f1-score': 0.27797081306462823, 'weighted avg_support': 623.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 1}, {'micro_f1': 0.9496110113704369, 'precision': 0.9496110113704369, 'Name_Calling-Labeling_precision': 0.3492647058823529, 'Name_Calling-Labeling_recall': 0.41424418604651164, 'Name_Calling-Labeling_f1-score': 0.3789893617021276, 'Name_Calling-Labeling_support': 688.0, 'micro avg_precision': 0.3492647058823529, 'micro avg_recall': 0.41424418604651164, 'micro avg_f1-score': 0.3789893617021276, 'micro avg_support': 688.0, 'macro avg_precision': 0.3492647058823529, 'macro avg_recall': 0.41424418604651164, 'macro avg_f1-score': 0.3789893617021276, 'macro avg_support': 688.0, 'weighted avg_precision': 0.3492647058823529, 'weighted avg_recall': 0.41424418604651164, 'weighted avg_f1-score': 0.3789893617021276, 'weighted avg_support': 688.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 2}, {'micro_f1': 0.9460203470975463, 'precision': 0.9460203470975463, 'Name_Calling-Labeling_precision': 0.33455882352941174, 'Name_Calling-Labeling_recall': 0.4403225806451613, 'Name_Calling-Labeling_f1-score': 0.3802228412256267, 'Name_Calling-Labeling_support': 620.0, 'micro avg_precision': 0.33455882352941174, 'micro avg_recall': 0.4403225806451613, 'micro avg_f1-score': 0.3802228412256267, 'micro avg_support': 620.0, 'macro avg_precision': 0.33455882352941174, 'macro avg_recall': 0.4403225806451613, 'macro avg_f1-score': 0.3802228412256267, 'macro avg_support': 620.0, 'weighted avg_precision': 0.33455882352941174, 'weighted avg_recall': 0.4403225806451613, 'weighted avg_f1-score': 0.3802228412256267, 'weighted avg_support': 620.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 3}, {'micro_f1': 0.950688210652304, 'precision': 0.950688210652304, 'Name_Calling-Labeling_precision': 0.38235294117647056, 'Name_Calling-Labeling_recall': 0.4450784593437946, 'Name_Calling-Labeling_f1-score': 0.4113381674357284, 'Name_Calling-Labeling_support': 701.0, 'micro avg_precision': 0.38235294117647056, 'micro avg_recall': 0.4450784593437946, 'micro avg_f1-score': 0.4113381674357284, 'micro avg_support': 701.0, 'macro avg_precision': 0.38235294117647056, 'macro avg_recall': 0.4450784593437946, 'macro avg_f1-score': 0.4113381674357284, 'macro avg_support': 701.0, 'weighted avg_precision': 0.38235294117647056, 'weighted avg_recall': 0.4450784593437946, 'weighted avg_f1-score': 0.4113381674357284, 'weighted avg_support': 701.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 4}]}
Best model updated: current epoch macro f1 = 0.4113381674357284
{'micro_f1': 0.9478156792339916, 'precision': 0.9478156792339916, 'Name_Calling-Labeling_precision': 0.35294117647058826, 'Name_Calling-Labeling_recall': 0.4458204334365325, 'Name_Calling-Labeling_f1-score': 0.39398084815321477, 'Name_Calling-Labeling_support': 646.0, 'micro avg_precision': 0.35294117647058826, 'micro avg_recall': 0.4458204334365325, 'micro avg_f1-score': 0.39398084815321477, 'micro avg_support': 646.0, 'macro avg_precision': 0.35294117647058826, 'macro avg_recall': 0.4458204334365325, 'macro avg_f1-score': 0.39398084815321477, 'macro avg_support': 646.0, 'weighted avg_precision': 0.35294117647058826, 'weighted avg_recall': 0.4458204334365325, 'weighted avg_f1-score': 0.39398084815321477, 'weighted avg_support': 646.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 5}
{'results': [{'micro_f1': 0.9359066427289049, 'precision': 0.9359066427289049, 'Name_Calling-Labeling_precision': 0.10049019607843138, 'Name_Calling-Labeling_recall': 0.16565656565656567, 'Name_Calling-Labeling_f1-score': 0.12509534706331044, 'Name_Calling-Labeling_support': 495.0, 'micro avg_precision': 0.10049019607843138, 'micro avg_recall': 0.16565656565656567, 'micro avg_f1-score': 0.12509534706331044, 'micro avg_support': 495.0, 'macro avg_precision': 0.10049019607843138, 'macro avg_recall': 0.16565656565656567, 'macro avg_f1-score': 0.12509534706331044, 'macro avg_support': 495.0, 'weighted avg_precision': 0.10049019607843138, 'weighted avg_recall': 0.16565656565656567, 'weighted avg_f1-score': 0.12509534706331044, 'weighted avg_support': 495.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 0}, {'micro_f1': 0.944524236983842, 'precision': 0.944524236983842, 'Name_Calling-Labeling_precision': 0.24509803921568626, 'Name_Calling-Labeling_recall': 0.32102728731942215, 'Name_Calling-Labeling_f1-score': 0.27797081306462823, 'Name_Calling-Labeling_support': 623.0, 'micro avg_precision': 0.24509803921568626, 'micro avg_recall': 0.32102728731942215, 'micro avg_f1-score': 0.27797081306462823, 'micro avg_support': 623.0, 'macro avg_precision': 0.24509803921568626, 'macro avg_recall': 0.32102728731942215, 'macro avg_f1-score': 0.27797081306462823, 'macro avg_support': 623.0, 'weighted avg_precision': 0.24509803921568626, 'weighted avg_recall': 0.32102728731942215, 'weighted avg_f1-score': 0.27797081306462823, 'weighted avg_support': 623.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 1}, {'micro_f1': 0.9496110113704369, 'precision': 0.9496110113704369, 'Name_Calling-Labeling_precision': 0.3492647058823529, 'Name_Calling-Labeling_recall': 0.41424418604651164, 'Name_Calling-Labeling_f1-score': 0.3789893617021276, 'Name_Calling-Labeling_support': 688.0, 'micro avg_precision': 0.3492647058823529, 'micro avg_recall': 0.41424418604651164, 'micro avg_f1-score': 0.3789893617021276, 'micro avg_support': 688.0, 'macro avg_precision': 0.3492647058823529, 'macro avg_recall': 0.41424418604651164, 'macro avg_f1-score': 0.3789893617021276, 'macro avg_support': 688.0, 'weighted avg_precision': 0.3492647058823529, 'weighted avg_recall': 0.41424418604651164, 'weighted avg_f1-score': 0.3789893617021276, 'weighted avg_support': 688.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 2}, {'micro_f1': 0.9460203470975463, 'precision': 0.9460203470975463, 'Name_Calling-Labeling_precision': 0.33455882352941174, 'Name_Calling-Labeling_recall': 0.4403225806451613, 'Name_Calling-Labeling_f1-score': 0.3802228412256267, 'Name_Calling-Labeling_support': 620.0, 'micro avg_precision': 0.33455882352941174, 'micro avg_recall': 0.4403225806451613, 'micro avg_f1-score': 0.3802228412256267, 'micro avg_support': 620.0, 'macro avg_precision': 0.33455882352941174, 'macro avg_recall': 0.4403225806451613, 'macro avg_f1-score': 0.3802228412256267, 'macro avg_support': 620.0, 'weighted avg_precision': 0.33455882352941174, 'weighted avg_recall': 0.4403225806451613, 'weighted avg_f1-score': 0.3802228412256267, 'weighted avg_support': 620.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 3}, {'micro_f1': 0.950688210652304, 'precision': 0.950688210652304, 'Name_Calling-Labeling_precision': 0.38235294117647056, 'Name_Calling-Labeling_recall': 0.4450784593437946, 'Name_Calling-Labeling_f1-score': 0.4113381674357284, 'Name_Calling-Labeling_support': 701.0, 'micro avg_precision': 0.38235294117647056, 'micro avg_recall': 0.4450784593437946, 'micro avg_f1-score': 0.4113381674357284, 'micro avg_support': 701.0, 'macro avg_precision': 0.38235294117647056, 'macro avg_recall': 0.4450784593437946, 'macro avg_f1-score': 0.4113381674357284, 'macro avg_support': 701.0, 'weighted avg_precision': 0.38235294117647056, 'weighted avg_recall': 0.4450784593437946, 'weighted avg_f1-score': 0.4113381674357284, 'weighted avg_support': 701.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 4}, {'micro_f1': 0.9478156792339916, 'precision': 0.9478156792339916, 'Name_Calling-Labeling_precision': 0.35294117647058826, 'Name_Calling-Labeling_recall': 0.4458204334365325, 'Name_Calling-Labeling_f1-score': 0.39398084815321477, 'Name_Calling-Labeling_support': 646.0, 'micro avg_precision': 0.35294117647058826, 'micro avg_recall': 0.4458204334365325, 'micro avg_f1-score': 0.39398084815321477, 'micro avg_support': 646.0, 'macro avg_precision': 0.35294117647058826, 'macro avg_recall': 0.4458204334365325, 'macro avg_f1-score': 0.39398084815321477, 'macro avg_support': 646.0, 'weighted avg_precision': 0.35294117647058826, 'weighted avg_recall': 0.4458204334365325, 'weighted avg_f1-score': 0.39398084815321477, 'weighted avg_support': 646.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 5}]}
{'micro_f1': 0.9491621783363255, 'precision': 0.9491621783363255, 'Name_Calling-Labeling_precision': 0.3799019607843137, 'Name_Calling-Labeling_recall': 0.4599406528189911, 'Name_Calling-Labeling_f1-score': 0.4161073825503356, 'Name_Calling-Labeling_support': 674.0, 'micro avg_precision': 0.3799019607843137, 'micro avg_recall': 0.4599406528189911, 'micro avg_f1-score': 0.4161073825503356, 'micro avg_support': 674.0, 'macro avg_precision': 0.3799019607843137, 'macro avg_recall': 0.4599406528189911, 'macro avg_f1-score': 0.4161073825503356, 'macro avg_support': 674.0, 'weighted avg_precision': 0.37990196078431376, 'weighted avg_recall': 0.4599406528189911, 'weighted avg_f1-score': 0.4161073825503356, 'weighted avg_support': 674.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 6}
{'results': [{'micro_f1': 0.9359066427289049, 'precision': 0.9359066427289049, 'Name_Calling-Labeling_precision': 0.10049019607843138, 'Name_Calling-Labeling_recall': 0.16565656565656567, 'Name_Calling-Labeling_f1-score': 0.12509534706331044, 'Name_Calling-Labeling_support': 495.0, 'micro avg_precision': 0.10049019607843138, 'micro avg_recall': 0.16565656565656567, 'micro avg_f1-score': 0.12509534706331044, 'micro avg_support': 495.0, 'macro avg_precision': 0.10049019607843138, 'macro avg_recall': 0.16565656565656567, 'macro avg_f1-score': 0.12509534706331044, 'macro avg_support': 495.0, 'weighted avg_precision': 0.10049019607843138, 'weighted avg_recall': 0.16565656565656567, 'weighted avg_f1-score': 0.12509534706331044, 'weighted avg_support': 495.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 0}, {'micro_f1': 0.944524236983842, 'precision': 0.944524236983842, 'Name_Calling-Labeling_precision': 0.24509803921568626, 'Name_Calling-Labeling_recall': 0.32102728731942215, 'Name_Calling-Labeling_f1-score': 0.27797081306462823, 'Name_Calling-Labeling_support': 623.0, 'micro avg_precision': 0.24509803921568626, 'micro avg_recall': 0.32102728731942215, 'micro avg_f1-score': 0.27797081306462823, 'micro avg_support': 623.0, 'macro avg_precision': 0.24509803921568626, 'macro avg_recall': 0.32102728731942215, 'macro avg_f1-score': 0.27797081306462823, 'macro avg_support': 623.0, 'weighted avg_precision': 0.24509803921568626, 'weighted avg_recall': 0.32102728731942215, 'weighted avg_f1-score': 0.27797081306462823, 'weighted avg_support': 623.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 1}, {'micro_f1': 0.9496110113704369, 'precision': 0.9496110113704369, 'Name_Calling-Labeling_precision': 0.3492647058823529, 'Name_Calling-Labeling_recall': 0.41424418604651164, 'Name_Calling-Labeling_f1-score': 0.3789893617021276, 'Name_Calling-Labeling_support': 688.0, 'micro avg_precision': 0.3492647058823529, 'micro avg_recall': 0.41424418604651164, 'micro avg_f1-score': 0.3789893617021276, 'micro avg_support': 688.0, 'macro avg_precision': 0.3492647058823529, 'macro avg_recall': 0.41424418604651164, 'macro avg_f1-score': 0.3789893617021276, 'macro avg_support': 688.0, 'weighted avg_precision': 0.3492647058823529, 'weighted avg_recall': 0.41424418604651164, 'weighted avg_f1-score': 0.3789893617021276, 'weighted avg_support': 688.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 2}, {'micro_f1': 0.9460203470975463, 'precision': 0.9460203470975463, 'Name_Calling-Labeling_precision': 0.33455882352941174, 'Name_Calling-Labeling_recall': 0.4403225806451613, 'Name_Calling-Labeling_f1-score': 0.3802228412256267, 'Name_Calling-Labeling_support': 620.0, 'micro avg_precision': 0.33455882352941174, 'micro avg_recall': 0.4403225806451613, 'micro avg_f1-score': 0.3802228412256267, 'micro avg_support': 620.0, 'macro avg_precision': 0.33455882352941174, 'macro avg_recall': 0.4403225806451613, 'macro avg_f1-score': 0.3802228412256267, 'macro avg_support': 620.0, 'weighted avg_precision': 0.33455882352941174, 'weighted avg_recall': 0.4403225806451613, 'weighted avg_f1-score': 0.3802228412256267, 'weighted avg_support': 620.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 3}, {'micro_f1': 0.950688210652304, 'precision': 0.950688210652304, 'Name_Calling-Labeling_precision': 0.38235294117647056, 'Name_Calling-Labeling_recall': 0.4450784593437946, 'Name_Calling-Labeling_f1-score': 0.4113381674357284, 'Name_Calling-Labeling_support': 701.0, 'micro avg_precision': 0.38235294117647056, 'micro avg_recall': 0.4450784593437946, 'micro avg_f1-score': 0.4113381674357284, 'micro avg_support': 701.0, 'macro avg_precision': 0.38235294117647056, 'macro avg_recall': 0.4450784593437946, 'macro avg_f1-score': 0.4113381674357284, 'macro avg_support': 701.0, 'weighted avg_precision': 0.38235294117647056, 'weighted avg_recall': 0.4450784593437946, 'weighted avg_f1-score': 0.4113381674357284, 'weighted avg_support': 701.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 4}, {'micro_f1': 0.9478156792339916, 'precision': 0.9478156792339916, 'Name_Calling-Labeling_precision': 0.35294117647058826, 'Name_Calling-Labeling_recall': 0.4458204334365325, 'Name_Calling-Labeling_f1-score': 0.39398084815321477, 'Name_Calling-Labeling_support': 646.0, 'micro avg_precision': 0.35294117647058826, 'micro avg_recall': 0.4458204334365325, 'micro avg_f1-score': 0.39398084815321477, 'micro avg_support': 646.0, 'macro avg_precision': 0.35294117647058826, 'macro avg_recall': 0.4458204334365325, 'macro avg_f1-score': 0.39398084815321477, 'macro avg_support': 646.0, 'weighted avg_precision': 0.35294117647058826, 'weighted avg_recall': 0.4458204334365325, 'weighted avg_f1-score': 0.39398084815321477, 'weighted avg_support': 646.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 5}, {'micro_f1': 0.9491621783363255, 'precision': 0.9491621783363255, 'Name_Calling-Labeling_precision': 0.3799019607843137, 'Name_Calling-Labeling_recall': 0.4599406528189911, 'Name_Calling-Labeling_f1-score': 0.4161073825503356, 'Name_Calling-Labeling_support': 674.0, 'micro avg_precision': 0.3799019607843137, 'micro avg_recall': 0.4599406528189911, 'micro avg_f1-score': 0.4161073825503356, 'micro avg_support': 674.0, 'macro avg_precision': 0.3799019607843137, 'macro avg_recall': 0.4599406528189911, 'macro avg_f1-score': 0.4161073825503356, 'macro avg_support': 674.0, 'weighted avg_precision': 0.37990196078431376, 'weighted avg_recall': 0.4599406528189911, 'weighted avg_f1-score': 0.4161073825503356, 'weighted avg_support': 674.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 6}]}
Best model updated: current epoch macro f1 = 0.4161073825503356
{'micro_f1': 0.9532315978456014, 'precision': 0.9532315978456014, 'Name_Calling-Labeling_precision': 0.4375, 'Name_Calling-Labeling_recall': 0.4870395634379263, 'Name_Calling-Labeling_f1-score': 0.46094254357650094, 'Name_Calling-Labeling_support': 733.0, 'micro avg_precision': 0.4375, 'micro avg_recall': 0.4870395634379263, 'micro avg_f1-score': 0.46094254357650094, 'micro avg_support': 733.0, 'macro avg_precision': 0.4375, 'macro avg_recall': 0.4870395634379263, 'macro avg_f1-score': 0.46094254357650094, 'macro avg_support': 733.0, 'weighted avg_precision': 0.4375, 'weighted avg_recall': 0.4870395634379263, 'weighted avg_f1-score': 0.46094254357650094, 'weighted avg_support': 733.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 7}
{'results': [{'micro_f1': 0.9359066427289049, 'precision': 0.9359066427289049, 'Name_Calling-Labeling_precision': 0.10049019607843138, 'Name_Calling-Labeling_recall': 0.16565656565656567, 'Name_Calling-Labeling_f1-score': 0.12509534706331044, 'Name_Calling-Labeling_support': 495.0, 'micro avg_precision': 0.10049019607843138, 'micro avg_recall': 0.16565656565656567, 'micro avg_f1-score': 0.12509534706331044, 'micro avg_support': 495.0, 'macro avg_precision': 0.10049019607843138, 'macro avg_recall': 0.16565656565656567, 'macro avg_f1-score': 0.12509534706331044, 'macro avg_support': 495.0, 'weighted avg_precision': 0.10049019607843138, 'weighted avg_recall': 0.16565656565656567, 'weighted avg_f1-score': 0.12509534706331044, 'weighted avg_support': 495.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 0}, {'micro_f1': 0.944524236983842, 'precision': 0.944524236983842, 'Name_Calling-Labeling_precision': 0.24509803921568626, 'Name_Calling-Labeling_recall': 0.32102728731942215, 'Name_Calling-Labeling_f1-score': 0.27797081306462823, 'Name_Calling-Labeling_support': 623.0, 'micro avg_precision': 0.24509803921568626, 'micro avg_recall': 0.32102728731942215, 'micro avg_f1-score': 0.27797081306462823, 'micro avg_support': 623.0, 'macro avg_precision': 0.24509803921568626, 'macro avg_recall': 0.32102728731942215, 'macro avg_f1-score': 0.27797081306462823, 'macro avg_support': 623.0, 'weighted avg_precision': 0.24509803921568626, 'weighted avg_recall': 0.32102728731942215, 'weighted avg_f1-score': 0.27797081306462823, 'weighted avg_support': 623.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 1}, {'micro_f1': 0.9496110113704369, 'precision': 0.9496110113704369, 'Name_Calling-Labeling_precision': 0.3492647058823529, 'Name_Calling-Labeling_recall': 0.41424418604651164, 'Name_Calling-Labeling_f1-score': 0.3789893617021276, 'Name_Calling-Labeling_support': 688.0, 'micro avg_precision': 0.3492647058823529, 'micro avg_recall': 0.41424418604651164, 'micro avg_f1-score': 0.3789893617021276, 'micro avg_support': 688.0, 'macro avg_precision': 0.3492647058823529, 'macro avg_recall': 0.41424418604651164, 'macro avg_f1-score': 0.3789893617021276, 'macro avg_support': 688.0, 'weighted avg_precision': 0.3492647058823529, 'weighted avg_recall': 0.41424418604651164, 'weighted avg_f1-score': 0.3789893617021276, 'weighted avg_support': 688.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 2}, {'micro_f1': 0.9460203470975463, 'precision': 0.9460203470975463, 'Name_Calling-Labeling_precision': 0.33455882352941174, 'Name_Calling-Labeling_recall': 0.4403225806451613, 'Name_Calling-Labeling_f1-score': 0.3802228412256267, 'Name_Calling-Labeling_support': 620.0, 'micro avg_precision': 0.33455882352941174, 'micro avg_recall': 0.4403225806451613, 'micro avg_f1-score': 0.3802228412256267, 'micro avg_support': 620.0, 'macro avg_precision': 0.33455882352941174, 'macro avg_recall': 0.4403225806451613, 'macro avg_f1-score': 0.3802228412256267, 'macro avg_support': 620.0, 'weighted avg_precision': 0.33455882352941174, 'weighted avg_recall': 0.4403225806451613, 'weighted avg_f1-score': 0.3802228412256267, 'weighted avg_support': 620.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 3}, {'micro_f1': 0.950688210652304, 'precision': 0.950688210652304, 'Name_Calling-Labeling_precision': 0.38235294117647056, 'Name_Calling-Labeling_recall': 0.4450784593437946, 'Name_Calling-Labeling_f1-score': 0.4113381674357284, 'Name_Calling-Labeling_support': 701.0, 'micro avg_precision': 0.38235294117647056, 'micro avg_recall': 0.4450784593437946, 'micro avg_f1-score': 0.4113381674357284, 'micro avg_support': 701.0, 'macro avg_precision': 0.38235294117647056, 'macro avg_recall': 0.4450784593437946, 'macro avg_f1-score': 0.4113381674357284, 'macro avg_support': 701.0, 'weighted avg_precision': 0.38235294117647056, 'weighted avg_recall': 0.4450784593437946, 'weighted avg_f1-score': 0.4113381674357284, 'weighted avg_support': 701.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 4}, {'micro_f1': 0.9478156792339916, 'precision': 0.9478156792339916, 'Name_Calling-Labeling_precision': 0.35294117647058826, 'Name_Calling-Labeling_recall': 0.4458204334365325, 'Name_Calling-Labeling_f1-score': 0.39398084815321477, 'Name_Calling-Labeling_support': 646.0, 'micro avg_precision': 0.35294117647058826, 'micro avg_recall': 0.4458204334365325, 'micro avg_f1-score': 0.39398084815321477, 'micro avg_support': 646.0, 'macro avg_precision': 0.35294117647058826, 'macro avg_recall': 0.4458204334365325, 'macro avg_f1-score': 0.39398084815321477, 'macro avg_support': 646.0, 'weighted avg_precision': 0.35294117647058826, 'weighted avg_recall': 0.4458204334365325, 'weighted avg_f1-score': 0.39398084815321477, 'weighted avg_support': 646.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 5}, {'micro_f1': 0.9491621783363255, 'precision': 0.9491621783363255, 'Name_Calling-Labeling_precision': 0.3799019607843137, 'Name_Calling-Labeling_recall': 0.4599406528189911, 'Name_Calling-Labeling_f1-score': 0.4161073825503356, 'Name_Calling-Labeling_support': 674.0, 'micro avg_precision': 0.3799019607843137, 'micro avg_recall': 0.4599406528189911, 'micro avg_f1-score': 0.4161073825503356, 'micro avg_support': 674.0, 'macro avg_precision': 0.3799019607843137, 'macro avg_recall': 0.4599406528189911, 'macro avg_f1-score': 0.4161073825503356, 'macro avg_support': 674.0, 'weighted avg_precision': 0.37990196078431376, 'weighted avg_recall': 0.4599406528189911, 'weighted avg_f1-score': 0.4161073825503356, 'weighted avg_support': 674.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 6}, {'micro_f1': 0.9532315978456014, 'precision': 0.9532315978456014, 'Name_Calling-Labeling_precision': 0.4375, 'Name_Calling-Labeling_recall': 0.4870395634379263, 'Name_Calling-Labeling_f1-score': 0.46094254357650094, 'Name_Calling-Labeling_support': 733.0, 'micro avg_precision': 0.4375, 'micro avg_recall': 0.4870395634379263, 'micro avg_f1-score': 0.46094254357650094, 'micro avg_support': 733.0, 'macro avg_precision': 0.4375, 'macro avg_recall': 0.4870395634379263, 'macro avg_f1-score': 0.46094254357650094, 'macro avg_support': 733.0, 'weighted avg_precision': 0.4375, 'weighted avg_recall': 0.4870395634379263, 'weighted avg_f1-score': 0.46094254357650094, 'weighted avg_support': 733.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 7}]}
Best model updated: current epoch macro f1 = 0.46094254357650094
{'micro_f1': 0.9489527229204069, 'precision': 0.9489527229204069, 'Name_Calling-Labeling_precision': 0.4497549019607843, 'Name_Calling-Labeling_recall': 0.45533498759305213, 'Name_Calling-Labeling_f1-score': 0.4525277435265105, 'Name_Calling-Labeling_support': 806.0, 'micro avg_precision': 0.4497549019607843, 'micro avg_recall': 0.45533498759305213, 'micro avg_f1-score': 0.4525277435265105, 'micro avg_support': 806.0, 'macro avg_precision': 0.4497549019607843, 'macro avg_recall': 0.45533498759305213, 'macro avg_f1-score': 0.4525277435265105, 'macro avg_support': 806.0, 'weighted avg_precision': 0.4497549019607843, 'weighted avg_recall': 0.45533498759305213, 'weighted avg_f1-score': 0.4525277435265105, 'weighted avg_support': 806.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 8}
{'results': [{'micro_f1': 0.9359066427289049, 'precision': 0.9359066427289049, 'Name_Calling-Labeling_precision': 0.10049019607843138, 'Name_Calling-Labeling_recall': 0.16565656565656567, 'Name_Calling-Labeling_f1-score': 0.12509534706331044, 'Name_Calling-Labeling_support': 495.0, 'micro avg_precision': 0.10049019607843138, 'micro avg_recall': 0.16565656565656567, 'micro avg_f1-score': 0.12509534706331044, 'micro avg_support': 495.0, 'macro avg_precision': 0.10049019607843138, 'macro avg_recall': 0.16565656565656567, 'macro avg_f1-score': 0.12509534706331044, 'macro avg_support': 495.0, 'weighted avg_precision': 0.10049019607843138, 'weighted avg_recall': 0.16565656565656567, 'weighted avg_f1-score': 0.12509534706331044, 'weighted avg_support': 495.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 0}, {'micro_f1': 0.944524236983842, 'precision': 0.944524236983842, 'Name_Calling-Labeling_precision': 0.24509803921568626, 'Name_Calling-Labeling_recall': 0.32102728731942215, 'Name_Calling-Labeling_f1-score': 0.27797081306462823, 'Name_Calling-Labeling_support': 623.0, 'micro avg_precision': 0.24509803921568626, 'micro avg_recall': 0.32102728731942215, 'micro avg_f1-score': 0.27797081306462823, 'micro avg_support': 623.0, 'macro avg_precision': 0.24509803921568626, 'macro avg_recall': 0.32102728731942215, 'macro avg_f1-score': 0.27797081306462823, 'macro avg_support': 623.0, 'weighted avg_precision': 0.24509803921568626, 'weighted avg_recall': 0.32102728731942215, 'weighted avg_f1-score': 0.27797081306462823, 'weighted avg_support': 623.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 1}, {'micro_f1': 0.9496110113704369, 'precision': 0.9496110113704369, 'Name_Calling-Labeling_precision': 0.3492647058823529, 'Name_Calling-Labeling_recall': 0.41424418604651164, 'Name_Calling-Labeling_f1-score': 0.3789893617021276, 'Name_Calling-Labeling_support': 688.0, 'micro avg_precision': 0.3492647058823529, 'micro avg_recall': 0.41424418604651164, 'micro avg_f1-score': 0.3789893617021276, 'micro avg_support': 688.0, 'macro avg_precision': 0.3492647058823529, 'macro avg_recall': 0.41424418604651164, 'macro avg_f1-score': 0.3789893617021276, 'macro avg_support': 688.0, 'weighted avg_precision': 0.3492647058823529, 'weighted avg_recall': 0.41424418604651164, 'weighted avg_f1-score': 0.3789893617021276, 'weighted avg_support': 688.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 2}, {'micro_f1': 0.9460203470975463, 'precision': 0.9460203470975463, 'Name_Calling-Labeling_precision': 0.33455882352941174, 'Name_Calling-Labeling_recall': 0.4403225806451613, 'Name_Calling-Labeling_f1-score': 0.3802228412256267, 'Name_Calling-Labeling_support': 620.0, 'micro avg_precision': 0.33455882352941174, 'micro avg_recall': 0.4403225806451613, 'micro avg_f1-score': 0.3802228412256267, 'micro avg_support': 620.0, 'macro avg_precision': 0.33455882352941174, 'macro avg_recall': 0.4403225806451613, 'macro avg_f1-score': 0.3802228412256267, 'macro avg_support': 620.0, 'weighted avg_precision': 0.33455882352941174, 'weighted avg_recall': 0.4403225806451613, 'weighted avg_f1-score': 0.3802228412256267, 'weighted avg_support': 620.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 3}, {'micro_f1': 0.950688210652304, 'precision': 0.950688210652304, 'Name_Calling-Labeling_precision': 0.38235294117647056, 'Name_Calling-Labeling_recall': 0.4450784593437946, 'Name_Calling-Labeling_f1-score': 0.4113381674357284, 'Name_Calling-Labeling_support': 701.0, 'micro avg_precision': 0.38235294117647056, 'micro avg_recall': 0.4450784593437946, 'micro avg_f1-score': 0.4113381674357284, 'micro avg_support': 701.0, 'macro avg_precision': 0.38235294117647056, 'macro avg_recall': 0.4450784593437946, 'macro avg_f1-score': 0.4113381674357284, 'macro avg_support': 701.0, 'weighted avg_precision': 0.38235294117647056, 'weighted avg_recall': 0.4450784593437946, 'weighted avg_f1-score': 0.4113381674357284, 'weighted avg_support': 701.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 4}, {'micro_f1': 0.9478156792339916, 'precision': 0.9478156792339916, 'Name_Calling-Labeling_precision': 0.35294117647058826, 'Name_Calling-Labeling_recall': 0.4458204334365325, 'Name_Calling-Labeling_f1-score': 0.39398084815321477, 'Name_Calling-Labeling_support': 646.0, 'micro avg_precision': 0.35294117647058826, 'micro avg_recall': 0.4458204334365325, 'micro avg_f1-score': 0.39398084815321477, 'micro avg_support': 646.0, 'macro avg_precision': 0.35294117647058826, 'macro avg_recall': 0.4458204334365325, 'macro avg_f1-score': 0.39398084815321477, 'macro avg_support': 646.0, 'weighted avg_precision': 0.35294117647058826, 'weighted avg_recall': 0.4458204334365325, 'weighted avg_f1-score': 0.39398084815321477, 'weighted avg_support': 646.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 5}, {'micro_f1': 0.9491621783363255, 'precision': 0.9491621783363255, 'Name_Calling-Labeling_precision': 0.3799019607843137, 'Name_Calling-Labeling_recall': 0.4599406528189911, 'Name_Calling-Labeling_f1-score': 0.4161073825503356, 'Name_Calling-Labeling_support': 674.0, 'micro avg_precision': 0.3799019607843137, 'micro avg_recall': 0.4599406528189911, 'micro avg_f1-score': 0.4161073825503356, 'micro avg_support': 674.0, 'macro avg_precision': 0.3799019607843137, 'macro avg_recall': 0.4599406528189911, 'macro avg_f1-score': 0.4161073825503356, 'macro avg_support': 674.0, 'weighted avg_precision': 0.37990196078431376, 'weighted avg_recall': 0.4599406528189911, 'weighted avg_f1-score': 0.4161073825503356, 'weighted avg_support': 674.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 6}, {'micro_f1': 0.9532315978456014, 'precision': 0.9532315978456014, 'Name_Calling-Labeling_precision': 0.4375, 'Name_Calling-Labeling_recall': 0.4870395634379263, 'Name_Calling-Labeling_f1-score': 0.46094254357650094, 'Name_Calling-Labeling_support': 733.0, 'micro avg_precision': 0.4375, 'micro avg_recall': 0.4870395634379263, 'micro avg_f1-score': 0.46094254357650094, 'micro avg_support': 733.0, 'macro avg_precision': 0.4375, 'macro avg_recall': 0.4870395634379263, 'macro avg_f1-score': 0.46094254357650094, 'macro avg_support': 733.0, 'weighted avg_precision': 0.4375, 'weighted avg_recall': 0.4870395634379263, 'weighted avg_f1-score': 0.46094254357650094, 'weighted avg_support': 733.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 7}, {'micro_f1': 0.9489527229204069, 'precision': 0.9489527229204069, 'Name_Calling-Labeling_precision': 0.4497549019607843, 'Name_Calling-Labeling_recall': 0.45533498759305213, 'Name_Calling-Labeling_f1-score': 0.4525277435265105, 'Name_Calling-Labeling_support': 806.0, 'micro avg_precision': 0.4497549019607843, 'micro avg_recall': 0.45533498759305213, 'micro avg_f1-score': 0.4525277435265105, 'micro avg_support': 806.0, 'macro avg_precision': 0.4497549019607843, 'macro avg_recall': 0.45533498759305213, 'macro avg_f1-score': 0.4525277435265105, 'macro avg_support': 806.0, 'weighted avg_precision': 0.4497549019607843, 'weighted avg_recall': 0.45533498759305213, 'weighted avg_f1-score': 0.4525277435265105, 'weighted avg_support': 806.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 8}]}
{'micro_f1': 0.9501496110113705, 'precision': 0.9501496110113704, 'Name_Calling-Labeling_precision': 0.39705882352941174, 'Name_Calling-Labeling_recall': 0.5046728971962616, 'Name_Calling-Labeling_f1-score': 0.4444444444444444, 'Name_Calling-Labeling_support': 642.0, 'micro avg_precision': 0.39705882352941174, 'micro avg_recall': 0.5046728971962616, 'micro avg_f1-score': 0.4444444444444444, 'micro avg_support': 642.0, 'macro avg_precision': 0.39705882352941174, 'macro avg_recall': 0.5046728971962616, 'macro avg_f1-score': 0.4444444444444444, 'macro avg_support': 642.0, 'weighted avg_precision': 0.39705882352941174, 'weighted avg_recall': 0.5046728971962616, 'weighted avg_f1-score': 0.4444444444444444, 'weighted avg_support': 642.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 9}
{'results': [{'micro_f1': 0.9359066427289049, 'precision': 0.9359066427289049, 'Name_Calling-Labeling_precision': 0.10049019607843138, 'Name_Calling-Labeling_recall': 0.16565656565656567, 'Name_Calling-Labeling_f1-score': 0.12509534706331044, 'Name_Calling-Labeling_support': 495.0, 'micro avg_precision': 0.10049019607843138, 'micro avg_recall': 0.16565656565656567, 'micro avg_f1-score': 0.12509534706331044, 'micro avg_support': 495.0, 'macro avg_precision': 0.10049019607843138, 'macro avg_recall': 0.16565656565656567, 'macro avg_f1-score': 0.12509534706331044, 'macro avg_support': 495.0, 'weighted avg_precision': 0.10049019607843138, 'weighted avg_recall': 0.16565656565656567, 'weighted avg_f1-score': 0.12509534706331044, 'weighted avg_support': 495.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 0}, {'micro_f1': 0.944524236983842, 'precision': 0.944524236983842, 'Name_Calling-Labeling_precision': 0.24509803921568626, 'Name_Calling-Labeling_recall': 0.32102728731942215, 'Name_Calling-Labeling_f1-score': 0.27797081306462823, 'Name_Calling-Labeling_support': 623.0, 'micro avg_precision': 0.24509803921568626, 'micro avg_recall': 0.32102728731942215, 'micro avg_f1-score': 0.27797081306462823, 'micro avg_support': 623.0, 'macro avg_precision': 0.24509803921568626, 'macro avg_recall': 0.32102728731942215, 'macro avg_f1-score': 0.27797081306462823, 'macro avg_support': 623.0, 'weighted avg_precision': 0.24509803921568626, 'weighted avg_recall': 0.32102728731942215, 'weighted avg_f1-score': 0.27797081306462823, 'weighted avg_support': 623.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 1}, {'micro_f1': 0.9496110113704369, 'precision': 0.9496110113704369, 'Name_Calling-Labeling_precision': 0.3492647058823529, 'Name_Calling-Labeling_recall': 0.41424418604651164, 'Name_Calling-Labeling_f1-score': 0.3789893617021276, 'Name_Calling-Labeling_support': 688.0, 'micro avg_precision': 0.3492647058823529, 'micro avg_recall': 0.41424418604651164, 'micro avg_f1-score': 0.3789893617021276, 'micro avg_support': 688.0, 'macro avg_precision': 0.3492647058823529, 'macro avg_recall': 0.41424418604651164, 'macro avg_f1-score': 0.3789893617021276, 'macro avg_support': 688.0, 'weighted avg_precision': 0.3492647058823529, 'weighted avg_recall': 0.41424418604651164, 'weighted avg_f1-score': 0.3789893617021276, 'weighted avg_support': 688.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 2}, {'micro_f1': 0.9460203470975463, 'precision': 0.9460203470975463, 'Name_Calling-Labeling_precision': 0.33455882352941174, 'Name_Calling-Labeling_recall': 0.4403225806451613, 'Name_Calling-Labeling_f1-score': 0.3802228412256267, 'Name_Calling-Labeling_support': 620.0, 'micro avg_precision': 0.33455882352941174, 'micro avg_recall': 0.4403225806451613, 'micro avg_f1-score': 0.3802228412256267, 'micro avg_support': 620.0, 'macro avg_precision': 0.33455882352941174, 'macro avg_recall': 0.4403225806451613, 'macro avg_f1-score': 0.3802228412256267, 'macro avg_support': 620.0, 'weighted avg_precision': 0.33455882352941174, 'weighted avg_recall': 0.4403225806451613, 'weighted avg_f1-score': 0.3802228412256267, 'weighted avg_support': 620.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 3}, {'micro_f1': 0.950688210652304, 'precision': 0.950688210652304, 'Name_Calling-Labeling_precision': 0.38235294117647056, 'Name_Calling-Labeling_recall': 0.4450784593437946, 'Name_Calling-Labeling_f1-score': 0.4113381674357284, 'Name_Calling-Labeling_support': 701.0, 'micro avg_precision': 0.38235294117647056, 'micro avg_recall': 0.4450784593437946, 'micro avg_f1-score': 0.4113381674357284, 'micro avg_support': 701.0, 'macro avg_precision': 0.38235294117647056, 'macro avg_recall': 0.4450784593437946, 'macro avg_f1-score': 0.4113381674357284, 'macro avg_support': 701.0, 'weighted avg_precision': 0.38235294117647056, 'weighted avg_recall': 0.4450784593437946, 'weighted avg_f1-score': 0.4113381674357284, 'weighted avg_support': 701.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 4}, {'micro_f1': 0.9478156792339916, 'precision': 0.9478156792339916, 'Name_Calling-Labeling_precision': 0.35294117647058826, 'Name_Calling-Labeling_recall': 0.4458204334365325, 'Name_Calling-Labeling_f1-score': 0.39398084815321477, 'Name_Calling-Labeling_support': 646.0, 'micro avg_precision': 0.35294117647058826, 'micro avg_recall': 0.4458204334365325, 'micro avg_f1-score': 0.39398084815321477, 'micro avg_support': 646.0, 'macro avg_precision': 0.35294117647058826, 'macro avg_recall': 0.4458204334365325, 'macro avg_f1-score': 0.39398084815321477, 'macro avg_support': 646.0, 'weighted avg_precision': 0.35294117647058826, 'weighted avg_recall': 0.4458204334365325, 'weighted avg_f1-score': 0.39398084815321477, 'weighted avg_support': 646.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 5}, {'micro_f1': 0.9491621783363255, 'precision': 0.9491621783363255, 'Name_Calling-Labeling_precision': 0.3799019607843137, 'Name_Calling-Labeling_recall': 0.4599406528189911, 'Name_Calling-Labeling_f1-score': 0.4161073825503356, 'Name_Calling-Labeling_support': 674.0, 'micro avg_precision': 0.3799019607843137, 'micro avg_recall': 0.4599406528189911, 'micro avg_f1-score': 0.4161073825503356, 'micro avg_support': 674.0, 'macro avg_precision': 0.3799019607843137, 'macro avg_recall': 0.4599406528189911, 'macro avg_f1-score': 0.4161073825503356, 'macro avg_support': 674.0, 'weighted avg_precision': 0.37990196078431376, 'weighted avg_recall': 0.4599406528189911, 'weighted avg_f1-score': 0.4161073825503356, 'weighted avg_support': 674.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 6}, {'micro_f1': 0.9532315978456014, 'precision': 0.9532315978456014, 'Name_Calling-Labeling_precision': 0.4375, 'Name_Calling-Labeling_recall': 0.4870395634379263, 'Name_Calling-Labeling_f1-score': 0.46094254357650094, 'Name_Calling-Labeling_support': 733.0, 'micro avg_precision': 0.4375, 'micro avg_recall': 0.4870395634379263, 'micro avg_f1-score': 0.46094254357650094, 'micro avg_support': 733.0, 'macro avg_precision': 0.4375, 'macro avg_recall': 0.4870395634379263, 'macro avg_f1-score': 0.46094254357650094, 'macro avg_support': 733.0, 'weighted avg_precision': 0.4375, 'weighted avg_recall': 0.4870395634379263, 'weighted avg_f1-score': 0.46094254357650094, 'weighted avg_support': 733.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 7}, {'micro_f1': 0.9489527229204069, 'precision': 0.9489527229204069, 'Name_Calling-Labeling_precision': 0.4497549019607843, 'Name_Calling-Labeling_recall': 0.45533498759305213, 'Name_Calling-Labeling_f1-score': 0.4525277435265105, 'Name_Calling-Labeling_support': 806.0, 'micro avg_precision': 0.4497549019607843, 'micro avg_recall': 0.45533498759305213, 'micro avg_f1-score': 0.4525277435265105, 'micro avg_support': 806.0, 'macro avg_precision': 0.4497549019607843, 'macro avg_recall': 0.45533498759305213, 'macro avg_f1-score': 0.4525277435265105, 'macro avg_support': 806.0, 'weighted avg_precision': 0.4497549019607843, 'weighted avg_recall': 0.45533498759305213, 'weighted avg_f1-score': 0.4525277435265105, 'weighted avg_support': 806.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 8}, {'micro_f1': 0.9501496110113705, 'precision': 0.9501496110113704, 'Name_Calling-Labeling_precision': 0.39705882352941174, 'Name_Calling-Labeling_recall': 0.5046728971962616, 'Name_Calling-Labeling_f1-score': 0.4444444444444444, 'Name_Calling-Labeling_support': 642.0, 'micro avg_precision': 0.39705882352941174, 'micro avg_recall': 0.5046728971962616, 'micro avg_f1-score': 0.4444444444444444, 'micro avg_support': 642.0, 'macro avg_precision': 0.39705882352941174, 'macro avg_recall': 0.5046728971962616, 'macro avg_f1-score': 0.4444444444444444, 'macro avg_support': 642.0, 'weighted avg_precision': 0.39705882352941174, 'weighted avg_recall': 0.5046728971962616, 'weighted avg_f1-score': 0.4444444444444444, 'weighted avg_support': 642.0, 'O_support': 30387, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 9}]}
Early stopping triggered.
Saving model to directory: ./models/M2/2024-05-13-23-08-48_aug/mdeberta-v3-base_18_ME10_target=Name_Calling-Labeling_SUBSAMPLED_2024-05-13-23-08-48
Training model no. 19 of 23 for (19, 'Doubt') persuasion technique...
{'micro_f1': 0.7139537303596822, 'precision': 0.7139537303596822, 'Doubt_precision': 0.10724233983286909, 'Doubt_recall': 0.08740068104426787, 'Doubt_f1-score': 0.09631019387116947, 'Doubt_support': 881.0, 'micro avg_precision': 0.10724233983286909, 'micro avg_recall': 0.08740068104426787, 'micro avg_f1-score': 0.09631019387116947, 'micro avg_support': 881.0, 'macro avg_precision': 0.10724233983286909, 'macro avg_recall': 0.08740068104426787, 'macro avg_f1-score': 0.09631019387116947, 'macro avg_support': 881.0, 'weighted avg_precision': 0.10724233983286909, 'weighted avg_recall': 0.08740068104426787, 'weighted avg_f1-score': 0.09631019387116947, 'weighted avg_support': 881.0, 'O_support': 16404, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'epoch': 0}
{'results': [{'micro_f1': 0.7139537303596822, 'precision': 0.7139537303596822, 'Doubt_precision': 0.10724233983286909, 'Doubt_recall': 0.08740068104426787, 'Doubt_f1-score': 0.09631019387116947, 'Doubt_support': 881.0, 'micro avg_precision': 0.10724233983286909, 'micro avg_recall': 0.08740068104426787, 'micro avg_f1-score': 0.09631019387116947, 'micro avg_support': 881.0, 'macro avg_precision': 0.10724233983286909, 'macro avg_recall': 0.08740068104426787, 'macro avg_f1-score': 0.09631019387116947, 'macro avg_support': 881.0, 'weighted avg_precision': 0.10724233983286909, 'weighted avg_recall': 0.08740068104426787, 'weighted avg_f1-score': 0.09631019387116947, 'weighted avg_support': 881.0, 'O_support': 16404, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'epoch': 0}]}
Best model updated: current epoch macro f1 = 0.09631019387116947
{'micro_f1': 0.7360480038847075, 'precision': 0.7360480038847075, 'Doubt_precision': 0.1671309192200557, 'Doubt_recall': 0.1377726750861079, 'Doubt_f1-score': 0.15103838892385146, 'Doubt_support': 871.0, 'micro avg_precision': 0.1671309192200557, 'micro avg_recall': 0.1377726750861079, 'micro avg_f1-score': 0.15103838892385146, 'micro avg_support': 871.0, 'macro avg_precision': 0.1671309192200557, 'macro avg_recall': 0.1377726750861079, 'macro avg_f1-score': 0.15103838892385146, 'macro avg_support': 871.0, 'weighted avg_precision': 0.16713091922005574, 'weighted avg_recall': 0.1377726750861079, 'weighted avg_f1-score': 0.15103838892385146, 'weighted avg_support': 871.0, 'O_support': 16404, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'epoch': 1}
{'results': [{'micro_f1': 0.7139537303596822, 'precision': 0.7139537303596822, 'Doubt_precision': 0.10724233983286909, 'Doubt_recall': 0.08740068104426787, 'Doubt_f1-score': 0.09631019387116947, 'Doubt_support': 881.0, 'micro avg_precision': 0.10724233983286909, 'micro avg_recall': 0.08740068104426787, 'micro avg_f1-score': 0.09631019387116947, 'micro avg_support': 881.0, 'macro avg_precision': 0.10724233983286909, 'macro avg_recall': 0.08740068104426787, 'macro avg_f1-score': 0.09631019387116947, 'macro avg_support': 881.0, 'weighted avg_precision': 0.10724233983286909, 'weighted avg_recall': 0.08740068104426787, 'weighted avg_f1-score': 0.09631019387116947, 'weighted avg_support': 881.0, 'O_support': 16404, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'epoch': 0}, {'micro_f1': 0.7360480038847075, 'precision': 0.7360480038847075, 'Doubt_precision': 0.1671309192200557, 'Doubt_recall': 0.1377726750861079, 'Doubt_f1-score': 0.15103838892385146, 'Doubt_support': 871.0, 'micro avg_precision': 0.1671309192200557, 'micro avg_recall': 0.1377726750861079, 'micro avg_f1-score': 0.15103838892385146, 'micro avg_support': 871.0, 'macro avg_precision': 0.1671309192200557, 'macro avg_recall': 0.1377726750861079, 'macro avg_f1-score': 0.15103838892385146, 'macro avg_support': 871.0, 'weighted avg_precision': 0.16713091922005574, 'weighted avg_recall': 0.1377726750861079, 'weighted avg_f1-score': 0.15103838892385146, 'weighted avg_support': 871.0, 'O_support': 16404, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'epoch': 1}]}
Best model updated: current epoch macro f1 = 0.15103838892385146
{'micro_f1': 0.7653914189587596, 'precision': 0.7653914189587596, 'Doubt_precision': 0.2562674094707521, 'Doubt_recall': 0.20512820512820512, 'Doubt_f1-score': 0.22786377708978328, 'Doubt_support': 897.0, 'micro avg_precision': 0.2562674094707521, 'micro avg_recall': 0.20512820512820512, 'micro avg_f1-score': 0.22786377708978328, 'micro avg_support': 897.0, 'macro avg_precision': 0.2562674094707521, 'macro avg_recall': 0.20512820512820512, 'macro avg_f1-score': 0.22786377708978328, 'macro avg_support': 897.0, 'weighted avg_precision': 0.2562674094707521, 'weighted avg_recall': 0.20512820512820512, 'weighted avg_f1-score': 0.22786377708978328, 'weighted avg_support': 897.0, 'O_support': 16404, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'epoch': 2}
{'results': [{'micro_f1': 0.7139537303596822, 'precision': 0.7139537303596822, 'Doubt_precision': 0.10724233983286909, 'Doubt_recall': 0.08740068104426787, 'Doubt_f1-score': 0.09631019387116947, 'Doubt_support': 881.0, 'micro avg_precision': 0.10724233983286909, 'micro avg_recall': 0.08740068104426787, 'micro avg_f1-score': 0.09631019387116947, 'micro avg_support': 881.0, 'macro avg_precision': 0.10724233983286909, 'macro avg_recall': 0.08740068104426787, 'macro avg_f1-score': 0.09631019387116947, 'macro avg_support': 881.0, 'weighted avg_precision': 0.10724233983286909, 'weighted avg_recall': 0.08740068104426787, 'weighted avg_f1-score': 0.09631019387116947, 'weighted avg_support': 881.0, 'O_support': 16404, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'epoch': 0}, {'micro_f1': 0.7360480038847075, 'precision': 0.7360480038847075, 'Doubt_precision': 0.1671309192200557, 'Doubt_recall': 0.1377726750861079, 'Doubt_f1-score': 0.15103838892385146, 'Doubt_support': 871.0, 'micro avg_precision': 0.1671309192200557, 'micro avg_recall': 0.1377726750861079, 'micro avg_f1-score': 0.15103838892385146, 'micro avg_support': 871.0, 'macro avg_precision': 0.1671309192200557, 'macro avg_recall': 0.1377726750861079, 'macro avg_f1-score': 0.15103838892385146, 'macro avg_support': 871.0, 'weighted avg_precision': 0.16713091922005574, 'weighted avg_recall': 0.1377726750861079, 'weighted avg_f1-score': 0.15103838892385146, 'weighted avg_support': 871.0, 'O_support': 16404, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'epoch': 1}, {'micro_f1': 0.7653914189587596, 'precision': 0.7653914189587596, 'Doubt_precision': 0.2562674094707521, 'Doubt_recall': 0.20512820512820512, 'Doubt_f1-score': 0.22786377708978328, 'Doubt_support': 897.0, 'micro avg_precision': 0.2562674094707521, 'micro avg_recall': 0.20512820512820512, 'micro avg_f1-score': 0.22786377708978328, 'micro avg_support': 897.0, 'macro avg_precision': 0.2562674094707521, 'macro avg_recall': 0.20512820512820512, 'macro avg_f1-score': 0.22786377708978328, 'macro avg_support': 897.0, 'weighted avg_precision': 0.2562674094707521, 'weighted avg_recall': 0.20512820512820512, 'weighted avg_f1-score': 0.22786377708978328, 'weighted avg_support': 897.0, 'O_support': 16404, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'epoch': 2}]}
Best model updated: current epoch macro f1 = 0.22786377708978328
{'micro_f1': 0.750407547431584, 'precision': 0.7504075474315841, 'Doubt_precision': 0.2883008356545961, 'Doubt_recall': 0.24210526315789474, 'Doubt_f1-score': 0.26319135410044503, 'Doubt_support': 855.0, 'micro avg_precision': 0.2883008356545961, 'micro avg_recall': 0.24210526315789474, 'micro avg_f1-score': 0.26319135410044503, 'micro avg_support': 855.0, 'macro avg_precision': 0.2883008356545961, 'macro avg_recall': 0.24210526315789474, 'macro avg_f1-score': 0.26319135410044503, 'macro avg_support': 855.0, 'weighted avg_precision': 0.2883008356545961, 'weighted avg_recall': 0.24210526315789474, 'weighted avg_f1-score': 0.26319135410044503, 'weighted avg_support': 855.0, 'O_support': 16404, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'epoch': 3}
{'results': [{'micro_f1': 0.7139537303596822, 'precision': 0.7139537303596822, 'Doubt_precision': 0.10724233983286909, 'Doubt_recall': 0.08740068104426787, 'Doubt_f1-score': 0.09631019387116947, 'Doubt_support': 881.0, 'micro avg_precision': 0.10724233983286909, 'micro avg_recall': 0.08740068104426787, 'micro avg_f1-score': 0.09631019387116947, 'micro avg_support': 881.0, 'macro avg_precision': 0.10724233983286909, 'macro avg_recall': 0.08740068104426787, 'macro avg_f1-score': 0.09631019387116947, 'macro avg_support': 881.0, 'weighted avg_precision': 0.10724233983286909, 'weighted avg_recall': 0.08740068104426787, 'weighted avg_f1-score': 0.09631019387116947, 'weighted avg_support': 881.0, 'O_support': 16404, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'epoch': 0}, {'micro_f1': 0.7360480038847075, 'precision': 0.7360480038847075, 'Doubt_precision': 0.1671309192200557, 'Doubt_recall': 0.1377726750861079, 'Doubt_f1-score': 0.15103838892385146, 'Doubt_support': 871.0, 'micro avg_precision': 0.1671309192200557, 'micro avg_recall': 0.1377726750861079, 'micro avg_f1-score': 0.15103838892385146, 'micro avg_support': 871.0, 'macro avg_precision': 0.1671309192200557, 'macro avg_recall': 0.1377726750861079, 'macro avg_f1-score': 0.15103838892385146, 'macro avg_support': 871.0, 'weighted avg_precision': 0.16713091922005574, 'weighted avg_recall': 0.1377726750861079, 'weighted avg_f1-score': 0.15103838892385146, 'weighted avg_support': 871.0, 'O_support': 16404, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'epoch': 1}, {'micro_f1': 0.7653914189587596, 'precision': 0.7653914189587596, 'Doubt_precision': 0.2562674094707521, 'Doubt_recall': 0.20512820512820512, 'Doubt_f1-score': 0.22786377708978328, 'Doubt_support': 897.0, 'micro avg_precision': 0.2562674094707521, 'micro avg_recall': 0.20512820512820512, 'micro avg_f1-score': 0.22786377708978328, 'micro avg_support': 897.0, 'macro avg_precision': 0.2562674094707521, 'macro avg_recall': 0.20512820512820512, 'macro avg_f1-score': 0.22786377708978328, 'macro avg_support': 897.0, 'weighted avg_precision': 0.2562674094707521, 'weighted avg_recall': 0.20512820512820512, 'weighted avg_f1-score': 0.22786377708978328, 'weighted avg_support': 897.0, 'O_support': 16404, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'epoch': 2}, {'micro_f1': 0.750407547431584, 'precision': 0.7504075474315841, 'Doubt_precision': 0.2883008356545961, 'Doubt_recall': 0.24210526315789474, 'Doubt_f1-score': 0.26319135410044503, 'Doubt_support': 855.0, 'micro avg_precision': 0.2883008356545961, 'micro avg_recall': 0.24210526315789474, 'micro avg_f1-score': 0.26319135410044503, 'micro avg_support': 855.0, 'macro avg_precision': 0.2883008356545961, 'macro avg_recall': 0.24210526315789474, 'macro avg_f1-score': 0.26319135410044503, 'macro avg_support': 855.0, 'weighted avg_precision': 0.2883008356545961, 'weighted avg_recall': 0.24210526315789474, 'weighted avg_f1-score': 0.26319135410044503, 'weighted avg_support': 855.0, 'O_support': 16404, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'epoch': 3}]}
Best model updated: current epoch macro f1 = 0.26319135410044503
{'micro_f1': 0.7469737435399397, 'precision': 0.7469737435399396, 'Doubt_precision': 0.23259052924791088, 'Doubt_recall': 0.2303448275862069, 'Doubt_f1-score': 0.23146223146223144, 'Doubt_support': 725.0, 'micro avg_precision': 0.23259052924791088, 'micro avg_recall': 0.2303448275862069, 'micro avg_f1-score': 0.23146223146223144, 'micro avg_support': 725.0, 'macro avg_precision': 0.23259052924791088, 'macro avg_recall': 0.2303448275862069, 'macro avg_f1-score': 0.23146223146223144, 'macro avg_support': 725.0, 'weighted avg_precision': 0.23259052924791088, 'weighted avg_recall': 0.2303448275862069, 'weighted avg_f1-score': 0.23146223146223144, 'weighted avg_support': 725.0, 'O_support': 16404, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'epoch': 4}
{'results': [{'micro_f1': 0.7139537303596822, 'precision': 0.7139537303596822, 'Doubt_precision': 0.10724233983286909, 'Doubt_recall': 0.08740068104426787, 'Doubt_f1-score': 0.09631019387116947, 'Doubt_support': 881.0, 'micro avg_precision': 0.10724233983286909, 'micro avg_recall': 0.08740068104426787, 'micro avg_f1-score': 0.09631019387116947, 'micro avg_support': 881.0, 'macro avg_precision': 0.10724233983286909, 'macro avg_recall': 0.08740068104426787, 'macro avg_f1-score': 0.09631019387116947, 'macro avg_support': 881.0, 'weighted avg_precision': 0.10724233983286909, 'weighted avg_recall': 0.08740068104426787, 'weighted avg_f1-score': 0.09631019387116947, 'weighted avg_support': 881.0, 'O_support': 16404, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'epoch': 0}, {'micro_f1': 0.7360480038847075, 'precision': 0.7360480038847075, 'Doubt_precision': 0.1671309192200557, 'Doubt_recall': 0.1377726750861079, 'Doubt_f1-score': 0.15103838892385146, 'Doubt_support': 871.0, 'micro avg_precision': 0.1671309192200557, 'micro avg_recall': 0.1377726750861079, 'micro avg_f1-score': 0.15103838892385146, 'micro avg_support': 871.0, 'macro avg_precision': 0.1671309192200557, 'macro avg_recall': 0.1377726750861079, 'macro avg_f1-score': 0.15103838892385146, 'macro avg_support': 871.0, 'weighted avg_precision': 0.16713091922005574, 'weighted avg_recall': 0.1377726750861079, 'weighted avg_f1-score': 0.15103838892385146, 'weighted avg_support': 871.0, 'O_support': 16404, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'epoch': 1}, {'micro_f1': 0.7653914189587596, 'precision': 0.7653914189587596, 'Doubt_precision': 0.2562674094707521, 'Doubt_recall': 0.20512820512820512, 'Doubt_f1-score': 0.22786377708978328, 'Doubt_support': 897.0, 'micro avg_precision': 0.2562674094707521, 'micro avg_recall': 0.20512820512820512, 'micro avg_f1-score': 0.22786377708978328, 'micro avg_support': 897.0, 'macro avg_precision': 0.2562674094707521, 'macro avg_recall': 0.20512820512820512, 'macro avg_f1-score': 0.22786377708978328, 'macro avg_support': 897.0, 'weighted avg_precision': 0.2562674094707521, 'weighted avg_recall': 0.20512820512820512, 'weighted avg_f1-score': 0.22786377708978328, 'weighted avg_support': 897.0, 'O_support': 16404, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'epoch': 2}, {'micro_f1': 0.750407547431584, 'precision': 0.7504075474315841, 'Doubt_precision': 0.2883008356545961, 'Doubt_recall': 0.24210526315789474, 'Doubt_f1-score': 0.26319135410044503, 'Doubt_support': 855.0, 'micro avg_precision': 0.2883008356545961, 'micro avg_recall': 0.24210526315789474, 'micro avg_f1-score': 0.26319135410044503, 'micro avg_support': 855.0, 'macro avg_precision': 0.2883008356545961, 'macro avg_recall': 0.24210526315789474, 'macro avg_f1-score': 0.26319135410044503, 'macro avg_support': 855.0, 'weighted avg_precision': 0.2883008356545961, 'weighted avg_recall': 0.24210526315789474, 'weighted avg_f1-score': 0.26319135410044503, 'weighted avg_support': 855.0, 'O_support': 16404, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'epoch': 3}, {'micro_f1': 0.7469737435399397, 'precision': 0.7469737435399396, 'Doubt_precision': 0.23259052924791088, 'Doubt_recall': 0.2303448275862069, 'Doubt_f1-score': 0.23146223146223144, 'Doubt_support': 725.0, 'micro avg_precision': 0.23259052924791088, 'micro avg_recall': 0.2303448275862069, 'micro avg_f1-score': 0.23146223146223144, 'micro avg_support': 725.0, 'macro avg_precision': 0.23259052924791088, 'macro avg_recall': 0.2303448275862069, 'macro avg_f1-score': 0.23146223146223144, 'macro avg_support': 725.0, 'weighted avg_precision': 0.23259052924791088, 'weighted avg_recall': 0.2303448275862069, 'weighted avg_f1-score': 0.23146223146223144, 'weighted avg_support': 725.0, 'O_support': 16404, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'epoch': 4}]}
{'micro_f1': 0.7560611841420694, 'precision': 0.7560611841420694, 'Doubt_precision': 0.3231197771587744, 'Doubt_recall': 0.2543859649122807, 'Doubt_f1-score': 0.2846625766871166, 'Doubt_support': 912.0, 'micro avg_precision': 0.3231197771587744, 'micro avg_recall': 0.2543859649122807, 'micro avg_f1-score': 0.2846625766871166, 'micro avg_support': 912.0, 'macro avg_precision': 0.3231197771587744, 'macro avg_recall': 0.2543859649122807, 'macro avg_f1-score': 0.2846625766871166, 'macro avg_support': 912.0, 'weighted avg_precision': 0.3231197771587744, 'weighted avg_recall': 0.2543859649122807, 'weighted avg_f1-score': 0.2846625766871166, 'weighted avg_support': 912.0, 'O_support': 16404, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'epoch': 5}
{'results': [{'micro_f1': 0.7139537303596822, 'precision': 0.7139537303596822, 'Doubt_precision': 0.10724233983286909, 'Doubt_recall': 0.08740068104426787, 'Doubt_f1-score': 0.09631019387116947, 'Doubt_support': 881.0, 'micro avg_precision': 0.10724233983286909, 'micro avg_recall': 0.08740068104426787, 'micro avg_f1-score': 0.09631019387116947, 'micro avg_support': 881.0, 'macro avg_precision': 0.10724233983286909, 'macro avg_recall': 0.08740068104426787, 'macro avg_f1-score': 0.09631019387116947, 'macro avg_support': 881.0, 'weighted avg_precision': 0.10724233983286909, 'weighted avg_recall': 0.08740068104426787, 'weighted avg_f1-score': 0.09631019387116947, 'weighted avg_support': 881.0, 'O_support': 16404, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'epoch': 0}, {'micro_f1': 0.7360480038847075, 'precision': 0.7360480038847075, 'Doubt_precision': 0.1671309192200557, 'Doubt_recall': 0.1377726750861079, 'Doubt_f1-score': 0.15103838892385146, 'Doubt_support': 871.0, 'micro avg_precision': 0.1671309192200557, 'micro avg_recall': 0.1377726750861079, 'micro avg_f1-score': 0.15103838892385146, 'micro avg_support': 871.0, 'macro avg_precision': 0.1671309192200557, 'macro avg_recall': 0.1377726750861079, 'macro avg_f1-score': 0.15103838892385146, 'macro avg_support': 871.0, 'weighted avg_precision': 0.16713091922005574, 'weighted avg_recall': 0.1377726750861079, 'weighted avg_f1-score': 0.15103838892385146, 'weighted avg_support': 871.0, 'O_support': 16404, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'epoch': 1}, {'micro_f1': 0.7653914189587596, 'precision': 0.7653914189587596, 'Doubt_precision': 0.2562674094707521, 'Doubt_recall': 0.20512820512820512, 'Doubt_f1-score': 0.22786377708978328, 'Doubt_support': 897.0, 'micro avg_precision': 0.2562674094707521, 'micro avg_recall': 0.20512820512820512, 'micro avg_f1-score': 0.22786377708978328, 'micro avg_support': 897.0, 'macro avg_precision': 0.2562674094707521, 'macro avg_recall': 0.20512820512820512, 'macro avg_f1-score': 0.22786377708978328, 'macro avg_support': 897.0, 'weighted avg_precision': 0.2562674094707521, 'weighted avg_recall': 0.20512820512820512, 'weighted avg_f1-score': 0.22786377708978328, 'weighted avg_support': 897.0, 'O_support': 16404, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'epoch': 2}, {'micro_f1': 0.750407547431584, 'precision': 0.7504075474315841, 'Doubt_precision': 0.2883008356545961, 'Doubt_recall': 0.24210526315789474, 'Doubt_f1-score': 0.26319135410044503, 'Doubt_support': 855.0, 'micro avg_precision': 0.2883008356545961, 'micro avg_recall': 0.24210526315789474, 'micro avg_f1-score': 0.26319135410044503, 'micro avg_support': 855.0, 'macro avg_precision': 0.2883008356545961, 'macro avg_recall': 0.24210526315789474, 'macro avg_f1-score': 0.26319135410044503, 'macro avg_support': 855.0, 'weighted avg_precision': 0.2883008356545961, 'weighted avg_recall': 0.24210526315789474, 'weighted avg_f1-score': 0.26319135410044503, 'weighted avg_support': 855.0, 'O_support': 16404, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'epoch': 3}, {'micro_f1': 0.7469737435399397, 'precision': 0.7469737435399396, 'Doubt_precision': 0.23259052924791088, 'Doubt_recall': 0.2303448275862069, 'Doubt_f1-score': 0.23146223146223144, 'Doubt_support': 725.0, 'micro avg_precision': 0.23259052924791088, 'micro avg_recall': 0.2303448275862069, 'micro avg_f1-score': 0.23146223146223144, 'micro avg_support': 725.0, 'macro avg_precision': 0.23259052924791088, 'macro avg_recall': 0.2303448275862069, 'macro avg_f1-score': 0.23146223146223144, 'macro avg_support': 725.0, 'weighted avg_precision': 0.23259052924791088, 'weighted avg_recall': 0.2303448275862069, 'weighted avg_f1-score': 0.23146223146223144, 'weighted avg_support': 725.0, 'O_support': 16404, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'epoch': 4}, {'micro_f1': 0.7560611841420694, 'precision': 0.7560611841420694, 'Doubt_precision': 0.3231197771587744, 'Doubt_recall': 0.2543859649122807, 'Doubt_f1-score': 0.2846625766871166, 'Doubt_support': 912.0, 'micro avg_precision': 0.3231197771587744, 'micro avg_recall': 0.2543859649122807, 'micro avg_f1-score': 0.2846625766871166, 'micro avg_support': 912.0, 'macro avg_precision': 0.3231197771587744, 'macro avg_recall': 0.2543859649122807, 'macro avg_f1-score': 0.2846625766871166, 'macro avg_support': 912.0, 'weighted avg_precision': 0.3231197771587744, 'weighted avg_recall': 0.2543859649122807, 'weighted avg_f1-score': 0.2846625766871166, 'weighted avg_support': 912.0, 'O_support': 16404, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'epoch': 5}]}
Best model updated: current epoch macro f1 = 0.2846625766871166
{'micro_f1': 0.7626513128230031, 'precision': 0.762651312823003, 'Doubt_precision': 0.318941504178273, 'Doubt_recall': 0.2762364294330519, 'Doubt_f1-score': 0.2960568842921784, 'Doubt_support': 829.0, 'micro avg_precision': 0.318941504178273, 'micro avg_recall': 0.2762364294330519, 'micro avg_f1-score': 0.2960568842921784, 'micro avg_support': 829.0, 'macro avg_precision': 0.318941504178273, 'macro avg_recall': 0.2762364294330519, 'macro avg_f1-score': 0.2960568842921784, 'macro avg_support': 829.0, 'weighted avg_precision': 0.318941504178273, 'weighted avg_recall': 0.2762364294330519, 'weighted avg_f1-score': 0.2960568842921784, 'weighted avg_support': 829.0, 'O_support': 16404, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'epoch': 6}
{'results': [{'micro_f1': 0.7139537303596822, 'precision': 0.7139537303596822, 'Doubt_precision': 0.10724233983286909, 'Doubt_recall': 0.08740068104426787, 'Doubt_f1-score': 0.09631019387116947, 'Doubt_support': 881.0, 'micro avg_precision': 0.10724233983286909, 'micro avg_recall': 0.08740068104426787, 'micro avg_f1-score': 0.09631019387116947, 'micro avg_support': 881.0, 'macro avg_precision': 0.10724233983286909, 'macro avg_recall': 0.08740068104426787, 'macro avg_f1-score': 0.09631019387116947, 'macro avg_support': 881.0, 'weighted avg_precision': 0.10724233983286909, 'weighted avg_recall': 0.08740068104426787, 'weighted avg_f1-score': 0.09631019387116947, 'weighted avg_support': 881.0, 'O_support': 16404, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'epoch': 0}, {'micro_f1': 0.7360480038847075, 'precision': 0.7360480038847075, 'Doubt_precision': 0.1671309192200557, 'Doubt_recall': 0.1377726750861079, 'Doubt_f1-score': 0.15103838892385146, 'Doubt_support': 871.0, 'micro avg_precision': 0.1671309192200557, 'micro avg_recall': 0.1377726750861079, 'micro avg_f1-score': 0.15103838892385146, 'micro avg_support': 871.0, 'macro avg_precision': 0.1671309192200557, 'macro avg_recall': 0.1377726750861079, 'macro avg_f1-score': 0.15103838892385146, 'macro avg_support': 871.0, 'weighted avg_precision': 0.16713091922005574, 'weighted avg_recall': 0.1377726750861079, 'weighted avg_f1-score': 0.15103838892385146, 'weighted avg_support': 871.0, 'O_support': 16404, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'epoch': 1}, {'micro_f1': 0.7653914189587596, 'precision': 0.7653914189587596, 'Doubt_precision': 0.2562674094707521, 'Doubt_recall': 0.20512820512820512, 'Doubt_f1-score': 0.22786377708978328, 'Doubt_support': 897.0, 'micro avg_precision': 0.2562674094707521, 'micro avg_recall': 0.20512820512820512, 'micro avg_f1-score': 0.22786377708978328, 'micro avg_support': 897.0, 'macro avg_precision': 0.2562674094707521, 'macro avg_recall': 0.20512820512820512, 'macro avg_f1-score': 0.22786377708978328, 'macro avg_support': 897.0, 'weighted avg_precision': 0.2562674094707521, 'weighted avg_recall': 0.20512820512820512, 'weighted avg_f1-score': 0.22786377708978328, 'weighted avg_support': 897.0, 'O_support': 16404, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'epoch': 2}, {'micro_f1': 0.750407547431584, 'precision': 0.7504075474315841, 'Doubt_precision': 0.2883008356545961, 'Doubt_recall': 0.24210526315789474, 'Doubt_f1-score': 0.26319135410044503, 'Doubt_support': 855.0, 'micro avg_precision': 0.2883008356545961, 'micro avg_recall': 0.24210526315789474, 'micro avg_f1-score': 0.26319135410044503, 'micro avg_support': 855.0, 'macro avg_precision': 0.2883008356545961, 'macro avg_recall': 0.24210526315789474, 'macro avg_f1-score': 0.26319135410044503, 'macro avg_support': 855.0, 'weighted avg_precision': 0.2883008356545961, 'weighted avg_recall': 0.24210526315789474, 'weighted avg_f1-score': 0.26319135410044503, 'weighted avg_support': 855.0, 'O_support': 16404, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'epoch': 3}, {'micro_f1': 0.7469737435399397, 'precision': 0.7469737435399396, 'Doubt_precision': 0.23259052924791088, 'Doubt_recall': 0.2303448275862069, 'Doubt_f1-score': 0.23146223146223144, 'Doubt_support': 725.0, 'micro avg_precision': 0.23259052924791088, 'micro avg_recall': 0.2303448275862069, 'micro avg_f1-score': 0.23146223146223144, 'micro avg_support': 725.0, 'macro avg_precision': 0.23259052924791088, 'macro avg_recall': 0.2303448275862069, 'macro avg_f1-score': 0.23146223146223144, 'macro avg_support': 725.0, 'weighted avg_precision': 0.23259052924791088, 'weighted avg_recall': 0.2303448275862069, 'weighted avg_f1-score': 0.23146223146223144, 'weighted avg_support': 725.0, 'O_support': 16404, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'epoch': 4}, {'micro_f1': 0.7560611841420694, 'precision': 0.7560611841420694, 'Doubt_precision': 0.3231197771587744, 'Doubt_recall': 0.2543859649122807, 'Doubt_f1-score': 0.2846625766871166, 'Doubt_support': 912.0, 'micro avg_precision': 0.3231197771587744, 'micro avg_recall': 0.2543859649122807, 'micro avg_f1-score': 0.2846625766871166, 'micro avg_support': 912.0, 'macro avg_precision': 0.3231197771587744, 'macro avg_recall': 0.2543859649122807, 'macro avg_f1-score': 0.2846625766871166, 'macro avg_support': 912.0, 'weighted avg_precision': 0.3231197771587744, 'weighted avg_recall': 0.2543859649122807, 'weighted avg_f1-score': 0.2846625766871166, 'weighted avg_support': 912.0, 'O_support': 16404, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'epoch': 5}, {'micro_f1': 0.7626513128230031, 'precision': 0.762651312823003, 'Doubt_precision': 0.318941504178273, 'Doubt_recall': 0.2762364294330519, 'Doubt_f1-score': 0.2960568842921784, 'Doubt_support': 829.0, 'micro avg_precision': 0.318941504178273, 'micro avg_recall': 0.2762364294330519, 'micro avg_f1-score': 0.2960568842921784, 'micro avg_support': 829.0, 'macro avg_precision': 0.318941504178273, 'macro avg_recall': 0.2762364294330519, 'macro avg_f1-score': 0.2960568842921784, 'macro avg_support': 829.0, 'weighted avg_precision': 0.318941504178273, 'weighted avg_recall': 0.2762364294330519, 'weighted avg_f1-score': 0.2960568842921784, 'weighted avg_support': 829.0, 'O_support': 16404, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'epoch': 6}]}
Best model updated: current epoch macro f1 = 0.2960568842921784
{'micro_f1': 0.7495751101245187, 'precision': 0.7495751101245187, 'Doubt_precision': 0.2841225626740947, 'Doubt_recall': 0.27419354838709675, 'Doubt_f1-score': 0.2790697674418605, 'Doubt_support': 744.0, 'micro avg_precision': 0.2841225626740947, 'micro avg_recall': 0.27419354838709675, 'micro avg_f1-score': 0.2790697674418605, 'micro avg_support': 744.0, 'macro avg_precision': 0.2841225626740947, 'macro avg_recall': 0.27419354838709675, 'macro avg_f1-score': 0.2790697674418605, 'macro avg_support': 744.0, 'weighted avg_precision': 0.2841225626740947, 'weighted avg_recall': 0.27419354838709675, 'weighted avg_f1-score': 0.2790697674418605, 'weighted avg_support': 744.0, 'O_support': 16404, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'epoch': 7}
{'results': [{'micro_f1': 0.7139537303596822, 'precision': 0.7139537303596822, 'Doubt_precision': 0.10724233983286909, 'Doubt_recall': 0.08740068104426787, 'Doubt_f1-score': 0.09631019387116947, 'Doubt_support': 881.0, 'micro avg_precision': 0.10724233983286909, 'micro avg_recall': 0.08740068104426787, 'micro avg_f1-score': 0.09631019387116947, 'micro avg_support': 881.0, 'macro avg_precision': 0.10724233983286909, 'macro avg_recall': 0.08740068104426787, 'macro avg_f1-score': 0.09631019387116947, 'macro avg_support': 881.0, 'weighted avg_precision': 0.10724233983286909, 'weighted avg_recall': 0.08740068104426787, 'weighted avg_f1-score': 0.09631019387116947, 'weighted avg_support': 881.0, 'O_support': 16404, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'epoch': 0}, {'micro_f1': 0.7360480038847075, 'precision': 0.7360480038847075, 'Doubt_precision': 0.1671309192200557, 'Doubt_recall': 0.1377726750861079, 'Doubt_f1-score': 0.15103838892385146, 'Doubt_support': 871.0, 'micro avg_precision': 0.1671309192200557, 'micro avg_recall': 0.1377726750861079, 'micro avg_f1-score': 0.15103838892385146, 'micro avg_support': 871.0, 'macro avg_precision': 0.1671309192200557, 'macro avg_recall': 0.1377726750861079, 'macro avg_f1-score': 0.15103838892385146, 'macro avg_support': 871.0, 'weighted avg_precision': 0.16713091922005574, 'weighted avg_recall': 0.1377726750861079, 'weighted avg_f1-score': 0.15103838892385146, 'weighted avg_support': 871.0, 'O_support': 16404, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'epoch': 1}, {'micro_f1': 0.7653914189587596, 'precision': 0.7653914189587596, 'Doubt_precision': 0.2562674094707521, 'Doubt_recall': 0.20512820512820512, 'Doubt_f1-score': 0.22786377708978328, 'Doubt_support': 897.0, 'micro avg_precision': 0.2562674094707521, 'micro avg_recall': 0.20512820512820512, 'micro avg_f1-score': 0.22786377708978328, 'micro avg_support': 897.0, 'macro avg_precision': 0.2562674094707521, 'macro avg_recall': 0.20512820512820512, 'macro avg_f1-score': 0.22786377708978328, 'macro avg_support': 897.0, 'weighted avg_precision': 0.2562674094707521, 'weighted avg_recall': 0.20512820512820512, 'weighted avg_f1-score': 0.22786377708978328, 'weighted avg_support': 897.0, 'O_support': 16404, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'epoch': 2}, {'micro_f1': 0.750407547431584, 'precision': 0.7504075474315841, 'Doubt_precision': 0.2883008356545961, 'Doubt_recall': 0.24210526315789474, 'Doubt_f1-score': 0.26319135410044503, 'Doubt_support': 855.0, 'micro avg_precision': 0.2883008356545961, 'micro avg_recall': 0.24210526315789474, 'micro avg_f1-score': 0.26319135410044503, 'micro avg_support': 855.0, 'macro avg_precision': 0.2883008356545961, 'macro avg_recall': 0.24210526315789474, 'macro avg_f1-score': 0.26319135410044503, 'macro avg_support': 855.0, 'weighted avg_precision': 0.2883008356545961, 'weighted avg_recall': 0.24210526315789474, 'weighted avg_f1-score': 0.26319135410044503, 'weighted avg_support': 855.0, 'O_support': 16404, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'epoch': 3}, {'micro_f1': 0.7469737435399397, 'precision': 0.7469737435399396, 'Doubt_precision': 0.23259052924791088, 'Doubt_recall': 0.2303448275862069, 'Doubt_f1-score': 0.23146223146223144, 'Doubt_support': 725.0, 'micro avg_precision': 0.23259052924791088, 'micro avg_recall': 0.2303448275862069, 'micro avg_f1-score': 0.23146223146223144, 'micro avg_support': 725.0, 'macro avg_precision': 0.23259052924791088, 'macro avg_recall': 0.2303448275862069, 'macro avg_f1-score': 0.23146223146223144, 'macro avg_support': 725.0, 'weighted avg_precision': 0.23259052924791088, 'weighted avg_recall': 0.2303448275862069, 'weighted avg_f1-score': 0.23146223146223144, 'weighted avg_support': 725.0, 'O_support': 16404, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'epoch': 4}, {'micro_f1': 0.7560611841420694, 'precision': 0.7560611841420694, 'Doubt_precision': 0.3231197771587744, 'Doubt_recall': 0.2543859649122807, 'Doubt_f1-score': 0.2846625766871166, 'Doubt_support': 912.0, 'micro avg_precision': 0.3231197771587744, 'micro avg_recall': 0.2543859649122807, 'micro avg_f1-score': 0.2846625766871166, 'micro avg_support': 912.0, 'macro avg_precision': 0.3231197771587744, 'macro avg_recall': 0.2543859649122807, 'macro avg_f1-score': 0.2846625766871166, 'macro avg_support': 912.0, 'weighted avg_precision': 0.3231197771587744, 'weighted avg_recall': 0.2543859649122807, 'weighted avg_f1-score': 0.2846625766871166, 'weighted avg_support': 912.0, 'O_support': 16404, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'epoch': 5}, {'micro_f1': 0.7626513128230031, 'precision': 0.762651312823003, 'Doubt_precision': 0.318941504178273, 'Doubt_recall': 0.2762364294330519, 'Doubt_f1-score': 0.2960568842921784, 'Doubt_support': 829.0, 'micro avg_precision': 0.318941504178273, 'micro avg_recall': 0.2762364294330519, 'micro avg_f1-score': 0.2960568842921784, 'micro avg_support': 829.0, 'macro avg_precision': 0.318941504178273, 'macro avg_recall': 0.2762364294330519, 'macro avg_f1-score': 0.2960568842921784, 'macro avg_support': 829.0, 'weighted avg_precision': 0.318941504178273, 'weighted avg_recall': 0.2762364294330519, 'weighted avg_f1-score': 0.2960568842921784, 'weighted avg_support': 829.0, 'O_support': 16404, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'epoch': 6}, {'micro_f1': 0.7495751101245187, 'precision': 0.7495751101245187, 'Doubt_precision': 0.2841225626740947, 'Doubt_recall': 0.27419354838709675, 'Doubt_f1-score': 0.2790697674418605, 'Doubt_support': 744.0, 'micro avg_precision': 0.2841225626740947, 'micro avg_recall': 0.27419354838709675, 'micro avg_f1-score': 0.2790697674418605, 'micro avg_support': 744.0, 'macro avg_precision': 0.2841225626740947, 'macro avg_recall': 0.27419354838709675, 'macro avg_f1-score': 0.2790697674418605, 'macro avg_support': 744.0, 'weighted avg_precision': 0.2841225626740947, 'weighted avg_recall': 0.27419354838709675, 'weighted avg_f1-score': 0.2790697674418605, 'weighted avg_support': 744.0, 'O_support': 16404, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'epoch': 7}]}
{'micro_f1': 0.7674031424508342, 'precision': 0.7674031424508342, 'Doubt_precision': 0.31754874651810583, 'Doubt_recall': 0.2698224852071006, 'Doubt_f1-score': 0.29174664107485604, 'Doubt_support': 845.0, 'micro avg_precision': 0.31754874651810583, 'micro avg_recall': 0.2698224852071006, 'micro avg_f1-score': 0.29174664107485604, 'micro avg_support': 845.0, 'macro avg_precision': 0.31754874651810583, 'macro avg_recall': 0.2698224852071006, 'macro avg_f1-score': 0.29174664107485604, 'macro avg_support': 845.0, 'weighted avg_precision': 0.31754874651810583, 'weighted avg_recall': 0.2698224852071006, 'weighted avg_f1-score': 0.29174664107485604, 'weighted avg_support': 845.0, 'O_support': 16404, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'epoch': 8}
{'results': [{'micro_f1': 0.7139537303596822, 'precision': 0.7139537303596822, 'Doubt_precision': 0.10724233983286909, 'Doubt_recall': 0.08740068104426787, 'Doubt_f1-score': 0.09631019387116947, 'Doubt_support': 881.0, 'micro avg_precision': 0.10724233983286909, 'micro avg_recall': 0.08740068104426787, 'micro avg_f1-score': 0.09631019387116947, 'micro avg_support': 881.0, 'macro avg_precision': 0.10724233983286909, 'macro avg_recall': 0.08740068104426787, 'macro avg_f1-score': 0.09631019387116947, 'macro avg_support': 881.0, 'weighted avg_precision': 0.10724233983286909, 'weighted avg_recall': 0.08740068104426787, 'weighted avg_f1-score': 0.09631019387116947, 'weighted avg_support': 881.0, 'O_support': 16404, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'epoch': 0}, {'micro_f1': 0.7360480038847075, 'precision': 0.7360480038847075, 'Doubt_precision': 0.1671309192200557, 'Doubt_recall': 0.1377726750861079, 'Doubt_f1-score': 0.15103838892385146, 'Doubt_support': 871.0, 'micro avg_precision': 0.1671309192200557, 'micro avg_recall': 0.1377726750861079, 'micro avg_f1-score': 0.15103838892385146, 'micro avg_support': 871.0, 'macro avg_precision': 0.1671309192200557, 'macro avg_recall': 0.1377726750861079, 'macro avg_f1-score': 0.15103838892385146, 'macro avg_support': 871.0, 'weighted avg_precision': 0.16713091922005574, 'weighted avg_recall': 0.1377726750861079, 'weighted avg_f1-score': 0.15103838892385146, 'weighted avg_support': 871.0, 'O_support': 16404, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'epoch': 1}, {'micro_f1': 0.7653914189587596, 'precision': 0.7653914189587596, 'Doubt_precision': 0.2562674094707521, 'Doubt_recall': 0.20512820512820512, 'Doubt_f1-score': 0.22786377708978328, 'Doubt_support': 897.0, 'micro avg_precision': 0.2562674094707521, 'micro avg_recall': 0.20512820512820512, 'micro avg_f1-score': 0.22786377708978328, 'micro avg_support': 897.0, 'macro avg_precision': 0.2562674094707521, 'macro avg_recall': 0.20512820512820512, 'macro avg_f1-score': 0.22786377708978328, 'macro avg_support': 897.0, 'weighted avg_precision': 0.2562674094707521, 'weighted avg_recall': 0.20512820512820512, 'weighted avg_f1-score': 0.22786377708978328, 'weighted avg_support': 897.0, 'O_support': 16404, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'epoch': 2}, {'micro_f1': 0.750407547431584, 'precision': 0.7504075474315841, 'Doubt_precision': 0.2883008356545961, 'Doubt_recall': 0.24210526315789474, 'Doubt_f1-score': 0.26319135410044503, 'Doubt_support': 855.0, 'micro avg_precision': 0.2883008356545961, 'micro avg_recall': 0.24210526315789474, 'micro avg_f1-score': 0.26319135410044503, 'micro avg_support': 855.0, 'macro avg_precision': 0.2883008356545961, 'macro avg_recall': 0.24210526315789474, 'macro avg_f1-score': 0.26319135410044503, 'macro avg_support': 855.0, 'weighted avg_precision': 0.2883008356545961, 'weighted avg_recall': 0.24210526315789474, 'weighted avg_f1-score': 0.26319135410044503, 'weighted avg_support': 855.0, 'O_support': 16404, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'epoch': 3}, {'micro_f1': 0.7469737435399397, 'precision': 0.7469737435399396, 'Doubt_precision': 0.23259052924791088, 'Doubt_recall': 0.2303448275862069, 'Doubt_f1-score': 0.23146223146223144, 'Doubt_support': 725.0, 'micro avg_precision': 0.23259052924791088, 'micro avg_recall': 0.2303448275862069, 'micro avg_f1-score': 0.23146223146223144, 'micro avg_support': 725.0, 'macro avg_precision': 0.23259052924791088, 'macro avg_recall': 0.2303448275862069, 'macro avg_f1-score': 0.23146223146223144, 'macro avg_support': 725.0, 'weighted avg_precision': 0.23259052924791088, 'weighted avg_recall': 0.2303448275862069, 'weighted avg_f1-score': 0.23146223146223144, 'weighted avg_support': 725.0, 'O_support': 16404, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'epoch': 4}, {'micro_f1': 0.7560611841420694, 'precision': 0.7560611841420694, 'Doubt_precision': 0.3231197771587744, 'Doubt_recall': 0.2543859649122807, 'Doubt_f1-score': 0.2846625766871166, 'Doubt_support': 912.0, 'micro avg_precision': 0.3231197771587744, 'micro avg_recall': 0.2543859649122807, 'micro avg_f1-score': 0.2846625766871166, 'micro avg_support': 912.0, 'macro avg_precision': 0.3231197771587744, 'macro avg_recall': 0.2543859649122807, 'macro avg_f1-score': 0.2846625766871166, 'macro avg_support': 912.0, 'weighted avg_precision': 0.3231197771587744, 'weighted avg_recall': 0.2543859649122807, 'weighted avg_f1-score': 0.2846625766871166, 'weighted avg_support': 912.0, 'O_support': 16404, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'epoch': 5}, {'micro_f1': 0.7626513128230031, 'precision': 0.762651312823003, 'Doubt_precision': 0.318941504178273, 'Doubt_recall': 0.2762364294330519, 'Doubt_f1-score': 0.2960568842921784, 'Doubt_support': 829.0, 'micro avg_precision': 0.318941504178273, 'micro avg_recall': 0.2762364294330519, 'micro avg_f1-score': 0.2960568842921784, 'micro avg_support': 829.0, 'macro avg_precision': 0.318941504178273, 'macro avg_recall': 0.2762364294330519, 'macro avg_f1-score': 0.2960568842921784, 'macro avg_support': 829.0, 'weighted avg_precision': 0.318941504178273, 'weighted avg_recall': 0.2762364294330519, 'weighted avg_f1-score': 0.2960568842921784, 'weighted avg_support': 829.0, 'O_support': 16404, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'epoch': 6}, {'micro_f1': 0.7495751101245187, 'precision': 0.7495751101245187, 'Doubt_precision': 0.2841225626740947, 'Doubt_recall': 0.27419354838709675, 'Doubt_f1-score': 0.2790697674418605, 'Doubt_support': 744.0, 'micro avg_precision': 0.2841225626740947, 'micro avg_recall': 0.27419354838709675, 'micro avg_f1-score': 0.2790697674418605, 'micro avg_support': 744.0, 'macro avg_precision': 0.2841225626740947, 'macro avg_recall': 0.27419354838709675, 'macro avg_f1-score': 0.2790697674418605, 'macro avg_support': 744.0, 'weighted avg_precision': 0.2841225626740947, 'weighted avg_recall': 0.27419354838709675, 'weighted avg_f1-score': 0.2790697674418605, 'weighted avg_support': 744.0, 'O_support': 16404, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'epoch': 7}, {'micro_f1': 0.7674031424508342, 'precision': 0.7674031424508342, 'Doubt_precision': 0.31754874651810583, 'Doubt_recall': 0.2698224852071006, 'Doubt_f1-score': 0.29174664107485604, 'Doubt_support': 845.0, 'micro avg_precision': 0.31754874651810583, 'micro avg_recall': 0.2698224852071006, 'micro avg_f1-score': 0.29174664107485604, 'micro avg_support': 845.0, 'macro avg_precision': 0.31754874651810583, 'macro avg_recall': 0.2698224852071006, 'macro avg_f1-score': 0.29174664107485604, 'macro avg_support': 845.0, 'weighted avg_precision': 0.31754874651810583, 'weighted avg_recall': 0.2698224852071006, 'weighted avg_f1-score': 0.29174664107485604, 'weighted avg_support': 845.0, 'O_support': 16404, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'epoch': 8}]}
Early stopping triggered.
Saving model to directory: ./models/M2/2024-05-13-23-08-48_aug/mdeberta-v3-base_19_ME10_target=Doubt_SUBSAMPLED_2024-05-13-23-08-48
Training model no. 20 of 23 for (20, 'Guilt_by_Association') persuasion technique...
{'micro_f1': 0.7542717656631408, 'precision': 0.7542717656631408, 'Guilt_by_Association_precision': 0.011764705882352941, 'Guilt_by_Association_recall': 0.006622516556291391, 'Guilt_by_Association_f1-score': 0.00847457627118644, 'Guilt_by_Association_support': 151.0, 'micro avg_precision': 0.011764705882352941, 'micro avg_recall': 0.006622516556291391, 'micro avg_f1-score': 0.00847457627118644, 'micro avg_support': 151.0, 'macro avg_precision': 0.011764705882352941, 'macro avg_recall': 0.006622516556291391, 'macro avg_f1-score': 0.00847457627118644, 'macro avg_support': 151.0, 'weighted avg_precision': 0.011764705882352941, 'weighted avg_recall': 0.006622516556291391, 'weighted avg_f1-score': 0.00847457627118644, 'weighted avg_support': 151.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 0}
{'results': [{'micro_f1': 0.7542717656631408, 'precision': 0.7542717656631408, 'Guilt_by_Association_precision': 0.011764705882352941, 'Guilt_by_Association_recall': 0.006622516556291391, 'Guilt_by_Association_f1-score': 0.00847457627118644, 'Guilt_by_Association_support': 151.0, 'micro avg_precision': 0.011764705882352941, 'micro avg_recall': 0.006622516556291391, 'micro avg_f1-score': 0.00847457627118644, 'micro avg_support': 151.0, 'macro avg_precision': 0.011764705882352941, 'macro avg_recall': 0.006622516556291391, 'macro avg_f1-score': 0.00847457627118644, 'macro avg_support': 151.0, 'weighted avg_precision': 0.011764705882352941, 'weighted avg_recall': 0.006622516556291391, 'weighted avg_f1-score': 0.00847457627118644, 'weighted avg_support': 151.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 0}]}
Best model updated: current epoch macro f1 = 0.00847457627118644
{'micro_f1': 0.7651206943314347, 'precision': 0.7651206943314348, 'Guilt_by_Association_precision': 0.11764705882352941, 'Guilt_by_Association_recall': 0.04716981132075472, 'Guilt_by_Association_f1-score': 0.06734006734006734, 'Guilt_by_Association_support': 212.0, 'micro avg_precision': 0.11764705882352941, 'micro avg_recall': 0.04716981132075472, 'micro avg_f1-score': 0.06734006734006734, 'micro avg_support': 212.0, 'macro avg_precision': 0.11764705882352941, 'macro avg_recall': 0.04716981132075472, 'macro avg_f1-score': 0.06734006734006734, 'macro avg_support': 212.0, 'weighted avg_precision': 0.11764705882352941, 'weighted avg_recall': 0.04716981132075472, 'weighted avg_f1-score': 0.06734006734006734, 'weighted avg_support': 212.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 1}
{'results': [{'micro_f1': 0.7542717656631408, 'precision': 0.7542717656631408, 'Guilt_by_Association_precision': 0.011764705882352941, 'Guilt_by_Association_recall': 0.006622516556291391, 'Guilt_by_Association_f1-score': 0.00847457627118644, 'Guilt_by_Association_support': 151.0, 'micro avg_precision': 0.011764705882352941, 'micro avg_recall': 0.006622516556291391, 'micro avg_f1-score': 0.00847457627118644, 'micro avg_support': 151.0, 'macro avg_precision': 0.011764705882352941, 'macro avg_recall': 0.006622516556291391, 'macro avg_f1-score': 0.00847457627118644, 'macro avg_support': 151.0, 'weighted avg_precision': 0.011764705882352941, 'weighted avg_recall': 0.006622516556291391, 'weighted avg_f1-score': 0.00847457627118644, 'weighted avg_support': 151.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 0}, {'micro_f1': 0.7651206943314347, 'precision': 0.7651206943314348, 'Guilt_by_Association_precision': 0.11764705882352941, 'Guilt_by_Association_recall': 0.04716981132075472, 'Guilt_by_Association_f1-score': 0.06734006734006734, 'Guilt_by_Association_support': 212.0, 'micro avg_precision': 0.11764705882352941, 'micro avg_recall': 0.04716981132075472, 'micro avg_f1-score': 0.06734006734006734, 'micro avg_support': 212.0, 'macro avg_precision': 0.11764705882352941, 'macro avg_recall': 0.04716981132075472, 'macro avg_f1-score': 0.06734006734006734, 'macro avg_support': 212.0, 'weighted avg_precision': 0.11764705882352941, 'weighted avg_recall': 0.04716981132075472, 'weighted avg_f1-score': 0.06734006734006734, 'weighted avg_support': 212.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 1}]}
Best model updated: current epoch macro f1 = 0.06734006734006734
{'micro_f1': 0.7849199891510714, 'precision': 0.7849199891510713, 'Guilt_by_Association_precision': 0.23529411764705882, 'Guilt_by_Association_recall': 0.11173184357541899, 'Guilt_by_Association_f1-score': 0.15151515151515152, 'Guilt_by_Association_support': 179.0, 'micro avg_precision': 0.23529411764705882, 'micro avg_recall': 0.11173184357541899, 'micro avg_f1-score': 0.15151515151515152, 'micro avg_support': 179.0, 'macro avg_precision': 0.23529411764705882, 'macro avg_recall': 0.11173184357541899, 'macro avg_f1-score': 0.15151515151515152, 'macro avg_support': 179.0, 'weighted avg_precision': 0.23529411764705882, 'weighted avg_recall': 0.11173184357541899, 'weighted avg_f1-score': 0.15151515151515152, 'weighted avg_support': 179.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 2}
{'results': [{'micro_f1': 0.7542717656631408, 'precision': 0.7542717656631408, 'Guilt_by_Association_precision': 0.011764705882352941, 'Guilt_by_Association_recall': 0.006622516556291391, 'Guilt_by_Association_f1-score': 0.00847457627118644, 'Guilt_by_Association_support': 151.0, 'micro avg_precision': 0.011764705882352941, 'micro avg_recall': 0.006622516556291391, 'micro avg_f1-score': 0.00847457627118644, 'micro avg_support': 151.0, 'macro avg_precision': 0.011764705882352941, 'macro avg_recall': 0.006622516556291391, 'macro avg_f1-score': 0.00847457627118644, 'macro avg_support': 151.0, 'weighted avg_precision': 0.011764705882352941, 'weighted avg_recall': 0.006622516556291391, 'weighted avg_f1-score': 0.00847457627118644, 'weighted avg_support': 151.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 0}, {'micro_f1': 0.7651206943314347, 'precision': 0.7651206943314348, 'Guilt_by_Association_precision': 0.11764705882352941, 'Guilt_by_Association_recall': 0.04716981132075472, 'Guilt_by_Association_f1-score': 0.06734006734006734, 'Guilt_by_Association_support': 212.0, 'micro avg_precision': 0.11764705882352941, 'micro avg_recall': 0.04716981132075472, 'micro avg_f1-score': 0.06734006734006734, 'micro avg_support': 212.0, 'macro avg_precision': 0.11764705882352941, 'macro avg_recall': 0.04716981132075472, 'macro avg_f1-score': 0.06734006734006734, 'macro avg_support': 212.0, 'weighted avg_precision': 0.11764705882352941, 'weighted avg_recall': 0.04716981132075472, 'weighted avg_f1-score': 0.06734006734006734, 'weighted avg_support': 212.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 1}, {'micro_f1': 0.7849199891510714, 'precision': 0.7849199891510713, 'Guilt_by_Association_precision': 0.23529411764705882, 'Guilt_by_Association_recall': 0.11173184357541899, 'Guilt_by_Association_f1-score': 0.15151515151515152, 'Guilt_by_Association_support': 179.0, 'micro avg_precision': 0.23529411764705882, 'micro avg_recall': 0.11173184357541899, 'micro avg_f1-score': 0.15151515151515152, 'micro avg_support': 179.0, 'macro avg_precision': 0.23529411764705882, 'macro avg_recall': 0.11173184357541899, 'macro avg_f1-score': 0.15151515151515152, 'macro avg_support': 179.0, 'weighted avg_precision': 0.23529411764705882, 'weighted avg_recall': 0.11173184357541899, 'weighted avg_f1-score': 0.15151515151515152, 'weighted avg_support': 179.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 2}]}
Best model updated: current epoch macro f1 = 0.15151515151515152
{'micro_f1': 0.786276105234608, 'precision': 0.7862761052346081, 'Guilt_by_Association_precision': 0.1411764705882353, 'Guilt_by_Association_recall': 0.10619469026548672, 'Guilt_by_Association_f1-score': 0.12121212121212122, 'Guilt_by_Association_support': 113.0, 'micro avg_precision': 0.1411764705882353, 'micro avg_recall': 0.10619469026548672, 'micro avg_f1-score': 0.12121212121212122, 'micro avg_support': 113.0, 'macro avg_precision': 0.1411764705882353, 'macro avg_recall': 0.10619469026548672, 'macro avg_f1-score': 0.12121212121212122, 'macro avg_support': 113.0, 'weighted avg_precision': 0.1411764705882353, 'weighted avg_recall': 0.10619469026548672, 'weighted avg_f1-score': 0.12121212121212122, 'weighted avg_support': 113.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 3}
{'results': [{'micro_f1': 0.7542717656631408, 'precision': 0.7542717656631408, 'Guilt_by_Association_precision': 0.011764705882352941, 'Guilt_by_Association_recall': 0.006622516556291391, 'Guilt_by_Association_f1-score': 0.00847457627118644, 'Guilt_by_Association_support': 151.0, 'micro avg_precision': 0.011764705882352941, 'micro avg_recall': 0.006622516556291391, 'micro avg_f1-score': 0.00847457627118644, 'micro avg_support': 151.0, 'macro avg_precision': 0.011764705882352941, 'macro avg_recall': 0.006622516556291391, 'macro avg_f1-score': 0.00847457627118644, 'macro avg_support': 151.0, 'weighted avg_precision': 0.011764705882352941, 'weighted avg_recall': 0.006622516556291391, 'weighted avg_f1-score': 0.00847457627118644, 'weighted avg_support': 151.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 0}, {'micro_f1': 0.7651206943314347, 'precision': 0.7651206943314348, 'Guilt_by_Association_precision': 0.11764705882352941, 'Guilt_by_Association_recall': 0.04716981132075472, 'Guilt_by_Association_f1-score': 0.06734006734006734, 'Guilt_by_Association_support': 212.0, 'micro avg_precision': 0.11764705882352941, 'micro avg_recall': 0.04716981132075472, 'micro avg_f1-score': 0.06734006734006734, 'micro avg_support': 212.0, 'macro avg_precision': 0.11764705882352941, 'macro avg_recall': 0.04716981132075472, 'macro avg_f1-score': 0.06734006734006734, 'macro avg_support': 212.0, 'weighted avg_precision': 0.11764705882352941, 'weighted avg_recall': 0.04716981132075472, 'weighted avg_f1-score': 0.06734006734006734, 'weighted avg_support': 212.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 1}, {'micro_f1': 0.7849199891510714, 'precision': 0.7849199891510713, 'Guilt_by_Association_precision': 0.23529411764705882, 'Guilt_by_Association_recall': 0.11173184357541899, 'Guilt_by_Association_f1-score': 0.15151515151515152, 'Guilt_by_Association_support': 179.0, 'micro avg_precision': 0.23529411764705882, 'micro avg_recall': 0.11173184357541899, 'micro avg_f1-score': 0.15151515151515152, 'micro avg_support': 179.0, 'macro avg_precision': 0.23529411764705882, 'macro avg_recall': 0.11173184357541899, 'macro avg_f1-score': 0.15151515151515152, 'macro avg_support': 179.0, 'weighted avg_precision': 0.23529411764705882, 'weighted avg_recall': 0.11173184357541899, 'weighted avg_f1-score': 0.15151515151515152, 'weighted avg_support': 179.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 2}, {'micro_f1': 0.786276105234608, 'precision': 0.7862761052346081, 'Guilt_by_Association_precision': 0.1411764705882353, 'Guilt_by_Association_recall': 0.10619469026548672, 'Guilt_by_Association_f1-score': 0.12121212121212122, 'Guilt_by_Association_support': 113.0, 'micro avg_precision': 0.1411764705882353, 'micro avg_recall': 0.10619469026548672, 'micro avg_f1-score': 0.12121212121212122, 'micro avg_support': 113.0, 'macro avg_precision': 0.1411764705882353, 'macro avg_recall': 0.10619469026548672, 'macro avg_f1-score': 0.12121212121212122, 'macro avg_support': 113.0, 'weighted avg_precision': 0.1411764705882353, 'weighted avg_recall': 0.10619469026548672, 'weighted avg_f1-score': 0.12121212121212122, 'weighted avg_support': 113.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 3}]}
{'micro_f1': 0.8030919446704639, 'precision': 0.8030919446704637, 'Guilt_by_Association_precision': 0.17647058823529413, 'Guilt_by_Association_recall': 0.13636363636363635, 'Guilt_by_Association_f1-score': 0.15384615384615383, 'Guilt_by_Association_support': 110.0, 'micro avg_precision': 0.17647058823529413, 'micro avg_recall': 0.13636363636363635, 'micro avg_f1-score': 0.15384615384615383, 'micro avg_support': 110.0, 'macro avg_precision': 0.17647058823529413, 'macro avg_recall': 0.13636363636363635, 'macro avg_f1-score': 0.15384615384615383, 'macro avg_support': 110.0, 'weighted avg_precision': 0.17647058823529413, 'weighted avg_recall': 0.13636363636363635, 'weighted avg_f1-score': 0.15384615384615383, 'weighted avg_support': 110.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 4}
{'results': [{'micro_f1': 0.7542717656631408, 'precision': 0.7542717656631408, 'Guilt_by_Association_precision': 0.011764705882352941, 'Guilt_by_Association_recall': 0.006622516556291391, 'Guilt_by_Association_f1-score': 0.00847457627118644, 'Guilt_by_Association_support': 151.0, 'micro avg_precision': 0.011764705882352941, 'micro avg_recall': 0.006622516556291391, 'micro avg_f1-score': 0.00847457627118644, 'micro avg_support': 151.0, 'macro avg_precision': 0.011764705882352941, 'macro avg_recall': 0.006622516556291391, 'macro avg_f1-score': 0.00847457627118644, 'macro avg_support': 151.0, 'weighted avg_precision': 0.011764705882352941, 'weighted avg_recall': 0.006622516556291391, 'weighted avg_f1-score': 0.00847457627118644, 'weighted avg_support': 151.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 0}, {'micro_f1': 0.7651206943314347, 'precision': 0.7651206943314348, 'Guilt_by_Association_precision': 0.11764705882352941, 'Guilt_by_Association_recall': 0.04716981132075472, 'Guilt_by_Association_f1-score': 0.06734006734006734, 'Guilt_by_Association_support': 212.0, 'micro avg_precision': 0.11764705882352941, 'micro avg_recall': 0.04716981132075472, 'micro avg_f1-score': 0.06734006734006734, 'micro avg_support': 212.0, 'macro avg_precision': 0.11764705882352941, 'macro avg_recall': 0.04716981132075472, 'macro avg_f1-score': 0.06734006734006734, 'macro avg_support': 212.0, 'weighted avg_precision': 0.11764705882352941, 'weighted avg_recall': 0.04716981132075472, 'weighted avg_f1-score': 0.06734006734006734, 'weighted avg_support': 212.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 1}, {'micro_f1': 0.7849199891510714, 'precision': 0.7849199891510713, 'Guilt_by_Association_precision': 0.23529411764705882, 'Guilt_by_Association_recall': 0.11173184357541899, 'Guilt_by_Association_f1-score': 0.15151515151515152, 'Guilt_by_Association_support': 179.0, 'micro avg_precision': 0.23529411764705882, 'micro avg_recall': 0.11173184357541899, 'micro avg_f1-score': 0.15151515151515152, 'micro avg_support': 179.0, 'macro avg_precision': 0.23529411764705882, 'macro avg_recall': 0.11173184357541899, 'macro avg_f1-score': 0.15151515151515152, 'macro avg_support': 179.0, 'weighted avg_precision': 0.23529411764705882, 'weighted avg_recall': 0.11173184357541899, 'weighted avg_f1-score': 0.15151515151515152, 'weighted avg_support': 179.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 2}, {'micro_f1': 0.786276105234608, 'precision': 0.7862761052346081, 'Guilt_by_Association_precision': 0.1411764705882353, 'Guilt_by_Association_recall': 0.10619469026548672, 'Guilt_by_Association_f1-score': 0.12121212121212122, 'Guilt_by_Association_support': 113.0, 'micro avg_precision': 0.1411764705882353, 'micro avg_recall': 0.10619469026548672, 'micro avg_f1-score': 0.12121212121212122, 'micro avg_support': 113.0, 'macro avg_precision': 0.1411764705882353, 'macro avg_recall': 0.10619469026548672, 'macro avg_f1-score': 0.12121212121212122, 'macro avg_support': 113.0, 'weighted avg_precision': 0.1411764705882353, 'weighted avg_recall': 0.10619469026548672, 'weighted avg_f1-score': 0.12121212121212122, 'weighted avg_support': 113.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 3}, {'micro_f1': 0.8030919446704639, 'precision': 0.8030919446704637, 'Guilt_by_Association_precision': 0.17647058823529413, 'Guilt_by_Association_recall': 0.13636363636363635, 'Guilt_by_Association_f1-score': 0.15384615384615383, 'Guilt_by_Association_support': 110.0, 'micro avg_precision': 0.17647058823529413, 'micro avg_recall': 0.13636363636363635, 'micro avg_f1-score': 0.15384615384615383, 'micro avg_support': 110.0, 'macro avg_precision': 0.17647058823529413, 'macro avg_recall': 0.13636363636363635, 'macro avg_f1-score': 0.15384615384615383, 'macro avg_support': 110.0, 'weighted avg_precision': 0.17647058823529413, 'weighted avg_recall': 0.13636363636363635, 'weighted avg_f1-score': 0.15384615384615383, 'weighted avg_support': 110.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 4}]}
Best model updated: current epoch macro f1 = 0.15384615384615383
{'micro_f1': 0.7914293463520478, 'precision': 0.7914293463520478, 'Guilt_by_Association_precision': 0.2235294117647059, 'Guilt_by_Association_recall': 0.12258064516129032, 'Guilt_by_Association_f1-score': 0.15833333333333333, 'Guilt_by_Association_support': 155.0, 'micro avg_precision': 0.2235294117647059, 'micro avg_recall': 0.12258064516129032, 'micro avg_f1-score': 0.15833333333333333, 'micro avg_support': 155.0, 'macro avg_precision': 0.2235294117647059, 'macro avg_recall': 0.12258064516129032, 'macro avg_f1-score': 0.15833333333333333, 'macro avg_support': 155.0, 'weighted avg_precision': 0.2235294117647059, 'weighted avg_recall': 0.12258064516129032, 'weighted avg_f1-score': 0.15833333333333333, 'weighted avg_support': 155.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 5}
{'results': [{'micro_f1': 0.7542717656631408, 'precision': 0.7542717656631408, 'Guilt_by_Association_precision': 0.011764705882352941, 'Guilt_by_Association_recall': 0.006622516556291391, 'Guilt_by_Association_f1-score': 0.00847457627118644, 'Guilt_by_Association_support': 151.0, 'micro avg_precision': 0.011764705882352941, 'micro avg_recall': 0.006622516556291391, 'micro avg_f1-score': 0.00847457627118644, 'micro avg_support': 151.0, 'macro avg_precision': 0.011764705882352941, 'macro avg_recall': 0.006622516556291391, 'macro avg_f1-score': 0.00847457627118644, 'macro avg_support': 151.0, 'weighted avg_precision': 0.011764705882352941, 'weighted avg_recall': 0.006622516556291391, 'weighted avg_f1-score': 0.00847457627118644, 'weighted avg_support': 151.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 0}, {'micro_f1': 0.7651206943314347, 'precision': 0.7651206943314348, 'Guilt_by_Association_precision': 0.11764705882352941, 'Guilt_by_Association_recall': 0.04716981132075472, 'Guilt_by_Association_f1-score': 0.06734006734006734, 'Guilt_by_Association_support': 212.0, 'micro avg_precision': 0.11764705882352941, 'micro avg_recall': 0.04716981132075472, 'micro avg_f1-score': 0.06734006734006734, 'micro avg_support': 212.0, 'macro avg_precision': 0.11764705882352941, 'macro avg_recall': 0.04716981132075472, 'macro avg_f1-score': 0.06734006734006734, 'macro avg_support': 212.0, 'weighted avg_precision': 0.11764705882352941, 'weighted avg_recall': 0.04716981132075472, 'weighted avg_f1-score': 0.06734006734006734, 'weighted avg_support': 212.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 1}, {'micro_f1': 0.7849199891510714, 'precision': 0.7849199891510713, 'Guilt_by_Association_precision': 0.23529411764705882, 'Guilt_by_Association_recall': 0.11173184357541899, 'Guilt_by_Association_f1-score': 0.15151515151515152, 'Guilt_by_Association_support': 179.0, 'micro avg_precision': 0.23529411764705882, 'micro avg_recall': 0.11173184357541899, 'micro avg_f1-score': 0.15151515151515152, 'micro avg_support': 179.0, 'macro avg_precision': 0.23529411764705882, 'macro avg_recall': 0.11173184357541899, 'macro avg_f1-score': 0.15151515151515152, 'macro avg_support': 179.0, 'weighted avg_precision': 0.23529411764705882, 'weighted avg_recall': 0.11173184357541899, 'weighted avg_f1-score': 0.15151515151515152, 'weighted avg_support': 179.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 2}, {'micro_f1': 0.786276105234608, 'precision': 0.7862761052346081, 'Guilt_by_Association_precision': 0.1411764705882353, 'Guilt_by_Association_recall': 0.10619469026548672, 'Guilt_by_Association_f1-score': 0.12121212121212122, 'Guilt_by_Association_support': 113.0, 'micro avg_precision': 0.1411764705882353, 'micro avg_recall': 0.10619469026548672, 'micro avg_f1-score': 0.12121212121212122, 'micro avg_support': 113.0, 'macro avg_precision': 0.1411764705882353, 'macro avg_recall': 0.10619469026548672, 'macro avg_f1-score': 0.12121212121212122, 'macro avg_support': 113.0, 'weighted avg_precision': 0.1411764705882353, 'weighted avg_recall': 0.10619469026548672, 'weighted avg_f1-score': 0.12121212121212122, 'weighted avg_support': 113.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 3}, {'micro_f1': 0.8030919446704639, 'precision': 0.8030919446704637, 'Guilt_by_Association_precision': 0.17647058823529413, 'Guilt_by_Association_recall': 0.13636363636363635, 'Guilt_by_Association_f1-score': 0.15384615384615383, 'Guilt_by_Association_support': 110.0, 'micro avg_precision': 0.17647058823529413, 'micro avg_recall': 0.13636363636363635, 'micro avg_f1-score': 0.15384615384615383, 'micro avg_support': 110.0, 'macro avg_precision': 0.17647058823529413, 'macro avg_recall': 0.13636363636363635, 'macro avg_f1-score': 0.15384615384615383, 'macro avg_support': 110.0, 'weighted avg_precision': 0.17647058823529413, 'weighted avg_recall': 0.13636363636363635, 'weighted avg_f1-score': 0.15384615384615383, 'weighted avg_support': 110.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 4}, {'micro_f1': 0.7914293463520478, 'precision': 0.7914293463520478, 'Guilt_by_Association_precision': 0.2235294117647059, 'Guilt_by_Association_recall': 0.12258064516129032, 'Guilt_by_Association_f1-score': 0.15833333333333333, 'Guilt_by_Association_support': 155.0, 'micro avg_precision': 0.2235294117647059, 'micro avg_recall': 0.12258064516129032, 'micro avg_f1-score': 0.15833333333333333, 'micro avg_support': 155.0, 'macro avg_precision': 0.2235294117647059, 'macro avg_recall': 0.12258064516129032, 'macro avg_f1-score': 0.15833333333333333, 'macro avg_support': 155.0, 'weighted avg_precision': 0.2235294117647059, 'weighted avg_recall': 0.12258064516129032, 'weighted avg_f1-score': 0.15833333333333333, 'weighted avg_support': 155.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 5}]}
Best model updated: current epoch macro f1 = 0.15833333333333333
{'micro_f1': 0.7727149443992406, 'precision': 0.7727149443992406, 'Guilt_by_Association_precision': 0.3058823529411765, 'Guilt_by_Association_recall': 0.15950920245398773, 'Guilt_by_Association_f1-score': 0.20967741935483875, 'Guilt_by_Association_support': 163.0, 'micro avg_precision': 0.3058823529411765, 'micro avg_recall': 0.15950920245398773, 'micro avg_f1-score': 0.20967741935483875, 'micro avg_support': 163.0, 'macro avg_precision': 0.3058823529411765, 'macro avg_recall': 0.15950920245398773, 'macro avg_f1-score': 0.20967741935483875, 'macro avg_support': 163.0, 'weighted avg_precision': 0.3058823529411765, 'weighted avg_recall': 0.15950920245398773, 'weighted avg_f1-score': 0.20967741935483877, 'weighted avg_support': 163.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 6}
{'results': [{'micro_f1': 0.7542717656631408, 'precision': 0.7542717656631408, 'Guilt_by_Association_precision': 0.011764705882352941, 'Guilt_by_Association_recall': 0.006622516556291391, 'Guilt_by_Association_f1-score': 0.00847457627118644, 'Guilt_by_Association_support': 151.0, 'micro avg_precision': 0.011764705882352941, 'micro avg_recall': 0.006622516556291391, 'micro avg_f1-score': 0.00847457627118644, 'micro avg_support': 151.0, 'macro avg_precision': 0.011764705882352941, 'macro avg_recall': 0.006622516556291391, 'macro avg_f1-score': 0.00847457627118644, 'macro avg_support': 151.0, 'weighted avg_precision': 0.011764705882352941, 'weighted avg_recall': 0.006622516556291391, 'weighted avg_f1-score': 0.00847457627118644, 'weighted avg_support': 151.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 0}, {'micro_f1': 0.7651206943314347, 'precision': 0.7651206943314348, 'Guilt_by_Association_precision': 0.11764705882352941, 'Guilt_by_Association_recall': 0.04716981132075472, 'Guilt_by_Association_f1-score': 0.06734006734006734, 'Guilt_by_Association_support': 212.0, 'micro avg_precision': 0.11764705882352941, 'micro avg_recall': 0.04716981132075472, 'micro avg_f1-score': 0.06734006734006734, 'micro avg_support': 212.0, 'macro avg_precision': 0.11764705882352941, 'macro avg_recall': 0.04716981132075472, 'macro avg_f1-score': 0.06734006734006734, 'macro avg_support': 212.0, 'weighted avg_precision': 0.11764705882352941, 'weighted avg_recall': 0.04716981132075472, 'weighted avg_f1-score': 0.06734006734006734, 'weighted avg_support': 212.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 1}, {'micro_f1': 0.7849199891510714, 'precision': 0.7849199891510713, 'Guilt_by_Association_precision': 0.23529411764705882, 'Guilt_by_Association_recall': 0.11173184357541899, 'Guilt_by_Association_f1-score': 0.15151515151515152, 'Guilt_by_Association_support': 179.0, 'micro avg_precision': 0.23529411764705882, 'micro avg_recall': 0.11173184357541899, 'micro avg_f1-score': 0.15151515151515152, 'micro avg_support': 179.0, 'macro avg_precision': 0.23529411764705882, 'macro avg_recall': 0.11173184357541899, 'macro avg_f1-score': 0.15151515151515152, 'macro avg_support': 179.0, 'weighted avg_precision': 0.23529411764705882, 'weighted avg_recall': 0.11173184357541899, 'weighted avg_f1-score': 0.15151515151515152, 'weighted avg_support': 179.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 2}, {'micro_f1': 0.786276105234608, 'precision': 0.7862761052346081, 'Guilt_by_Association_precision': 0.1411764705882353, 'Guilt_by_Association_recall': 0.10619469026548672, 'Guilt_by_Association_f1-score': 0.12121212121212122, 'Guilt_by_Association_support': 113.0, 'micro avg_precision': 0.1411764705882353, 'micro avg_recall': 0.10619469026548672, 'micro avg_f1-score': 0.12121212121212122, 'micro avg_support': 113.0, 'macro avg_precision': 0.1411764705882353, 'macro avg_recall': 0.10619469026548672, 'macro avg_f1-score': 0.12121212121212122, 'macro avg_support': 113.0, 'weighted avg_precision': 0.1411764705882353, 'weighted avg_recall': 0.10619469026548672, 'weighted avg_f1-score': 0.12121212121212122, 'weighted avg_support': 113.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 3}, {'micro_f1': 0.8030919446704639, 'precision': 0.8030919446704637, 'Guilt_by_Association_precision': 0.17647058823529413, 'Guilt_by_Association_recall': 0.13636363636363635, 'Guilt_by_Association_f1-score': 0.15384615384615383, 'Guilt_by_Association_support': 110.0, 'micro avg_precision': 0.17647058823529413, 'micro avg_recall': 0.13636363636363635, 'micro avg_f1-score': 0.15384615384615383, 'micro avg_support': 110.0, 'macro avg_precision': 0.17647058823529413, 'macro avg_recall': 0.13636363636363635, 'macro avg_f1-score': 0.15384615384615383, 'macro avg_support': 110.0, 'weighted avg_precision': 0.17647058823529413, 'weighted avg_recall': 0.13636363636363635, 'weighted avg_f1-score': 0.15384615384615383, 'weighted avg_support': 110.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 4}, {'micro_f1': 0.7914293463520478, 'precision': 0.7914293463520478, 'Guilt_by_Association_precision': 0.2235294117647059, 'Guilt_by_Association_recall': 0.12258064516129032, 'Guilt_by_Association_f1-score': 0.15833333333333333, 'Guilt_by_Association_support': 155.0, 'micro avg_precision': 0.2235294117647059, 'micro avg_recall': 0.12258064516129032, 'micro avg_f1-score': 0.15833333333333333, 'micro avg_support': 155.0, 'macro avg_precision': 0.2235294117647059, 'macro avg_recall': 0.12258064516129032, 'macro avg_f1-score': 0.15833333333333333, 'macro avg_support': 155.0, 'weighted avg_precision': 0.2235294117647059, 'weighted avg_recall': 0.12258064516129032, 'weighted avg_f1-score': 0.15833333333333333, 'weighted avg_support': 155.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 5}, {'micro_f1': 0.7727149443992406, 'precision': 0.7727149443992406, 'Guilt_by_Association_precision': 0.3058823529411765, 'Guilt_by_Association_recall': 0.15950920245398773, 'Guilt_by_Association_f1-score': 0.20967741935483875, 'Guilt_by_Association_support': 163.0, 'micro avg_precision': 0.3058823529411765, 'micro avg_recall': 0.15950920245398773, 'micro avg_f1-score': 0.20967741935483875, 'micro avg_support': 163.0, 'macro avg_precision': 0.3058823529411765, 'macro avg_recall': 0.15950920245398773, 'macro avg_f1-score': 0.20967741935483875, 'macro avg_support': 163.0, 'weighted avg_precision': 0.3058823529411765, 'weighted avg_recall': 0.15950920245398773, 'weighted avg_f1-score': 0.20967741935483877, 'weighted avg_support': 163.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 6}]}
Best model updated: current epoch macro f1 = 0.20967741935483875
{'micro_f1': 0.7719012747491185, 'precision': 0.7719012747491185, 'Guilt_by_Association_precision': 0.3058823529411765, 'Guilt_by_Association_recall': 0.16352201257861634, 'Guilt_by_Association_f1-score': 0.21311475409836067, 'Guilt_by_Association_support': 159.0, 'micro avg_precision': 0.3058823529411765, 'micro avg_recall': 0.16352201257861634, 'micro avg_f1-score': 0.21311475409836067, 'micro avg_support': 159.0, 'macro avg_precision': 0.3058823529411765, 'macro avg_recall': 0.16352201257861634, 'macro avg_f1-score': 0.21311475409836067, 'macro avg_support': 159.0, 'weighted avg_precision': 0.3058823529411765, 'weighted avg_recall': 0.16352201257861634, 'weighted avg_f1-score': 0.21311475409836064, 'weighted avg_support': 159.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 7}
{'results': [{'micro_f1': 0.7542717656631408, 'precision': 0.7542717656631408, 'Guilt_by_Association_precision': 0.011764705882352941, 'Guilt_by_Association_recall': 0.006622516556291391, 'Guilt_by_Association_f1-score': 0.00847457627118644, 'Guilt_by_Association_support': 151.0, 'micro avg_precision': 0.011764705882352941, 'micro avg_recall': 0.006622516556291391, 'micro avg_f1-score': 0.00847457627118644, 'micro avg_support': 151.0, 'macro avg_precision': 0.011764705882352941, 'macro avg_recall': 0.006622516556291391, 'macro avg_f1-score': 0.00847457627118644, 'macro avg_support': 151.0, 'weighted avg_precision': 0.011764705882352941, 'weighted avg_recall': 0.006622516556291391, 'weighted avg_f1-score': 0.00847457627118644, 'weighted avg_support': 151.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 0}, {'micro_f1': 0.7651206943314347, 'precision': 0.7651206943314348, 'Guilt_by_Association_precision': 0.11764705882352941, 'Guilt_by_Association_recall': 0.04716981132075472, 'Guilt_by_Association_f1-score': 0.06734006734006734, 'Guilt_by_Association_support': 212.0, 'micro avg_precision': 0.11764705882352941, 'micro avg_recall': 0.04716981132075472, 'micro avg_f1-score': 0.06734006734006734, 'micro avg_support': 212.0, 'macro avg_precision': 0.11764705882352941, 'macro avg_recall': 0.04716981132075472, 'macro avg_f1-score': 0.06734006734006734, 'macro avg_support': 212.0, 'weighted avg_precision': 0.11764705882352941, 'weighted avg_recall': 0.04716981132075472, 'weighted avg_f1-score': 0.06734006734006734, 'weighted avg_support': 212.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 1}, {'micro_f1': 0.7849199891510714, 'precision': 0.7849199891510713, 'Guilt_by_Association_precision': 0.23529411764705882, 'Guilt_by_Association_recall': 0.11173184357541899, 'Guilt_by_Association_f1-score': 0.15151515151515152, 'Guilt_by_Association_support': 179.0, 'micro avg_precision': 0.23529411764705882, 'micro avg_recall': 0.11173184357541899, 'micro avg_f1-score': 0.15151515151515152, 'micro avg_support': 179.0, 'macro avg_precision': 0.23529411764705882, 'macro avg_recall': 0.11173184357541899, 'macro avg_f1-score': 0.15151515151515152, 'macro avg_support': 179.0, 'weighted avg_precision': 0.23529411764705882, 'weighted avg_recall': 0.11173184357541899, 'weighted avg_f1-score': 0.15151515151515152, 'weighted avg_support': 179.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 2}, {'micro_f1': 0.786276105234608, 'precision': 0.7862761052346081, 'Guilt_by_Association_precision': 0.1411764705882353, 'Guilt_by_Association_recall': 0.10619469026548672, 'Guilt_by_Association_f1-score': 0.12121212121212122, 'Guilt_by_Association_support': 113.0, 'micro avg_precision': 0.1411764705882353, 'micro avg_recall': 0.10619469026548672, 'micro avg_f1-score': 0.12121212121212122, 'micro avg_support': 113.0, 'macro avg_precision': 0.1411764705882353, 'macro avg_recall': 0.10619469026548672, 'macro avg_f1-score': 0.12121212121212122, 'macro avg_support': 113.0, 'weighted avg_precision': 0.1411764705882353, 'weighted avg_recall': 0.10619469026548672, 'weighted avg_f1-score': 0.12121212121212122, 'weighted avg_support': 113.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 3}, {'micro_f1': 0.8030919446704639, 'precision': 0.8030919446704637, 'Guilt_by_Association_precision': 0.17647058823529413, 'Guilt_by_Association_recall': 0.13636363636363635, 'Guilt_by_Association_f1-score': 0.15384615384615383, 'Guilt_by_Association_support': 110.0, 'micro avg_precision': 0.17647058823529413, 'micro avg_recall': 0.13636363636363635, 'micro avg_f1-score': 0.15384615384615383, 'micro avg_support': 110.0, 'macro avg_precision': 0.17647058823529413, 'macro avg_recall': 0.13636363636363635, 'macro avg_f1-score': 0.15384615384615383, 'macro avg_support': 110.0, 'weighted avg_precision': 0.17647058823529413, 'weighted avg_recall': 0.13636363636363635, 'weighted avg_f1-score': 0.15384615384615383, 'weighted avg_support': 110.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 4}, {'micro_f1': 0.7914293463520478, 'precision': 0.7914293463520478, 'Guilt_by_Association_precision': 0.2235294117647059, 'Guilt_by_Association_recall': 0.12258064516129032, 'Guilt_by_Association_f1-score': 0.15833333333333333, 'Guilt_by_Association_support': 155.0, 'micro avg_precision': 0.2235294117647059, 'micro avg_recall': 0.12258064516129032, 'micro avg_f1-score': 0.15833333333333333, 'micro avg_support': 155.0, 'macro avg_precision': 0.2235294117647059, 'macro avg_recall': 0.12258064516129032, 'macro avg_f1-score': 0.15833333333333333, 'macro avg_support': 155.0, 'weighted avg_precision': 0.2235294117647059, 'weighted avg_recall': 0.12258064516129032, 'weighted avg_f1-score': 0.15833333333333333, 'weighted avg_support': 155.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 5}, {'micro_f1': 0.7727149443992406, 'precision': 0.7727149443992406, 'Guilt_by_Association_precision': 0.3058823529411765, 'Guilt_by_Association_recall': 0.15950920245398773, 'Guilt_by_Association_f1-score': 0.20967741935483875, 'Guilt_by_Association_support': 163.0, 'micro avg_precision': 0.3058823529411765, 'micro avg_recall': 0.15950920245398773, 'micro avg_f1-score': 0.20967741935483875, 'micro avg_support': 163.0, 'macro avg_precision': 0.3058823529411765, 'macro avg_recall': 0.15950920245398773, 'macro avg_f1-score': 0.20967741935483875, 'macro avg_support': 163.0, 'weighted avg_precision': 0.3058823529411765, 'weighted avg_recall': 0.15950920245398773, 'weighted avg_f1-score': 0.20967741935483877, 'weighted avg_support': 163.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 6}, {'micro_f1': 0.7719012747491185, 'precision': 0.7719012747491185, 'Guilt_by_Association_precision': 0.3058823529411765, 'Guilt_by_Association_recall': 0.16352201257861634, 'Guilt_by_Association_f1-score': 0.21311475409836067, 'Guilt_by_Association_support': 159.0, 'micro avg_precision': 0.3058823529411765, 'micro avg_recall': 0.16352201257861634, 'micro avg_f1-score': 0.21311475409836067, 'micro avg_support': 159.0, 'macro avg_precision': 0.3058823529411765, 'macro avg_recall': 0.16352201257861634, 'macro avg_f1-score': 0.21311475409836067, 'macro avg_support': 159.0, 'weighted avg_precision': 0.3058823529411765, 'weighted avg_recall': 0.16352201257861634, 'weighted avg_f1-score': 0.21311475409836064, 'weighted avg_support': 159.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 7}]}
Best model updated: current epoch macro f1 = 0.21311475409836067
{'micro_f1': 0.7849199891510714, 'precision': 0.7849199891510713, 'Guilt_by_Association_precision': 0.25882352941176473, 'Guilt_by_Association_recall': 0.16417910447761194, 'Guilt_by_Association_f1-score': 0.20091324200913244, 'Guilt_by_Association_support': 134.0, 'micro avg_precision': 0.25882352941176473, 'micro avg_recall': 0.16417910447761194, 'micro avg_f1-score': 0.20091324200913244, 'micro avg_support': 134.0, 'macro avg_precision': 0.25882352941176473, 'macro avg_recall': 0.16417910447761194, 'macro avg_f1-score': 0.20091324200913244, 'macro avg_support': 134.0, 'weighted avg_precision': 0.25882352941176473, 'weighted avg_recall': 0.16417910447761194, 'weighted avg_f1-score': 0.20091324200913244, 'weighted avg_support': 134.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 8}
{'results': [{'micro_f1': 0.7542717656631408, 'precision': 0.7542717656631408, 'Guilt_by_Association_precision': 0.011764705882352941, 'Guilt_by_Association_recall': 0.006622516556291391, 'Guilt_by_Association_f1-score': 0.00847457627118644, 'Guilt_by_Association_support': 151.0, 'micro avg_precision': 0.011764705882352941, 'micro avg_recall': 0.006622516556291391, 'micro avg_f1-score': 0.00847457627118644, 'micro avg_support': 151.0, 'macro avg_precision': 0.011764705882352941, 'macro avg_recall': 0.006622516556291391, 'macro avg_f1-score': 0.00847457627118644, 'macro avg_support': 151.0, 'weighted avg_precision': 0.011764705882352941, 'weighted avg_recall': 0.006622516556291391, 'weighted avg_f1-score': 0.00847457627118644, 'weighted avg_support': 151.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 0}, {'micro_f1': 0.7651206943314347, 'precision': 0.7651206943314348, 'Guilt_by_Association_precision': 0.11764705882352941, 'Guilt_by_Association_recall': 0.04716981132075472, 'Guilt_by_Association_f1-score': 0.06734006734006734, 'Guilt_by_Association_support': 212.0, 'micro avg_precision': 0.11764705882352941, 'micro avg_recall': 0.04716981132075472, 'micro avg_f1-score': 0.06734006734006734, 'micro avg_support': 212.0, 'macro avg_precision': 0.11764705882352941, 'macro avg_recall': 0.04716981132075472, 'macro avg_f1-score': 0.06734006734006734, 'macro avg_support': 212.0, 'weighted avg_precision': 0.11764705882352941, 'weighted avg_recall': 0.04716981132075472, 'weighted avg_f1-score': 0.06734006734006734, 'weighted avg_support': 212.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 1}, {'micro_f1': 0.7849199891510714, 'precision': 0.7849199891510713, 'Guilt_by_Association_precision': 0.23529411764705882, 'Guilt_by_Association_recall': 0.11173184357541899, 'Guilt_by_Association_f1-score': 0.15151515151515152, 'Guilt_by_Association_support': 179.0, 'micro avg_precision': 0.23529411764705882, 'micro avg_recall': 0.11173184357541899, 'micro avg_f1-score': 0.15151515151515152, 'micro avg_support': 179.0, 'macro avg_precision': 0.23529411764705882, 'macro avg_recall': 0.11173184357541899, 'macro avg_f1-score': 0.15151515151515152, 'macro avg_support': 179.0, 'weighted avg_precision': 0.23529411764705882, 'weighted avg_recall': 0.11173184357541899, 'weighted avg_f1-score': 0.15151515151515152, 'weighted avg_support': 179.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 2}, {'micro_f1': 0.786276105234608, 'precision': 0.7862761052346081, 'Guilt_by_Association_precision': 0.1411764705882353, 'Guilt_by_Association_recall': 0.10619469026548672, 'Guilt_by_Association_f1-score': 0.12121212121212122, 'Guilt_by_Association_support': 113.0, 'micro avg_precision': 0.1411764705882353, 'micro avg_recall': 0.10619469026548672, 'micro avg_f1-score': 0.12121212121212122, 'micro avg_support': 113.0, 'macro avg_precision': 0.1411764705882353, 'macro avg_recall': 0.10619469026548672, 'macro avg_f1-score': 0.12121212121212122, 'macro avg_support': 113.0, 'weighted avg_precision': 0.1411764705882353, 'weighted avg_recall': 0.10619469026548672, 'weighted avg_f1-score': 0.12121212121212122, 'weighted avg_support': 113.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 3}, {'micro_f1': 0.8030919446704639, 'precision': 0.8030919446704637, 'Guilt_by_Association_precision': 0.17647058823529413, 'Guilt_by_Association_recall': 0.13636363636363635, 'Guilt_by_Association_f1-score': 0.15384615384615383, 'Guilt_by_Association_support': 110.0, 'micro avg_precision': 0.17647058823529413, 'micro avg_recall': 0.13636363636363635, 'micro avg_f1-score': 0.15384615384615383, 'micro avg_support': 110.0, 'macro avg_precision': 0.17647058823529413, 'macro avg_recall': 0.13636363636363635, 'macro avg_f1-score': 0.15384615384615383, 'macro avg_support': 110.0, 'weighted avg_precision': 0.17647058823529413, 'weighted avg_recall': 0.13636363636363635, 'weighted avg_f1-score': 0.15384615384615383, 'weighted avg_support': 110.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 4}, {'micro_f1': 0.7914293463520478, 'precision': 0.7914293463520478, 'Guilt_by_Association_precision': 0.2235294117647059, 'Guilt_by_Association_recall': 0.12258064516129032, 'Guilt_by_Association_f1-score': 0.15833333333333333, 'Guilt_by_Association_support': 155.0, 'micro avg_precision': 0.2235294117647059, 'micro avg_recall': 0.12258064516129032, 'micro avg_f1-score': 0.15833333333333333, 'micro avg_support': 155.0, 'macro avg_precision': 0.2235294117647059, 'macro avg_recall': 0.12258064516129032, 'macro avg_f1-score': 0.15833333333333333, 'macro avg_support': 155.0, 'weighted avg_precision': 0.2235294117647059, 'weighted avg_recall': 0.12258064516129032, 'weighted avg_f1-score': 0.15833333333333333, 'weighted avg_support': 155.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 5}, {'micro_f1': 0.7727149443992406, 'precision': 0.7727149443992406, 'Guilt_by_Association_precision': 0.3058823529411765, 'Guilt_by_Association_recall': 0.15950920245398773, 'Guilt_by_Association_f1-score': 0.20967741935483875, 'Guilt_by_Association_support': 163.0, 'micro avg_precision': 0.3058823529411765, 'micro avg_recall': 0.15950920245398773, 'micro avg_f1-score': 0.20967741935483875, 'micro avg_support': 163.0, 'macro avg_precision': 0.3058823529411765, 'macro avg_recall': 0.15950920245398773, 'macro avg_f1-score': 0.20967741935483875, 'macro avg_support': 163.0, 'weighted avg_precision': 0.3058823529411765, 'weighted avg_recall': 0.15950920245398773, 'weighted avg_f1-score': 0.20967741935483877, 'weighted avg_support': 163.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 6}, {'micro_f1': 0.7719012747491185, 'precision': 0.7719012747491185, 'Guilt_by_Association_precision': 0.3058823529411765, 'Guilt_by_Association_recall': 0.16352201257861634, 'Guilt_by_Association_f1-score': 0.21311475409836067, 'Guilt_by_Association_support': 159.0, 'micro avg_precision': 0.3058823529411765, 'micro avg_recall': 0.16352201257861634, 'micro avg_f1-score': 0.21311475409836067, 'micro avg_support': 159.0, 'macro avg_precision': 0.3058823529411765, 'macro avg_recall': 0.16352201257861634, 'macro avg_f1-score': 0.21311475409836067, 'macro avg_support': 159.0, 'weighted avg_precision': 0.3058823529411765, 'weighted avg_recall': 0.16352201257861634, 'weighted avg_f1-score': 0.21311475409836064, 'weighted avg_support': 159.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 7}, {'micro_f1': 0.7849199891510714, 'precision': 0.7849199891510713, 'Guilt_by_Association_precision': 0.25882352941176473, 'Guilt_by_Association_recall': 0.16417910447761194, 'Guilt_by_Association_f1-score': 0.20091324200913244, 'Guilt_by_Association_support': 134.0, 'micro avg_precision': 0.25882352941176473, 'micro avg_recall': 0.16417910447761194, 'micro avg_f1-score': 0.20091324200913244, 'micro avg_support': 134.0, 'macro avg_precision': 0.25882352941176473, 'macro avg_recall': 0.16417910447761194, 'macro avg_f1-score': 0.20091324200913244, 'macro avg_support': 134.0, 'weighted avg_precision': 0.25882352941176473, 'weighted avg_recall': 0.16417910447761194, 'weighted avg_f1-score': 0.20091324200913244, 'weighted avg_support': 134.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 8}]}
{'micro_f1': 0.735828586927041, 'precision': 0.735828586927041, 'Guilt_by_Association_precision': 0.11764705882352941, 'Guilt_by_Association_recall': 0.14492753623188406, 'Guilt_by_Association_f1-score': 0.12987012987012989, 'Guilt_by_Association_support': 69.0, 'micro avg_precision': 0.11764705882352941, 'micro avg_recall': 0.14492753623188406, 'micro avg_f1-score': 0.12987012987012989, 'micro avg_support': 69.0, 'macro avg_precision': 0.11764705882352941, 'macro avg_recall': 0.14492753623188406, 'macro avg_f1-score': 0.12987012987012989, 'macro avg_support': 69.0, 'weighted avg_precision': 0.11764705882352941, 'weighted avg_recall': 0.14492753623188406, 'weighted avg_f1-score': 0.12987012987012989, 'weighted avg_support': 69.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 9}
{'results': [{'micro_f1': 0.7542717656631408, 'precision': 0.7542717656631408, 'Guilt_by_Association_precision': 0.011764705882352941, 'Guilt_by_Association_recall': 0.006622516556291391, 'Guilt_by_Association_f1-score': 0.00847457627118644, 'Guilt_by_Association_support': 151.0, 'micro avg_precision': 0.011764705882352941, 'micro avg_recall': 0.006622516556291391, 'micro avg_f1-score': 0.00847457627118644, 'micro avg_support': 151.0, 'macro avg_precision': 0.011764705882352941, 'macro avg_recall': 0.006622516556291391, 'macro avg_f1-score': 0.00847457627118644, 'macro avg_support': 151.0, 'weighted avg_precision': 0.011764705882352941, 'weighted avg_recall': 0.006622516556291391, 'weighted avg_f1-score': 0.00847457627118644, 'weighted avg_support': 151.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 0}, {'micro_f1': 0.7651206943314347, 'precision': 0.7651206943314348, 'Guilt_by_Association_precision': 0.11764705882352941, 'Guilt_by_Association_recall': 0.04716981132075472, 'Guilt_by_Association_f1-score': 0.06734006734006734, 'Guilt_by_Association_support': 212.0, 'micro avg_precision': 0.11764705882352941, 'micro avg_recall': 0.04716981132075472, 'micro avg_f1-score': 0.06734006734006734, 'micro avg_support': 212.0, 'macro avg_precision': 0.11764705882352941, 'macro avg_recall': 0.04716981132075472, 'macro avg_f1-score': 0.06734006734006734, 'macro avg_support': 212.0, 'weighted avg_precision': 0.11764705882352941, 'weighted avg_recall': 0.04716981132075472, 'weighted avg_f1-score': 0.06734006734006734, 'weighted avg_support': 212.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 1}, {'micro_f1': 0.7849199891510714, 'precision': 0.7849199891510713, 'Guilt_by_Association_precision': 0.23529411764705882, 'Guilt_by_Association_recall': 0.11173184357541899, 'Guilt_by_Association_f1-score': 0.15151515151515152, 'Guilt_by_Association_support': 179.0, 'micro avg_precision': 0.23529411764705882, 'micro avg_recall': 0.11173184357541899, 'micro avg_f1-score': 0.15151515151515152, 'micro avg_support': 179.0, 'macro avg_precision': 0.23529411764705882, 'macro avg_recall': 0.11173184357541899, 'macro avg_f1-score': 0.15151515151515152, 'macro avg_support': 179.0, 'weighted avg_precision': 0.23529411764705882, 'weighted avg_recall': 0.11173184357541899, 'weighted avg_f1-score': 0.15151515151515152, 'weighted avg_support': 179.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 2}, {'micro_f1': 0.786276105234608, 'precision': 0.7862761052346081, 'Guilt_by_Association_precision': 0.1411764705882353, 'Guilt_by_Association_recall': 0.10619469026548672, 'Guilt_by_Association_f1-score': 0.12121212121212122, 'Guilt_by_Association_support': 113.0, 'micro avg_precision': 0.1411764705882353, 'micro avg_recall': 0.10619469026548672, 'micro avg_f1-score': 0.12121212121212122, 'micro avg_support': 113.0, 'macro avg_precision': 0.1411764705882353, 'macro avg_recall': 0.10619469026548672, 'macro avg_f1-score': 0.12121212121212122, 'macro avg_support': 113.0, 'weighted avg_precision': 0.1411764705882353, 'weighted avg_recall': 0.10619469026548672, 'weighted avg_f1-score': 0.12121212121212122, 'weighted avg_support': 113.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 3}, {'micro_f1': 0.8030919446704639, 'precision': 0.8030919446704637, 'Guilt_by_Association_precision': 0.17647058823529413, 'Guilt_by_Association_recall': 0.13636363636363635, 'Guilt_by_Association_f1-score': 0.15384615384615383, 'Guilt_by_Association_support': 110.0, 'micro avg_precision': 0.17647058823529413, 'micro avg_recall': 0.13636363636363635, 'micro avg_f1-score': 0.15384615384615383, 'micro avg_support': 110.0, 'macro avg_precision': 0.17647058823529413, 'macro avg_recall': 0.13636363636363635, 'macro avg_f1-score': 0.15384615384615383, 'macro avg_support': 110.0, 'weighted avg_precision': 0.17647058823529413, 'weighted avg_recall': 0.13636363636363635, 'weighted avg_f1-score': 0.15384615384615383, 'weighted avg_support': 110.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 4}, {'micro_f1': 0.7914293463520478, 'precision': 0.7914293463520478, 'Guilt_by_Association_precision': 0.2235294117647059, 'Guilt_by_Association_recall': 0.12258064516129032, 'Guilt_by_Association_f1-score': 0.15833333333333333, 'Guilt_by_Association_support': 155.0, 'micro avg_precision': 0.2235294117647059, 'micro avg_recall': 0.12258064516129032, 'micro avg_f1-score': 0.15833333333333333, 'micro avg_support': 155.0, 'macro avg_precision': 0.2235294117647059, 'macro avg_recall': 0.12258064516129032, 'macro avg_f1-score': 0.15833333333333333, 'macro avg_support': 155.0, 'weighted avg_precision': 0.2235294117647059, 'weighted avg_recall': 0.12258064516129032, 'weighted avg_f1-score': 0.15833333333333333, 'weighted avg_support': 155.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 5}, {'micro_f1': 0.7727149443992406, 'precision': 0.7727149443992406, 'Guilt_by_Association_precision': 0.3058823529411765, 'Guilt_by_Association_recall': 0.15950920245398773, 'Guilt_by_Association_f1-score': 0.20967741935483875, 'Guilt_by_Association_support': 163.0, 'micro avg_precision': 0.3058823529411765, 'micro avg_recall': 0.15950920245398773, 'micro avg_f1-score': 0.20967741935483875, 'micro avg_support': 163.0, 'macro avg_precision': 0.3058823529411765, 'macro avg_recall': 0.15950920245398773, 'macro avg_f1-score': 0.20967741935483875, 'macro avg_support': 163.0, 'weighted avg_precision': 0.3058823529411765, 'weighted avg_recall': 0.15950920245398773, 'weighted avg_f1-score': 0.20967741935483877, 'weighted avg_support': 163.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 6}, {'micro_f1': 0.7719012747491185, 'precision': 0.7719012747491185, 'Guilt_by_Association_precision': 0.3058823529411765, 'Guilt_by_Association_recall': 0.16352201257861634, 'Guilt_by_Association_f1-score': 0.21311475409836067, 'Guilt_by_Association_support': 159.0, 'micro avg_precision': 0.3058823529411765, 'micro avg_recall': 0.16352201257861634, 'micro avg_f1-score': 0.21311475409836067, 'micro avg_support': 159.0, 'macro avg_precision': 0.3058823529411765, 'macro avg_recall': 0.16352201257861634, 'macro avg_f1-score': 0.21311475409836067, 'macro avg_support': 159.0, 'weighted avg_precision': 0.3058823529411765, 'weighted avg_recall': 0.16352201257861634, 'weighted avg_f1-score': 0.21311475409836064, 'weighted avg_support': 159.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 7}, {'micro_f1': 0.7849199891510714, 'precision': 0.7849199891510713, 'Guilt_by_Association_precision': 0.25882352941176473, 'Guilt_by_Association_recall': 0.16417910447761194, 'Guilt_by_Association_f1-score': 0.20091324200913244, 'Guilt_by_Association_support': 134.0, 'micro avg_precision': 0.25882352941176473, 'micro avg_recall': 0.16417910447761194, 'micro avg_f1-score': 0.20091324200913244, 'micro avg_support': 134.0, 'macro avg_precision': 0.25882352941176473, 'macro avg_recall': 0.16417910447761194, 'macro avg_f1-score': 0.20091324200913244, 'macro avg_support': 134.0, 'weighted avg_precision': 0.25882352941176473, 'weighted avg_recall': 0.16417910447761194, 'weighted avg_f1-score': 0.20091324200913244, 'weighted avg_support': 134.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 8}, {'micro_f1': 0.735828586927041, 'precision': 0.735828586927041, 'Guilt_by_Association_precision': 0.11764705882352941, 'Guilt_by_Association_recall': 0.14492753623188406, 'Guilt_by_Association_f1-score': 0.12987012987012989, 'Guilt_by_Association_support': 69.0, 'micro avg_precision': 0.11764705882352941, 'micro avg_recall': 0.14492753623188406, 'micro avg_f1-score': 0.12987012987012989, 'micro avg_support': 69.0, 'macro avg_precision': 0.11764705882352941, 'macro avg_recall': 0.14492753623188406, 'macro avg_f1-score': 0.12987012987012989, 'macro avg_support': 69.0, 'weighted avg_precision': 0.11764705882352941, 'weighted avg_recall': 0.14492753623188406, 'weighted avg_f1-score': 0.12987012987012989, 'weighted avg_support': 69.0, 'O_support': 2332, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 9}]}
Early stopping triggered.
Saving model to directory: ./models/M2/2024-05-13-23-08-48_aug/mdeberta-v3-base_20_ME10_target=Guilt_by_Association_SUBSAMPLED_2024-05-13-23-08-48
Training model no. 21 of 23 for (21, 'Appeal_to_Hypocrisy') persuasion technique...
{'micro_f1': 0.7643256464011181, 'precision': 0.7643256464011181, 'Appeal_to_Hypocrisy_precision': 0.15441176470588236, 'Appeal_to_Hypocrisy_recall': 0.084, 'Appeal_to_Hypocrisy_f1-score': 0.10880829015544041, 'Appeal_to_Hypocrisy_support': 250.0, 'micro avg_precision': 0.15441176470588236, 'micro avg_recall': 0.084, 'micro avg_f1-score': 0.10880829015544041, 'micro avg_support': 250.0, 'macro avg_precision': 0.15441176470588236, 'macro avg_recall': 0.084, 'macro avg_f1-score': 0.10880829015544041, 'macro avg_support': 250.0, 'weighted avg_precision': 0.15441176470588236, 'weighted avg_recall': 0.084, 'weighted avg_f1-score': 0.10880829015544041, 'weighted avg_support': 250.0, 'B-Appeal_to_Hypocrisy_support': 136, 'I-Appeal_to_Hypocrisy_support': 2879, 'O_support': 2709, 'epoch': 0}
{'results': [{'micro_f1': 0.7643256464011181, 'precision': 0.7643256464011181, 'Appeal_to_Hypocrisy_precision': 0.15441176470588236, 'Appeal_to_Hypocrisy_recall': 0.084, 'Appeal_to_Hypocrisy_f1-score': 0.10880829015544041, 'Appeal_to_Hypocrisy_support': 250.0, 'micro avg_precision': 0.15441176470588236, 'micro avg_recall': 0.084, 'micro avg_f1-score': 0.10880829015544041, 'micro avg_support': 250.0, 'macro avg_precision': 0.15441176470588236, 'macro avg_recall': 0.084, 'macro avg_f1-score': 0.10880829015544041, 'macro avg_support': 250.0, 'weighted avg_precision': 0.15441176470588236, 'weighted avg_recall': 0.084, 'weighted avg_f1-score': 0.10880829015544041, 'weighted avg_support': 250.0, 'B-Appeal_to_Hypocrisy_support': 136, 'I-Appeal_to_Hypocrisy_support': 2879, 'O_support': 2709, 'epoch': 0}]}
Best model updated: current epoch macro f1 = 0.10880829015544041
{'micro_f1': 0.7351502445842067, 'precision': 0.7351502445842069, 'Appeal_to_Hypocrisy_precision': 0.0661764705882353, 'Appeal_to_Hypocrisy_recall': 0.037037037037037035, 'Appeal_to_Hypocrisy_f1-score': 0.047493403693931395, 'Appeal_to_Hypocrisy_support': 243.0, 'micro avg_precision': 0.0661764705882353, 'micro avg_recall': 0.037037037037037035, 'micro avg_f1-score': 0.047493403693931395, 'micro avg_support': 243.0, 'macro avg_precision': 0.0661764705882353, 'macro avg_recall': 0.037037037037037035, 'macro avg_f1-score': 0.047493403693931395, 'macro avg_support': 243.0, 'weighted avg_precision': 0.0661764705882353, 'weighted avg_recall': 0.037037037037037035, 'weighted avg_f1-score': 0.047493403693931395, 'weighted avg_support': 243.0, 'B-Appeal_to_Hypocrisy_support': 136, 'I-Appeal_to_Hypocrisy_support': 2879, 'O_support': 2709, 'epoch': 1}
{'results': [{'micro_f1': 0.7643256464011181, 'precision': 0.7643256464011181, 'Appeal_to_Hypocrisy_precision': 0.15441176470588236, 'Appeal_to_Hypocrisy_recall': 0.084, 'Appeal_to_Hypocrisy_f1-score': 0.10880829015544041, 'Appeal_to_Hypocrisy_support': 250.0, 'micro avg_precision': 0.15441176470588236, 'micro avg_recall': 0.084, 'micro avg_f1-score': 0.10880829015544041, 'micro avg_support': 250.0, 'macro avg_precision': 0.15441176470588236, 'macro avg_recall': 0.084, 'macro avg_f1-score': 0.10880829015544041, 'macro avg_support': 250.0, 'weighted avg_precision': 0.15441176470588236, 'weighted avg_recall': 0.084, 'weighted avg_f1-score': 0.10880829015544041, 'weighted avg_support': 250.0, 'B-Appeal_to_Hypocrisy_support': 136, 'I-Appeal_to_Hypocrisy_support': 2879, 'O_support': 2709, 'epoch': 0}, {'micro_f1': 0.7351502445842067, 'precision': 0.7351502445842069, 'Appeal_to_Hypocrisy_precision': 0.0661764705882353, 'Appeal_to_Hypocrisy_recall': 0.037037037037037035, 'Appeal_to_Hypocrisy_f1-score': 0.047493403693931395, 'Appeal_to_Hypocrisy_support': 243.0, 'micro avg_precision': 0.0661764705882353, 'micro avg_recall': 0.037037037037037035, 'micro avg_f1-score': 0.047493403693931395, 'micro avg_support': 243.0, 'macro avg_precision': 0.0661764705882353, 'macro avg_recall': 0.037037037037037035, 'macro avg_f1-score': 0.047493403693931395, 'macro avg_support': 243.0, 'weighted avg_precision': 0.0661764705882353, 'weighted avg_recall': 0.037037037037037035, 'weighted avg_f1-score': 0.047493403693931395, 'weighted avg_support': 243.0, 'B-Appeal_to_Hypocrisy_support': 136, 'I-Appeal_to_Hypocrisy_support': 2879, 'O_support': 2709, 'epoch': 1}]}
{'micro_f1': 0.7091194968553459, 'precision': 0.7091194968553459, 'Appeal_to_Hypocrisy_precision': 0.08088235294117647, 'Appeal_to_Hypocrisy_recall': 0.05116279069767442, 'Appeal_to_Hypocrisy_f1-score': 0.06267806267806268, 'Appeal_to_Hypocrisy_support': 215.0, 'micro avg_precision': 0.08088235294117647, 'micro avg_recall': 0.05116279069767442, 'micro avg_f1-score': 0.06267806267806268, 'micro avg_support': 215.0, 'macro avg_precision': 0.08088235294117647, 'macro avg_recall': 0.05116279069767442, 'macro avg_f1-score': 0.06267806267806268, 'macro avg_support': 215.0, 'weighted avg_precision': 0.08088235294117647, 'weighted avg_recall': 0.05116279069767442, 'weighted avg_f1-score': 0.06267806267806268, 'weighted avg_support': 215.0, 'B-Appeal_to_Hypocrisy_support': 136, 'I-Appeal_to_Hypocrisy_support': 2879, 'O_support': 2709, 'epoch': 2}
{'results': [{'micro_f1': 0.7643256464011181, 'precision': 0.7643256464011181, 'Appeal_to_Hypocrisy_precision': 0.15441176470588236, 'Appeal_to_Hypocrisy_recall': 0.084, 'Appeal_to_Hypocrisy_f1-score': 0.10880829015544041, 'Appeal_to_Hypocrisy_support': 250.0, 'micro avg_precision': 0.15441176470588236, 'micro avg_recall': 0.084, 'micro avg_f1-score': 0.10880829015544041, 'micro avg_support': 250.0, 'macro avg_precision': 0.15441176470588236, 'macro avg_recall': 0.084, 'macro avg_f1-score': 0.10880829015544041, 'macro avg_support': 250.0, 'weighted avg_precision': 0.15441176470588236, 'weighted avg_recall': 0.084, 'weighted avg_f1-score': 0.10880829015544041, 'weighted avg_support': 250.0, 'B-Appeal_to_Hypocrisy_support': 136, 'I-Appeal_to_Hypocrisy_support': 2879, 'O_support': 2709, 'epoch': 0}, {'micro_f1': 0.7351502445842067, 'precision': 0.7351502445842069, 'Appeal_to_Hypocrisy_precision': 0.0661764705882353, 'Appeal_to_Hypocrisy_recall': 0.037037037037037035, 'Appeal_to_Hypocrisy_f1-score': 0.047493403693931395, 'Appeal_to_Hypocrisy_support': 243.0, 'micro avg_precision': 0.0661764705882353, 'micro avg_recall': 0.037037037037037035, 'micro avg_f1-score': 0.047493403693931395, 'micro avg_support': 243.0, 'macro avg_precision': 0.0661764705882353, 'macro avg_recall': 0.037037037037037035, 'macro avg_f1-score': 0.047493403693931395, 'macro avg_support': 243.0, 'weighted avg_precision': 0.0661764705882353, 'weighted avg_recall': 0.037037037037037035, 'weighted avg_f1-score': 0.047493403693931395, 'weighted avg_support': 243.0, 'B-Appeal_to_Hypocrisy_support': 136, 'I-Appeal_to_Hypocrisy_support': 2879, 'O_support': 2709, 'epoch': 1}, {'micro_f1': 0.7091194968553459, 'precision': 0.7091194968553459, 'Appeal_to_Hypocrisy_precision': 0.08088235294117647, 'Appeal_to_Hypocrisy_recall': 0.05116279069767442, 'Appeal_to_Hypocrisy_f1-score': 0.06267806267806268, 'Appeal_to_Hypocrisy_support': 215.0, 'micro avg_precision': 0.08088235294117647, 'micro avg_recall': 0.05116279069767442, 'micro avg_f1-score': 0.06267806267806268, 'micro avg_support': 215.0, 'macro avg_precision': 0.08088235294117647, 'macro avg_recall': 0.05116279069767442, 'macro avg_f1-score': 0.06267806267806268, 'macro avg_support': 215.0, 'weighted avg_precision': 0.08088235294117647, 'weighted avg_recall': 0.05116279069767442, 'weighted avg_f1-score': 0.06267806267806268, 'weighted avg_support': 215.0, 'B-Appeal_to_Hypocrisy_support': 136, 'I-Appeal_to_Hypocrisy_support': 2879, 'O_support': 2709, 'epoch': 2}]}
Early stopping triggered.
Saving model to directory: ./models/M2/2024-05-13-23-08-48_aug/mdeberta-v3-base_21_ME10_target=Appeal_to_Hypocrisy_SUBSAMPLED_2024-05-13-23-08-48
Training model no. 22 of 23 for (22, 'Questioning_the_Reputation') persuasion technique...
{'micro_f1': 0.7491741741741742, 'precision': 0.7491741741741742, 'Questioning_the_Reputation_precision': 0.07142857142857142, 'Questioning_the_Reputation_recall': 0.03146374829001368, 'Questioning_the_Reputation_f1-score': 0.04368471035137701, 'Questioning_the_Reputation_support': 731.0, 'micro avg_precision': 0.07142857142857142, 'micro avg_recall': 0.03146374829001368, 'micro avg_f1-score': 0.04368471035137701, 'micro avg_support': 731.0, 'macro avg_precision': 0.07142857142857142, 'macro avg_recall': 0.03146374829001368, 'macro avg_f1-score': 0.04368471035137701, 'macro avg_support': 731.0, 'weighted avg_precision': 0.07142857142857142, 'weighted avg_recall': 0.03146374829001368, 'weighted avg_f1-score': 0.04368471035137701, 'weighted avg_support': 731.0, 'O_support': 7777, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 0}
{'results': [{'micro_f1': 0.7491741741741742, 'precision': 0.7491741741741742, 'Questioning_the_Reputation_precision': 0.07142857142857142, 'Questioning_the_Reputation_recall': 0.03146374829001368, 'Questioning_the_Reputation_f1-score': 0.04368471035137701, 'Questioning_the_Reputation_support': 731.0, 'micro avg_precision': 0.07142857142857142, 'micro avg_recall': 0.03146374829001368, 'micro avg_f1-score': 0.04368471035137701, 'micro avg_support': 731.0, 'macro avg_precision': 0.07142857142857142, 'macro avg_recall': 0.03146374829001368, 'macro avg_f1-score': 0.04368471035137701, 'macro avg_support': 731.0, 'weighted avg_precision': 0.07142857142857142, 'weighted avg_recall': 0.03146374829001368, 'weighted avg_f1-score': 0.04368471035137701, 'weighted avg_support': 731.0, 'O_support': 7777, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 0}]}
Best model updated: current epoch macro f1 = 0.04368471035137701
{'micro_f1': 0.6197447447447447, 'precision': 0.6197447447447447, 'Questioning_the_Reputation_precision': 0.009316770186335404, 'Questioning_the_Reputation_recall': 0.01694915254237288, 'Questioning_the_Reputation_f1-score': 0.012024048096192385, 'Questioning_the_Reputation_support': 177.0, 'micro avg_precision': 0.009316770186335404, 'micro avg_recall': 0.01694915254237288, 'micro avg_f1-score': 0.012024048096192385, 'micro avg_support': 177.0, 'macro avg_precision': 0.009316770186335404, 'macro avg_recall': 0.01694915254237288, 'macro avg_f1-score': 0.012024048096192385, 'macro avg_support': 177.0, 'weighted avg_precision': 0.009316770186335404, 'weighted avg_recall': 0.01694915254237288, 'weighted avg_f1-score': 0.012024048096192385, 'weighted avg_support': 177.0, 'O_support': 7777, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 1}
{'results': [{'micro_f1': 0.7491741741741742, 'precision': 0.7491741741741742, 'Questioning_the_Reputation_precision': 0.07142857142857142, 'Questioning_the_Reputation_recall': 0.03146374829001368, 'Questioning_the_Reputation_f1-score': 0.04368471035137701, 'Questioning_the_Reputation_support': 731.0, 'micro avg_precision': 0.07142857142857142, 'micro avg_recall': 0.03146374829001368, 'micro avg_f1-score': 0.04368471035137701, 'micro avg_support': 731.0, 'macro avg_precision': 0.07142857142857142, 'macro avg_recall': 0.03146374829001368, 'macro avg_f1-score': 0.04368471035137701, 'macro avg_support': 731.0, 'weighted avg_precision': 0.07142857142857142, 'weighted avg_recall': 0.03146374829001368, 'weighted avg_f1-score': 0.04368471035137701, 'weighted avg_support': 731.0, 'O_support': 7777, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 0}, {'micro_f1': 0.6197447447447447, 'precision': 0.6197447447447447, 'Questioning_the_Reputation_precision': 0.009316770186335404, 'Questioning_the_Reputation_recall': 0.01694915254237288, 'Questioning_the_Reputation_f1-score': 0.012024048096192385, 'Questioning_the_Reputation_support': 177.0, 'micro avg_precision': 0.009316770186335404, 'micro avg_recall': 0.01694915254237288, 'micro avg_f1-score': 0.012024048096192385, 'micro avg_support': 177.0, 'macro avg_precision': 0.009316770186335404, 'macro avg_recall': 0.01694915254237288, 'macro avg_f1-score': 0.012024048096192385, 'macro avg_support': 177.0, 'weighted avg_precision': 0.009316770186335404, 'weighted avg_recall': 0.01694915254237288, 'weighted avg_f1-score': 0.012024048096192385, 'weighted avg_support': 177.0, 'O_support': 7777, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 1}]}
{'micro_f1': 0.7617117117117117, 'precision': 0.7617117117117117, 'Questioning_the_Reputation_precision': 0.15217391304347827, 'Questioning_the_Reputation_recall': 0.09645669291338582, 'Questioning_the_Reputation_f1-score': 0.1180722891566265, 'Questioning_the_Reputation_support': 508.0, 'micro avg_precision': 0.15217391304347827, 'micro avg_recall': 0.09645669291338582, 'micro avg_f1-score': 0.1180722891566265, 'micro avg_support': 508.0, 'macro avg_precision': 0.15217391304347827, 'macro avg_recall': 0.09645669291338582, 'macro avg_f1-score': 0.1180722891566265, 'macro avg_support': 508.0, 'weighted avg_precision': 0.15217391304347827, 'weighted avg_recall': 0.09645669291338582, 'weighted avg_f1-score': 0.1180722891566265, 'weighted avg_support': 508.0, 'O_support': 7777, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 2}
{'results': [{'micro_f1': 0.7491741741741742, 'precision': 0.7491741741741742, 'Questioning_the_Reputation_precision': 0.07142857142857142, 'Questioning_the_Reputation_recall': 0.03146374829001368, 'Questioning_the_Reputation_f1-score': 0.04368471035137701, 'Questioning_the_Reputation_support': 731.0, 'micro avg_precision': 0.07142857142857142, 'micro avg_recall': 0.03146374829001368, 'micro avg_f1-score': 0.04368471035137701, 'micro avg_support': 731.0, 'macro avg_precision': 0.07142857142857142, 'macro avg_recall': 0.03146374829001368, 'macro avg_f1-score': 0.04368471035137701, 'macro avg_support': 731.0, 'weighted avg_precision': 0.07142857142857142, 'weighted avg_recall': 0.03146374829001368, 'weighted avg_f1-score': 0.04368471035137701, 'weighted avg_support': 731.0, 'O_support': 7777, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 0}, {'micro_f1': 0.6197447447447447, 'precision': 0.6197447447447447, 'Questioning_the_Reputation_precision': 0.009316770186335404, 'Questioning_the_Reputation_recall': 0.01694915254237288, 'Questioning_the_Reputation_f1-score': 0.012024048096192385, 'Questioning_the_Reputation_support': 177.0, 'micro avg_precision': 0.009316770186335404, 'micro avg_recall': 0.01694915254237288, 'micro avg_f1-score': 0.012024048096192385, 'micro avg_support': 177.0, 'macro avg_precision': 0.009316770186335404, 'macro avg_recall': 0.01694915254237288, 'macro avg_f1-score': 0.012024048096192385, 'macro avg_support': 177.0, 'weighted avg_precision': 0.009316770186335404, 'weighted avg_recall': 0.01694915254237288, 'weighted avg_f1-score': 0.012024048096192385, 'weighted avg_support': 177.0, 'O_support': 7777, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 1}, {'micro_f1': 0.7617117117117117, 'precision': 0.7617117117117117, 'Questioning_the_Reputation_precision': 0.15217391304347827, 'Questioning_the_Reputation_recall': 0.09645669291338582, 'Questioning_the_Reputation_f1-score': 0.1180722891566265, 'Questioning_the_Reputation_support': 508.0, 'micro avg_precision': 0.15217391304347827, 'micro avg_recall': 0.09645669291338582, 'micro avg_f1-score': 0.1180722891566265, 'micro avg_support': 508.0, 'macro avg_precision': 0.15217391304347827, 'macro avg_recall': 0.09645669291338582, 'macro avg_f1-score': 0.1180722891566265, 'macro avg_support': 508.0, 'weighted avg_precision': 0.15217391304347827, 'weighted avg_recall': 0.09645669291338582, 'weighted avg_f1-score': 0.1180722891566265, 'weighted avg_support': 508.0, 'O_support': 7777, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 2}]}
Best model updated: current epoch macro f1 = 0.1180722891566265
{'micro_f1': 0.7797297297297298, 'precision': 0.7797297297297298, 'Questioning_the_Reputation_precision': 0.20496894409937888, 'Questioning_the_Reputation_recall': 0.12406015037593984, 'Questioning_the_Reputation_f1-score': 0.15456674473067916, 'Questioning_the_Reputation_support': 532.0, 'micro avg_precision': 0.20496894409937888, 'micro avg_recall': 0.12406015037593984, 'micro avg_f1-score': 0.15456674473067916, 'micro avg_support': 532.0, 'macro avg_precision': 0.20496894409937888, 'macro avg_recall': 0.12406015037593984, 'macro avg_f1-score': 0.15456674473067916, 'macro avg_support': 532.0, 'weighted avg_precision': 0.20496894409937888, 'weighted avg_recall': 0.12406015037593984, 'weighted avg_f1-score': 0.15456674473067916, 'weighted avg_support': 532.0, 'O_support': 7777, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 3}
{'results': [{'micro_f1': 0.7491741741741742, 'precision': 0.7491741741741742, 'Questioning_the_Reputation_precision': 0.07142857142857142, 'Questioning_the_Reputation_recall': 0.03146374829001368, 'Questioning_the_Reputation_f1-score': 0.04368471035137701, 'Questioning_the_Reputation_support': 731.0, 'micro avg_precision': 0.07142857142857142, 'micro avg_recall': 0.03146374829001368, 'micro avg_f1-score': 0.04368471035137701, 'micro avg_support': 731.0, 'macro avg_precision': 0.07142857142857142, 'macro avg_recall': 0.03146374829001368, 'macro avg_f1-score': 0.04368471035137701, 'macro avg_support': 731.0, 'weighted avg_precision': 0.07142857142857142, 'weighted avg_recall': 0.03146374829001368, 'weighted avg_f1-score': 0.04368471035137701, 'weighted avg_support': 731.0, 'O_support': 7777, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 0}, {'micro_f1': 0.6197447447447447, 'precision': 0.6197447447447447, 'Questioning_the_Reputation_precision': 0.009316770186335404, 'Questioning_the_Reputation_recall': 0.01694915254237288, 'Questioning_the_Reputation_f1-score': 0.012024048096192385, 'Questioning_the_Reputation_support': 177.0, 'micro avg_precision': 0.009316770186335404, 'micro avg_recall': 0.01694915254237288, 'micro avg_f1-score': 0.012024048096192385, 'micro avg_support': 177.0, 'macro avg_precision': 0.009316770186335404, 'macro avg_recall': 0.01694915254237288, 'macro avg_f1-score': 0.012024048096192385, 'macro avg_support': 177.0, 'weighted avg_precision': 0.009316770186335404, 'weighted avg_recall': 0.01694915254237288, 'weighted avg_f1-score': 0.012024048096192385, 'weighted avg_support': 177.0, 'O_support': 7777, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 1}, {'micro_f1': 0.7617117117117117, 'precision': 0.7617117117117117, 'Questioning_the_Reputation_precision': 0.15217391304347827, 'Questioning_the_Reputation_recall': 0.09645669291338582, 'Questioning_the_Reputation_f1-score': 0.1180722891566265, 'Questioning_the_Reputation_support': 508.0, 'micro avg_precision': 0.15217391304347827, 'micro avg_recall': 0.09645669291338582, 'micro avg_f1-score': 0.1180722891566265, 'micro avg_support': 508.0, 'macro avg_precision': 0.15217391304347827, 'macro avg_recall': 0.09645669291338582, 'macro avg_f1-score': 0.1180722891566265, 'macro avg_support': 508.0, 'weighted avg_precision': 0.15217391304347827, 'weighted avg_recall': 0.09645669291338582, 'weighted avg_f1-score': 0.1180722891566265, 'weighted avg_support': 508.0, 'O_support': 7777, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 2}, {'micro_f1': 0.7797297297297298, 'precision': 0.7797297297297298, 'Questioning_the_Reputation_precision': 0.20496894409937888, 'Questioning_the_Reputation_recall': 0.12406015037593984, 'Questioning_the_Reputation_f1-score': 0.15456674473067916, 'Questioning_the_Reputation_support': 532.0, 'micro avg_precision': 0.20496894409937888, 'micro avg_recall': 0.12406015037593984, 'micro avg_f1-score': 0.15456674473067916, 'micro avg_support': 532.0, 'macro avg_precision': 0.20496894409937888, 'macro avg_recall': 0.12406015037593984, 'macro avg_f1-score': 0.15456674473067916, 'macro avg_support': 532.0, 'weighted avg_precision': 0.20496894409937888, 'weighted avg_recall': 0.12406015037593984, 'weighted avg_f1-score': 0.15456674473067916, 'weighted avg_support': 532.0, 'O_support': 7777, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 3}]}
Best model updated: current epoch macro f1 = 0.15456674473067916
{'micro_f1': 0.7695945945945947, 'precision': 0.7695945945945946, 'Questioning_the_Reputation_precision': 0.2546583850931677, 'Questioning_the_Reputation_recall': 0.15045871559633028, 'Questioning_the_Reputation_f1-score': 0.18915801614763553, 'Questioning_the_Reputation_support': 545.0, 'micro avg_precision': 0.2546583850931677, 'micro avg_recall': 0.15045871559633028, 'micro avg_f1-score': 0.18915801614763553, 'micro avg_support': 545.0, 'macro avg_precision': 0.2546583850931677, 'macro avg_recall': 0.15045871559633028, 'macro avg_f1-score': 0.18915801614763553, 'macro avg_support': 545.0, 'weighted avg_precision': 0.2546583850931677, 'weighted avg_recall': 0.15045871559633028, 'weighted avg_f1-score': 0.18915801614763553, 'weighted avg_support': 545.0, 'O_support': 7777, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 4}
{'results': [{'micro_f1': 0.7491741741741742, 'precision': 0.7491741741741742, 'Questioning_the_Reputation_precision': 0.07142857142857142, 'Questioning_the_Reputation_recall': 0.03146374829001368, 'Questioning_the_Reputation_f1-score': 0.04368471035137701, 'Questioning_the_Reputation_support': 731.0, 'micro avg_precision': 0.07142857142857142, 'micro avg_recall': 0.03146374829001368, 'micro avg_f1-score': 0.04368471035137701, 'micro avg_support': 731.0, 'macro avg_precision': 0.07142857142857142, 'macro avg_recall': 0.03146374829001368, 'macro avg_f1-score': 0.04368471035137701, 'macro avg_support': 731.0, 'weighted avg_precision': 0.07142857142857142, 'weighted avg_recall': 0.03146374829001368, 'weighted avg_f1-score': 0.04368471035137701, 'weighted avg_support': 731.0, 'O_support': 7777, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 0}, {'micro_f1': 0.6197447447447447, 'precision': 0.6197447447447447, 'Questioning_the_Reputation_precision': 0.009316770186335404, 'Questioning_the_Reputation_recall': 0.01694915254237288, 'Questioning_the_Reputation_f1-score': 0.012024048096192385, 'Questioning_the_Reputation_support': 177.0, 'micro avg_precision': 0.009316770186335404, 'micro avg_recall': 0.01694915254237288, 'micro avg_f1-score': 0.012024048096192385, 'micro avg_support': 177.0, 'macro avg_precision': 0.009316770186335404, 'macro avg_recall': 0.01694915254237288, 'macro avg_f1-score': 0.012024048096192385, 'macro avg_support': 177.0, 'weighted avg_precision': 0.009316770186335404, 'weighted avg_recall': 0.01694915254237288, 'weighted avg_f1-score': 0.012024048096192385, 'weighted avg_support': 177.0, 'O_support': 7777, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 1}, {'micro_f1': 0.7617117117117117, 'precision': 0.7617117117117117, 'Questioning_the_Reputation_precision': 0.15217391304347827, 'Questioning_the_Reputation_recall': 0.09645669291338582, 'Questioning_the_Reputation_f1-score': 0.1180722891566265, 'Questioning_the_Reputation_support': 508.0, 'micro avg_precision': 0.15217391304347827, 'micro avg_recall': 0.09645669291338582, 'micro avg_f1-score': 0.1180722891566265, 'micro avg_support': 508.0, 'macro avg_precision': 0.15217391304347827, 'macro avg_recall': 0.09645669291338582, 'macro avg_f1-score': 0.1180722891566265, 'macro avg_support': 508.0, 'weighted avg_precision': 0.15217391304347827, 'weighted avg_recall': 0.09645669291338582, 'weighted avg_f1-score': 0.1180722891566265, 'weighted avg_support': 508.0, 'O_support': 7777, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 2}, {'micro_f1': 0.7797297297297298, 'precision': 0.7797297297297298, 'Questioning_the_Reputation_precision': 0.20496894409937888, 'Questioning_the_Reputation_recall': 0.12406015037593984, 'Questioning_the_Reputation_f1-score': 0.15456674473067916, 'Questioning_the_Reputation_support': 532.0, 'micro avg_precision': 0.20496894409937888, 'micro avg_recall': 0.12406015037593984, 'micro avg_f1-score': 0.15456674473067916, 'micro avg_support': 532.0, 'macro avg_precision': 0.20496894409937888, 'macro avg_recall': 0.12406015037593984, 'macro avg_f1-score': 0.15456674473067916, 'macro avg_support': 532.0, 'weighted avg_precision': 0.20496894409937888, 'weighted avg_recall': 0.12406015037593984, 'weighted avg_f1-score': 0.15456674473067916, 'weighted avg_support': 532.0, 'O_support': 7777, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 3}, {'micro_f1': 0.7695945945945947, 'precision': 0.7695945945945946, 'Questioning_the_Reputation_precision': 0.2546583850931677, 'Questioning_the_Reputation_recall': 0.15045871559633028, 'Questioning_the_Reputation_f1-score': 0.18915801614763553, 'Questioning_the_Reputation_support': 545.0, 'micro avg_precision': 0.2546583850931677, 'micro avg_recall': 0.15045871559633028, 'micro avg_f1-score': 0.18915801614763553, 'micro avg_support': 545.0, 'macro avg_precision': 0.2546583850931677, 'macro avg_recall': 0.15045871559633028, 'macro avg_f1-score': 0.18915801614763553, 'macro avg_support': 545.0, 'weighted avg_precision': 0.2546583850931677, 'weighted avg_recall': 0.15045871559633028, 'weighted avg_f1-score': 0.18915801614763553, 'weighted avg_support': 545.0, 'O_support': 7777, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 4}]}
Best model updated: current epoch macro f1 = 0.18915801614763553
{'micro_f1': 0.7554054054054052, 'precision': 0.7554054054054054, 'Questioning_the_Reputation_precision': 0.17080745341614906, 'Questioning_the_Reputation_recall': 0.12910798122065728, 'Questioning_the_Reputation_f1-score': 0.14705882352941174, 'Questioning_the_Reputation_support': 426.0, 'micro avg_precision': 0.17080745341614906, 'micro avg_recall': 0.12910798122065728, 'micro avg_f1-score': 0.14705882352941174, 'micro avg_support': 426.0, 'macro avg_precision': 0.17080745341614906, 'macro avg_recall': 0.12910798122065728, 'macro avg_f1-score': 0.14705882352941174, 'macro avg_support': 426.0, 'weighted avg_precision': 0.17080745341614906, 'weighted avg_recall': 0.12910798122065728, 'weighted avg_f1-score': 0.14705882352941174, 'weighted avg_support': 426.0, 'O_support': 7777, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 5}
{'results': [{'micro_f1': 0.7491741741741742, 'precision': 0.7491741741741742, 'Questioning_the_Reputation_precision': 0.07142857142857142, 'Questioning_the_Reputation_recall': 0.03146374829001368, 'Questioning_the_Reputation_f1-score': 0.04368471035137701, 'Questioning_the_Reputation_support': 731.0, 'micro avg_precision': 0.07142857142857142, 'micro avg_recall': 0.03146374829001368, 'micro avg_f1-score': 0.04368471035137701, 'micro avg_support': 731.0, 'macro avg_precision': 0.07142857142857142, 'macro avg_recall': 0.03146374829001368, 'macro avg_f1-score': 0.04368471035137701, 'macro avg_support': 731.0, 'weighted avg_precision': 0.07142857142857142, 'weighted avg_recall': 0.03146374829001368, 'weighted avg_f1-score': 0.04368471035137701, 'weighted avg_support': 731.0, 'O_support': 7777, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 0}, {'micro_f1': 0.6197447447447447, 'precision': 0.6197447447447447, 'Questioning_the_Reputation_precision': 0.009316770186335404, 'Questioning_the_Reputation_recall': 0.01694915254237288, 'Questioning_the_Reputation_f1-score': 0.012024048096192385, 'Questioning_the_Reputation_support': 177.0, 'micro avg_precision': 0.009316770186335404, 'micro avg_recall': 0.01694915254237288, 'micro avg_f1-score': 0.012024048096192385, 'micro avg_support': 177.0, 'macro avg_precision': 0.009316770186335404, 'macro avg_recall': 0.01694915254237288, 'macro avg_f1-score': 0.012024048096192385, 'macro avg_support': 177.0, 'weighted avg_precision': 0.009316770186335404, 'weighted avg_recall': 0.01694915254237288, 'weighted avg_f1-score': 0.012024048096192385, 'weighted avg_support': 177.0, 'O_support': 7777, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 1}, {'micro_f1': 0.7617117117117117, 'precision': 0.7617117117117117, 'Questioning_the_Reputation_precision': 0.15217391304347827, 'Questioning_the_Reputation_recall': 0.09645669291338582, 'Questioning_the_Reputation_f1-score': 0.1180722891566265, 'Questioning_the_Reputation_support': 508.0, 'micro avg_precision': 0.15217391304347827, 'micro avg_recall': 0.09645669291338582, 'micro avg_f1-score': 0.1180722891566265, 'micro avg_support': 508.0, 'macro avg_precision': 0.15217391304347827, 'macro avg_recall': 0.09645669291338582, 'macro avg_f1-score': 0.1180722891566265, 'macro avg_support': 508.0, 'weighted avg_precision': 0.15217391304347827, 'weighted avg_recall': 0.09645669291338582, 'weighted avg_f1-score': 0.1180722891566265, 'weighted avg_support': 508.0, 'O_support': 7777, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 2}, {'micro_f1': 0.7797297297297298, 'precision': 0.7797297297297298, 'Questioning_the_Reputation_precision': 0.20496894409937888, 'Questioning_the_Reputation_recall': 0.12406015037593984, 'Questioning_the_Reputation_f1-score': 0.15456674473067916, 'Questioning_the_Reputation_support': 532.0, 'micro avg_precision': 0.20496894409937888, 'micro avg_recall': 0.12406015037593984, 'micro avg_f1-score': 0.15456674473067916, 'micro avg_support': 532.0, 'macro avg_precision': 0.20496894409937888, 'macro avg_recall': 0.12406015037593984, 'macro avg_f1-score': 0.15456674473067916, 'macro avg_support': 532.0, 'weighted avg_precision': 0.20496894409937888, 'weighted avg_recall': 0.12406015037593984, 'weighted avg_f1-score': 0.15456674473067916, 'weighted avg_support': 532.0, 'O_support': 7777, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 3}, {'micro_f1': 0.7695945945945947, 'precision': 0.7695945945945946, 'Questioning_the_Reputation_precision': 0.2546583850931677, 'Questioning_the_Reputation_recall': 0.15045871559633028, 'Questioning_the_Reputation_f1-score': 0.18915801614763553, 'Questioning_the_Reputation_support': 545.0, 'micro avg_precision': 0.2546583850931677, 'micro avg_recall': 0.15045871559633028, 'micro avg_f1-score': 0.18915801614763553, 'micro avg_support': 545.0, 'macro avg_precision': 0.2546583850931677, 'macro avg_recall': 0.15045871559633028, 'macro avg_f1-score': 0.18915801614763553, 'macro avg_support': 545.0, 'weighted avg_precision': 0.2546583850931677, 'weighted avg_recall': 0.15045871559633028, 'weighted avg_f1-score': 0.18915801614763553, 'weighted avg_support': 545.0, 'O_support': 7777, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 4}, {'micro_f1': 0.7554054054054052, 'precision': 0.7554054054054054, 'Questioning_the_Reputation_precision': 0.17080745341614906, 'Questioning_the_Reputation_recall': 0.12910798122065728, 'Questioning_the_Reputation_f1-score': 0.14705882352941174, 'Questioning_the_Reputation_support': 426.0, 'micro avg_precision': 0.17080745341614906, 'micro avg_recall': 0.12910798122065728, 'micro avg_f1-score': 0.14705882352941174, 'micro avg_support': 426.0, 'macro avg_precision': 0.17080745341614906, 'macro avg_recall': 0.12910798122065728, 'macro avg_f1-score': 0.14705882352941174, 'macro avg_support': 426.0, 'weighted avg_precision': 0.17080745341614906, 'weighted avg_recall': 0.12910798122065728, 'weighted avg_f1-score': 0.14705882352941174, 'weighted avg_support': 426.0, 'O_support': 7777, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 5}]}
{'micro_f1': 0.6936186186186186, 'precision': 0.6936186186186186, 'Questioning_the_Reputation_precision': 0.09006211180124224, 'Questioning_the_Reputation_recall': 0.08734939759036145, 'Questioning_the_Reputation_f1-score': 0.08868501529051988, 'Questioning_the_Reputation_support': 332.0, 'micro avg_precision': 0.09006211180124224, 'micro avg_recall': 0.08734939759036145, 'micro avg_f1-score': 0.08868501529051988, 'micro avg_support': 332.0, 'macro avg_precision': 0.09006211180124224, 'macro avg_recall': 0.08734939759036145, 'macro avg_f1-score': 0.08868501529051988, 'macro avg_support': 332.0, 'weighted avg_precision': 0.09006211180124224, 'weighted avg_recall': 0.08734939759036145, 'weighted avg_f1-score': 0.08868501529051988, 'weighted avg_support': 332.0, 'O_support': 7777, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 6}
{'results': [{'micro_f1': 0.7491741741741742, 'precision': 0.7491741741741742, 'Questioning_the_Reputation_precision': 0.07142857142857142, 'Questioning_the_Reputation_recall': 0.03146374829001368, 'Questioning_the_Reputation_f1-score': 0.04368471035137701, 'Questioning_the_Reputation_support': 731.0, 'micro avg_precision': 0.07142857142857142, 'micro avg_recall': 0.03146374829001368, 'micro avg_f1-score': 0.04368471035137701, 'micro avg_support': 731.0, 'macro avg_precision': 0.07142857142857142, 'macro avg_recall': 0.03146374829001368, 'macro avg_f1-score': 0.04368471035137701, 'macro avg_support': 731.0, 'weighted avg_precision': 0.07142857142857142, 'weighted avg_recall': 0.03146374829001368, 'weighted avg_f1-score': 0.04368471035137701, 'weighted avg_support': 731.0, 'O_support': 7777, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 0}, {'micro_f1': 0.6197447447447447, 'precision': 0.6197447447447447, 'Questioning_the_Reputation_precision': 0.009316770186335404, 'Questioning_the_Reputation_recall': 0.01694915254237288, 'Questioning_the_Reputation_f1-score': 0.012024048096192385, 'Questioning_the_Reputation_support': 177.0, 'micro avg_precision': 0.009316770186335404, 'micro avg_recall': 0.01694915254237288, 'micro avg_f1-score': 0.012024048096192385, 'micro avg_support': 177.0, 'macro avg_precision': 0.009316770186335404, 'macro avg_recall': 0.01694915254237288, 'macro avg_f1-score': 0.012024048096192385, 'macro avg_support': 177.0, 'weighted avg_precision': 0.009316770186335404, 'weighted avg_recall': 0.01694915254237288, 'weighted avg_f1-score': 0.012024048096192385, 'weighted avg_support': 177.0, 'O_support': 7777, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 1}, {'micro_f1': 0.7617117117117117, 'precision': 0.7617117117117117, 'Questioning_the_Reputation_precision': 0.15217391304347827, 'Questioning_the_Reputation_recall': 0.09645669291338582, 'Questioning_the_Reputation_f1-score': 0.1180722891566265, 'Questioning_the_Reputation_support': 508.0, 'micro avg_precision': 0.15217391304347827, 'micro avg_recall': 0.09645669291338582, 'micro avg_f1-score': 0.1180722891566265, 'micro avg_support': 508.0, 'macro avg_precision': 0.15217391304347827, 'macro avg_recall': 0.09645669291338582, 'macro avg_f1-score': 0.1180722891566265, 'macro avg_support': 508.0, 'weighted avg_precision': 0.15217391304347827, 'weighted avg_recall': 0.09645669291338582, 'weighted avg_f1-score': 0.1180722891566265, 'weighted avg_support': 508.0, 'O_support': 7777, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 2}, {'micro_f1': 0.7797297297297298, 'precision': 0.7797297297297298, 'Questioning_the_Reputation_precision': 0.20496894409937888, 'Questioning_the_Reputation_recall': 0.12406015037593984, 'Questioning_the_Reputation_f1-score': 0.15456674473067916, 'Questioning_the_Reputation_support': 532.0, 'micro avg_precision': 0.20496894409937888, 'micro avg_recall': 0.12406015037593984, 'micro avg_f1-score': 0.15456674473067916, 'micro avg_support': 532.0, 'macro avg_precision': 0.20496894409937888, 'macro avg_recall': 0.12406015037593984, 'macro avg_f1-score': 0.15456674473067916, 'macro avg_support': 532.0, 'weighted avg_precision': 0.20496894409937888, 'weighted avg_recall': 0.12406015037593984, 'weighted avg_f1-score': 0.15456674473067916, 'weighted avg_support': 532.0, 'O_support': 7777, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 3}, {'micro_f1': 0.7695945945945947, 'precision': 0.7695945945945946, 'Questioning_the_Reputation_precision': 0.2546583850931677, 'Questioning_the_Reputation_recall': 0.15045871559633028, 'Questioning_the_Reputation_f1-score': 0.18915801614763553, 'Questioning_the_Reputation_support': 545.0, 'micro avg_precision': 0.2546583850931677, 'micro avg_recall': 0.15045871559633028, 'micro avg_f1-score': 0.18915801614763553, 'micro avg_support': 545.0, 'macro avg_precision': 0.2546583850931677, 'macro avg_recall': 0.15045871559633028, 'macro avg_f1-score': 0.18915801614763553, 'macro avg_support': 545.0, 'weighted avg_precision': 0.2546583850931677, 'weighted avg_recall': 0.15045871559633028, 'weighted avg_f1-score': 0.18915801614763553, 'weighted avg_support': 545.0, 'O_support': 7777, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 4}, {'micro_f1': 0.7554054054054052, 'precision': 0.7554054054054054, 'Questioning_the_Reputation_precision': 0.17080745341614906, 'Questioning_the_Reputation_recall': 0.12910798122065728, 'Questioning_the_Reputation_f1-score': 0.14705882352941174, 'Questioning_the_Reputation_support': 426.0, 'micro avg_precision': 0.17080745341614906, 'micro avg_recall': 0.12910798122065728, 'micro avg_f1-score': 0.14705882352941174, 'micro avg_support': 426.0, 'macro avg_precision': 0.17080745341614906, 'macro avg_recall': 0.12910798122065728, 'macro avg_f1-score': 0.14705882352941174, 'macro avg_support': 426.0, 'weighted avg_precision': 0.17080745341614906, 'weighted avg_recall': 0.12910798122065728, 'weighted avg_f1-score': 0.14705882352941174, 'weighted avg_support': 426.0, 'O_support': 7777, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 5}, {'micro_f1': 0.6936186186186186, 'precision': 0.6936186186186186, 'Questioning_the_Reputation_precision': 0.09006211180124224, 'Questioning_the_Reputation_recall': 0.08734939759036145, 'Questioning_the_Reputation_f1-score': 0.08868501529051988, 'Questioning_the_Reputation_support': 332.0, 'micro avg_precision': 0.09006211180124224, 'micro avg_recall': 0.08734939759036145, 'micro avg_f1-score': 0.08868501529051988, 'micro avg_support': 332.0, 'macro avg_precision': 0.09006211180124224, 'macro avg_recall': 0.08734939759036145, 'macro avg_f1-score': 0.08868501529051988, 'macro avg_support': 332.0, 'weighted avg_precision': 0.09006211180124224, 'weighted avg_recall': 0.08734939759036145, 'weighted avg_f1-score': 0.08868501529051988, 'weighted avg_support': 332.0, 'O_support': 7777, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 6}]}
Early stopping triggered.
Saving model to directory: ./models/M2/2024-05-13-23-08-48_aug/mdeberta-v3-base_22_ME10_target=Questioning_the_Reputation_SUBSAMPLED_2024-05-13-23-08-48
