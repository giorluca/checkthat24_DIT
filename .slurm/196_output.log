Training model no. 0 of 23 for (0, 'Appeal_to_Authority') persuasion technique...
{'micro_f1': 0.7247437774524158, 'Appeal_to_Authority_precision': 0.1111111111111111, 'Appeal_to_Authority_recall': 0.04100946372239748, 'Appeal_to_Authority_f1-score': 0.05990783410138249, 'Appeal_to_Authority_support': 317.0, 'micro avg_precision': 0.1111111111111111, 'micro avg_recall': 0.04100946372239748, 'micro avg_f1-score': 0.05990783410138249, 'micro avg_support': 317.0, 'macro avg_precision': 0.1111111111111111, 'macro avg_recall': 0.04100946372239748, 'macro avg_f1-score': 0.05990783410138249, 'macro avg_support': 317.0, 'weighted avg_precision': 0.1111111111111111, 'weighted avg_recall': 0.04100946372239748, 'weighted avg_f1-score': 0.05990783410138249, 'weighted avg_support': 317.0, 'O_support': 2736, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 0}
{'results': [{'micro_f1': 0.7247437774524158, 'Appeal_to_Authority_precision': 0.1111111111111111, 'Appeal_to_Authority_recall': 0.04100946372239748, 'Appeal_to_Authority_f1-score': 0.05990783410138249, 'Appeal_to_Authority_support': 317.0, 'micro avg_precision': 0.1111111111111111, 'micro avg_recall': 0.04100946372239748, 'micro avg_f1-score': 0.05990783410138249, 'micro avg_support': 317.0, 'macro avg_precision': 0.1111111111111111, 'macro avg_recall': 0.04100946372239748, 'macro avg_f1-score': 0.05990783410138249, 'macro avg_support': 317.0, 'weighted avg_precision': 0.1111111111111111, 'weighted avg_recall': 0.04100946372239748, 'weighted avg_f1-score': 0.05990783410138249, 'weighted avg_support': 317.0, 'O_support': 2736, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 0}]}
Best model updated: current epoch macro f1 = 0.05990783410138249
{'micro_f1': 0.7195147458690652, 'Appeal_to_Authority_precision': 0.1623931623931624, 'Appeal_to_Authority_recall': 0.0778688524590164, 'Appeal_to_Authority_f1-score': 0.10526315789473684, 'Appeal_to_Authority_support': 244.0, 'micro avg_precision': 0.1623931623931624, 'micro avg_recall': 0.0778688524590164, 'micro avg_f1-score': 0.10526315789473684, 'micro avg_support': 244.0, 'macro avg_precision': 0.1623931623931624, 'macro avg_recall': 0.0778688524590164, 'macro avg_f1-score': 0.10526315789473684, 'macro avg_support': 244.0, 'weighted avg_precision': 0.1623931623931624, 'weighted avg_recall': 0.0778688524590164, 'weighted avg_f1-score': 0.10526315789473684, 'weighted avg_support': 244.0, 'O_support': 2736, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 1}
{'results': [{'micro_f1': 0.7247437774524158, 'Appeal_to_Authority_precision': 0.1111111111111111, 'Appeal_to_Authority_recall': 0.04100946372239748, 'Appeal_to_Authority_f1-score': 0.05990783410138249, 'Appeal_to_Authority_support': 317.0, 'micro avg_precision': 0.1111111111111111, 'micro avg_recall': 0.04100946372239748, 'micro avg_f1-score': 0.05990783410138249, 'micro avg_support': 317.0, 'macro avg_precision': 0.1111111111111111, 'macro avg_recall': 0.04100946372239748, 'macro avg_f1-score': 0.05990783410138249, 'macro avg_support': 317.0, 'weighted avg_precision': 0.1111111111111111, 'weighted avg_recall': 0.04100946372239748, 'weighted avg_f1-score': 0.05990783410138249, 'weighted avg_support': 317.0, 'O_support': 2736, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 0}, {'micro_f1': 0.7195147458690652, 'Appeal_to_Authority_precision': 0.1623931623931624, 'Appeal_to_Authority_recall': 0.0778688524590164, 'Appeal_to_Authority_f1-score': 0.10526315789473684, 'Appeal_to_Authority_support': 244.0, 'micro avg_precision': 0.1623931623931624, 'micro avg_recall': 0.0778688524590164, 'micro avg_f1-score': 0.10526315789473684, 'micro avg_support': 244.0, 'macro avg_precision': 0.1623931623931624, 'macro avg_recall': 0.0778688524590164, 'macro avg_f1-score': 0.10526315789473684, 'macro avg_support': 244.0, 'weighted avg_precision': 0.1623931623931624, 'weighted avg_recall': 0.0778688524590164, 'weighted avg_f1-score': 0.10526315789473684, 'weighted avg_support': 244.0, 'O_support': 2736, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 1}]}
Best model updated: current epoch macro f1 = 0.10526315789473684
{'micro_f1': 0.7337377117757792, 'Appeal_to_Authority_precision': 0.27350427350427353, 'Appeal_to_Authority_recall': 0.14953271028037382, 'Appeal_to_Authority_f1-score': 0.19335347432024166, 'Appeal_to_Authority_support': 214.0, 'micro avg_precision': 0.27350427350427353, 'micro avg_recall': 0.14953271028037382, 'micro avg_f1-score': 0.19335347432024166, 'micro avg_support': 214.0, 'macro avg_precision': 0.27350427350427353, 'macro avg_recall': 0.14953271028037382, 'macro avg_f1-score': 0.19335347432024166, 'macro avg_support': 214.0, 'weighted avg_precision': 0.27350427350427353, 'weighted avg_recall': 0.14953271028037382, 'weighted avg_f1-score': 0.19335347432024166, 'weighted avg_support': 214.0, 'O_support': 2736, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 2}
{'results': [{'micro_f1': 0.7247437774524158, 'Appeal_to_Authority_precision': 0.1111111111111111, 'Appeal_to_Authority_recall': 0.04100946372239748, 'Appeal_to_Authority_f1-score': 0.05990783410138249, 'Appeal_to_Authority_support': 317.0, 'micro avg_precision': 0.1111111111111111, 'micro avg_recall': 0.04100946372239748, 'micro avg_f1-score': 0.05990783410138249, 'micro avg_support': 317.0, 'macro avg_precision': 0.1111111111111111, 'macro avg_recall': 0.04100946372239748, 'macro avg_f1-score': 0.05990783410138249, 'macro avg_support': 317.0, 'weighted avg_precision': 0.1111111111111111, 'weighted avg_recall': 0.04100946372239748, 'weighted avg_f1-score': 0.05990783410138249, 'weighted avg_support': 317.0, 'O_support': 2736, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 0}, {'micro_f1': 0.7195147458690652, 'Appeal_to_Authority_precision': 0.1623931623931624, 'Appeal_to_Authority_recall': 0.0778688524590164, 'Appeal_to_Authority_f1-score': 0.10526315789473684, 'Appeal_to_Authority_support': 244.0, 'micro avg_precision': 0.1623931623931624, 'micro avg_recall': 0.0778688524590164, 'micro avg_f1-score': 0.10526315789473684, 'micro avg_support': 244.0, 'macro avg_precision': 0.1623931623931624, 'macro avg_recall': 0.0778688524590164, 'macro avg_f1-score': 0.10526315789473684, 'macro avg_support': 244.0, 'weighted avg_precision': 0.1623931623931624, 'weighted avg_recall': 0.0778688524590164, 'weighted avg_f1-score': 0.10526315789473684, 'weighted avg_support': 244.0, 'O_support': 2736, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 1}, {'micro_f1': 0.7337377117757792, 'Appeal_to_Authority_precision': 0.27350427350427353, 'Appeal_to_Authority_recall': 0.14953271028037382, 'Appeal_to_Authority_f1-score': 0.19335347432024166, 'Appeal_to_Authority_support': 214.0, 'micro avg_precision': 0.27350427350427353, 'micro avg_recall': 0.14953271028037382, 'micro avg_f1-score': 0.19335347432024166, 'micro avg_support': 214.0, 'macro avg_precision': 0.27350427350427353, 'macro avg_recall': 0.14953271028037382, 'macro avg_f1-score': 0.19335347432024166, 'macro avg_support': 214.0, 'weighted avg_precision': 0.27350427350427353, 'weighted avg_recall': 0.14953271028037382, 'weighted avg_f1-score': 0.19335347432024166, 'weighted avg_support': 214.0, 'O_support': 2736, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 2}]}
Best model updated: current epoch macro f1 = 0.19335347432024166
{'micro_f1': 0.7500522903158335, 'Appeal_to_Authority_precision': 0.29914529914529914, 'Appeal_to_Authority_recall': 0.17326732673267325, 'Appeal_to_Authority_f1-score': 0.21943573667711597, 'Appeal_to_Authority_support': 202.0, 'micro avg_precision': 0.29914529914529914, 'micro avg_recall': 0.17326732673267325, 'micro avg_f1-score': 0.21943573667711597, 'micro avg_support': 202.0, 'macro avg_precision': 0.29914529914529914, 'macro avg_recall': 0.17326732673267325, 'macro avg_f1-score': 0.21943573667711597, 'macro avg_support': 202.0, 'weighted avg_precision': 0.29914529914529914, 'weighted avg_recall': 0.17326732673267325, 'weighted avg_f1-score': 0.21943573667711597, 'weighted avg_support': 202.0, 'O_support': 2736, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 3}
{'results': [{'micro_f1': 0.7247437774524158, 'Appeal_to_Authority_precision': 0.1111111111111111, 'Appeal_to_Authority_recall': 0.04100946372239748, 'Appeal_to_Authority_f1-score': 0.05990783410138249, 'Appeal_to_Authority_support': 317.0, 'micro avg_precision': 0.1111111111111111, 'micro avg_recall': 0.04100946372239748, 'micro avg_f1-score': 0.05990783410138249, 'micro avg_support': 317.0, 'macro avg_precision': 0.1111111111111111, 'macro avg_recall': 0.04100946372239748, 'macro avg_f1-score': 0.05990783410138249, 'macro avg_support': 317.0, 'weighted avg_precision': 0.1111111111111111, 'weighted avg_recall': 0.04100946372239748, 'weighted avg_f1-score': 0.05990783410138249, 'weighted avg_support': 317.0, 'O_support': 2736, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 0}, {'micro_f1': 0.7195147458690652, 'Appeal_to_Authority_precision': 0.1623931623931624, 'Appeal_to_Authority_recall': 0.0778688524590164, 'Appeal_to_Authority_f1-score': 0.10526315789473684, 'Appeal_to_Authority_support': 244.0, 'micro avg_precision': 0.1623931623931624, 'micro avg_recall': 0.0778688524590164, 'micro avg_f1-score': 0.10526315789473684, 'micro avg_support': 244.0, 'macro avg_precision': 0.1623931623931624, 'macro avg_recall': 0.0778688524590164, 'macro avg_f1-score': 0.10526315789473684, 'macro avg_support': 244.0, 'weighted avg_precision': 0.1623931623931624, 'weighted avg_recall': 0.0778688524590164, 'weighted avg_f1-score': 0.10526315789473684, 'weighted avg_support': 244.0, 'O_support': 2736, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 1}, {'micro_f1': 0.7337377117757792, 'Appeal_to_Authority_precision': 0.27350427350427353, 'Appeal_to_Authority_recall': 0.14953271028037382, 'Appeal_to_Authority_f1-score': 0.19335347432024166, 'Appeal_to_Authority_support': 214.0, 'micro avg_precision': 0.27350427350427353, 'micro avg_recall': 0.14953271028037382, 'micro avg_f1-score': 0.19335347432024166, 'micro avg_support': 214.0, 'macro avg_precision': 0.27350427350427353, 'macro avg_recall': 0.14953271028037382, 'macro avg_f1-score': 0.19335347432024166, 'macro avg_support': 214.0, 'weighted avg_precision': 0.27350427350427353, 'weighted avg_recall': 0.14953271028037382, 'weighted avg_f1-score': 0.19335347432024166, 'weighted avg_support': 214.0, 'O_support': 2736, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 2}, {'micro_f1': 0.7500522903158335, 'Appeal_to_Authority_precision': 0.29914529914529914, 'Appeal_to_Authority_recall': 0.17326732673267325, 'Appeal_to_Authority_f1-score': 0.21943573667711597, 'Appeal_to_Authority_support': 202.0, 'micro avg_precision': 0.29914529914529914, 'micro avg_recall': 0.17326732673267325, 'micro avg_f1-score': 0.21943573667711597, 'micro avg_support': 202.0, 'macro avg_precision': 0.29914529914529914, 'macro avg_recall': 0.17326732673267325, 'macro avg_f1-score': 0.21943573667711597, 'macro avg_support': 202.0, 'weighted avg_precision': 0.29914529914529914, 'weighted avg_recall': 0.17326732673267325, 'weighted avg_f1-score': 0.21943573667711597, 'weighted avg_support': 202.0, 'O_support': 2736, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 3}]}
Best model updated: current epoch macro f1 = 0.21943573667711597
{'micro_f1': 0.7454507425224849, 'Appeal_to_Authority_precision': 0.3076923076923077, 'Appeal_to_Authority_recall': 0.17391304347826086, 'Appeal_to_Authority_f1-score': 0.2222222222222222, 'Appeal_to_Authority_support': 207.0, 'micro avg_precision': 0.3076923076923077, 'micro avg_recall': 0.17391304347826086, 'micro avg_f1-score': 0.2222222222222222, 'micro avg_support': 207.0, 'macro avg_precision': 0.3076923076923077, 'macro avg_recall': 0.17391304347826086, 'macro avg_f1-score': 0.2222222222222222, 'macro avg_support': 207.0, 'weighted avg_precision': 0.3076923076923077, 'weighted avg_recall': 0.17391304347826086, 'weighted avg_f1-score': 0.2222222222222222, 'weighted avg_support': 207.0, 'O_support': 2736, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 4}
{'results': [{'micro_f1': 0.7247437774524158, 'Appeal_to_Authority_precision': 0.1111111111111111, 'Appeal_to_Authority_recall': 0.04100946372239748, 'Appeal_to_Authority_f1-score': 0.05990783410138249, 'Appeal_to_Authority_support': 317.0, 'micro avg_precision': 0.1111111111111111, 'micro avg_recall': 0.04100946372239748, 'micro avg_f1-score': 0.05990783410138249, 'micro avg_support': 317.0, 'macro avg_precision': 0.1111111111111111, 'macro avg_recall': 0.04100946372239748, 'macro avg_f1-score': 0.05990783410138249, 'macro avg_support': 317.0, 'weighted avg_precision': 0.1111111111111111, 'weighted avg_recall': 0.04100946372239748, 'weighted avg_f1-score': 0.05990783410138249, 'weighted avg_support': 317.0, 'O_support': 2736, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 0}, {'micro_f1': 0.7195147458690652, 'Appeal_to_Authority_precision': 0.1623931623931624, 'Appeal_to_Authority_recall': 0.0778688524590164, 'Appeal_to_Authority_f1-score': 0.10526315789473684, 'Appeal_to_Authority_support': 244.0, 'micro avg_precision': 0.1623931623931624, 'micro avg_recall': 0.0778688524590164, 'micro avg_f1-score': 0.10526315789473684, 'micro avg_support': 244.0, 'macro avg_precision': 0.1623931623931624, 'macro avg_recall': 0.0778688524590164, 'macro avg_f1-score': 0.10526315789473684, 'macro avg_support': 244.0, 'weighted avg_precision': 0.1623931623931624, 'weighted avg_recall': 0.0778688524590164, 'weighted avg_f1-score': 0.10526315789473684, 'weighted avg_support': 244.0, 'O_support': 2736, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 1}, {'micro_f1': 0.7337377117757792, 'Appeal_to_Authority_precision': 0.27350427350427353, 'Appeal_to_Authority_recall': 0.14953271028037382, 'Appeal_to_Authority_f1-score': 0.19335347432024166, 'Appeal_to_Authority_support': 214.0, 'micro avg_precision': 0.27350427350427353, 'micro avg_recall': 0.14953271028037382, 'micro avg_f1-score': 0.19335347432024166, 'micro avg_support': 214.0, 'macro avg_precision': 0.27350427350427353, 'macro avg_recall': 0.14953271028037382, 'macro avg_f1-score': 0.19335347432024166, 'macro avg_support': 214.0, 'weighted avg_precision': 0.27350427350427353, 'weighted avg_recall': 0.14953271028037382, 'weighted avg_f1-score': 0.19335347432024166, 'weighted avg_support': 214.0, 'O_support': 2736, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 2}, {'micro_f1': 0.7500522903158335, 'Appeal_to_Authority_precision': 0.29914529914529914, 'Appeal_to_Authority_recall': 0.17326732673267325, 'Appeal_to_Authority_f1-score': 0.21943573667711597, 'Appeal_to_Authority_support': 202.0, 'micro avg_precision': 0.29914529914529914, 'micro avg_recall': 0.17326732673267325, 'micro avg_f1-score': 0.21943573667711597, 'micro avg_support': 202.0, 'macro avg_precision': 0.29914529914529914, 'macro avg_recall': 0.17326732673267325, 'macro avg_f1-score': 0.21943573667711597, 'macro avg_support': 202.0, 'weighted avg_precision': 0.29914529914529914, 'weighted avg_recall': 0.17326732673267325, 'weighted avg_f1-score': 0.21943573667711597, 'weighted avg_support': 202.0, 'O_support': 2736, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 3}, {'micro_f1': 0.7454507425224849, 'Appeal_to_Authority_precision': 0.3076923076923077, 'Appeal_to_Authority_recall': 0.17391304347826086, 'Appeal_to_Authority_f1-score': 0.2222222222222222, 'Appeal_to_Authority_support': 207.0, 'micro avg_precision': 0.3076923076923077, 'micro avg_recall': 0.17391304347826086, 'micro avg_f1-score': 0.2222222222222222, 'micro avg_support': 207.0, 'macro avg_precision': 0.3076923076923077, 'macro avg_recall': 0.17391304347826086, 'macro avg_f1-score': 0.2222222222222222, 'macro avg_support': 207.0, 'weighted avg_precision': 0.3076923076923077, 'weighted avg_recall': 0.17391304347826086, 'weighted avg_f1-score': 0.2222222222222222, 'weighted avg_support': 207.0, 'O_support': 2736, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 4}]}
Best model updated: current epoch macro f1 = 0.2222222222222222
{'micro_f1': 0.7337377117757792, 'Appeal_to_Authority_precision': 0.3076923076923077, 'Appeal_to_Authority_recall': 0.16901408450704225, 'Appeal_to_Authority_f1-score': 0.21818181818181817, 'Appeal_to_Authority_support': 213.0, 'micro avg_precision': 0.3076923076923077, 'micro avg_recall': 0.16901408450704225, 'micro avg_f1-score': 0.21818181818181817, 'micro avg_support': 213.0, 'macro avg_precision': 0.3076923076923077, 'macro avg_recall': 0.16901408450704225, 'macro avg_f1-score': 0.21818181818181817, 'macro avg_support': 213.0, 'weighted avg_precision': 0.3076923076923077, 'weighted avg_recall': 0.16901408450704225, 'weighted avg_f1-score': 0.21818181818181817, 'weighted avg_support': 213.0, 'O_support': 2736, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 5}
{'results': [{'micro_f1': 0.7247437774524158, 'Appeal_to_Authority_precision': 0.1111111111111111, 'Appeal_to_Authority_recall': 0.04100946372239748, 'Appeal_to_Authority_f1-score': 0.05990783410138249, 'Appeal_to_Authority_support': 317.0, 'micro avg_precision': 0.1111111111111111, 'micro avg_recall': 0.04100946372239748, 'micro avg_f1-score': 0.05990783410138249, 'micro avg_support': 317.0, 'macro avg_precision': 0.1111111111111111, 'macro avg_recall': 0.04100946372239748, 'macro avg_f1-score': 0.05990783410138249, 'macro avg_support': 317.0, 'weighted avg_precision': 0.1111111111111111, 'weighted avg_recall': 0.04100946372239748, 'weighted avg_f1-score': 0.05990783410138249, 'weighted avg_support': 317.0, 'O_support': 2736, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 0}, {'micro_f1': 0.7195147458690652, 'Appeal_to_Authority_precision': 0.1623931623931624, 'Appeal_to_Authority_recall': 0.0778688524590164, 'Appeal_to_Authority_f1-score': 0.10526315789473684, 'Appeal_to_Authority_support': 244.0, 'micro avg_precision': 0.1623931623931624, 'micro avg_recall': 0.0778688524590164, 'micro avg_f1-score': 0.10526315789473684, 'micro avg_support': 244.0, 'macro avg_precision': 0.1623931623931624, 'macro avg_recall': 0.0778688524590164, 'macro avg_f1-score': 0.10526315789473684, 'macro avg_support': 244.0, 'weighted avg_precision': 0.1623931623931624, 'weighted avg_recall': 0.0778688524590164, 'weighted avg_f1-score': 0.10526315789473684, 'weighted avg_support': 244.0, 'O_support': 2736, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 1}, {'micro_f1': 0.7337377117757792, 'Appeal_to_Authority_precision': 0.27350427350427353, 'Appeal_to_Authority_recall': 0.14953271028037382, 'Appeal_to_Authority_f1-score': 0.19335347432024166, 'Appeal_to_Authority_support': 214.0, 'micro avg_precision': 0.27350427350427353, 'micro avg_recall': 0.14953271028037382, 'micro avg_f1-score': 0.19335347432024166, 'micro avg_support': 214.0, 'macro avg_precision': 0.27350427350427353, 'macro avg_recall': 0.14953271028037382, 'macro avg_f1-score': 0.19335347432024166, 'macro avg_support': 214.0, 'weighted avg_precision': 0.27350427350427353, 'weighted avg_recall': 0.14953271028037382, 'weighted avg_f1-score': 0.19335347432024166, 'weighted avg_support': 214.0, 'O_support': 2736, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 2}, {'micro_f1': 0.7500522903158335, 'Appeal_to_Authority_precision': 0.29914529914529914, 'Appeal_to_Authority_recall': 0.17326732673267325, 'Appeal_to_Authority_f1-score': 0.21943573667711597, 'Appeal_to_Authority_support': 202.0, 'micro avg_precision': 0.29914529914529914, 'micro avg_recall': 0.17326732673267325, 'micro avg_f1-score': 0.21943573667711597, 'micro avg_support': 202.0, 'macro avg_precision': 0.29914529914529914, 'macro avg_recall': 0.17326732673267325, 'macro avg_f1-score': 0.21943573667711597, 'macro avg_support': 202.0, 'weighted avg_precision': 0.29914529914529914, 'weighted avg_recall': 0.17326732673267325, 'weighted avg_f1-score': 0.21943573667711597, 'weighted avg_support': 202.0, 'O_support': 2736, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 3}, {'micro_f1': 0.7454507425224849, 'Appeal_to_Authority_precision': 0.3076923076923077, 'Appeal_to_Authority_recall': 0.17391304347826086, 'Appeal_to_Authority_f1-score': 0.2222222222222222, 'Appeal_to_Authority_support': 207.0, 'micro avg_precision': 0.3076923076923077, 'micro avg_recall': 0.17391304347826086, 'micro avg_f1-score': 0.2222222222222222, 'micro avg_support': 207.0, 'macro avg_precision': 0.3076923076923077, 'macro avg_recall': 0.17391304347826086, 'macro avg_f1-score': 0.2222222222222222, 'macro avg_support': 207.0, 'weighted avg_precision': 0.3076923076923077, 'weighted avg_recall': 0.17391304347826086, 'weighted avg_f1-score': 0.2222222222222222, 'weighted avg_support': 207.0, 'O_support': 2736, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 4}, {'micro_f1': 0.7337377117757792, 'Appeal_to_Authority_precision': 0.3076923076923077, 'Appeal_to_Authority_recall': 0.16901408450704225, 'Appeal_to_Authority_f1-score': 0.21818181818181817, 'Appeal_to_Authority_support': 213.0, 'micro avg_precision': 0.3076923076923077, 'micro avg_recall': 0.16901408450704225, 'micro avg_f1-score': 0.21818181818181817, 'micro avg_support': 213.0, 'macro avg_precision': 0.3076923076923077, 'macro avg_recall': 0.16901408450704225, 'macro avg_f1-score': 0.21818181818181817, 'macro avg_support': 213.0, 'weighted avg_precision': 0.3076923076923077, 'weighted avg_recall': 0.16901408450704225, 'weighted avg_f1-score': 0.21818181818181817, 'weighted avg_support': 213.0, 'O_support': 2736, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 5}]}
{'micro_f1': 0.732901066722443, 'Appeal_to_Authority_precision': 0.38461538461538464, 'Appeal_to_Authority_recall': 0.22613065326633167, 'Appeal_to_Authority_f1-score': 0.2848101265822785, 'Appeal_to_Authority_support': 199.0, 'micro avg_precision': 0.38461538461538464, 'micro avg_recall': 0.22613065326633167, 'micro avg_f1-score': 0.2848101265822785, 'micro avg_support': 199.0, 'macro avg_precision': 0.38461538461538464, 'macro avg_recall': 0.22613065326633167, 'macro avg_f1-score': 0.2848101265822785, 'macro avg_support': 199.0, 'weighted avg_precision': 0.38461538461538464, 'weighted avg_recall': 0.22613065326633167, 'weighted avg_f1-score': 0.2848101265822785, 'weighted avg_support': 199.0, 'O_support': 2736, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 6}
{'results': [{'micro_f1': 0.7247437774524158, 'Appeal_to_Authority_precision': 0.1111111111111111, 'Appeal_to_Authority_recall': 0.04100946372239748, 'Appeal_to_Authority_f1-score': 0.05990783410138249, 'Appeal_to_Authority_support': 317.0, 'micro avg_precision': 0.1111111111111111, 'micro avg_recall': 0.04100946372239748, 'micro avg_f1-score': 0.05990783410138249, 'micro avg_support': 317.0, 'macro avg_precision': 0.1111111111111111, 'macro avg_recall': 0.04100946372239748, 'macro avg_f1-score': 0.05990783410138249, 'macro avg_support': 317.0, 'weighted avg_precision': 0.1111111111111111, 'weighted avg_recall': 0.04100946372239748, 'weighted avg_f1-score': 0.05990783410138249, 'weighted avg_support': 317.0, 'O_support': 2736, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 0}, {'micro_f1': 0.7195147458690652, 'Appeal_to_Authority_precision': 0.1623931623931624, 'Appeal_to_Authority_recall': 0.0778688524590164, 'Appeal_to_Authority_f1-score': 0.10526315789473684, 'Appeal_to_Authority_support': 244.0, 'micro avg_precision': 0.1623931623931624, 'micro avg_recall': 0.0778688524590164, 'micro avg_f1-score': 0.10526315789473684, 'micro avg_support': 244.0, 'macro avg_precision': 0.1623931623931624, 'macro avg_recall': 0.0778688524590164, 'macro avg_f1-score': 0.10526315789473684, 'macro avg_support': 244.0, 'weighted avg_precision': 0.1623931623931624, 'weighted avg_recall': 0.0778688524590164, 'weighted avg_f1-score': 0.10526315789473684, 'weighted avg_support': 244.0, 'O_support': 2736, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 1}, {'micro_f1': 0.7337377117757792, 'Appeal_to_Authority_precision': 0.27350427350427353, 'Appeal_to_Authority_recall': 0.14953271028037382, 'Appeal_to_Authority_f1-score': 0.19335347432024166, 'Appeal_to_Authority_support': 214.0, 'micro avg_precision': 0.27350427350427353, 'micro avg_recall': 0.14953271028037382, 'micro avg_f1-score': 0.19335347432024166, 'micro avg_support': 214.0, 'macro avg_precision': 0.27350427350427353, 'macro avg_recall': 0.14953271028037382, 'macro avg_f1-score': 0.19335347432024166, 'macro avg_support': 214.0, 'weighted avg_precision': 0.27350427350427353, 'weighted avg_recall': 0.14953271028037382, 'weighted avg_f1-score': 0.19335347432024166, 'weighted avg_support': 214.0, 'O_support': 2736, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 2}, {'micro_f1': 0.7500522903158335, 'Appeal_to_Authority_precision': 0.29914529914529914, 'Appeal_to_Authority_recall': 0.17326732673267325, 'Appeal_to_Authority_f1-score': 0.21943573667711597, 'Appeal_to_Authority_support': 202.0, 'micro avg_precision': 0.29914529914529914, 'micro avg_recall': 0.17326732673267325, 'micro avg_f1-score': 0.21943573667711597, 'micro avg_support': 202.0, 'macro avg_precision': 0.29914529914529914, 'macro avg_recall': 0.17326732673267325, 'macro avg_f1-score': 0.21943573667711597, 'macro avg_support': 202.0, 'weighted avg_precision': 0.29914529914529914, 'weighted avg_recall': 0.17326732673267325, 'weighted avg_f1-score': 0.21943573667711597, 'weighted avg_support': 202.0, 'O_support': 2736, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 3}, {'micro_f1': 0.7454507425224849, 'Appeal_to_Authority_precision': 0.3076923076923077, 'Appeal_to_Authority_recall': 0.17391304347826086, 'Appeal_to_Authority_f1-score': 0.2222222222222222, 'Appeal_to_Authority_support': 207.0, 'micro avg_precision': 0.3076923076923077, 'micro avg_recall': 0.17391304347826086, 'micro avg_f1-score': 0.2222222222222222, 'micro avg_support': 207.0, 'macro avg_precision': 0.3076923076923077, 'macro avg_recall': 0.17391304347826086, 'macro avg_f1-score': 0.2222222222222222, 'macro avg_support': 207.0, 'weighted avg_precision': 0.3076923076923077, 'weighted avg_recall': 0.17391304347826086, 'weighted avg_f1-score': 0.2222222222222222, 'weighted avg_support': 207.0, 'O_support': 2736, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 4}, {'micro_f1': 0.7337377117757792, 'Appeal_to_Authority_precision': 0.3076923076923077, 'Appeal_to_Authority_recall': 0.16901408450704225, 'Appeal_to_Authority_f1-score': 0.21818181818181817, 'Appeal_to_Authority_support': 213.0, 'micro avg_precision': 0.3076923076923077, 'micro avg_recall': 0.16901408450704225, 'micro avg_f1-score': 0.21818181818181817, 'micro avg_support': 213.0, 'macro avg_precision': 0.3076923076923077, 'macro avg_recall': 0.16901408450704225, 'macro avg_f1-score': 0.21818181818181817, 'macro avg_support': 213.0, 'weighted avg_precision': 0.3076923076923077, 'weighted avg_recall': 0.16901408450704225, 'weighted avg_f1-score': 0.21818181818181817, 'weighted avg_support': 213.0, 'O_support': 2736, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 5}, {'micro_f1': 0.732901066722443, 'Appeal_to_Authority_precision': 0.38461538461538464, 'Appeal_to_Authority_recall': 0.22613065326633167, 'Appeal_to_Authority_f1-score': 0.2848101265822785, 'Appeal_to_Authority_support': 199.0, 'micro avg_precision': 0.38461538461538464, 'micro avg_recall': 0.22613065326633167, 'micro avg_f1-score': 0.2848101265822785, 'micro avg_support': 199.0, 'macro avg_precision': 0.38461538461538464, 'macro avg_recall': 0.22613065326633167, 'macro avg_f1-score': 0.2848101265822785, 'macro avg_support': 199.0, 'weighted avg_precision': 0.38461538461538464, 'weighted avg_recall': 0.22613065326633167, 'weighted avg_f1-score': 0.2848101265822785, 'weighted avg_support': 199.0, 'O_support': 2736, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 6}]}
Best model updated: current epoch macro f1 = 0.2848101265822785
{'micro_f1': 0.7347835180924491, 'Appeal_to_Authority_precision': 0.3076923076923077, 'Appeal_to_Authority_recall': 0.17391304347826086, 'Appeal_to_Authority_f1-score': 0.2222222222222222, 'Appeal_to_Authority_support': 207.0, 'micro avg_precision': 0.3076923076923077, 'micro avg_recall': 0.17391304347826086, 'micro avg_f1-score': 0.2222222222222222, 'micro avg_support': 207.0, 'macro avg_precision': 0.3076923076923077, 'macro avg_recall': 0.17391304347826086, 'macro avg_f1-score': 0.2222222222222222, 'macro avg_support': 207.0, 'weighted avg_precision': 0.3076923076923077, 'weighted avg_recall': 0.17391304347826086, 'weighted avg_f1-score': 0.2222222222222222, 'weighted avg_support': 207.0, 'O_support': 2736, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 7}
{'results': [{'micro_f1': 0.7247437774524158, 'Appeal_to_Authority_precision': 0.1111111111111111, 'Appeal_to_Authority_recall': 0.04100946372239748, 'Appeal_to_Authority_f1-score': 0.05990783410138249, 'Appeal_to_Authority_support': 317.0, 'micro avg_precision': 0.1111111111111111, 'micro avg_recall': 0.04100946372239748, 'micro avg_f1-score': 0.05990783410138249, 'micro avg_support': 317.0, 'macro avg_precision': 0.1111111111111111, 'macro avg_recall': 0.04100946372239748, 'macro avg_f1-score': 0.05990783410138249, 'macro avg_support': 317.0, 'weighted avg_precision': 0.1111111111111111, 'weighted avg_recall': 0.04100946372239748, 'weighted avg_f1-score': 0.05990783410138249, 'weighted avg_support': 317.0, 'O_support': 2736, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 0}, {'micro_f1': 0.7195147458690652, 'Appeal_to_Authority_precision': 0.1623931623931624, 'Appeal_to_Authority_recall': 0.0778688524590164, 'Appeal_to_Authority_f1-score': 0.10526315789473684, 'Appeal_to_Authority_support': 244.0, 'micro avg_precision': 0.1623931623931624, 'micro avg_recall': 0.0778688524590164, 'micro avg_f1-score': 0.10526315789473684, 'micro avg_support': 244.0, 'macro avg_precision': 0.1623931623931624, 'macro avg_recall': 0.0778688524590164, 'macro avg_f1-score': 0.10526315789473684, 'macro avg_support': 244.0, 'weighted avg_precision': 0.1623931623931624, 'weighted avg_recall': 0.0778688524590164, 'weighted avg_f1-score': 0.10526315789473684, 'weighted avg_support': 244.0, 'O_support': 2736, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 1}, {'micro_f1': 0.7337377117757792, 'Appeal_to_Authority_precision': 0.27350427350427353, 'Appeal_to_Authority_recall': 0.14953271028037382, 'Appeal_to_Authority_f1-score': 0.19335347432024166, 'Appeal_to_Authority_support': 214.0, 'micro avg_precision': 0.27350427350427353, 'micro avg_recall': 0.14953271028037382, 'micro avg_f1-score': 0.19335347432024166, 'micro avg_support': 214.0, 'macro avg_precision': 0.27350427350427353, 'macro avg_recall': 0.14953271028037382, 'macro avg_f1-score': 0.19335347432024166, 'macro avg_support': 214.0, 'weighted avg_precision': 0.27350427350427353, 'weighted avg_recall': 0.14953271028037382, 'weighted avg_f1-score': 0.19335347432024166, 'weighted avg_support': 214.0, 'O_support': 2736, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 2}, {'micro_f1': 0.7500522903158335, 'Appeal_to_Authority_precision': 0.29914529914529914, 'Appeal_to_Authority_recall': 0.17326732673267325, 'Appeal_to_Authority_f1-score': 0.21943573667711597, 'Appeal_to_Authority_support': 202.0, 'micro avg_precision': 0.29914529914529914, 'micro avg_recall': 0.17326732673267325, 'micro avg_f1-score': 0.21943573667711597, 'micro avg_support': 202.0, 'macro avg_precision': 0.29914529914529914, 'macro avg_recall': 0.17326732673267325, 'macro avg_f1-score': 0.21943573667711597, 'macro avg_support': 202.0, 'weighted avg_precision': 0.29914529914529914, 'weighted avg_recall': 0.17326732673267325, 'weighted avg_f1-score': 0.21943573667711597, 'weighted avg_support': 202.0, 'O_support': 2736, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 3}, {'micro_f1': 0.7454507425224849, 'Appeal_to_Authority_precision': 0.3076923076923077, 'Appeal_to_Authority_recall': 0.17391304347826086, 'Appeal_to_Authority_f1-score': 0.2222222222222222, 'Appeal_to_Authority_support': 207.0, 'micro avg_precision': 0.3076923076923077, 'micro avg_recall': 0.17391304347826086, 'micro avg_f1-score': 0.2222222222222222, 'micro avg_support': 207.0, 'macro avg_precision': 0.3076923076923077, 'macro avg_recall': 0.17391304347826086, 'macro avg_f1-score': 0.2222222222222222, 'macro avg_support': 207.0, 'weighted avg_precision': 0.3076923076923077, 'weighted avg_recall': 0.17391304347826086, 'weighted avg_f1-score': 0.2222222222222222, 'weighted avg_support': 207.0, 'O_support': 2736, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 4}, {'micro_f1': 0.7337377117757792, 'Appeal_to_Authority_precision': 0.3076923076923077, 'Appeal_to_Authority_recall': 0.16901408450704225, 'Appeal_to_Authority_f1-score': 0.21818181818181817, 'Appeal_to_Authority_support': 213.0, 'micro avg_precision': 0.3076923076923077, 'micro avg_recall': 0.16901408450704225, 'micro avg_f1-score': 0.21818181818181817, 'micro avg_support': 213.0, 'macro avg_precision': 0.3076923076923077, 'macro avg_recall': 0.16901408450704225, 'macro avg_f1-score': 0.21818181818181817, 'macro avg_support': 213.0, 'weighted avg_precision': 0.3076923076923077, 'weighted avg_recall': 0.16901408450704225, 'weighted avg_f1-score': 0.21818181818181817, 'weighted avg_support': 213.0, 'O_support': 2736, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 5}, {'micro_f1': 0.732901066722443, 'Appeal_to_Authority_precision': 0.38461538461538464, 'Appeal_to_Authority_recall': 0.22613065326633167, 'Appeal_to_Authority_f1-score': 0.2848101265822785, 'Appeal_to_Authority_support': 199.0, 'micro avg_precision': 0.38461538461538464, 'micro avg_recall': 0.22613065326633167, 'micro avg_f1-score': 0.2848101265822785, 'micro avg_support': 199.0, 'macro avg_precision': 0.38461538461538464, 'macro avg_recall': 0.22613065326633167, 'macro avg_f1-score': 0.2848101265822785, 'macro avg_support': 199.0, 'weighted avg_precision': 0.38461538461538464, 'weighted avg_recall': 0.22613065326633167, 'weighted avg_f1-score': 0.2848101265822785, 'weighted avg_support': 199.0, 'O_support': 2736, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 6}, {'micro_f1': 0.7347835180924491, 'Appeal_to_Authority_precision': 0.3076923076923077, 'Appeal_to_Authority_recall': 0.17391304347826086, 'Appeal_to_Authority_f1-score': 0.2222222222222222, 'Appeal_to_Authority_support': 207.0, 'micro avg_precision': 0.3076923076923077, 'micro avg_recall': 0.17391304347826086, 'micro avg_f1-score': 0.2222222222222222, 'micro avg_support': 207.0, 'macro avg_precision': 0.3076923076923077, 'macro avg_recall': 0.17391304347826086, 'macro avg_f1-score': 0.2222222222222222, 'macro avg_support': 207.0, 'weighted avg_precision': 0.3076923076923077, 'weighted avg_recall': 0.17391304347826086, 'weighted avg_f1-score': 0.2222222222222222, 'weighted avg_support': 207.0, 'O_support': 2736, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 7}]}
{'micro_f1': 0.7467057101024889, 'Appeal_to_Authority_precision': 0.3162393162393162, 'Appeal_to_Authority_recall': 0.18781725888324874, 'Appeal_to_Authority_f1-score': 0.2356687898089172, 'Appeal_to_Authority_support': 197.0, 'micro avg_precision': 0.3162393162393162, 'micro avg_recall': 0.18781725888324874, 'micro avg_f1-score': 0.2356687898089172, 'micro avg_support': 197.0, 'macro avg_precision': 0.3162393162393162, 'macro avg_recall': 0.18781725888324874, 'macro avg_f1-score': 0.2356687898089172, 'macro avg_support': 197.0, 'weighted avg_precision': 0.3162393162393162, 'weighted avg_recall': 0.18781725888324874, 'weighted avg_f1-score': 0.2356687898089172, 'weighted avg_support': 197.0, 'O_support': 2736, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 8}
{'results': [{'micro_f1': 0.7247437774524158, 'Appeal_to_Authority_precision': 0.1111111111111111, 'Appeal_to_Authority_recall': 0.04100946372239748, 'Appeal_to_Authority_f1-score': 0.05990783410138249, 'Appeal_to_Authority_support': 317.0, 'micro avg_precision': 0.1111111111111111, 'micro avg_recall': 0.04100946372239748, 'micro avg_f1-score': 0.05990783410138249, 'micro avg_support': 317.0, 'macro avg_precision': 0.1111111111111111, 'macro avg_recall': 0.04100946372239748, 'macro avg_f1-score': 0.05990783410138249, 'macro avg_support': 317.0, 'weighted avg_precision': 0.1111111111111111, 'weighted avg_recall': 0.04100946372239748, 'weighted avg_f1-score': 0.05990783410138249, 'weighted avg_support': 317.0, 'O_support': 2736, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 0}, {'micro_f1': 0.7195147458690652, 'Appeal_to_Authority_precision': 0.1623931623931624, 'Appeal_to_Authority_recall': 0.0778688524590164, 'Appeal_to_Authority_f1-score': 0.10526315789473684, 'Appeal_to_Authority_support': 244.0, 'micro avg_precision': 0.1623931623931624, 'micro avg_recall': 0.0778688524590164, 'micro avg_f1-score': 0.10526315789473684, 'micro avg_support': 244.0, 'macro avg_precision': 0.1623931623931624, 'macro avg_recall': 0.0778688524590164, 'macro avg_f1-score': 0.10526315789473684, 'macro avg_support': 244.0, 'weighted avg_precision': 0.1623931623931624, 'weighted avg_recall': 0.0778688524590164, 'weighted avg_f1-score': 0.10526315789473684, 'weighted avg_support': 244.0, 'O_support': 2736, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 1}, {'micro_f1': 0.7337377117757792, 'Appeal_to_Authority_precision': 0.27350427350427353, 'Appeal_to_Authority_recall': 0.14953271028037382, 'Appeal_to_Authority_f1-score': 0.19335347432024166, 'Appeal_to_Authority_support': 214.0, 'micro avg_precision': 0.27350427350427353, 'micro avg_recall': 0.14953271028037382, 'micro avg_f1-score': 0.19335347432024166, 'micro avg_support': 214.0, 'macro avg_precision': 0.27350427350427353, 'macro avg_recall': 0.14953271028037382, 'macro avg_f1-score': 0.19335347432024166, 'macro avg_support': 214.0, 'weighted avg_precision': 0.27350427350427353, 'weighted avg_recall': 0.14953271028037382, 'weighted avg_f1-score': 0.19335347432024166, 'weighted avg_support': 214.0, 'O_support': 2736, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 2}, {'micro_f1': 0.7500522903158335, 'Appeal_to_Authority_precision': 0.29914529914529914, 'Appeal_to_Authority_recall': 0.17326732673267325, 'Appeal_to_Authority_f1-score': 0.21943573667711597, 'Appeal_to_Authority_support': 202.0, 'micro avg_precision': 0.29914529914529914, 'micro avg_recall': 0.17326732673267325, 'micro avg_f1-score': 0.21943573667711597, 'micro avg_support': 202.0, 'macro avg_precision': 0.29914529914529914, 'macro avg_recall': 0.17326732673267325, 'macro avg_f1-score': 0.21943573667711597, 'macro avg_support': 202.0, 'weighted avg_precision': 0.29914529914529914, 'weighted avg_recall': 0.17326732673267325, 'weighted avg_f1-score': 0.21943573667711597, 'weighted avg_support': 202.0, 'O_support': 2736, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 3}, {'micro_f1': 0.7454507425224849, 'Appeal_to_Authority_precision': 0.3076923076923077, 'Appeal_to_Authority_recall': 0.17391304347826086, 'Appeal_to_Authority_f1-score': 0.2222222222222222, 'Appeal_to_Authority_support': 207.0, 'micro avg_precision': 0.3076923076923077, 'micro avg_recall': 0.17391304347826086, 'micro avg_f1-score': 0.2222222222222222, 'micro avg_support': 207.0, 'macro avg_precision': 0.3076923076923077, 'macro avg_recall': 0.17391304347826086, 'macro avg_f1-score': 0.2222222222222222, 'macro avg_support': 207.0, 'weighted avg_precision': 0.3076923076923077, 'weighted avg_recall': 0.17391304347826086, 'weighted avg_f1-score': 0.2222222222222222, 'weighted avg_support': 207.0, 'O_support': 2736, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 4}, {'micro_f1': 0.7337377117757792, 'Appeal_to_Authority_precision': 0.3076923076923077, 'Appeal_to_Authority_recall': 0.16901408450704225, 'Appeal_to_Authority_f1-score': 0.21818181818181817, 'Appeal_to_Authority_support': 213.0, 'micro avg_precision': 0.3076923076923077, 'micro avg_recall': 0.16901408450704225, 'micro avg_f1-score': 0.21818181818181817, 'micro avg_support': 213.0, 'macro avg_precision': 0.3076923076923077, 'macro avg_recall': 0.16901408450704225, 'macro avg_f1-score': 0.21818181818181817, 'macro avg_support': 213.0, 'weighted avg_precision': 0.3076923076923077, 'weighted avg_recall': 0.16901408450704225, 'weighted avg_f1-score': 0.21818181818181817, 'weighted avg_support': 213.0, 'O_support': 2736, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 5}, {'micro_f1': 0.732901066722443, 'Appeal_to_Authority_precision': 0.38461538461538464, 'Appeal_to_Authority_recall': 0.22613065326633167, 'Appeal_to_Authority_f1-score': 0.2848101265822785, 'Appeal_to_Authority_support': 199.0, 'micro avg_precision': 0.38461538461538464, 'micro avg_recall': 0.22613065326633167, 'micro avg_f1-score': 0.2848101265822785, 'micro avg_support': 199.0, 'macro avg_precision': 0.38461538461538464, 'macro avg_recall': 0.22613065326633167, 'macro avg_f1-score': 0.2848101265822785, 'macro avg_support': 199.0, 'weighted avg_precision': 0.38461538461538464, 'weighted avg_recall': 0.22613065326633167, 'weighted avg_f1-score': 0.2848101265822785, 'weighted avg_support': 199.0, 'O_support': 2736, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 6}, {'micro_f1': 0.7347835180924491, 'Appeal_to_Authority_precision': 0.3076923076923077, 'Appeal_to_Authority_recall': 0.17391304347826086, 'Appeal_to_Authority_f1-score': 0.2222222222222222, 'Appeal_to_Authority_support': 207.0, 'micro avg_precision': 0.3076923076923077, 'micro avg_recall': 0.17391304347826086, 'micro avg_f1-score': 0.2222222222222222, 'micro avg_support': 207.0, 'macro avg_precision': 0.3076923076923077, 'macro avg_recall': 0.17391304347826086, 'macro avg_f1-score': 0.2222222222222222, 'macro avg_support': 207.0, 'weighted avg_precision': 0.3076923076923077, 'weighted avg_recall': 0.17391304347826086, 'weighted avg_f1-score': 0.2222222222222222, 'weighted avg_support': 207.0, 'O_support': 2736, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 7}, {'micro_f1': 0.7467057101024889, 'Appeal_to_Authority_precision': 0.3162393162393162, 'Appeal_to_Authority_recall': 0.18781725888324874, 'Appeal_to_Authority_f1-score': 0.2356687898089172, 'Appeal_to_Authority_support': 197.0, 'micro avg_precision': 0.3162393162393162, 'micro avg_recall': 0.18781725888324874, 'micro avg_f1-score': 0.2356687898089172, 'micro avg_support': 197.0, 'macro avg_precision': 0.3162393162393162, 'macro avg_recall': 0.18781725888324874, 'macro avg_f1-score': 0.2356687898089172, 'macro avg_support': 197.0, 'weighted avg_precision': 0.3162393162393162, 'weighted avg_recall': 0.18781725888324874, 'weighted avg_f1-score': 0.2356687898089172, 'weighted avg_support': 197.0, 'O_support': 2736, 'B-Appeal_to_Authority_support': 117, 'I-Appeal_to_Authority_support': 1928, 'epoch': 8}]}
Early stopping triggered.
Saving model to directory: ./models/M2/2024-05-12-17-42-10_aug/mdeberta-v3-base_0_ME10_target=Appeal_to_Authority_SUBSAMPLED_2024-05-12-17-42-10
Training model no. 1 of 23 for (1, 'Appeal_to_Popularity') persuasion technique...
{'micro_f1': 0.754591836734694, 'Appeal_to_Popularity_precision': 0.0425531914893617, 'Appeal_to_Popularity_recall': 0.014285714285714285, 'Appeal_to_Popularity_f1-score': 0.0213903743315508, 'Appeal_to_Popularity_support': 140.0, 'micro avg_precision': 0.0425531914893617, 'micro avg_recall': 0.014285714285714285, 'micro avg_f1-score': 0.0213903743315508, 'micro avg_support': 140.0, 'macro avg_precision': 0.0425531914893617, 'macro avg_recall': 0.014285714285714285, 'macro avg_f1-score': 0.0213903743315508, 'macro avg_support': 140.0, 'weighted avg_precision': 0.0425531914893617, 'weighted avg_recall': 0.014285714285714285, 'weighted avg_f1-score': 0.0213903743315508, 'weighted avg_support': 140.0, 'O_support': 1292, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 0}
{'results': [{'micro_f1': 0.754591836734694, 'Appeal_to_Popularity_precision': 0.0425531914893617, 'Appeal_to_Popularity_recall': 0.014285714285714285, 'Appeal_to_Popularity_f1-score': 0.0213903743315508, 'Appeal_to_Popularity_support': 140.0, 'micro avg_precision': 0.0425531914893617, 'micro avg_recall': 0.014285714285714285, 'micro avg_f1-score': 0.0213903743315508, 'micro avg_support': 140.0, 'macro avg_precision': 0.0425531914893617, 'macro avg_recall': 0.014285714285714285, 'macro avg_f1-score': 0.0213903743315508, 'macro avg_support': 140.0, 'weighted avg_precision': 0.0425531914893617, 'weighted avg_recall': 0.014285714285714285, 'weighted avg_f1-score': 0.0213903743315508, 'weighted avg_support': 140.0, 'O_support': 1292, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 0}]}
Best model updated: current epoch macro f1 = 0.0213903743315508
{'micro_f1': 0.6301020408163265, 'Appeal_to_Popularity_precision': 0.14893617021276595, 'Appeal_to_Popularity_recall': 0.058333333333333334, 'Appeal_to_Popularity_f1-score': 0.08383233532934131, 'Appeal_to_Popularity_support': 120.0, 'micro avg_precision': 0.14893617021276595, 'micro avg_recall': 0.058333333333333334, 'micro avg_f1-score': 0.08383233532934131, 'micro avg_support': 120.0, 'macro avg_precision': 0.14893617021276595, 'macro avg_recall': 0.058333333333333334, 'macro avg_f1-score': 0.08383233532934131, 'macro avg_support': 120.0, 'weighted avg_precision': 0.14893617021276595, 'weighted avg_recall': 0.058333333333333334, 'weighted avg_f1-score': 0.08383233532934131, 'weighted avg_support': 120.0, 'O_support': 1292, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 1}
{'results': [{'micro_f1': 0.754591836734694, 'Appeal_to_Popularity_precision': 0.0425531914893617, 'Appeal_to_Popularity_recall': 0.014285714285714285, 'Appeal_to_Popularity_f1-score': 0.0213903743315508, 'Appeal_to_Popularity_support': 140.0, 'micro avg_precision': 0.0425531914893617, 'micro avg_recall': 0.014285714285714285, 'micro avg_f1-score': 0.0213903743315508, 'micro avg_support': 140.0, 'macro avg_precision': 0.0425531914893617, 'macro avg_recall': 0.014285714285714285, 'macro avg_f1-score': 0.0213903743315508, 'macro avg_support': 140.0, 'weighted avg_precision': 0.0425531914893617, 'weighted avg_recall': 0.014285714285714285, 'weighted avg_f1-score': 0.0213903743315508, 'weighted avg_support': 140.0, 'O_support': 1292, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 0}, {'micro_f1': 0.6301020408163265, 'Appeal_to_Popularity_precision': 0.14893617021276595, 'Appeal_to_Popularity_recall': 0.058333333333333334, 'Appeal_to_Popularity_f1-score': 0.08383233532934131, 'Appeal_to_Popularity_support': 120.0, 'micro avg_precision': 0.14893617021276595, 'micro avg_recall': 0.058333333333333334, 'micro avg_f1-score': 0.08383233532934131, 'micro avg_support': 120.0, 'macro avg_precision': 0.14893617021276595, 'macro avg_recall': 0.058333333333333334, 'macro avg_f1-score': 0.08383233532934131, 'macro avg_support': 120.0, 'weighted avg_precision': 0.14893617021276595, 'weighted avg_recall': 0.058333333333333334, 'weighted avg_f1-score': 0.08383233532934131, 'weighted avg_support': 120.0, 'O_support': 1292, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 1}]}
Best model updated: current epoch macro f1 = 0.08383233532934131
{'micro_f1': 0.7683673469387755, 'Appeal_to_Popularity_precision': 0.10638297872340426, 'Appeal_to_Popularity_recall': 0.06756756756756757, 'Appeal_to_Popularity_f1-score': 0.08264462809917356, 'Appeal_to_Popularity_support': 74.0, 'micro avg_precision': 0.10638297872340426, 'micro avg_recall': 0.06756756756756757, 'micro avg_f1-score': 0.08264462809917356, 'micro avg_support': 74.0, 'macro avg_precision': 0.10638297872340426, 'macro avg_recall': 0.06756756756756757, 'macro avg_f1-score': 0.08264462809917356, 'macro avg_support': 74.0, 'weighted avg_precision': 0.10638297872340426, 'weighted avg_recall': 0.06756756756756757, 'weighted avg_f1-score': 0.08264462809917356, 'weighted avg_support': 74.0, 'O_support': 1292, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 2}
{'results': [{'micro_f1': 0.754591836734694, 'Appeal_to_Popularity_precision': 0.0425531914893617, 'Appeal_to_Popularity_recall': 0.014285714285714285, 'Appeal_to_Popularity_f1-score': 0.0213903743315508, 'Appeal_to_Popularity_support': 140.0, 'micro avg_precision': 0.0425531914893617, 'micro avg_recall': 0.014285714285714285, 'micro avg_f1-score': 0.0213903743315508, 'micro avg_support': 140.0, 'macro avg_precision': 0.0425531914893617, 'macro avg_recall': 0.014285714285714285, 'macro avg_f1-score': 0.0213903743315508, 'macro avg_support': 140.0, 'weighted avg_precision': 0.0425531914893617, 'weighted avg_recall': 0.014285714285714285, 'weighted avg_f1-score': 0.0213903743315508, 'weighted avg_support': 140.0, 'O_support': 1292, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 0}, {'micro_f1': 0.6301020408163265, 'Appeal_to_Popularity_precision': 0.14893617021276595, 'Appeal_to_Popularity_recall': 0.058333333333333334, 'Appeal_to_Popularity_f1-score': 0.08383233532934131, 'Appeal_to_Popularity_support': 120.0, 'micro avg_precision': 0.14893617021276595, 'micro avg_recall': 0.058333333333333334, 'micro avg_f1-score': 0.08383233532934131, 'micro avg_support': 120.0, 'macro avg_precision': 0.14893617021276595, 'macro avg_recall': 0.058333333333333334, 'macro avg_f1-score': 0.08383233532934131, 'macro avg_support': 120.0, 'weighted avg_precision': 0.14893617021276595, 'weighted avg_recall': 0.058333333333333334, 'weighted avg_f1-score': 0.08383233532934131, 'weighted avg_support': 120.0, 'O_support': 1292, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 1}, {'micro_f1': 0.7683673469387755, 'Appeal_to_Popularity_precision': 0.10638297872340426, 'Appeal_to_Popularity_recall': 0.06756756756756757, 'Appeal_to_Popularity_f1-score': 0.08264462809917356, 'Appeal_to_Popularity_support': 74.0, 'micro avg_precision': 0.10638297872340426, 'micro avg_recall': 0.06756756756756757, 'micro avg_f1-score': 0.08264462809917356, 'micro avg_support': 74.0, 'macro avg_precision': 0.10638297872340426, 'macro avg_recall': 0.06756756756756757, 'macro avg_f1-score': 0.08264462809917356, 'macro avg_support': 74.0, 'weighted avg_precision': 0.10638297872340426, 'weighted avg_recall': 0.06756756756756757, 'weighted avg_f1-score': 0.08264462809917356, 'weighted avg_support': 74.0, 'O_support': 1292, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 2}]}
{'micro_f1': 0.7688775510204081, 'Appeal_to_Popularity_precision': 0.23404255319148937, 'Appeal_to_Popularity_recall': 0.10679611650485436, 'Appeal_to_Popularity_f1-score': 0.14666666666666664, 'Appeal_to_Popularity_support': 103.0, 'micro avg_precision': 0.23404255319148937, 'micro avg_recall': 0.10679611650485436, 'micro avg_f1-score': 0.14666666666666664, 'micro avg_support': 103.0, 'macro avg_precision': 0.23404255319148937, 'macro avg_recall': 0.10679611650485436, 'macro avg_f1-score': 0.14666666666666664, 'macro avg_support': 103.0, 'weighted avg_precision': 0.2340425531914894, 'weighted avg_recall': 0.10679611650485436, 'weighted avg_f1-score': 0.14666666666666664, 'weighted avg_support': 103.0, 'O_support': 1292, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 3}
{'results': [{'micro_f1': 0.754591836734694, 'Appeal_to_Popularity_precision': 0.0425531914893617, 'Appeal_to_Popularity_recall': 0.014285714285714285, 'Appeal_to_Popularity_f1-score': 0.0213903743315508, 'Appeal_to_Popularity_support': 140.0, 'micro avg_precision': 0.0425531914893617, 'micro avg_recall': 0.014285714285714285, 'micro avg_f1-score': 0.0213903743315508, 'micro avg_support': 140.0, 'macro avg_precision': 0.0425531914893617, 'macro avg_recall': 0.014285714285714285, 'macro avg_f1-score': 0.0213903743315508, 'macro avg_support': 140.0, 'weighted avg_precision': 0.0425531914893617, 'weighted avg_recall': 0.014285714285714285, 'weighted avg_f1-score': 0.0213903743315508, 'weighted avg_support': 140.0, 'O_support': 1292, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 0}, {'micro_f1': 0.6301020408163265, 'Appeal_to_Popularity_precision': 0.14893617021276595, 'Appeal_to_Popularity_recall': 0.058333333333333334, 'Appeal_to_Popularity_f1-score': 0.08383233532934131, 'Appeal_to_Popularity_support': 120.0, 'micro avg_precision': 0.14893617021276595, 'micro avg_recall': 0.058333333333333334, 'micro avg_f1-score': 0.08383233532934131, 'micro avg_support': 120.0, 'macro avg_precision': 0.14893617021276595, 'macro avg_recall': 0.058333333333333334, 'macro avg_f1-score': 0.08383233532934131, 'macro avg_support': 120.0, 'weighted avg_precision': 0.14893617021276595, 'weighted avg_recall': 0.058333333333333334, 'weighted avg_f1-score': 0.08383233532934131, 'weighted avg_support': 120.0, 'O_support': 1292, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 1}, {'micro_f1': 0.7683673469387755, 'Appeal_to_Popularity_precision': 0.10638297872340426, 'Appeal_to_Popularity_recall': 0.06756756756756757, 'Appeal_to_Popularity_f1-score': 0.08264462809917356, 'Appeal_to_Popularity_support': 74.0, 'micro avg_precision': 0.10638297872340426, 'micro avg_recall': 0.06756756756756757, 'micro avg_f1-score': 0.08264462809917356, 'micro avg_support': 74.0, 'macro avg_precision': 0.10638297872340426, 'macro avg_recall': 0.06756756756756757, 'macro avg_f1-score': 0.08264462809917356, 'macro avg_support': 74.0, 'weighted avg_precision': 0.10638297872340426, 'weighted avg_recall': 0.06756756756756757, 'weighted avg_f1-score': 0.08264462809917356, 'weighted avg_support': 74.0, 'O_support': 1292, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 2}, {'micro_f1': 0.7688775510204081, 'Appeal_to_Popularity_precision': 0.23404255319148937, 'Appeal_to_Popularity_recall': 0.10679611650485436, 'Appeal_to_Popularity_f1-score': 0.14666666666666664, 'Appeal_to_Popularity_support': 103.0, 'micro avg_precision': 0.23404255319148937, 'micro avg_recall': 0.10679611650485436, 'micro avg_f1-score': 0.14666666666666664, 'micro avg_support': 103.0, 'macro avg_precision': 0.23404255319148937, 'macro avg_recall': 0.10679611650485436, 'macro avg_f1-score': 0.14666666666666664, 'macro avg_support': 103.0, 'weighted avg_precision': 0.2340425531914894, 'weighted avg_recall': 0.10679611650485436, 'weighted avg_f1-score': 0.14666666666666664, 'weighted avg_support': 103.0, 'O_support': 1292, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 3}]}
Best model updated: current epoch macro f1 = 0.14666666666666664
{'micro_f1': 0.7806122448979592, 'Appeal_to_Popularity_precision': 0.2978723404255319, 'Appeal_to_Popularity_recall': 0.16666666666666666, 'Appeal_to_Popularity_f1-score': 0.21374045801526717, 'Appeal_to_Popularity_support': 84.0, 'micro avg_precision': 0.2978723404255319, 'micro avg_recall': 0.16666666666666666, 'micro avg_f1-score': 0.21374045801526717, 'micro avg_support': 84.0, 'macro avg_precision': 0.2978723404255319, 'macro avg_recall': 0.16666666666666666, 'macro avg_f1-score': 0.21374045801526717, 'macro avg_support': 84.0, 'weighted avg_precision': 0.2978723404255319, 'weighted avg_recall': 0.16666666666666666, 'weighted avg_f1-score': 0.21374045801526717, 'weighted avg_support': 84.0, 'O_support': 1292, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 4}
{'results': [{'micro_f1': 0.754591836734694, 'Appeal_to_Popularity_precision': 0.0425531914893617, 'Appeal_to_Popularity_recall': 0.014285714285714285, 'Appeal_to_Popularity_f1-score': 0.0213903743315508, 'Appeal_to_Popularity_support': 140.0, 'micro avg_precision': 0.0425531914893617, 'micro avg_recall': 0.014285714285714285, 'micro avg_f1-score': 0.0213903743315508, 'micro avg_support': 140.0, 'macro avg_precision': 0.0425531914893617, 'macro avg_recall': 0.014285714285714285, 'macro avg_f1-score': 0.0213903743315508, 'macro avg_support': 140.0, 'weighted avg_precision': 0.0425531914893617, 'weighted avg_recall': 0.014285714285714285, 'weighted avg_f1-score': 0.0213903743315508, 'weighted avg_support': 140.0, 'O_support': 1292, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 0}, {'micro_f1': 0.6301020408163265, 'Appeal_to_Popularity_precision': 0.14893617021276595, 'Appeal_to_Popularity_recall': 0.058333333333333334, 'Appeal_to_Popularity_f1-score': 0.08383233532934131, 'Appeal_to_Popularity_support': 120.0, 'micro avg_precision': 0.14893617021276595, 'micro avg_recall': 0.058333333333333334, 'micro avg_f1-score': 0.08383233532934131, 'micro avg_support': 120.0, 'macro avg_precision': 0.14893617021276595, 'macro avg_recall': 0.058333333333333334, 'macro avg_f1-score': 0.08383233532934131, 'macro avg_support': 120.0, 'weighted avg_precision': 0.14893617021276595, 'weighted avg_recall': 0.058333333333333334, 'weighted avg_f1-score': 0.08383233532934131, 'weighted avg_support': 120.0, 'O_support': 1292, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 1}, {'micro_f1': 0.7683673469387755, 'Appeal_to_Popularity_precision': 0.10638297872340426, 'Appeal_to_Popularity_recall': 0.06756756756756757, 'Appeal_to_Popularity_f1-score': 0.08264462809917356, 'Appeal_to_Popularity_support': 74.0, 'micro avg_precision': 0.10638297872340426, 'micro avg_recall': 0.06756756756756757, 'micro avg_f1-score': 0.08264462809917356, 'micro avg_support': 74.0, 'macro avg_precision': 0.10638297872340426, 'macro avg_recall': 0.06756756756756757, 'macro avg_f1-score': 0.08264462809917356, 'macro avg_support': 74.0, 'weighted avg_precision': 0.10638297872340426, 'weighted avg_recall': 0.06756756756756757, 'weighted avg_f1-score': 0.08264462809917356, 'weighted avg_support': 74.0, 'O_support': 1292, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 2}, {'micro_f1': 0.7688775510204081, 'Appeal_to_Popularity_precision': 0.23404255319148937, 'Appeal_to_Popularity_recall': 0.10679611650485436, 'Appeal_to_Popularity_f1-score': 0.14666666666666664, 'Appeal_to_Popularity_support': 103.0, 'micro avg_precision': 0.23404255319148937, 'micro avg_recall': 0.10679611650485436, 'micro avg_f1-score': 0.14666666666666664, 'micro avg_support': 103.0, 'macro avg_precision': 0.23404255319148937, 'macro avg_recall': 0.10679611650485436, 'macro avg_f1-score': 0.14666666666666664, 'macro avg_support': 103.0, 'weighted avg_precision': 0.2340425531914894, 'weighted avg_recall': 0.10679611650485436, 'weighted avg_f1-score': 0.14666666666666664, 'weighted avg_support': 103.0, 'O_support': 1292, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 3}, {'micro_f1': 0.7806122448979592, 'Appeal_to_Popularity_precision': 0.2978723404255319, 'Appeal_to_Popularity_recall': 0.16666666666666666, 'Appeal_to_Popularity_f1-score': 0.21374045801526717, 'Appeal_to_Popularity_support': 84.0, 'micro avg_precision': 0.2978723404255319, 'micro avg_recall': 0.16666666666666666, 'micro avg_f1-score': 0.21374045801526717, 'micro avg_support': 84.0, 'macro avg_precision': 0.2978723404255319, 'macro avg_recall': 0.16666666666666666, 'macro avg_f1-score': 0.21374045801526717, 'macro avg_support': 84.0, 'weighted avg_precision': 0.2978723404255319, 'weighted avg_recall': 0.16666666666666666, 'weighted avg_f1-score': 0.21374045801526717, 'weighted avg_support': 84.0, 'O_support': 1292, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 4}]}
Best model updated: current epoch macro f1 = 0.21374045801526717
{'micro_f1': 0.7882653061224489, 'Appeal_to_Popularity_precision': 0.3617021276595745, 'Appeal_to_Popularity_recall': 0.18681318681318682, 'Appeal_to_Popularity_f1-score': 0.24637681159420297, 'Appeal_to_Popularity_support': 91.0, 'micro avg_precision': 0.3617021276595745, 'micro avg_recall': 0.18681318681318682, 'micro avg_f1-score': 0.24637681159420297, 'micro avg_support': 91.0, 'macro avg_precision': 0.3617021276595745, 'macro avg_recall': 0.18681318681318682, 'macro avg_f1-score': 0.24637681159420297, 'macro avg_support': 91.0, 'weighted avg_precision': 0.3617021276595745, 'weighted avg_recall': 0.18681318681318682, 'weighted avg_f1-score': 0.24637681159420294, 'weighted avg_support': 91.0, 'O_support': 1292, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 5}
{'results': [{'micro_f1': 0.754591836734694, 'Appeal_to_Popularity_precision': 0.0425531914893617, 'Appeal_to_Popularity_recall': 0.014285714285714285, 'Appeal_to_Popularity_f1-score': 0.0213903743315508, 'Appeal_to_Popularity_support': 140.0, 'micro avg_precision': 0.0425531914893617, 'micro avg_recall': 0.014285714285714285, 'micro avg_f1-score': 0.0213903743315508, 'micro avg_support': 140.0, 'macro avg_precision': 0.0425531914893617, 'macro avg_recall': 0.014285714285714285, 'macro avg_f1-score': 0.0213903743315508, 'macro avg_support': 140.0, 'weighted avg_precision': 0.0425531914893617, 'weighted avg_recall': 0.014285714285714285, 'weighted avg_f1-score': 0.0213903743315508, 'weighted avg_support': 140.0, 'O_support': 1292, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 0}, {'micro_f1': 0.6301020408163265, 'Appeal_to_Popularity_precision': 0.14893617021276595, 'Appeal_to_Popularity_recall': 0.058333333333333334, 'Appeal_to_Popularity_f1-score': 0.08383233532934131, 'Appeal_to_Popularity_support': 120.0, 'micro avg_precision': 0.14893617021276595, 'micro avg_recall': 0.058333333333333334, 'micro avg_f1-score': 0.08383233532934131, 'micro avg_support': 120.0, 'macro avg_precision': 0.14893617021276595, 'macro avg_recall': 0.058333333333333334, 'macro avg_f1-score': 0.08383233532934131, 'macro avg_support': 120.0, 'weighted avg_precision': 0.14893617021276595, 'weighted avg_recall': 0.058333333333333334, 'weighted avg_f1-score': 0.08383233532934131, 'weighted avg_support': 120.0, 'O_support': 1292, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 1}, {'micro_f1': 0.7683673469387755, 'Appeal_to_Popularity_precision': 0.10638297872340426, 'Appeal_to_Popularity_recall': 0.06756756756756757, 'Appeal_to_Popularity_f1-score': 0.08264462809917356, 'Appeal_to_Popularity_support': 74.0, 'micro avg_precision': 0.10638297872340426, 'micro avg_recall': 0.06756756756756757, 'micro avg_f1-score': 0.08264462809917356, 'micro avg_support': 74.0, 'macro avg_precision': 0.10638297872340426, 'macro avg_recall': 0.06756756756756757, 'macro avg_f1-score': 0.08264462809917356, 'macro avg_support': 74.0, 'weighted avg_precision': 0.10638297872340426, 'weighted avg_recall': 0.06756756756756757, 'weighted avg_f1-score': 0.08264462809917356, 'weighted avg_support': 74.0, 'O_support': 1292, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 2}, {'micro_f1': 0.7688775510204081, 'Appeal_to_Popularity_precision': 0.23404255319148937, 'Appeal_to_Popularity_recall': 0.10679611650485436, 'Appeal_to_Popularity_f1-score': 0.14666666666666664, 'Appeal_to_Popularity_support': 103.0, 'micro avg_precision': 0.23404255319148937, 'micro avg_recall': 0.10679611650485436, 'micro avg_f1-score': 0.14666666666666664, 'micro avg_support': 103.0, 'macro avg_precision': 0.23404255319148937, 'macro avg_recall': 0.10679611650485436, 'macro avg_f1-score': 0.14666666666666664, 'macro avg_support': 103.0, 'weighted avg_precision': 0.2340425531914894, 'weighted avg_recall': 0.10679611650485436, 'weighted avg_f1-score': 0.14666666666666664, 'weighted avg_support': 103.0, 'O_support': 1292, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 3}, {'micro_f1': 0.7806122448979592, 'Appeal_to_Popularity_precision': 0.2978723404255319, 'Appeal_to_Popularity_recall': 0.16666666666666666, 'Appeal_to_Popularity_f1-score': 0.21374045801526717, 'Appeal_to_Popularity_support': 84.0, 'micro avg_precision': 0.2978723404255319, 'micro avg_recall': 0.16666666666666666, 'micro avg_f1-score': 0.21374045801526717, 'micro avg_support': 84.0, 'macro avg_precision': 0.2978723404255319, 'macro avg_recall': 0.16666666666666666, 'macro avg_f1-score': 0.21374045801526717, 'macro avg_support': 84.0, 'weighted avg_precision': 0.2978723404255319, 'weighted avg_recall': 0.16666666666666666, 'weighted avg_f1-score': 0.21374045801526717, 'weighted avg_support': 84.0, 'O_support': 1292, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 4}, {'micro_f1': 0.7882653061224489, 'Appeal_to_Popularity_precision': 0.3617021276595745, 'Appeal_to_Popularity_recall': 0.18681318681318682, 'Appeal_to_Popularity_f1-score': 0.24637681159420297, 'Appeal_to_Popularity_support': 91.0, 'micro avg_precision': 0.3617021276595745, 'micro avg_recall': 0.18681318681318682, 'micro avg_f1-score': 0.24637681159420297, 'micro avg_support': 91.0, 'macro avg_precision': 0.3617021276595745, 'macro avg_recall': 0.18681318681318682, 'macro avg_f1-score': 0.24637681159420297, 'macro avg_support': 91.0, 'weighted avg_precision': 0.3617021276595745, 'weighted avg_recall': 0.18681318681318682, 'weighted avg_f1-score': 0.24637681159420294, 'weighted avg_support': 91.0, 'O_support': 1292, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 5}]}
Best model updated: current epoch macro f1 = 0.24637681159420297
{'micro_f1': 0.8045918367346939, 'Appeal_to_Popularity_precision': 0.2765957446808511, 'Appeal_to_Popularity_recall': 0.15294117647058825, 'Appeal_to_Popularity_f1-score': 0.196969696969697, 'Appeal_to_Popularity_support': 85.0, 'micro avg_precision': 0.2765957446808511, 'micro avg_recall': 0.15294117647058825, 'micro avg_f1-score': 0.196969696969697, 'micro avg_support': 85.0, 'macro avg_precision': 0.2765957446808511, 'macro avg_recall': 0.15294117647058825, 'macro avg_f1-score': 0.196969696969697, 'macro avg_support': 85.0, 'weighted avg_precision': 0.2765957446808511, 'weighted avg_recall': 0.15294117647058825, 'weighted avg_f1-score': 0.19696969696969702, 'weighted avg_support': 85.0, 'O_support': 1292, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 6}
{'results': [{'micro_f1': 0.754591836734694, 'Appeal_to_Popularity_precision': 0.0425531914893617, 'Appeal_to_Popularity_recall': 0.014285714285714285, 'Appeal_to_Popularity_f1-score': 0.0213903743315508, 'Appeal_to_Popularity_support': 140.0, 'micro avg_precision': 0.0425531914893617, 'micro avg_recall': 0.014285714285714285, 'micro avg_f1-score': 0.0213903743315508, 'micro avg_support': 140.0, 'macro avg_precision': 0.0425531914893617, 'macro avg_recall': 0.014285714285714285, 'macro avg_f1-score': 0.0213903743315508, 'macro avg_support': 140.0, 'weighted avg_precision': 0.0425531914893617, 'weighted avg_recall': 0.014285714285714285, 'weighted avg_f1-score': 0.0213903743315508, 'weighted avg_support': 140.0, 'O_support': 1292, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 0}, {'micro_f1': 0.6301020408163265, 'Appeal_to_Popularity_precision': 0.14893617021276595, 'Appeal_to_Popularity_recall': 0.058333333333333334, 'Appeal_to_Popularity_f1-score': 0.08383233532934131, 'Appeal_to_Popularity_support': 120.0, 'micro avg_precision': 0.14893617021276595, 'micro avg_recall': 0.058333333333333334, 'micro avg_f1-score': 0.08383233532934131, 'micro avg_support': 120.0, 'macro avg_precision': 0.14893617021276595, 'macro avg_recall': 0.058333333333333334, 'macro avg_f1-score': 0.08383233532934131, 'macro avg_support': 120.0, 'weighted avg_precision': 0.14893617021276595, 'weighted avg_recall': 0.058333333333333334, 'weighted avg_f1-score': 0.08383233532934131, 'weighted avg_support': 120.0, 'O_support': 1292, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 1}, {'micro_f1': 0.7683673469387755, 'Appeal_to_Popularity_precision': 0.10638297872340426, 'Appeal_to_Popularity_recall': 0.06756756756756757, 'Appeal_to_Popularity_f1-score': 0.08264462809917356, 'Appeal_to_Popularity_support': 74.0, 'micro avg_precision': 0.10638297872340426, 'micro avg_recall': 0.06756756756756757, 'micro avg_f1-score': 0.08264462809917356, 'micro avg_support': 74.0, 'macro avg_precision': 0.10638297872340426, 'macro avg_recall': 0.06756756756756757, 'macro avg_f1-score': 0.08264462809917356, 'macro avg_support': 74.0, 'weighted avg_precision': 0.10638297872340426, 'weighted avg_recall': 0.06756756756756757, 'weighted avg_f1-score': 0.08264462809917356, 'weighted avg_support': 74.0, 'O_support': 1292, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 2}, {'micro_f1': 0.7688775510204081, 'Appeal_to_Popularity_precision': 0.23404255319148937, 'Appeal_to_Popularity_recall': 0.10679611650485436, 'Appeal_to_Popularity_f1-score': 0.14666666666666664, 'Appeal_to_Popularity_support': 103.0, 'micro avg_precision': 0.23404255319148937, 'micro avg_recall': 0.10679611650485436, 'micro avg_f1-score': 0.14666666666666664, 'micro avg_support': 103.0, 'macro avg_precision': 0.23404255319148937, 'macro avg_recall': 0.10679611650485436, 'macro avg_f1-score': 0.14666666666666664, 'macro avg_support': 103.0, 'weighted avg_precision': 0.2340425531914894, 'weighted avg_recall': 0.10679611650485436, 'weighted avg_f1-score': 0.14666666666666664, 'weighted avg_support': 103.0, 'O_support': 1292, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 3}, {'micro_f1': 0.7806122448979592, 'Appeal_to_Popularity_precision': 0.2978723404255319, 'Appeal_to_Popularity_recall': 0.16666666666666666, 'Appeal_to_Popularity_f1-score': 0.21374045801526717, 'Appeal_to_Popularity_support': 84.0, 'micro avg_precision': 0.2978723404255319, 'micro avg_recall': 0.16666666666666666, 'micro avg_f1-score': 0.21374045801526717, 'micro avg_support': 84.0, 'macro avg_precision': 0.2978723404255319, 'macro avg_recall': 0.16666666666666666, 'macro avg_f1-score': 0.21374045801526717, 'macro avg_support': 84.0, 'weighted avg_precision': 0.2978723404255319, 'weighted avg_recall': 0.16666666666666666, 'weighted avg_f1-score': 0.21374045801526717, 'weighted avg_support': 84.0, 'O_support': 1292, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 4}, {'micro_f1': 0.7882653061224489, 'Appeal_to_Popularity_precision': 0.3617021276595745, 'Appeal_to_Popularity_recall': 0.18681318681318682, 'Appeal_to_Popularity_f1-score': 0.24637681159420297, 'Appeal_to_Popularity_support': 91.0, 'micro avg_precision': 0.3617021276595745, 'micro avg_recall': 0.18681318681318682, 'micro avg_f1-score': 0.24637681159420297, 'micro avg_support': 91.0, 'macro avg_precision': 0.3617021276595745, 'macro avg_recall': 0.18681318681318682, 'macro avg_f1-score': 0.24637681159420297, 'macro avg_support': 91.0, 'weighted avg_precision': 0.3617021276595745, 'weighted avg_recall': 0.18681318681318682, 'weighted avg_f1-score': 0.24637681159420294, 'weighted avg_support': 91.0, 'O_support': 1292, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 5}, {'micro_f1': 0.8045918367346939, 'Appeal_to_Popularity_precision': 0.2765957446808511, 'Appeal_to_Popularity_recall': 0.15294117647058825, 'Appeal_to_Popularity_f1-score': 0.196969696969697, 'Appeal_to_Popularity_support': 85.0, 'micro avg_precision': 0.2765957446808511, 'micro avg_recall': 0.15294117647058825, 'micro avg_f1-score': 0.196969696969697, 'micro avg_support': 85.0, 'macro avg_precision': 0.2765957446808511, 'macro avg_recall': 0.15294117647058825, 'macro avg_f1-score': 0.196969696969697, 'macro avg_support': 85.0, 'weighted avg_precision': 0.2765957446808511, 'weighted avg_recall': 0.15294117647058825, 'weighted avg_f1-score': 0.19696969696969702, 'weighted avg_support': 85.0, 'O_support': 1292, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 6}]}
{'micro_f1': 0.7790816326530612, 'Appeal_to_Popularity_precision': 0.3404255319148936, 'Appeal_to_Popularity_recall': 0.18823529411764706, 'Appeal_to_Popularity_f1-score': 0.24242424242424238, 'Appeal_to_Popularity_support': 85.0, 'micro avg_precision': 0.3404255319148936, 'micro avg_recall': 0.18823529411764706, 'micro avg_f1-score': 0.24242424242424238, 'micro avg_support': 85.0, 'macro avg_precision': 0.3404255319148936, 'macro avg_recall': 0.18823529411764706, 'macro avg_f1-score': 0.24242424242424238, 'macro avg_support': 85.0, 'weighted avg_precision': 0.3404255319148936, 'weighted avg_recall': 0.18823529411764706, 'weighted avg_f1-score': 0.24242424242424238, 'weighted avg_support': 85.0, 'O_support': 1292, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 7}
{'results': [{'micro_f1': 0.754591836734694, 'Appeal_to_Popularity_precision': 0.0425531914893617, 'Appeal_to_Popularity_recall': 0.014285714285714285, 'Appeal_to_Popularity_f1-score': 0.0213903743315508, 'Appeal_to_Popularity_support': 140.0, 'micro avg_precision': 0.0425531914893617, 'micro avg_recall': 0.014285714285714285, 'micro avg_f1-score': 0.0213903743315508, 'micro avg_support': 140.0, 'macro avg_precision': 0.0425531914893617, 'macro avg_recall': 0.014285714285714285, 'macro avg_f1-score': 0.0213903743315508, 'macro avg_support': 140.0, 'weighted avg_precision': 0.0425531914893617, 'weighted avg_recall': 0.014285714285714285, 'weighted avg_f1-score': 0.0213903743315508, 'weighted avg_support': 140.0, 'O_support': 1292, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 0}, {'micro_f1': 0.6301020408163265, 'Appeal_to_Popularity_precision': 0.14893617021276595, 'Appeal_to_Popularity_recall': 0.058333333333333334, 'Appeal_to_Popularity_f1-score': 0.08383233532934131, 'Appeal_to_Popularity_support': 120.0, 'micro avg_precision': 0.14893617021276595, 'micro avg_recall': 0.058333333333333334, 'micro avg_f1-score': 0.08383233532934131, 'micro avg_support': 120.0, 'macro avg_precision': 0.14893617021276595, 'macro avg_recall': 0.058333333333333334, 'macro avg_f1-score': 0.08383233532934131, 'macro avg_support': 120.0, 'weighted avg_precision': 0.14893617021276595, 'weighted avg_recall': 0.058333333333333334, 'weighted avg_f1-score': 0.08383233532934131, 'weighted avg_support': 120.0, 'O_support': 1292, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 1}, {'micro_f1': 0.7683673469387755, 'Appeal_to_Popularity_precision': 0.10638297872340426, 'Appeal_to_Popularity_recall': 0.06756756756756757, 'Appeal_to_Popularity_f1-score': 0.08264462809917356, 'Appeal_to_Popularity_support': 74.0, 'micro avg_precision': 0.10638297872340426, 'micro avg_recall': 0.06756756756756757, 'micro avg_f1-score': 0.08264462809917356, 'micro avg_support': 74.0, 'macro avg_precision': 0.10638297872340426, 'macro avg_recall': 0.06756756756756757, 'macro avg_f1-score': 0.08264462809917356, 'macro avg_support': 74.0, 'weighted avg_precision': 0.10638297872340426, 'weighted avg_recall': 0.06756756756756757, 'weighted avg_f1-score': 0.08264462809917356, 'weighted avg_support': 74.0, 'O_support': 1292, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 2}, {'micro_f1': 0.7688775510204081, 'Appeal_to_Popularity_precision': 0.23404255319148937, 'Appeal_to_Popularity_recall': 0.10679611650485436, 'Appeal_to_Popularity_f1-score': 0.14666666666666664, 'Appeal_to_Popularity_support': 103.0, 'micro avg_precision': 0.23404255319148937, 'micro avg_recall': 0.10679611650485436, 'micro avg_f1-score': 0.14666666666666664, 'micro avg_support': 103.0, 'macro avg_precision': 0.23404255319148937, 'macro avg_recall': 0.10679611650485436, 'macro avg_f1-score': 0.14666666666666664, 'macro avg_support': 103.0, 'weighted avg_precision': 0.2340425531914894, 'weighted avg_recall': 0.10679611650485436, 'weighted avg_f1-score': 0.14666666666666664, 'weighted avg_support': 103.0, 'O_support': 1292, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 3}, {'micro_f1': 0.7806122448979592, 'Appeal_to_Popularity_precision': 0.2978723404255319, 'Appeal_to_Popularity_recall': 0.16666666666666666, 'Appeal_to_Popularity_f1-score': 0.21374045801526717, 'Appeal_to_Popularity_support': 84.0, 'micro avg_precision': 0.2978723404255319, 'micro avg_recall': 0.16666666666666666, 'micro avg_f1-score': 0.21374045801526717, 'micro avg_support': 84.0, 'macro avg_precision': 0.2978723404255319, 'macro avg_recall': 0.16666666666666666, 'macro avg_f1-score': 0.21374045801526717, 'macro avg_support': 84.0, 'weighted avg_precision': 0.2978723404255319, 'weighted avg_recall': 0.16666666666666666, 'weighted avg_f1-score': 0.21374045801526717, 'weighted avg_support': 84.0, 'O_support': 1292, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 4}, {'micro_f1': 0.7882653061224489, 'Appeal_to_Popularity_precision': 0.3617021276595745, 'Appeal_to_Popularity_recall': 0.18681318681318682, 'Appeal_to_Popularity_f1-score': 0.24637681159420297, 'Appeal_to_Popularity_support': 91.0, 'micro avg_precision': 0.3617021276595745, 'micro avg_recall': 0.18681318681318682, 'micro avg_f1-score': 0.24637681159420297, 'micro avg_support': 91.0, 'macro avg_precision': 0.3617021276595745, 'macro avg_recall': 0.18681318681318682, 'macro avg_f1-score': 0.24637681159420297, 'macro avg_support': 91.0, 'weighted avg_precision': 0.3617021276595745, 'weighted avg_recall': 0.18681318681318682, 'weighted avg_f1-score': 0.24637681159420294, 'weighted avg_support': 91.0, 'O_support': 1292, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 5}, {'micro_f1': 0.8045918367346939, 'Appeal_to_Popularity_precision': 0.2765957446808511, 'Appeal_to_Popularity_recall': 0.15294117647058825, 'Appeal_to_Popularity_f1-score': 0.196969696969697, 'Appeal_to_Popularity_support': 85.0, 'micro avg_precision': 0.2765957446808511, 'micro avg_recall': 0.15294117647058825, 'micro avg_f1-score': 0.196969696969697, 'micro avg_support': 85.0, 'macro avg_precision': 0.2765957446808511, 'macro avg_recall': 0.15294117647058825, 'macro avg_f1-score': 0.196969696969697, 'macro avg_support': 85.0, 'weighted avg_precision': 0.2765957446808511, 'weighted avg_recall': 0.15294117647058825, 'weighted avg_f1-score': 0.19696969696969702, 'weighted avg_support': 85.0, 'O_support': 1292, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 6}, {'micro_f1': 0.7790816326530612, 'Appeal_to_Popularity_precision': 0.3404255319148936, 'Appeal_to_Popularity_recall': 0.18823529411764706, 'Appeal_to_Popularity_f1-score': 0.24242424242424238, 'Appeal_to_Popularity_support': 85.0, 'micro avg_precision': 0.3404255319148936, 'micro avg_recall': 0.18823529411764706, 'micro avg_f1-score': 0.24242424242424238, 'micro avg_support': 85.0, 'macro avg_precision': 0.3404255319148936, 'macro avg_recall': 0.18823529411764706, 'macro avg_f1-score': 0.24242424242424238, 'macro avg_support': 85.0, 'weighted avg_precision': 0.3404255319148936, 'weighted avg_recall': 0.18823529411764706, 'weighted avg_f1-score': 0.24242424242424238, 'weighted avg_support': 85.0, 'O_support': 1292, 'B-Appeal_to_Popularity_support': 47, 'I-Appeal_to_Popularity_support': 621, 'epoch': 7}]}
Early stopping triggered.
Saving model to directory: ./models/M2/2024-05-12-17-42-10_aug/mdeberta-v3-base_1_ME10_target=Appeal_to_Popularity_SUBSAMPLED_2024-05-12-17-42-10
Training model no. 2 of 23 for (2, 'Appeal_to_Values') persuasion technique...
{'micro_f1': 0.7707170459424646, 'Appeal_to_Values_precision': 0.050505050505050504, 'Appeal_to_Values_recall': 0.020833333333333332, 'Appeal_to_Values_f1-score': 0.029498525073746312, 'Appeal_to_Values_support': 240.0, 'micro avg_precision': 0.050505050505050504, 'micro avg_recall': 0.020833333333333332, 'micro avg_f1-score': 0.029498525073746312, 'micro avg_support': 240.0, 'macro avg_precision': 0.050505050505050504, 'macro avg_recall': 0.020833333333333332, 'macro avg_f1-score': 0.029498525073746312, 'macro avg_support': 240.0, 'weighted avg_precision': 0.050505050505050504, 'weighted avg_recall': 0.020833333333333332, 'weighted avg_f1-score': 0.029498525073746316, 'weighted avg_support': 240.0, 'O_support': 2851, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'epoch': 0}
{'results': [{'micro_f1': 0.7707170459424646, 'Appeal_to_Values_precision': 0.050505050505050504, 'Appeal_to_Values_recall': 0.020833333333333332, 'Appeal_to_Values_f1-score': 0.029498525073746312, 'Appeal_to_Values_support': 240.0, 'micro avg_precision': 0.050505050505050504, 'micro avg_recall': 0.020833333333333332, 'micro avg_f1-score': 0.029498525073746312, 'micro avg_support': 240.0, 'macro avg_precision': 0.050505050505050504, 'macro avg_recall': 0.020833333333333332, 'macro avg_f1-score': 0.029498525073746312, 'macro avg_support': 240.0, 'weighted avg_precision': 0.050505050505050504, 'weighted avg_recall': 0.020833333333333332, 'weighted avg_f1-score': 0.029498525073746316, 'weighted avg_support': 240.0, 'O_support': 2851, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'epoch': 0}]}
Best model updated: current epoch macro f1 = 0.029498525073746312
{'micro_f1': 0.8295405753542293, 'Appeal_to_Values_precision': 0.26262626262626265, 'Appeal_to_Values_recall': 0.1326530612244898, 'Appeal_to_Values_f1-score': 0.17627118644067796, 'Appeal_to_Values_support': 196.0, 'micro avg_precision': 0.26262626262626265, 'micro avg_recall': 0.1326530612244898, 'micro avg_f1-score': 0.17627118644067796, 'micro avg_support': 196.0, 'macro avg_precision': 0.26262626262626265, 'macro avg_recall': 0.1326530612244898, 'macro avg_f1-score': 0.17627118644067796, 'macro avg_support': 196.0, 'weighted avg_precision': 0.26262626262626265, 'weighted avg_recall': 0.1326530612244898, 'weighted avg_f1-score': 0.17627118644067796, 'weighted avg_support': 196.0, 'O_support': 2851, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'epoch': 1}
{'results': [{'micro_f1': 0.7707170459424646, 'Appeal_to_Values_precision': 0.050505050505050504, 'Appeal_to_Values_recall': 0.020833333333333332, 'Appeal_to_Values_f1-score': 0.029498525073746312, 'Appeal_to_Values_support': 240.0, 'micro avg_precision': 0.050505050505050504, 'micro avg_recall': 0.020833333333333332, 'micro avg_f1-score': 0.029498525073746312, 'micro avg_support': 240.0, 'macro avg_precision': 0.050505050505050504, 'macro avg_recall': 0.020833333333333332, 'macro avg_f1-score': 0.029498525073746312, 'macro avg_support': 240.0, 'weighted avg_precision': 0.050505050505050504, 'weighted avg_recall': 0.020833333333333332, 'weighted avg_f1-score': 0.029498525073746316, 'weighted avg_support': 240.0, 'O_support': 2851, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'epoch': 0}, {'micro_f1': 0.8295405753542293, 'Appeal_to_Values_precision': 0.26262626262626265, 'Appeal_to_Values_recall': 0.1326530612244898, 'Appeal_to_Values_f1-score': 0.17627118644067796, 'Appeal_to_Values_support': 196.0, 'micro avg_precision': 0.26262626262626265, 'micro avg_recall': 0.1326530612244898, 'micro avg_f1-score': 0.17627118644067796, 'micro avg_support': 196.0, 'macro avg_precision': 0.26262626262626265, 'macro avg_recall': 0.1326530612244898, 'macro avg_f1-score': 0.17627118644067796, 'macro avg_support': 196.0, 'weighted avg_precision': 0.26262626262626265, 'weighted avg_recall': 0.1326530612244898, 'weighted avg_f1-score': 0.17627118644067796, 'weighted avg_support': 196.0, 'O_support': 2851, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'epoch': 1}]}
Best model updated: current epoch macro f1 = 0.17627118644067796
{'micro_f1': 0.8093602404465435, 'Appeal_to_Values_precision': 0.2222222222222222, 'Appeal_to_Values_recall': 0.15827338129496402, 'Appeal_to_Values_f1-score': 0.1848739495798319, 'Appeal_to_Values_support': 139.0, 'micro avg_precision': 0.2222222222222222, 'micro avg_recall': 0.15827338129496402, 'micro avg_f1-score': 0.1848739495798319, 'micro avg_support': 139.0, 'macro avg_precision': 0.2222222222222222, 'macro avg_recall': 0.15827338129496402, 'macro avg_f1-score': 0.1848739495798319, 'macro avg_support': 139.0, 'weighted avg_precision': 0.2222222222222222, 'weighted avg_recall': 0.15827338129496402, 'weighted avg_f1-score': 0.1848739495798319, 'weighted avg_support': 139.0, 'O_support': 2851, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'epoch': 2}
{'results': [{'micro_f1': 0.7707170459424646, 'Appeal_to_Values_precision': 0.050505050505050504, 'Appeal_to_Values_recall': 0.020833333333333332, 'Appeal_to_Values_f1-score': 0.029498525073746312, 'Appeal_to_Values_support': 240.0, 'micro avg_precision': 0.050505050505050504, 'micro avg_recall': 0.020833333333333332, 'micro avg_f1-score': 0.029498525073746312, 'micro avg_support': 240.0, 'macro avg_precision': 0.050505050505050504, 'macro avg_recall': 0.020833333333333332, 'macro avg_f1-score': 0.029498525073746312, 'macro avg_support': 240.0, 'weighted avg_precision': 0.050505050505050504, 'weighted avg_recall': 0.020833333333333332, 'weighted avg_f1-score': 0.029498525073746316, 'weighted avg_support': 240.0, 'O_support': 2851, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'epoch': 0}, {'micro_f1': 0.8295405753542293, 'Appeal_to_Values_precision': 0.26262626262626265, 'Appeal_to_Values_recall': 0.1326530612244898, 'Appeal_to_Values_f1-score': 0.17627118644067796, 'Appeal_to_Values_support': 196.0, 'micro avg_precision': 0.26262626262626265, 'micro avg_recall': 0.1326530612244898, 'micro avg_f1-score': 0.17627118644067796, 'micro avg_support': 196.0, 'macro avg_precision': 0.26262626262626265, 'macro avg_recall': 0.1326530612244898, 'macro avg_f1-score': 0.17627118644067796, 'macro avg_support': 196.0, 'weighted avg_precision': 0.26262626262626265, 'weighted avg_recall': 0.1326530612244898, 'weighted avg_f1-score': 0.17627118644067796, 'weighted avg_support': 196.0, 'O_support': 2851, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'epoch': 1}, {'micro_f1': 0.8093602404465435, 'Appeal_to_Values_precision': 0.2222222222222222, 'Appeal_to_Values_recall': 0.15827338129496402, 'Appeal_to_Values_f1-score': 0.1848739495798319, 'Appeal_to_Values_support': 139.0, 'micro avg_precision': 0.2222222222222222, 'micro avg_recall': 0.15827338129496402, 'micro avg_f1-score': 0.1848739495798319, 'micro avg_support': 139.0, 'macro avg_precision': 0.2222222222222222, 'macro avg_recall': 0.15827338129496402, 'macro avg_f1-score': 0.1848739495798319, 'macro avg_support': 139.0, 'weighted avg_precision': 0.2222222222222222, 'weighted avg_recall': 0.15827338129496402, 'weighted avg_f1-score': 0.1848739495798319, 'weighted avg_support': 139.0, 'O_support': 2851, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'epoch': 2}]}
Best model updated: current epoch macro f1 = 0.1848739495798319
{'micro_f1': 0.8162301416917132, 'Appeal_to_Values_precision': 0.3434343434343434, 'Appeal_to_Values_recall': 0.17894736842105263, 'Appeal_to_Values_f1-score': 0.23529411764705882, 'Appeal_to_Values_support': 190.0, 'micro avg_precision': 0.3434343434343434, 'micro avg_recall': 0.17894736842105263, 'micro avg_f1-score': 0.23529411764705882, 'micro avg_support': 190.0, 'macro avg_precision': 0.3434343434343434, 'macro avg_recall': 0.17894736842105263, 'macro avg_f1-score': 0.23529411764705882, 'macro avg_support': 190.0, 'weighted avg_precision': 0.34343434343434337, 'weighted avg_recall': 0.17894736842105263, 'weighted avg_f1-score': 0.23529411764705882, 'weighted avg_support': 190.0, 'O_support': 2851, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'epoch': 3}
{'results': [{'micro_f1': 0.7707170459424646, 'Appeal_to_Values_precision': 0.050505050505050504, 'Appeal_to_Values_recall': 0.020833333333333332, 'Appeal_to_Values_f1-score': 0.029498525073746312, 'Appeal_to_Values_support': 240.0, 'micro avg_precision': 0.050505050505050504, 'micro avg_recall': 0.020833333333333332, 'micro avg_f1-score': 0.029498525073746312, 'micro avg_support': 240.0, 'macro avg_precision': 0.050505050505050504, 'macro avg_recall': 0.020833333333333332, 'macro avg_f1-score': 0.029498525073746312, 'macro avg_support': 240.0, 'weighted avg_precision': 0.050505050505050504, 'weighted avg_recall': 0.020833333333333332, 'weighted avg_f1-score': 0.029498525073746316, 'weighted avg_support': 240.0, 'O_support': 2851, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'epoch': 0}, {'micro_f1': 0.8295405753542293, 'Appeal_to_Values_precision': 0.26262626262626265, 'Appeal_to_Values_recall': 0.1326530612244898, 'Appeal_to_Values_f1-score': 0.17627118644067796, 'Appeal_to_Values_support': 196.0, 'micro avg_precision': 0.26262626262626265, 'micro avg_recall': 0.1326530612244898, 'micro avg_f1-score': 0.17627118644067796, 'micro avg_support': 196.0, 'macro avg_precision': 0.26262626262626265, 'macro avg_recall': 0.1326530612244898, 'macro avg_f1-score': 0.17627118644067796, 'macro avg_support': 196.0, 'weighted avg_precision': 0.26262626262626265, 'weighted avg_recall': 0.1326530612244898, 'weighted avg_f1-score': 0.17627118644067796, 'weighted avg_support': 196.0, 'O_support': 2851, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'epoch': 1}, {'micro_f1': 0.8093602404465435, 'Appeal_to_Values_precision': 0.2222222222222222, 'Appeal_to_Values_recall': 0.15827338129496402, 'Appeal_to_Values_f1-score': 0.1848739495798319, 'Appeal_to_Values_support': 139.0, 'micro avg_precision': 0.2222222222222222, 'micro avg_recall': 0.15827338129496402, 'micro avg_f1-score': 0.1848739495798319, 'micro avg_support': 139.0, 'macro avg_precision': 0.2222222222222222, 'macro avg_recall': 0.15827338129496402, 'macro avg_f1-score': 0.1848739495798319, 'macro avg_support': 139.0, 'weighted avg_precision': 0.2222222222222222, 'weighted avg_recall': 0.15827338129496402, 'weighted avg_f1-score': 0.1848739495798319, 'weighted avg_support': 139.0, 'O_support': 2851, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'epoch': 2}, {'micro_f1': 0.8162301416917132, 'Appeal_to_Values_precision': 0.3434343434343434, 'Appeal_to_Values_recall': 0.17894736842105263, 'Appeal_to_Values_f1-score': 0.23529411764705882, 'Appeal_to_Values_support': 190.0, 'micro avg_precision': 0.3434343434343434, 'micro avg_recall': 0.17894736842105263, 'micro avg_f1-score': 0.23529411764705882, 'micro avg_support': 190.0, 'macro avg_precision': 0.3434343434343434, 'macro avg_recall': 0.17894736842105263, 'macro avg_f1-score': 0.23529411764705882, 'macro avg_support': 190.0, 'weighted avg_precision': 0.34343434343434337, 'weighted avg_recall': 0.17894736842105263, 'weighted avg_f1-score': 0.23529411764705882, 'weighted avg_support': 190.0, 'O_support': 2851, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'epoch': 3}]}
Best model updated: current epoch macro f1 = 0.23529411764705882
{'micro_f1': 0.8254615714899098, 'Appeal_to_Values_precision': 0.35353535353535354, 'Appeal_to_Values_recall': 0.20833333333333334, 'Appeal_to_Values_f1-score': 0.26217228464419473, 'Appeal_to_Values_support': 168.0, 'micro avg_precision': 0.35353535353535354, 'micro avg_recall': 0.20833333333333334, 'micro avg_f1-score': 0.26217228464419473, 'micro avg_support': 168.0, 'macro avg_precision': 0.35353535353535354, 'macro avg_recall': 0.20833333333333334, 'macro avg_f1-score': 0.26217228464419473, 'macro avg_support': 168.0, 'weighted avg_precision': 0.35353535353535354, 'weighted avg_recall': 0.20833333333333334, 'weighted avg_f1-score': 0.26217228464419473, 'weighted avg_support': 168.0, 'O_support': 2851, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'epoch': 4}
{'results': [{'micro_f1': 0.7707170459424646, 'Appeal_to_Values_precision': 0.050505050505050504, 'Appeal_to_Values_recall': 0.020833333333333332, 'Appeal_to_Values_f1-score': 0.029498525073746312, 'Appeal_to_Values_support': 240.0, 'micro avg_precision': 0.050505050505050504, 'micro avg_recall': 0.020833333333333332, 'micro avg_f1-score': 0.029498525073746312, 'micro avg_support': 240.0, 'macro avg_precision': 0.050505050505050504, 'macro avg_recall': 0.020833333333333332, 'macro avg_f1-score': 0.029498525073746312, 'macro avg_support': 240.0, 'weighted avg_precision': 0.050505050505050504, 'weighted avg_recall': 0.020833333333333332, 'weighted avg_f1-score': 0.029498525073746316, 'weighted avg_support': 240.0, 'O_support': 2851, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'epoch': 0}, {'micro_f1': 0.8295405753542293, 'Appeal_to_Values_precision': 0.26262626262626265, 'Appeal_to_Values_recall': 0.1326530612244898, 'Appeal_to_Values_f1-score': 0.17627118644067796, 'Appeal_to_Values_support': 196.0, 'micro avg_precision': 0.26262626262626265, 'micro avg_recall': 0.1326530612244898, 'micro avg_f1-score': 0.17627118644067796, 'micro avg_support': 196.0, 'macro avg_precision': 0.26262626262626265, 'macro avg_recall': 0.1326530612244898, 'macro avg_f1-score': 0.17627118644067796, 'macro avg_support': 196.0, 'weighted avg_precision': 0.26262626262626265, 'weighted avg_recall': 0.1326530612244898, 'weighted avg_f1-score': 0.17627118644067796, 'weighted avg_support': 196.0, 'O_support': 2851, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'epoch': 1}, {'micro_f1': 0.8093602404465435, 'Appeal_to_Values_precision': 0.2222222222222222, 'Appeal_to_Values_recall': 0.15827338129496402, 'Appeal_to_Values_f1-score': 0.1848739495798319, 'Appeal_to_Values_support': 139.0, 'micro avg_precision': 0.2222222222222222, 'micro avg_recall': 0.15827338129496402, 'micro avg_f1-score': 0.1848739495798319, 'micro avg_support': 139.0, 'macro avg_precision': 0.2222222222222222, 'macro avg_recall': 0.15827338129496402, 'macro avg_f1-score': 0.1848739495798319, 'macro avg_support': 139.0, 'weighted avg_precision': 0.2222222222222222, 'weighted avg_recall': 0.15827338129496402, 'weighted avg_f1-score': 0.1848739495798319, 'weighted avg_support': 139.0, 'O_support': 2851, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'epoch': 2}, {'micro_f1': 0.8162301416917132, 'Appeal_to_Values_precision': 0.3434343434343434, 'Appeal_to_Values_recall': 0.17894736842105263, 'Appeal_to_Values_f1-score': 0.23529411764705882, 'Appeal_to_Values_support': 190.0, 'micro avg_precision': 0.3434343434343434, 'micro avg_recall': 0.17894736842105263, 'micro avg_f1-score': 0.23529411764705882, 'micro avg_support': 190.0, 'macro avg_precision': 0.3434343434343434, 'macro avg_recall': 0.17894736842105263, 'macro avg_f1-score': 0.23529411764705882, 'macro avg_support': 190.0, 'weighted avg_precision': 0.34343434343434337, 'weighted avg_recall': 0.17894736842105263, 'weighted avg_f1-score': 0.23529411764705882, 'weighted avg_support': 190.0, 'O_support': 2851, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'epoch': 3}, {'micro_f1': 0.8254615714899098, 'Appeal_to_Values_precision': 0.35353535353535354, 'Appeal_to_Values_recall': 0.20833333333333334, 'Appeal_to_Values_f1-score': 0.26217228464419473, 'Appeal_to_Values_support': 168.0, 'micro avg_precision': 0.35353535353535354, 'micro avg_recall': 0.20833333333333334, 'micro avg_f1-score': 0.26217228464419473, 'micro avg_support': 168.0, 'macro avg_precision': 0.35353535353535354, 'macro avg_recall': 0.20833333333333334, 'macro avg_f1-score': 0.26217228464419473, 'macro avg_support': 168.0, 'weighted avg_precision': 0.35353535353535354, 'weighted avg_recall': 0.20833333333333334, 'weighted avg_f1-score': 0.26217228464419473, 'weighted avg_support': 168.0, 'O_support': 2851, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'epoch': 4}]}
Best model updated: current epoch macro f1 = 0.26217228464419473
{'micro_f1': 0.8224559896951481, 'Appeal_to_Values_precision': 0.3333333333333333, 'Appeal_to_Values_recall': 0.20625, 'Appeal_to_Values_f1-score': 0.2548262548262548, 'Appeal_to_Values_support': 160.0, 'micro avg_precision': 0.3333333333333333, 'micro avg_recall': 0.20625, 'micro avg_f1-score': 0.2548262548262548, 'micro avg_support': 160.0, 'macro avg_precision': 0.3333333333333333, 'macro avg_recall': 0.20625, 'macro avg_f1-score': 0.2548262548262548, 'macro avg_support': 160.0, 'weighted avg_precision': 0.3333333333333333, 'weighted avg_recall': 0.20625, 'weighted avg_f1-score': 0.2548262548262548, 'weighted avg_support': 160.0, 'O_support': 2851, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'epoch': 5}
{'results': [{'micro_f1': 0.7707170459424646, 'Appeal_to_Values_precision': 0.050505050505050504, 'Appeal_to_Values_recall': 0.020833333333333332, 'Appeal_to_Values_f1-score': 0.029498525073746312, 'Appeal_to_Values_support': 240.0, 'micro avg_precision': 0.050505050505050504, 'micro avg_recall': 0.020833333333333332, 'micro avg_f1-score': 0.029498525073746312, 'micro avg_support': 240.0, 'macro avg_precision': 0.050505050505050504, 'macro avg_recall': 0.020833333333333332, 'macro avg_f1-score': 0.029498525073746312, 'macro avg_support': 240.0, 'weighted avg_precision': 0.050505050505050504, 'weighted avg_recall': 0.020833333333333332, 'weighted avg_f1-score': 0.029498525073746316, 'weighted avg_support': 240.0, 'O_support': 2851, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'epoch': 0}, {'micro_f1': 0.8295405753542293, 'Appeal_to_Values_precision': 0.26262626262626265, 'Appeal_to_Values_recall': 0.1326530612244898, 'Appeal_to_Values_f1-score': 0.17627118644067796, 'Appeal_to_Values_support': 196.0, 'micro avg_precision': 0.26262626262626265, 'micro avg_recall': 0.1326530612244898, 'micro avg_f1-score': 0.17627118644067796, 'micro avg_support': 196.0, 'macro avg_precision': 0.26262626262626265, 'macro avg_recall': 0.1326530612244898, 'macro avg_f1-score': 0.17627118644067796, 'macro avg_support': 196.0, 'weighted avg_precision': 0.26262626262626265, 'weighted avg_recall': 0.1326530612244898, 'weighted avg_f1-score': 0.17627118644067796, 'weighted avg_support': 196.0, 'O_support': 2851, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'epoch': 1}, {'micro_f1': 0.8093602404465435, 'Appeal_to_Values_precision': 0.2222222222222222, 'Appeal_to_Values_recall': 0.15827338129496402, 'Appeal_to_Values_f1-score': 0.1848739495798319, 'Appeal_to_Values_support': 139.0, 'micro avg_precision': 0.2222222222222222, 'micro avg_recall': 0.15827338129496402, 'micro avg_f1-score': 0.1848739495798319, 'micro avg_support': 139.0, 'macro avg_precision': 0.2222222222222222, 'macro avg_recall': 0.15827338129496402, 'macro avg_f1-score': 0.1848739495798319, 'macro avg_support': 139.0, 'weighted avg_precision': 0.2222222222222222, 'weighted avg_recall': 0.15827338129496402, 'weighted avg_f1-score': 0.1848739495798319, 'weighted avg_support': 139.0, 'O_support': 2851, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'epoch': 2}, {'micro_f1': 0.8162301416917132, 'Appeal_to_Values_precision': 0.3434343434343434, 'Appeal_to_Values_recall': 0.17894736842105263, 'Appeal_to_Values_f1-score': 0.23529411764705882, 'Appeal_to_Values_support': 190.0, 'micro avg_precision': 0.3434343434343434, 'micro avg_recall': 0.17894736842105263, 'micro avg_f1-score': 0.23529411764705882, 'micro avg_support': 190.0, 'macro avg_precision': 0.3434343434343434, 'macro avg_recall': 0.17894736842105263, 'macro avg_f1-score': 0.23529411764705882, 'macro avg_support': 190.0, 'weighted avg_precision': 0.34343434343434337, 'weighted avg_recall': 0.17894736842105263, 'weighted avg_f1-score': 0.23529411764705882, 'weighted avg_support': 190.0, 'O_support': 2851, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'epoch': 3}, {'micro_f1': 0.8254615714899098, 'Appeal_to_Values_precision': 0.35353535353535354, 'Appeal_to_Values_recall': 0.20833333333333334, 'Appeal_to_Values_f1-score': 0.26217228464419473, 'Appeal_to_Values_support': 168.0, 'micro avg_precision': 0.35353535353535354, 'micro avg_recall': 0.20833333333333334, 'micro avg_f1-score': 0.26217228464419473, 'micro avg_support': 168.0, 'macro avg_precision': 0.35353535353535354, 'macro avg_recall': 0.20833333333333334, 'macro avg_f1-score': 0.26217228464419473, 'macro avg_support': 168.0, 'weighted avg_precision': 0.35353535353535354, 'weighted avg_recall': 0.20833333333333334, 'weighted avg_f1-score': 0.26217228464419473, 'weighted avg_support': 168.0, 'O_support': 2851, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'epoch': 4}, {'micro_f1': 0.8224559896951481, 'Appeal_to_Values_precision': 0.3333333333333333, 'Appeal_to_Values_recall': 0.20625, 'Appeal_to_Values_f1-score': 0.2548262548262548, 'Appeal_to_Values_support': 160.0, 'micro avg_precision': 0.3333333333333333, 'micro avg_recall': 0.20625, 'micro avg_f1-score': 0.2548262548262548, 'micro avg_support': 160.0, 'macro avg_precision': 0.3333333333333333, 'macro avg_recall': 0.20625, 'macro avg_f1-score': 0.2548262548262548, 'macro avg_support': 160.0, 'weighted avg_precision': 0.3333333333333333, 'weighted avg_recall': 0.20625, 'weighted avg_f1-score': 0.2548262548262548, 'weighted avg_support': 160.0, 'O_support': 2851, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'epoch': 5}]}
{'micro_f1': 0.8190210390725634, 'Appeal_to_Values_precision': 0.32323232323232326, 'Appeal_to_Values_recall': 0.25, 'Appeal_to_Values_f1-score': 0.2819383259911894, 'Appeal_to_Values_support': 128.0, 'micro avg_precision': 0.32323232323232326, 'micro avg_recall': 0.25, 'micro avg_f1-score': 0.2819383259911894, 'micro avg_support': 128.0, 'macro avg_precision': 0.32323232323232326, 'macro avg_recall': 0.25, 'macro avg_f1-score': 0.2819383259911894, 'macro avg_support': 128.0, 'weighted avg_precision': 0.32323232323232326, 'weighted avg_recall': 0.25, 'weighted avg_f1-score': 0.2819383259911894, 'weighted avg_support': 128.0, 'O_support': 2851, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'epoch': 6}
{'results': [{'micro_f1': 0.7707170459424646, 'Appeal_to_Values_precision': 0.050505050505050504, 'Appeal_to_Values_recall': 0.020833333333333332, 'Appeal_to_Values_f1-score': 0.029498525073746312, 'Appeal_to_Values_support': 240.0, 'micro avg_precision': 0.050505050505050504, 'micro avg_recall': 0.020833333333333332, 'micro avg_f1-score': 0.029498525073746312, 'micro avg_support': 240.0, 'macro avg_precision': 0.050505050505050504, 'macro avg_recall': 0.020833333333333332, 'macro avg_f1-score': 0.029498525073746312, 'macro avg_support': 240.0, 'weighted avg_precision': 0.050505050505050504, 'weighted avg_recall': 0.020833333333333332, 'weighted avg_f1-score': 0.029498525073746316, 'weighted avg_support': 240.0, 'O_support': 2851, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'epoch': 0}, {'micro_f1': 0.8295405753542293, 'Appeal_to_Values_precision': 0.26262626262626265, 'Appeal_to_Values_recall': 0.1326530612244898, 'Appeal_to_Values_f1-score': 0.17627118644067796, 'Appeal_to_Values_support': 196.0, 'micro avg_precision': 0.26262626262626265, 'micro avg_recall': 0.1326530612244898, 'micro avg_f1-score': 0.17627118644067796, 'micro avg_support': 196.0, 'macro avg_precision': 0.26262626262626265, 'macro avg_recall': 0.1326530612244898, 'macro avg_f1-score': 0.17627118644067796, 'macro avg_support': 196.0, 'weighted avg_precision': 0.26262626262626265, 'weighted avg_recall': 0.1326530612244898, 'weighted avg_f1-score': 0.17627118644067796, 'weighted avg_support': 196.0, 'O_support': 2851, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'epoch': 1}, {'micro_f1': 0.8093602404465435, 'Appeal_to_Values_precision': 0.2222222222222222, 'Appeal_to_Values_recall': 0.15827338129496402, 'Appeal_to_Values_f1-score': 0.1848739495798319, 'Appeal_to_Values_support': 139.0, 'micro avg_precision': 0.2222222222222222, 'micro avg_recall': 0.15827338129496402, 'micro avg_f1-score': 0.1848739495798319, 'micro avg_support': 139.0, 'macro avg_precision': 0.2222222222222222, 'macro avg_recall': 0.15827338129496402, 'macro avg_f1-score': 0.1848739495798319, 'macro avg_support': 139.0, 'weighted avg_precision': 0.2222222222222222, 'weighted avg_recall': 0.15827338129496402, 'weighted avg_f1-score': 0.1848739495798319, 'weighted avg_support': 139.0, 'O_support': 2851, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'epoch': 2}, {'micro_f1': 0.8162301416917132, 'Appeal_to_Values_precision': 0.3434343434343434, 'Appeal_to_Values_recall': 0.17894736842105263, 'Appeal_to_Values_f1-score': 0.23529411764705882, 'Appeal_to_Values_support': 190.0, 'micro avg_precision': 0.3434343434343434, 'micro avg_recall': 0.17894736842105263, 'micro avg_f1-score': 0.23529411764705882, 'micro avg_support': 190.0, 'macro avg_precision': 0.3434343434343434, 'macro avg_recall': 0.17894736842105263, 'macro avg_f1-score': 0.23529411764705882, 'macro avg_support': 190.0, 'weighted avg_precision': 0.34343434343434337, 'weighted avg_recall': 0.17894736842105263, 'weighted avg_f1-score': 0.23529411764705882, 'weighted avg_support': 190.0, 'O_support': 2851, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'epoch': 3}, {'micro_f1': 0.8254615714899098, 'Appeal_to_Values_precision': 0.35353535353535354, 'Appeal_to_Values_recall': 0.20833333333333334, 'Appeal_to_Values_f1-score': 0.26217228464419473, 'Appeal_to_Values_support': 168.0, 'micro avg_precision': 0.35353535353535354, 'micro avg_recall': 0.20833333333333334, 'micro avg_f1-score': 0.26217228464419473, 'micro avg_support': 168.0, 'macro avg_precision': 0.35353535353535354, 'macro avg_recall': 0.20833333333333334, 'macro avg_f1-score': 0.26217228464419473, 'macro avg_support': 168.0, 'weighted avg_precision': 0.35353535353535354, 'weighted avg_recall': 0.20833333333333334, 'weighted avg_f1-score': 0.26217228464419473, 'weighted avg_support': 168.0, 'O_support': 2851, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'epoch': 4}, {'micro_f1': 0.8224559896951481, 'Appeal_to_Values_precision': 0.3333333333333333, 'Appeal_to_Values_recall': 0.20625, 'Appeal_to_Values_f1-score': 0.2548262548262548, 'Appeal_to_Values_support': 160.0, 'micro avg_precision': 0.3333333333333333, 'micro avg_recall': 0.20625, 'micro avg_f1-score': 0.2548262548262548, 'micro avg_support': 160.0, 'macro avg_precision': 0.3333333333333333, 'macro avg_recall': 0.20625, 'macro avg_f1-score': 0.2548262548262548, 'macro avg_support': 160.0, 'weighted avg_precision': 0.3333333333333333, 'weighted avg_recall': 0.20625, 'weighted avg_f1-score': 0.2548262548262548, 'weighted avg_support': 160.0, 'O_support': 2851, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'epoch': 5}, {'micro_f1': 0.8190210390725634, 'Appeal_to_Values_precision': 0.32323232323232326, 'Appeal_to_Values_recall': 0.25, 'Appeal_to_Values_f1-score': 0.2819383259911894, 'Appeal_to_Values_support': 128.0, 'micro avg_precision': 0.32323232323232326, 'micro avg_recall': 0.25, 'micro avg_f1-score': 0.2819383259911894, 'micro avg_support': 128.0, 'macro avg_precision': 0.32323232323232326, 'macro avg_recall': 0.25, 'macro avg_f1-score': 0.2819383259911894, 'macro avg_support': 128.0, 'weighted avg_precision': 0.32323232323232326, 'weighted avg_recall': 0.25, 'weighted avg_f1-score': 0.2819383259911894, 'weighted avg_support': 128.0, 'O_support': 2851, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'epoch': 6}]}
Best model updated: current epoch macro f1 = 0.2819383259911894
{'micro_f1': 0.8190210390725634, 'Appeal_to_Values_precision': 0.2828282828282828, 'Appeal_to_Values_recall': 0.1917808219178082, 'Appeal_to_Values_f1-score': 0.22857142857142856, 'Appeal_to_Values_support': 146.0, 'micro avg_precision': 0.2828282828282828, 'micro avg_recall': 0.1917808219178082, 'micro avg_f1-score': 0.22857142857142856, 'micro avg_support': 146.0, 'macro avg_precision': 0.2828282828282828, 'macro avg_recall': 0.1917808219178082, 'macro avg_f1-score': 0.22857142857142856, 'macro avg_support': 146.0, 'weighted avg_precision': 0.2828282828282828, 'weighted avg_recall': 0.1917808219178082, 'weighted avg_f1-score': 0.2285714285714286, 'weighted avg_support': 146.0, 'O_support': 2851, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'epoch': 7}
{'results': [{'micro_f1': 0.7707170459424646, 'Appeal_to_Values_precision': 0.050505050505050504, 'Appeal_to_Values_recall': 0.020833333333333332, 'Appeal_to_Values_f1-score': 0.029498525073746312, 'Appeal_to_Values_support': 240.0, 'micro avg_precision': 0.050505050505050504, 'micro avg_recall': 0.020833333333333332, 'micro avg_f1-score': 0.029498525073746312, 'micro avg_support': 240.0, 'macro avg_precision': 0.050505050505050504, 'macro avg_recall': 0.020833333333333332, 'macro avg_f1-score': 0.029498525073746312, 'macro avg_support': 240.0, 'weighted avg_precision': 0.050505050505050504, 'weighted avg_recall': 0.020833333333333332, 'weighted avg_f1-score': 0.029498525073746316, 'weighted avg_support': 240.0, 'O_support': 2851, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'epoch': 0}, {'micro_f1': 0.8295405753542293, 'Appeal_to_Values_precision': 0.26262626262626265, 'Appeal_to_Values_recall': 0.1326530612244898, 'Appeal_to_Values_f1-score': 0.17627118644067796, 'Appeal_to_Values_support': 196.0, 'micro avg_precision': 0.26262626262626265, 'micro avg_recall': 0.1326530612244898, 'micro avg_f1-score': 0.17627118644067796, 'micro avg_support': 196.0, 'macro avg_precision': 0.26262626262626265, 'macro avg_recall': 0.1326530612244898, 'macro avg_f1-score': 0.17627118644067796, 'macro avg_support': 196.0, 'weighted avg_precision': 0.26262626262626265, 'weighted avg_recall': 0.1326530612244898, 'weighted avg_f1-score': 0.17627118644067796, 'weighted avg_support': 196.0, 'O_support': 2851, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'epoch': 1}, {'micro_f1': 0.8093602404465435, 'Appeal_to_Values_precision': 0.2222222222222222, 'Appeal_to_Values_recall': 0.15827338129496402, 'Appeal_to_Values_f1-score': 0.1848739495798319, 'Appeal_to_Values_support': 139.0, 'micro avg_precision': 0.2222222222222222, 'micro avg_recall': 0.15827338129496402, 'micro avg_f1-score': 0.1848739495798319, 'micro avg_support': 139.0, 'macro avg_precision': 0.2222222222222222, 'macro avg_recall': 0.15827338129496402, 'macro avg_f1-score': 0.1848739495798319, 'macro avg_support': 139.0, 'weighted avg_precision': 0.2222222222222222, 'weighted avg_recall': 0.15827338129496402, 'weighted avg_f1-score': 0.1848739495798319, 'weighted avg_support': 139.0, 'O_support': 2851, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'epoch': 2}, {'micro_f1': 0.8162301416917132, 'Appeal_to_Values_precision': 0.3434343434343434, 'Appeal_to_Values_recall': 0.17894736842105263, 'Appeal_to_Values_f1-score': 0.23529411764705882, 'Appeal_to_Values_support': 190.0, 'micro avg_precision': 0.3434343434343434, 'micro avg_recall': 0.17894736842105263, 'micro avg_f1-score': 0.23529411764705882, 'micro avg_support': 190.0, 'macro avg_precision': 0.3434343434343434, 'macro avg_recall': 0.17894736842105263, 'macro avg_f1-score': 0.23529411764705882, 'macro avg_support': 190.0, 'weighted avg_precision': 0.34343434343434337, 'weighted avg_recall': 0.17894736842105263, 'weighted avg_f1-score': 0.23529411764705882, 'weighted avg_support': 190.0, 'O_support': 2851, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'epoch': 3}, {'micro_f1': 0.8254615714899098, 'Appeal_to_Values_precision': 0.35353535353535354, 'Appeal_to_Values_recall': 0.20833333333333334, 'Appeal_to_Values_f1-score': 0.26217228464419473, 'Appeal_to_Values_support': 168.0, 'micro avg_precision': 0.35353535353535354, 'micro avg_recall': 0.20833333333333334, 'micro avg_f1-score': 0.26217228464419473, 'micro avg_support': 168.0, 'macro avg_precision': 0.35353535353535354, 'macro avg_recall': 0.20833333333333334, 'macro avg_f1-score': 0.26217228464419473, 'macro avg_support': 168.0, 'weighted avg_precision': 0.35353535353535354, 'weighted avg_recall': 0.20833333333333334, 'weighted avg_f1-score': 0.26217228464419473, 'weighted avg_support': 168.0, 'O_support': 2851, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'epoch': 4}, {'micro_f1': 0.8224559896951481, 'Appeal_to_Values_precision': 0.3333333333333333, 'Appeal_to_Values_recall': 0.20625, 'Appeal_to_Values_f1-score': 0.2548262548262548, 'Appeal_to_Values_support': 160.0, 'micro avg_precision': 0.3333333333333333, 'micro avg_recall': 0.20625, 'micro avg_f1-score': 0.2548262548262548, 'micro avg_support': 160.0, 'macro avg_precision': 0.3333333333333333, 'macro avg_recall': 0.20625, 'macro avg_f1-score': 0.2548262548262548, 'macro avg_support': 160.0, 'weighted avg_precision': 0.3333333333333333, 'weighted avg_recall': 0.20625, 'weighted avg_f1-score': 0.2548262548262548, 'weighted avg_support': 160.0, 'O_support': 2851, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'epoch': 5}, {'micro_f1': 0.8190210390725634, 'Appeal_to_Values_precision': 0.32323232323232326, 'Appeal_to_Values_recall': 0.25, 'Appeal_to_Values_f1-score': 0.2819383259911894, 'Appeal_to_Values_support': 128.0, 'micro avg_precision': 0.32323232323232326, 'micro avg_recall': 0.25, 'micro avg_f1-score': 0.2819383259911894, 'micro avg_support': 128.0, 'macro avg_precision': 0.32323232323232326, 'macro avg_recall': 0.25, 'macro avg_f1-score': 0.2819383259911894, 'macro avg_support': 128.0, 'weighted avg_precision': 0.32323232323232326, 'weighted avg_recall': 0.25, 'weighted avg_f1-score': 0.2819383259911894, 'weighted avg_support': 128.0, 'O_support': 2851, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'epoch': 6}, {'micro_f1': 0.8190210390725634, 'Appeal_to_Values_precision': 0.2828282828282828, 'Appeal_to_Values_recall': 0.1917808219178082, 'Appeal_to_Values_f1-score': 0.22857142857142856, 'Appeal_to_Values_support': 146.0, 'micro avg_precision': 0.2828282828282828, 'micro avg_recall': 0.1917808219178082, 'micro avg_f1-score': 0.22857142857142856, 'micro avg_support': 146.0, 'macro avg_precision': 0.2828282828282828, 'macro avg_recall': 0.1917808219178082, 'macro avg_f1-score': 0.22857142857142856, 'macro avg_support': 146.0, 'weighted avg_precision': 0.2828282828282828, 'weighted avg_recall': 0.1917808219178082, 'weighted avg_f1-score': 0.2285714285714286, 'weighted avg_support': 146.0, 'O_support': 2851, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'epoch': 7}]}
{'micro_f1': 0.8359811077715757, 'Appeal_to_Values_precision': 0.3434343434343434, 'Appeal_to_Values_recall': 0.22077922077922077, 'Appeal_to_Values_f1-score': 0.26877470355731226, 'Appeal_to_Values_support': 154.0, 'micro avg_precision': 0.3434343434343434, 'micro avg_recall': 0.22077922077922077, 'micro avg_f1-score': 0.26877470355731226, 'micro avg_support': 154.0, 'macro avg_precision': 0.3434343434343434, 'macro avg_recall': 0.22077922077922077, 'macro avg_f1-score': 0.26877470355731226, 'macro avg_support': 154.0, 'weighted avg_precision': 0.3434343434343434, 'weighted avg_recall': 0.22077922077922077, 'weighted avg_f1-score': 0.26877470355731226, 'weighted avg_support': 154.0, 'O_support': 2851, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'epoch': 8}
{'results': [{'micro_f1': 0.7707170459424646, 'Appeal_to_Values_precision': 0.050505050505050504, 'Appeal_to_Values_recall': 0.020833333333333332, 'Appeal_to_Values_f1-score': 0.029498525073746312, 'Appeal_to_Values_support': 240.0, 'micro avg_precision': 0.050505050505050504, 'micro avg_recall': 0.020833333333333332, 'micro avg_f1-score': 0.029498525073746312, 'micro avg_support': 240.0, 'macro avg_precision': 0.050505050505050504, 'macro avg_recall': 0.020833333333333332, 'macro avg_f1-score': 0.029498525073746312, 'macro avg_support': 240.0, 'weighted avg_precision': 0.050505050505050504, 'weighted avg_recall': 0.020833333333333332, 'weighted avg_f1-score': 0.029498525073746316, 'weighted avg_support': 240.0, 'O_support': 2851, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'epoch': 0}, {'micro_f1': 0.8295405753542293, 'Appeal_to_Values_precision': 0.26262626262626265, 'Appeal_to_Values_recall': 0.1326530612244898, 'Appeal_to_Values_f1-score': 0.17627118644067796, 'Appeal_to_Values_support': 196.0, 'micro avg_precision': 0.26262626262626265, 'micro avg_recall': 0.1326530612244898, 'micro avg_f1-score': 0.17627118644067796, 'micro avg_support': 196.0, 'macro avg_precision': 0.26262626262626265, 'macro avg_recall': 0.1326530612244898, 'macro avg_f1-score': 0.17627118644067796, 'macro avg_support': 196.0, 'weighted avg_precision': 0.26262626262626265, 'weighted avg_recall': 0.1326530612244898, 'weighted avg_f1-score': 0.17627118644067796, 'weighted avg_support': 196.0, 'O_support': 2851, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'epoch': 1}, {'micro_f1': 0.8093602404465435, 'Appeal_to_Values_precision': 0.2222222222222222, 'Appeal_to_Values_recall': 0.15827338129496402, 'Appeal_to_Values_f1-score': 0.1848739495798319, 'Appeal_to_Values_support': 139.0, 'micro avg_precision': 0.2222222222222222, 'micro avg_recall': 0.15827338129496402, 'micro avg_f1-score': 0.1848739495798319, 'micro avg_support': 139.0, 'macro avg_precision': 0.2222222222222222, 'macro avg_recall': 0.15827338129496402, 'macro avg_f1-score': 0.1848739495798319, 'macro avg_support': 139.0, 'weighted avg_precision': 0.2222222222222222, 'weighted avg_recall': 0.15827338129496402, 'weighted avg_f1-score': 0.1848739495798319, 'weighted avg_support': 139.0, 'O_support': 2851, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'epoch': 2}, {'micro_f1': 0.8162301416917132, 'Appeal_to_Values_precision': 0.3434343434343434, 'Appeal_to_Values_recall': 0.17894736842105263, 'Appeal_to_Values_f1-score': 0.23529411764705882, 'Appeal_to_Values_support': 190.0, 'micro avg_precision': 0.3434343434343434, 'micro avg_recall': 0.17894736842105263, 'micro avg_f1-score': 0.23529411764705882, 'micro avg_support': 190.0, 'macro avg_precision': 0.3434343434343434, 'macro avg_recall': 0.17894736842105263, 'macro avg_f1-score': 0.23529411764705882, 'macro avg_support': 190.0, 'weighted avg_precision': 0.34343434343434337, 'weighted avg_recall': 0.17894736842105263, 'weighted avg_f1-score': 0.23529411764705882, 'weighted avg_support': 190.0, 'O_support': 2851, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'epoch': 3}, {'micro_f1': 0.8254615714899098, 'Appeal_to_Values_precision': 0.35353535353535354, 'Appeal_to_Values_recall': 0.20833333333333334, 'Appeal_to_Values_f1-score': 0.26217228464419473, 'Appeal_to_Values_support': 168.0, 'micro avg_precision': 0.35353535353535354, 'micro avg_recall': 0.20833333333333334, 'micro avg_f1-score': 0.26217228464419473, 'micro avg_support': 168.0, 'macro avg_precision': 0.35353535353535354, 'macro avg_recall': 0.20833333333333334, 'macro avg_f1-score': 0.26217228464419473, 'macro avg_support': 168.0, 'weighted avg_precision': 0.35353535353535354, 'weighted avg_recall': 0.20833333333333334, 'weighted avg_f1-score': 0.26217228464419473, 'weighted avg_support': 168.0, 'O_support': 2851, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'epoch': 4}, {'micro_f1': 0.8224559896951481, 'Appeal_to_Values_precision': 0.3333333333333333, 'Appeal_to_Values_recall': 0.20625, 'Appeal_to_Values_f1-score': 0.2548262548262548, 'Appeal_to_Values_support': 160.0, 'micro avg_precision': 0.3333333333333333, 'micro avg_recall': 0.20625, 'micro avg_f1-score': 0.2548262548262548, 'micro avg_support': 160.0, 'macro avg_precision': 0.3333333333333333, 'macro avg_recall': 0.20625, 'macro avg_f1-score': 0.2548262548262548, 'macro avg_support': 160.0, 'weighted avg_precision': 0.3333333333333333, 'weighted avg_recall': 0.20625, 'weighted avg_f1-score': 0.2548262548262548, 'weighted avg_support': 160.0, 'O_support': 2851, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'epoch': 5}, {'micro_f1': 0.8190210390725634, 'Appeal_to_Values_precision': 0.32323232323232326, 'Appeal_to_Values_recall': 0.25, 'Appeal_to_Values_f1-score': 0.2819383259911894, 'Appeal_to_Values_support': 128.0, 'micro avg_precision': 0.32323232323232326, 'micro avg_recall': 0.25, 'micro avg_f1-score': 0.2819383259911894, 'micro avg_support': 128.0, 'macro avg_precision': 0.32323232323232326, 'macro avg_recall': 0.25, 'macro avg_f1-score': 0.2819383259911894, 'macro avg_support': 128.0, 'weighted avg_precision': 0.32323232323232326, 'weighted avg_recall': 0.25, 'weighted avg_f1-score': 0.2819383259911894, 'weighted avg_support': 128.0, 'O_support': 2851, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'epoch': 6}, {'micro_f1': 0.8190210390725634, 'Appeal_to_Values_precision': 0.2828282828282828, 'Appeal_to_Values_recall': 0.1917808219178082, 'Appeal_to_Values_f1-score': 0.22857142857142856, 'Appeal_to_Values_support': 146.0, 'micro avg_precision': 0.2828282828282828, 'micro avg_recall': 0.1917808219178082, 'micro avg_f1-score': 0.22857142857142856, 'micro avg_support': 146.0, 'macro avg_precision': 0.2828282828282828, 'macro avg_recall': 0.1917808219178082, 'macro avg_f1-score': 0.22857142857142856, 'macro avg_support': 146.0, 'weighted avg_precision': 0.2828282828282828, 'weighted avg_recall': 0.1917808219178082, 'weighted avg_f1-score': 0.2285714285714286, 'weighted avg_support': 146.0, 'O_support': 2851, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'epoch': 7}, {'micro_f1': 0.8359811077715757, 'Appeal_to_Values_precision': 0.3434343434343434, 'Appeal_to_Values_recall': 0.22077922077922077, 'Appeal_to_Values_f1-score': 0.26877470355731226, 'Appeal_to_Values_support': 154.0, 'micro avg_precision': 0.3434343434343434, 'micro avg_recall': 0.22077922077922077, 'micro avg_f1-score': 0.26877470355731226, 'micro avg_support': 154.0, 'macro avg_precision': 0.3434343434343434, 'macro avg_recall': 0.22077922077922077, 'macro avg_f1-score': 0.26877470355731226, 'macro avg_support': 154.0, 'weighted avg_precision': 0.3434343434343434, 'weighted avg_recall': 0.22077922077922077, 'weighted avg_f1-score': 0.26877470355731226, 'weighted avg_support': 154.0, 'O_support': 2851, 'B-Appeal_to_Values_support': 99, 'I-Appeal_to_Values_support': 1708, 'epoch': 8}]}
Early stopping triggered.
Saving model to directory: ./models/M2/2024-05-12-17-42-10_aug/mdeberta-v3-base_2_ME10_target=Appeal_to_Values_SUBSAMPLED_2024-05-12-17-42-10
Training model no. 3 of 23 for (3, 'Appeal_to_Fear-Prejudice') persuasion technique...
{'micro_f1': 0.7984373230664704, 'Appeal_to_Fear-Prejudice_precision': 0.12568306010928962, 'Appeal_to_Fear-Prejudice_recall': 0.0756578947368421, 'Appeal_to_Fear-Prejudice_f1-score': 0.0944558521560575, 'Appeal_to_Fear-Prejudice_support': 304.0, 'micro avg_precision': 0.12568306010928962, 'micro avg_recall': 0.0756578947368421, 'micro avg_f1-score': 0.0944558521560575, 'micro avg_support': 304.0, 'macro avg_precision': 0.12568306010928962, 'macro avg_recall': 0.0756578947368421, 'macro avg_f1-score': 0.0944558521560575, 'macro avg_support': 304.0, 'weighted avg_precision': 0.12568306010928962, 'weighted avg_recall': 0.0756578947368421, 'weighted avg_f1-score': 0.0944558521560575, 'weighted avg_support': 304.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 0}
{'results': [{'micro_f1': 0.7984373230664704, 'Appeal_to_Fear-Prejudice_precision': 0.12568306010928962, 'Appeal_to_Fear-Prejudice_recall': 0.0756578947368421, 'Appeal_to_Fear-Prejudice_f1-score': 0.0944558521560575, 'Appeal_to_Fear-Prejudice_support': 304.0, 'micro avg_precision': 0.12568306010928962, 'micro avg_recall': 0.0756578947368421, 'micro avg_f1-score': 0.0944558521560575, 'micro avg_support': 304.0, 'macro avg_precision': 0.12568306010928962, 'macro avg_recall': 0.0756578947368421, 'macro avg_f1-score': 0.0944558521560575, 'macro avg_support': 304.0, 'weighted avg_precision': 0.12568306010928962, 'weighted avg_recall': 0.0756578947368421, 'weighted avg_f1-score': 0.0944558521560575, 'weighted avg_support': 304.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 0}]}
Best model updated: current epoch macro f1 = 0.0944558521560575
{'micro_f1': 0.8399954705016419, 'Appeal_to_Fear-Prejudice_precision': 0.2677595628415301, 'Appeal_to_Fear-Prejudice_recall': 0.1801470588235294, 'Appeal_to_Fear-Prejudice_f1-score': 0.2153846153846154, 'Appeal_to_Fear-Prejudice_support': 272.0, 'micro avg_precision': 0.2677595628415301, 'micro avg_recall': 0.1801470588235294, 'micro avg_f1-score': 0.2153846153846154, 'micro avg_support': 272.0, 'macro avg_precision': 0.2677595628415301, 'macro avg_recall': 0.1801470588235294, 'macro avg_f1-score': 0.2153846153846154, 'macro avg_support': 272.0, 'weighted avg_precision': 0.2677595628415301, 'weighted avg_recall': 0.1801470588235294, 'weighted avg_f1-score': 0.2153846153846154, 'weighted avg_support': 272.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 1}
{'results': [{'micro_f1': 0.7984373230664704, 'Appeal_to_Fear-Prejudice_precision': 0.12568306010928962, 'Appeal_to_Fear-Prejudice_recall': 0.0756578947368421, 'Appeal_to_Fear-Prejudice_f1-score': 0.0944558521560575, 'Appeal_to_Fear-Prejudice_support': 304.0, 'micro avg_precision': 0.12568306010928962, 'micro avg_recall': 0.0756578947368421, 'micro avg_f1-score': 0.0944558521560575, 'micro avg_support': 304.0, 'macro avg_precision': 0.12568306010928962, 'macro avg_recall': 0.0756578947368421, 'macro avg_f1-score': 0.0944558521560575, 'macro avg_support': 304.0, 'weighted avg_precision': 0.12568306010928962, 'weighted avg_recall': 0.0756578947368421, 'weighted avg_f1-score': 0.0944558521560575, 'weighted avg_support': 304.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 0}, {'micro_f1': 0.8399954705016419, 'Appeal_to_Fear-Prejudice_precision': 0.2677595628415301, 'Appeal_to_Fear-Prejudice_recall': 0.1801470588235294, 'Appeal_to_Fear-Prejudice_f1-score': 0.2153846153846154, 'Appeal_to_Fear-Prejudice_support': 272.0, 'micro avg_precision': 0.2677595628415301, 'micro avg_recall': 0.1801470588235294, 'micro avg_f1-score': 0.2153846153846154, 'micro avg_support': 272.0, 'macro avg_precision': 0.2677595628415301, 'macro avg_recall': 0.1801470588235294, 'macro avg_f1-score': 0.2153846153846154, 'macro avg_support': 272.0, 'weighted avg_precision': 0.2677595628415301, 'weighted avg_recall': 0.1801470588235294, 'weighted avg_f1-score': 0.2153846153846154, 'weighted avg_support': 272.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 1}]}
Best model updated: current epoch macro f1 = 0.2153846153846154
{'micro_f1': 0.8286717246064998, 'Appeal_to_Fear-Prejudice_precision': 0.273224043715847, 'Appeal_to_Fear-Prejudice_recall': 0.20080321285140562, 'Appeal_to_Fear-Prejudice_f1-score': 0.23148148148148148, 'Appeal_to_Fear-Prejudice_support': 249.0, 'micro avg_precision': 0.273224043715847, 'micro avg_recall': 0.20080321285140562, 'micro avg_f1-score': 0.23148148148148148, 'micro avg_support': 249.0, 'macro avg_precision': 0.273224043715847, 'macro avg_recall': 0.20080321285140562, 'macro avg_f1-score': 0.23148148148148148, 'macro avg_support': 249.0, 'weighted avg_precision': 0.273224043715847, 'weighted avg_recall': 0.20080321285140562, 'weighted avg_f1-score': 0.23148148148148148, 'weighted avg_support': 249.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 2}
{'results': [{'micro_f1': 0.7984373230664704, 'Appeal_to_Fear-Prejudice_precision': 0.12568306010928962, 'Appeal_to_Fear-Prejudice_recall': 0.0756578947368421, 'Appeal_to_Fear-Prejudice_f1-score': 0.0944558521560575, 'Appeal_to_Fear-Prejudice_support': 304.0, 'micro avg_precision': 0.12568306010928962, 'micro avg_recall': 0.0756578947368421, 'micro avg_f1-score': 0.0944558521560575, 'micro avg_support': 304.0, 'macro avg_precision': 0.12568306010928962, 'macro avg_recall': 0.0756578947368421, 'macro avg_f1-score': 0.0944558521560575, 'macro avg_support': 304.0, 'weighted avg_precision': 0.12568306010928962, 'weighted avg_recall': 0.0756578947368421, 'weighted avg_f1-score': 0.0944558521560575, 'weighted avg_support': 304.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 0}, {'micro_f1': 0.8399954705016419, 'Appeal_to_Fear-Prejudice_precision': 0.2677595628415301, 'Appeal_to_Fear-Prejudice_recall': 0.1801470588235294, 'Appeal_to_Fear-Prejudice_f1-score': 0.2153846153846154, 'Appeal_to_Fear-Prejudice_support': 272.0, 'micro avg_precision': 0.2677595628415301, 'micro avg_recall': 0.1801470588235294, 'micro avg_f1-score': 0.2153846153846154, 'micro avg_support': 272.0, 'macro avg_precision': 0.2677595628415301, 'macro avg_recall': 0.1801470588235294, 'macro avg_f1-score': 0.2153846153846154, 'macro avg_support': 272.0, 'weighted avg_precision': 0.2677595628415301, 'weighted avg_recall': 0.1801470588235294, 'weighted avg_f1-score': 0.2153846153846154, 'weighted avg_support': 272.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 1}, {'micro_f1': 0.8286717246064998, 'Appeal_to_Fear-Prejudice_precision': 0.273224043715847, 'Appeal_to_Fear-Prejudice_recall': 0.20080321285140562, 'Appeal_to_Fear-Prejudice_f1-score': 0.23148148148148148, 'Appeal_to_Fear-Prejudice_support': 249.0, 'micro avg_precision': 0.273224043715847, 'micro avg_recall': 0.20080321285140562, 'micro avg_f1-score': 0.23148148148148148, 'micro avg_support': 249.0, 'macro avg_precision': 0.273224043715847, 'macro avg_recall': 0.20080321285140562, 'macro avg_f1-score': 0.23148148148148148, 'macro avg_support': 249.0, 'weighted avg_precision': 0.273224043715847, 'weighted avg_recall': 0.20080321285140562, 'weighted avg_f1-score': 0.23148148148148148, 'weighted avg_support': 249.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 2}]}
Best model updated: current epoch macro f1 = 0.23148148148148148
{'micro_f1': 0.8425999320575246, 'Appeal_to_Fear-Prejudice_precision': 0.30601092896174864, 'Appeal_to_Fear-Prejudice_recall': 0.2196078431372549, 'Appeal_to_Fear-Prejudice_f1-score': 0.2557077625570776, 'Appeal_to_Fear-Prejudice_support': 255.0, 'micro avg_precision': 0.30601092896174864, 'micro avg_recall': 0.2196078431372549, 'micro avg_f1-score': 0.2557077625570776, 'micro avg_support': 255.0, 'macro avg_precision': 0.30601092896174864, 'macro avg_recall': 0.2196078431372549, 'macro avg_f1-score': 0.2557077625570776, 'macro avg_support': 255.0, 'weighted avg_precision': 0.30601092896174864, 'weighted avg_recall': 0.2196078431372549, 'weighted avg_f1-score': 0.2557077625570776, 'weighted avg_support': 255.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 3}
{'results': [{'micro_f1': 0.7984373230664704, 'Appeal_to_Fear-Prejudice_precision': 0.12568306010928962, 'Appeal_to_Fear-Prejudice_recall': 0.0756578947368421, 'Appeal_to_Fear-Prejudice_f1-score': 0.0944558521560575, 'Appeal_to_Fear-Prejudice_support': 304.0, 'micro avg_precision': 0.12568306010928962, 'micro avg_recall': 0.0756578947368421, 'micro avg_f1-score': 0.0944558521560575, 'micro avg_support': 304.0, 'macro avg_precision': 0.12568306010928962, 'macro avg_recall': 0.0756578947368421, 'macro avg_f1-score': 0.0944558521560575, 'macro avg_support': 304.0, 'weighted avg_precision': 0.12568306010928962, 'weighted avg_recall': 0.0756578947368421, 'weighted avg_f1-score': 0.0944558521560575, 'weighted avg_support': 304.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 0}, {'micro_f1': 0.8399954705016419, 'Appeal_to_Fear-Prejudice_precision': 0.2677595628415301, 'Appeal_to_Fear-Prejudice_recall': 0.1801470588235294, 'Appeal_to_Fear-Prejudice_f1-score': 0.2153846153846154, 'Appeal_to_Fear-Prejudice_support': 272.0, 'micro avg_precision': 0.2677595628415301, 'micro avg_recall': 0.1801470588235294, 'micro avg_f1-score': 0.2153846153846154, 'micro avg_support': 272.0, 'macro avg_precision': 0.2677595628415301, 'macro avg_recall': 0.1801470588235294, 'macro avg_f1-score': 0.2153846153846154, 'macro avg_support': 272.0, 'weighted avg_precision': 0.2677595628415301, 'weighted avg_recall': 0.1801470588235294, 'weighted avg_f1-score': 0.2153846153846154, 'weighted avg_support': 272.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 1}, {'micro_f1': 0.8286717246064998, 'Appeal_to_Fear-Prejudice_precision': 0.273224043715847, 'Appeal_to_Fear-Prejudice_recall': 0.20080321285140562, 'Appeal_to_Fear-Prejudice_f1-score': 0.23148148148148148, 'Appeal_to_Fear-Prejudice_support': 249.0, 'micro avg_precision': 0.273224043715847, 'micro avg_recall': 0.20080321285140562, 'micro avg_f1-score': 0.23148148148148148, 'micro avg_support': 249.0, 'macro avg_precision': 0.273224043715847, 'macro avg_recall': 0.20080321285140562, 'macro avg_f1-score': 0.23148148148148148, 'macro avg_support': 249.0, 'weighted avg_precision': 0.273224043715847, 'weighted avg_recall': 0.20080321285140562, 'weighted avg_f1-score': 0.23148148148148148, 'weighted avg_support': 249.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 2}, {'micro_f1': 0.8425999320575246, 'Appeal_to_Fear-Prejudice_precision': 0.30601092896174864, 'Appeal_to_Fear-Prejudice_recall': 0.2196078431372549, 'Appeal_to_Fear-Prejudice_f1-score': 0.2557077625570776, 'Appeal_to_Fear-Prejudice_support': 255.0, 'micro avg_precision': 0.30601092896174864, 'micro avg_recall': 0.2196078431372549, 'micro avg_f1-score': 0.2557077625570776, 'micro avg_support': 255.0, 'macro avg_precision': 0.30601092896174864, 'macro avg_recall': 0.2196078431372549, 'macro avg_f1-score': 0.2557077625570776, 'macro avg_support': 255.0, 'weighted avg_precision': 0.30601092896174864, 'weighted avg_recall': 0.2196078431372549, 'weighted avg_f1-score': 0.2557077625570776, 'weighted avg_support': 255.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 3}]}
Best model updated: current epoch macro f1 = 0.2557077625570776
{'micro_f1': 0.822783376741026, 'Appeal_to_Fear-Prejudice_precision': 0.366120218579235, 'Appeal_to_Fear-Prejudice_recall': 0.24814814814814815, 'Appeal_to_Fear-Prejudice_f1-score': 0.2958057395143488, 'Appeal_to_Fear-Prejudice_support': 270.0, 'micro avg_precision': 0.366120218579235, 'micro avg_recall': 0.24814814814814815, 'micro avg_f1-score': 0.2958057395143488, 'micro avg_support': 270.0, 'macro avg_precision': 0.366120218579235, 'macro avg_recall': 0.24814814814814815, 'macro avg_f1-score': 0.2958057395143488, 'macro avg_support': 270.0, 'weighted avg_precision': 0.366120218579235, 'weighted avg_recall': 0.24814814814814815, 'weighted avg_f1-score': 0.2958057395143488, 'weighted avg_support': 270.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 4}
{'results': [{'micro_f1': 0.7984373230664704, 'Appeal_to_Fear-Prejudice_precision': 0.12568306010928962, 'Appeal_to_Fear-Prejudice_recall': 0.0756578947368421, 'Appeal_to_Fear-Prejudice_f1-score': 0.0944558521560575, 'Appeal_to_Fear-Prejudice_support': 304.0, 'micro avg_precision': 0.12568306010928962, 'micro avg_recall': 0.0756578947368421, 'micro avg_f1-score': 0.0944558521560575, 'micro avg_support': 304.0, 'macro avg_precision': 0.12568306010928962, 'macro avg_recall': 0.0756578947368421, 'macro avg_f1-score': 0.0944558521560575, 'macro avg_support': 304.0, 'weighted avg_precision': 0.12568306010928962, 'weighted avg_recall': 0.0756578947368421, 'weighted avg_f1-score': 0.0944558521560575, 'weighted avg_support': 304.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 0}, {'micro_f1': 0.8399954705016419, 'Appeal_to_Fear-Prejudice_precision': 0.2677595628415301, 'Appeal_to_Fear-Prejudice_recall': 0.1801470588235294, 'Appeal_to_Fear-Prejudice_f1-score': 0.2153846153846154, 'Appeal_to_Fear-Prejudice_support': 272.0, 'micro avg_precision': 0.2677595628415301, 'micro avg_recall': 0.1801470588235294, 'micro avg_f1-score': 0.2153846153846154, 'micro avg_support': 272.0, 'macro avg_precision': 0.2677595628415301, 'macro avg_recall': 0.1801470588235294, 'macro avg_f1-score': 0.2153846153846154, 'macro avg_support': 272.0, 'weighted avg_precision': 0.2677595628415301, 'weighted avg_recall': 0.1801470588235294, 'weighted avg_f1-score': 0.2153846153846154, 'weighted avg_support': 272.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 1}, {'micro_f1': 0.8286717246064998, 'Appeal_to_Fear-Prejudice_precision': 0.273224043715847, 'Appeal_to_Fear-Prejudice_recall': 0.20080321285140562, 'Appeal_to_Fear-Prejudice_f1-score': 0.23148148148148148, 'Appeal_to_Fear-Prejudice_support': 249.0, 'micro avg_precision': 0.273224043715847, 'micro avg_recall': 0.20080321285140562, 'micro avg_f1-score': 0.23148148148148148, 'micro avg_support': 249.0, 'macro avg_precision': 0.273224043715847, 'macro avg_recall': 0.20080321285140562, 'macro avg_f1-score': 0.23148148148148148, 'macro avg_support': 249.0, 'weighted avg_precision': 0.273224043715847, 'weighted avg_recall': 0.20080321285140562, 'weighted avg_f1-score': 0.23148148148148148, 'weighted avg_support': 249.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 2}, {'micro_f1': 0.8425999320575246, 'Appeal_to_Fear-Prejudice_precision': 0.30601092896174864, 'Appeal_to_Fear-Prejudice_recall': 0.2196078431372549, 'Appeal_to_Fear-Prejudice_f1-score': 0.2557077625570776, 'Appeal_to_Fear-Prejudice_support': 255.0, 'micro avg_precision': 0.30601092896174864, 'micro avg_recall': 0.2196078431372549, 'micro avg_f1-score': 0.2557077625570776, 'micro avg_support': 255.0, 'macro avg_precision': 0.30601092896174864, 'macro avg_recall': 0.2196078431372549, 'macro avg_f1-score': 0.2557077625570776, 'macro avg_support': 255.0, 'weighted avg_precision': 0.30601092896174864, 'weighted avg_recall': 0.2196078431372549, 'weighted avg_f1-score': 0.2557077625570776, 'weighted avg_support': 255.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 3}, {'micro_f1': 0.822783376741026, 'Appeal_to_Fear-Prejudice_precision': 0.366120218579235, 'Appeal_to_Fear-Prejudice_recall': 0.24814814814814815, 'Appeal_to_Fear-Prejudice_f1-score': 0.2958057395143488, 'Appeal_to_Fear-Prejudice_support': 270.0, 'micro avg_precision': 0.366120218579235, 'micro avg_recall': 0.24814814814814815, 'micro avg_f1-score': 0.2958057395143488, 'micro avg_support': 270.0, 'macro avg_precision': 0.366120218579235, 'macro avg_recall': 0.24814814814814815, 'macro avg_f1-score': 0.2958057395143488, 'macro avg_support': 270.0, 'weighted avg_precision': 0.366120218579235, 'weighted avg_recall': 0.24814814814814815, 'weighted avg_f1-score': 0.2958057395143488, 'weighted avg_support': 270.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 4}]}
Best model updated: current epoch macro f1 = 0.2958057395143488
{'micro_f1': 0.8425999320575246, 'Appeal_to_Fear-Prejudice_precision': 0.3224043715846995, 'Appeal_to_Fear-Prejudice_recall': 0.2489451476793249, 'Appeal_to_Fear-Prejudice_f1-score': 0.28095238095238095, 'Appeal_to_Fear-Prejudice_support': 237.0, 'micro avg_precision': 0.3224043715846995, 'micro avg_recall': 0.2489451476793249, 'micro avg_f1-score': 0.28095238095238095, 'micro avg_support': 237.0, 'macro avg_precision': 0.3224043715846995, 'macro avg_recall': 0.2489451476793249, 'macro avg_f1-score': 0.28095238095238095, 'macro avg_support': 237.0, 'weighted avg_precision': 0.3224043715846995, 'weighted avg_recall': 0.2489451476793249, 'weighted avg_f1-score': 0.28095238095238095, 'weighted avg_support': 237.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 5}
{'results': [{'micro_f1': 0.7984373230664704, 'Appeal_to_Fear-Prejudice_precision': 0.12568306010928962, 'Appeal_to_Fear-Prejudice_recall': 0.0756578947368421, 'Appeal_to_Fear-Prejudice_f1-score': 0.0944558521560575, 'Appeal_to_Fear-Prejudice_support': 304.0, 'micro avg_precision': 0.12568306010928962, 'micro avg_recall': 0.0756578947368421, 'micro avg_f1-score': 0.0944558521560575, 'micro avg_support': 304.0, 'macro avg_precision': 0.12568306010928962, 'macro avg_recall': 0.0756578947368421, 'macro avg_f1-score': 0.0944558521560575, 'macro avg_support': 304.0, 'weighted avg_precision': 0.12568306010928962, 'weighted avg_recall': 0.0756578947368421, 'weighted avg_f1-score': 0.0944558521560575, 'weighted avg_support': 304.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 0}, {'micro_f1': 0.8399954705016419, 'Appeal_to_Fear-Prejudice_precision': 0.2677595628415301, 'Appeal_to_Fear-Prejudice_recall': 0.1801470588235294, 'Appeal_to_Fear-Prejudice_f1-score': 0.2153846153846154, 'Appeal_to_Fear-Prejudice_support': 272.0, 'micro avg_precision': 0.2677595628415301, 'micro avg_recall': 0.1801470588235294, 'micro avg_f1-score': 0.2153846153846154, 'micro avg_support': 272.0, 'macro avg_precision': 0.2677595628415301, 'macro avg_recall': 0.1801470588235294, 'macro avg_f1-score': 0.2153846153846154, 'macro avg_support': 272.0, 'weighted avg_precision': 0.2677595628415301, 'weighted avg_recall': 0.1801470588235294, 'weighted avg_f1-score': 0.2153846153846154, 'weighted avg_support': 272.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 1}, {'micro_f1': 0.8286717246064998, 'Appeal_to_Fear-Prejudice_precision': 0.273224043715847, 'Appeal_to_Fear-Prejudice_recall': 0.20080321285140562, 'Appeal_to_Fear-Prejudice_f1-score': 0.23148148148148148, 'Appeal_to_Fear-Prejudice_support': 249.0, 'micro avg_precision': 0.273224043715847, 'micro avg_recall': 0.20080321285140562, 'micro avg_f1-score': 0.23148148148148148, 'micro avg_support': 249.0, 'macro avg_precision': 0.273224043715847, 'macro avg_recall': 0.20080321285140562, 'macro avg_f1-score': 0.23148148148148148, 'macro avg_support': 249.0, 'weighted avg_precision': 0.273224043715847, 'weighted avg_recall': 0.20080321285140562, 'weighted avg_f1-score': 0.23148148148148148, 'weighted avg_support': 249.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 2}, {'micro_f1': 0.8425999320575246, 'Appeal_to_Fear-Prejudice_precision': 0.30601092896174864, 'Appeal_to_Fear-Prejudice_recall': 0.2196078431372549, 'Appeal_to_Fear-Prejudice_f1-score': 0.2557077625570776, 'Appeal_to_Fear-Prejudice_support': 255.0, 'micro avg_precision': 0.30601092896174864, 'micro avg_recall': 0.2196078431372549, 'micro avg_f1-score': 0.2557077625570776, 'micro avg_support': 255.0, 'macro avg_precision': 0.30601092896174864, 'macro avg_recall': 0.2196078431372549, 'macro avg_f1-score': 0.2557077625570776, 'macro avg_support': 255.0, 'weighted avg_precision': 0.30601092896174864, 'weighted avg_recall': 0.2196078431372549, 'weighted avg_f1-score': 0.2557077625570776, 'weighted avg_support': 255.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 3}, {'micro_f1': 0.822783376741026, 'Appeal_to_Fear-Prejudice_precision': 0.366120218579235, 'Appeal_to_Fear-Prejudice_recall': 0.24814814814814815, 'Appeal_to_Fear-Prejudice_f1-score': 0.2958057395143488, 'Appeal_to_Fear-Prejudice_support': 270.0, 'micro avg_precision': 0.366120218579235, 'micro avg_recall': 0.24814814814814815, 'micro avg_f1-score': 0.2958057395143488, 'micro avg_support': 270.0, 'macro avg_precision': 0.366120218579235, 'macro avg_recall': 0.24814814814814815, 'macro avg_f1-score': 0.2958057395143488, 'macro avg_support': 270.0, 'weighted avg_precision': 0.366120218579235, 'weighted avg_recall': 0.24814814814814815, 'weighted avg_f1-score': 0.2958057395143488, 'weighted avg_support': 270.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 4}, {'micro_f1': 0.8425999320575246, 'Appeal_to_Fear-Prejudice_precision': 0.3224043715846995, 'Appeal_to_Fear-Prejudice_recall': 0.2489451476793249, 'Appeal_to_Fear-Prejudice_f1-score': 0.28095238095238095, 'Appeal_to_Fear-Prejudice_support': 237.0, 'micro avg_precision': 0.3224043715846995, 'micro avg_recall': 0.2489451476793249, 'micro avg_f1-score': 0.28095238095238095, 'micro avg_support': 237.0, 'macro avg_precision': 0.3224043715846995, 'macro avg_recall': 0.2489451476793249, 'macro avg_f1-score': 0.28095238095238095, 'macro avg_support': 237.0, 'weighted avg_precision': 0.3224043715846995, 'weighted avg_recall': 0.2489451476793249, 'weighted avg_f1-score': 0.28095238095238095, 'weighted avg_support': 237.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 5}]}
{'micro_f1': 0.8365983467330993, 'Appeal_to_Fear-Prejudice_precision': 0.34972677595628415, 'Appeal_to_Fear-Prejudice_recall': 0.26229508196721313, 'Appeal_to_Fear-Prejudice_f1-score': 0.2997658079625293, 'Appeal_to_Fear-Prejudice_support': 244.0, 'micro avg_precision': 0.34972677595628415, 'micro avg_recall': 0.26229508196721313, 'micro avg_f1-score': 0.2997658079625293, 'micro avg_support': 244.0, 'macro avg_precision': 0.34972677595628415, 'macro avg_recall': 0.26229508196721313, 'macro avg_f1-score': 0.2997658079625293, 'macro avg_support': 244.0, 'weighted avg_precision': 0.34972677595628415, 'weighted avg_recall': 0.26229508196721313, 'weighted avg_f1-score': 0.2997658079625293, 'weighted avg_support': 244.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 6}
{'results': [{'micro_f1': 0.7984373230664704, 'Appeal_to_Fear-Prejudice_precision': 0.12568306010928962, 'Appeal_to_Fear-Prejudice_recall': 0.0756578947368421, 'Appeal_to_Fear-Prejudice_f1-score': 0.0944558521560575, 'Appeal_to_Fear-Prejudice_support': 304.0, 'micro avg_precision': 0.12568306010928962, 'micro avg_recall': 0.0756578947368421, 'micro avg_f1-score': 0.0944558521560575, 'micro avg_support': 304.0, 'macro avg_precision': 0.12568306010928962, 'macro avg_recall': 0.0756578947368421, 'macro avg_f1-score': 0.0944558521560575, 'macro avg_support': 304.0, 'weighted avg_precision': 0.12568306010928962, 'weighted avg_recall': 0.0756578947368421, 'weighted avg_f1-score': 0.0944558521560575, 'weighted avg_support': 304.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 0}, {'micro_f1': 0.8399954705016419, 'Appeal_to_Fear-Prejudice_precision': 0.2677595628415301, 'Appeal_to_Fear-Prejudice_recall': 0.1801470588235294, 'Appeal_to_Fear-Prejudice_f1-score': 0.2153846153846154, 'Appeal_to_Fear-Prejudice_support': 272.0, 'micro avg_precision': 0.2677595628415301, 'micro avg_recall': 0.1801470588235294, 'micro avg_f1-score': 0.2153846153846154, 'micro avg_support': 272.0, 'macro avg_precision': 0.2677595628415301, 'macro avg_recall': 0.1801470588235294, 'macro avg_f1-score': 0.2153846153846154, 'macro avg_support': 272.0, 'weighted avg_precision': 0.2677595628415301, 'weighted avg_recall': 0.1801470588235294, 'weighted avg_f1-score': 0.2153846153846154, 'weighted avg_support': 272.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 1}, {'micro_f1': 0.8286717246064998, 'Appeal_to_Fear-Prejudice_precision': 0.273224043715847, 'Appeal_to_Fear-Prejudice_recall': 0.20080321285140562, 'Appeal_to_Fear-Prejudice_f1-score': 0.23148148148148148, 'Appeal_to_Fear-Prejudice_support': 249.0, 'micro avg_precision': 0.273224043715847, 'micro avg_recall': 0.20080321285140562, 'micro avg_f1-score': 0.23148148148148148, 'micro avg_support': 249.0, 'macro avg_precision': 0.273224043715847, 'macro avg_recall': 0.20080321285140562, 'macro avg_f1-score': 0.23148148148148148, 'macro avg_support': 249.0, 'weighted avg_precision': 0.273224043715847, 'weighted avg_recall': 0.20080321285140562, 'weighted avg_f1-score': 0.23148148148148148, 'weighted avg_support': 249.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 2}, {'micro_f1': 0.8425999320575246, 'Appeal_to_Fear-Prejudice_precision': 0.30601092896174864, 'Appeal_to_Fear-Prejudice_recall': 0.2196078431372549, 'Appeal_to_Fear-Prejudice_f1-score': 0.2557077625570776, 'Appeal_to_Fear-Prejudice_support': 255.0, 'micro avg_precision': 0.30601092896174864, 'micro avg_recall': 0.2196078431372549, 'micro avg_f1-score': 0.2557077625570776, 'micro avg_support': 255.0, 'macro avg_precision': 0.30601092896174864, 'macro avg_recall': 0.2196078431372549, 'macro avg_f1-score': 0.2557077625570776, 'macro avg_support': 255.0, 'weighted avg_precision': 0.30601092896174864, 'weighted avg_recall': 0.2196078431372549, 'weighted avg_f1-score': 0.2557077625570776, 'weighted avg_support': 255.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 3}, {'micro_f1': 0.822783376741026, 'Appeal_to_Fear-Prejudice_precision': 0.366120218579235, 'Appeal_to_Fear-Prejudice_recall': 0.24814814814814815, 'Appeal_to_Fear-Prejudice_f1-score': 0.2958057395143488, 'Appeal_to_Fear-Prejudice_support': 270.0, 'micro avg_precision': 0.366120218579235, 'micro avg_recall': 0.24814814814814815, 'micro avg_f1-score': 0.2958057395143488, 'micro avg_support': 270.0, 'macro avg_precision': 0.366120218579235, 'macro avg_recall': 0.24814814814814815, 'macro avg_f1-score': 0.2958057395143488, 'macro avg_support': 270.0, 'weighted avg_precision': 0.366120218579235, 'weighted avg_recall': 0.24814814814814815, 'weighted avg_f1-score': 0.2958057395143488, 'weighted avg_support': 270.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 4}, {'micro_f1': 0.8425999320575246, 'Appeal_to_Fear-Prejudice_precision': 0.3224043715846995, 'Appeal_to_Fear-Prejudice_recall': 0.2489451476793249, 'Appeal_to_Fear-Prejudice_f1-score': 0.28095238095238095, 'Appeal_to_Fear-Prejudice_support': 237.0, 'micro avg_precision': 0.3224043715846995, 'micro avg_recall': 0.2489451476793249, 'micro avg_f1-score': 0.28095238095238095, 'micro avg_support': 237.0, 'macro avg_precision': 0.3224043715846995, 'macro avg_recall': 0.2489451476793249, 'macro avg_f1-score': 0.28095238095238095, 'macro avg_support': 237.0, 'weighted avg_precision': 0.3224043715846995, 'weighted avg_recall': 0.2489451476793249, 'weighted avg_f1-score': 0.28095238095238095, 'weighted avg_support': 237.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 5}, {'micro_f1': 0.8365983467330993, 'Appeal_to_Fear-Prejudice_precision': 0.34972677595628415, 'Appeal_to_Fear-Prejudice_recall': 0.26229508196721313, 'Appeal_to_Fear-Prejudice_f1-score': 0.2997658079625293, 'Appeal_to_Fear-Prejudice_support': 244.0, 'micro avg_precision': 0.34972677595628415, 'micro avg_recall': 0.26229508196721313, 'micro avg_f1-score': 0.2997658079625293, 'micro avg_support': 244.0, 'macro avg_precision': 0.34972677595628415, 'macro avg_recall': 0.26229508196721313, 'macro avg_f1-score': 0.2997658079625293, 'macro avg_support': 244.0, 'weighted avg_precision': 0.34972677595628415, 'weighted avg_recall': 0.26229508196721313, 'weighted avg_f1-score': 0.2997658079625293, 'weighted avg_support': 244.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 6}]}
Best model updated: current epoch macro f1 = 0.2997658079625293
{'micro_f1': 0.8355792096025365, 'Appeal_to_Fear-Prejudice_precision': 0.366120218579235, 'Appeal_to_Fear-Prejudice_recall': 0.2838983050847458, 'Appeal_to_Fear-Prejudice_f1-score': 0.3198090692124105, 'Appeal_to_Fear-Prejudice_support': 236.0, 'micro avg_precision': 0.366120218579235, 'micro avg_recall': 0.2838983050847458, 'micro avg_f1-score': 0.3198090692124105, 'micro avg_support': 236.0, 'macro avg_precision': 0.366120218579235, 'macro avg_recall': 0.2838983050847458, 'macro avg_f1-score': 0.3198090692124105, 'macro avg_support': 236.0, 'weighted avg_precision': 0.366120218579235, 'weighted avg_recall': 0.2838983050847458, 'weighted avg_f1-score': 0.3198090692124105, 'weighted avg_support': 236.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 7}
{'results': [{'micro_f1': 0.7984373230664704, 'Appeal_to_Fear-Prejudice_precision': 0.12568306010928962, 'Appeal_to_Fear-Prejudice_recall': 0.0756578947368421, 'Appeal_to_Fear-Prejudice_f1-score': 0.0944558521560575, 'Appeal_to_Fear-Prejudice_support': 304.0, 'micro avg_precision': 0.12568306010928962, 'micro avg_recall': 0.0756578947368421, 'micro avg_f1-score': 0.0944558521560575, 'micro avg_support': 304.0, 'macro avg_precision': 0.12568306010928962, 'macro avg_recall': 0.0756578947368421, 'macro avg_f1-score': 0.0944558521560575, 'macro avg_support': 304.0, 'weighted avg_precision': 0.12568306010928962, 'weighted avg_recall': 0.0756578947368421, 'weighted avg_f1-score': 0.0944558521560575, 'weighted avg_support': 304.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 0}, {'micro_f1': 0.8399954705016419, 'Appeal_to_Fear-Prejudice_precision': 0.2677595628415301, 'Appeal_to_Fear-Prejudice_recall': 0.1801470588235294, 'Appeal_to_Fear-Prejudice_f1-score': 0.2153846153846154, 'Appeal_to_Fear-Prejudice_support': 272.0, 'micro avg_precision': 0.2677595628415301, 'micro avg_recall': 0.1801470588235294, 'micro avg_f1-score': 0.2153846153846154, 'micro avg_support': 272.0, 'macro avg_precision': 0.2677595628415301, 'macro avg_recall': 0.1801470588235294, 'macro avg_f1-score': 0.2153846153846154, 'macro avg_support': 272.0, 'weighted avg_precision': 0.2677595628415301, 'weighted avg_recall': 0.1801470588235294, 'weighted avg_f1-score': 0.2153846153846154, 'weighted avg_support': 272.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 1}, {'micro_f1': 0.8286717246064998, 'Appeal_to_Fear-Prejudice_precision': 0.273224043715847, 'Appeal_to_Fear-Prejudice_recall': 0.20080321285140562, 'Appeal_to_Fear-Prejudice_f1-score': 0.23148148148148148, 'Appeal_to_Fear-Prejudice_support': 249.0, 'micro avg_precision': 0.273224043715847, 'micro avg_recall': 0.20080321285140562, 'micro avg_f1-score': 0.23148148148148148, 'micro avg_support': 249.0, 'macro avg_precision': 0.273224043715847, 'macro avg_recall': 0.20080321285140562, 'macro avg_f1-score': 0.23148148148148148, 'macro avg_support': 249.0, 'weighted avg_precision': 0.273224043715847, 'weighted avg_recall': 0.20080321285140562, 'weighted avg_f1-score': 0.23148148148148148, 'weighted avg_support': 249.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 2}, {'micro_f1': 0.8425999320575246, 'Appeal_to_Fear-Prejudice_precision': 0.30601092896174864, 'Appeal_to_Fear-Prejudice_recall': 0.2196078431372549, 'Appeal_to_Fear-Prejudice_f1-score': 0.2557077625570776, 'Appeal_to_Fear-Prejudice_support': 255.0, 'micro avg_precision': 0.30601092896174864, 'micro avg_recall': 0.2196078431372549, 'micro avg_f1-score': 0.2557077625570776, 'micro avg_support': 255.0, 'macro avg_precision': 0.30601092896174864, 'macro avg_recall': 0.2196078431372549, 'macro avg_f1-score': 0.2557077625570776, 'macro avg_support': 255.0, 'weighted avg_precision': 0.30601092896174864, 'weighted avg_recall': 0.2196078431372549, 'weighted avg_f1-score': 0.2557077625570776, 'weighted avg_support': 255.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 3}, {'micro_f1': 0.822783376741026, 'Appeal_to_Fear-Prejudice_precision': 0.366120218579235, 'Appeal_to_Fear-Prejudice_recall': 0.24814814814814815, 'Appeal_to_Fear-Prejudice_f1-score': 0.2958057395143488, 'Appeal_to_Fear-Prejudice_support': 270.0, 'micro avg_precision': 0.366120218579235, 'micro avg_recall': 0.24814814814814815, 'micro avg_f1-score': 0.2958057395143488, 'micro avg_support': 270.0, 'macro avg_precision': 0.366120218579235, 'macro avg_recall': 0.24814814814814815, 'macro avg_f1-score': 0.2958057395143488, 'macro avg_support': 270.0, 'weighted avg_precision': 0.366120218579235, 'weighted avg_recall': 0.24814814814814815, 'weighted avg_f1-score': 0.2958057395143488, 'weighted avg_support': 270.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 4}, {'micro_f1': 0.8425999320575246, 'Appeal_to_Fear-Prejudice_precision': 0.3224043715846995, 'Appeal_to_Fear-Prejudice_recall': 0.2489451476793249, 'Appeal_to_Fear-Prejudice_f1-score': 0.28095238095238095, 'Appeal_to_Fear-Prejudice_support': 237.0, 'micro avg_precision': 0.3224043715846995, 'micro avg_recall': 0.2489451476793249, 'micro avg_f1-score': 0.28095238095238095, 'micro avg_support': 237.0, 'macro avg_precision': 0.3224043715846995, 'macro avg_recall': 0.2489451476793249, 'macro avg_f1-score': 0.28095238095238095, 'macro avg_support': 237.0, 'weighted avg_precision': 0.3224043715846995, 'weighted avg_recall': 0.2489451476793249, 'weighted avg_f1-score': 0.28095238095238095, 'weighted avg_support': 237.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 5}, {'micro_f1': 0.8365983467330993, 'Appeal_to_Fear-Prejudice_precision': 0.34972677595628415, 'Appeal_to_Fear-Prejudice_recall': 0.26229508196721313, 'Appeal_to_Fear-Prejudice_f1-score': 0.2997658079625293, 'Appeal_to_Fear-Prejudice_support': 244.0, 'micro avg_precision': 0.34972677595628415, 'micro avg_recall': 0.26229508196721313, 'micro avg_f1-score': 0.2997658079625293, 'micro avg_support': 244.0, 'macro avg_precision': 0.34972677595628415, 'macro avg_recall': 0.26229508196721313, 'macro avg_f1-score': 0.2997658079625293, 'macro avg_support': 244.0, 'weighted avg_precision': 0.34972677595628415, 'weighted avg_recall': 0.26229508196721313, 'weighted avg_f1-score': 0.2997658079625293, 'weighted avg_support': 244.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 6}, {'micro_f1': 0.8355792096025365, 'Appeal_to_Fear-Prejudice_precision': 0.366120218579235, 'Appeal_to_Fear-Prejudice_recall': 0.2838983050847458, 'Appeal_to_Fear-Prejudice_f1-score': 0.3198090692124105, 'Appeal_to_Fear-Prejudice_support': 236.0, 'micro avg_precision': 0.366120218579235, 'micro avg_recall': 0.2838983050847458, 'micro avg_f1-score': 0.3198090692124105, 'micro avg_support': 236.0, 'macro avg_precision': 0.366120218579235, 'macro avg_recall': 0.2838983050847458, 'macro avg_f1-score': 0.3198090692124105, 'macro avg_support': 236.0, 'weighted avg_precision': 0.366120218579235, 'weighted avg_recall': 0.2838983050847458, 'weighted avg_f1-score': 0.3198090692124105, 'weighted avg_support': 236.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 7}]}
Best model updated: current epoch macro f1 = 0.3198090692124105
{'micro_f1': 0.8548295776242781, 'Appeal_to_Fear-Prejudice_precision': 0.37158469945355194, 'Appeal_to_Fear-Prejudice_recall': 0.29694323144104806, 'Appeal_to_Fear-Prejudice_f1-score': 0.33009708737864085, 'Appeal_to_Fear-Prejudice_support': 229.0, 'micro avg_precision': 0.37158469945355194, 'micro avg_recall': 0.29694323144104806, 'micro avg_f1-score': 0.33009708737864085, 'micro avg_support': 229.0, 'macro avg_precision': 0.37158469945355194, 'macro avg_recall': 0.29694323144104806, 'macro avg_f1-score': 0.33009708737864085, 'macro avg_support': 229.0, 'weighted avg_precision': 0.37158469945355194, 'weighted avg_recall': 0.29694323144104806, 'weighted avg_f1-score': 0.33009708737864085, 'weighted avg_support': 229.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 8}
{'results': [{'micro_f1': 0.7984373230664704, 'Appeal_to_Fear-Prejudice_precision': 0.12568306010928962, 'Appeal_to_Fear-Prejudice_recall': 0.0756578947368421, 'Appeal_to_Fear-Prejudice_f1-score': 0.0944558521560575, 'Appeal_to_Fear-Prejudice_support': 304.0, 'micro avg_precision': 0.12568306010928962, 'micro avg_recall': 0.0756578947368421, 'micro avg_f1-score': 0.0944558521560575, 'micro avg_support': 304.0, 'macro avg_precision': 0.12568306010928962, 'macro avg_recall': 0.0756578947368421, 'macro avg_f1-score': 0.0944558521560575, 'macro avg_support': 304.0, 'weighted avg_precision': 0.12568306010928962, 'weighted avg_recall': 0.0756578947368421, 'weighted avg_f1-score': 0.0944558521560575, 'weighted avg_support': 304.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 0}, {'micro_f1': 0.8399954705016419, 'Appeal_to_Fear-Prejudice_precision': 0.2677595628415301, 'Appeal_to_Fear-Prejudice_recall': 0.1801470588235294, 'Appeal_to_Fear-Prejudice_f1-score': 0.2153846153846154, 'Appeal_to_Fear-Prejudice_support': 272.0, 'micro avg_precision': 0.2677595628415301, 'micro avg_recall': 0.1801470588235294, 'micro avg_f1-score': 0.2153846153846154, 'micro avg_support': 272.0, 'macro avg_precision': 0.2677595628415301, 'macro avg_recall': 0.1801470588235294, 'macro avg_f1-score': 0.2153846153846154, 'macro avg_support': 272.0, 'weighted avg_precision': 0.2677595628415301, 'weighted avg_recall': 0.1801470588235294, 'weighted avg_f1-score': 0.2153846153846154, 'weighted avg_support': 272.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 1}, {'micro_f1': 0.8286717246064998, 'Appeal_to_Fear-Prejudice_precision': 0.273224043715847, 'Appeal_to_Fear-Prejudice_recall': 0.20080321285140562, 'Appeal_to_Fear-Prejudice_f1-score': 0.23148148148148148, 'Appeal_to_Fear-Prejudice_support': 249.0, 'micro avg_precision': 0.273224043715847, 'micro avg_recall': 0.20080321285140562, 'micro avg_f1-score': 0.23148148148148148, 'micro avg_support': 249.0, 'macro avg_precision': 0.273224043715847, 'macro avg_recall': 0.20080321285140562, 'macro avg_f1-score': 0.23148148148148148, 'macro avg_support': 249.0, 'weighted avg_precision': 0.273224043715847, 'weighted avg_recall': 0.20080321285140562, 'weighted avg_f1-score': 0.23148148148148148, 'weighted avg_support': 249.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 2}, {'micro_f1': 0.8425999320575246, 'Appeal_to_Fear-Prejudice_precision': 0.30601092896174864, 'Appeal_to_Fear-Prejudice_recall': 0.2196078431372549, 'Appeal_to_Fear-Prejudice_f1-score': 0.2557077625570776, 'Appeal_to_Fear-Prejudice_support': 255.0, 'micro avg_precision': 0.30601092896174864, 'micro avg_recall': 0.2196078431372549, 'micro avg_f1-score': 0.2557077625570776, 'micro avg_support': 255.0, 'macro avg_precision': 0.30601092896174864, 'macro avg_recall': 0.2196078431372549, 'macro avg_f1-score': 0.2557077625570776, 'macro avg_support': 255.0, 'weighted avg_precision': 0.30601092896174864, 'weighted avg_recall': 0.2196078431372549, 'weighted avg_f1-score': 0.2557077625570776, 'weighted avg_support': 255.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 3}, {'micro_f1': 0.822783376741026, 'Appeal_to_Fear-Prejudice_precision': 0.366120218579235, 'Appeal_to_Fear-Prejudice_recall': 0.24814814814814815, 'Appeal_to_Fear-Prejudice_f1-score': 0.2958057395143488, 'Appeal_to_Fear-Prejudice_support': 270.0, 'micro avg_precision': 0.366120218579235, 'micro avg_recall': 0.24814814814814815, 'micro avg_f1-score': 0.2958057395143488, 'micro avg_support': 270.0, 'macro avg_precision': 0.366120218579235, 'macro avg_recall': 0.24814814814814815, 'macro avg_f1-score': 0.2958057395143488, 'macro avg_support': 270.0, 'weighted avg_precision': 0.366120218579235, 'weighted avg_recall': 0.24814814814814815, 'weighted avg_f1-score': 0.2958057395143488, 'weighted avg_support': 270.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 4}, {'micro_f1': 0.8425999320575246, 'Appeal_to_Fear-Prejudice_precision': 0.3224043715846995, 'Appeal_to_Fear-Prejudice_recall': 0.2489451476793249, 'Appeal_to_Fear-Prejudice_f1-score': 0.28095238095238095, 'Appeal_to_Fear-Prejudice_support': 237.0, 'micro avg_precision': 0.3224043715846995, 'micro avg_recall': 0.2489451476793249, 'micro avg_f1-score': 0.28095238095238095, 'micro avg_support': 237.0, 'macro avg_precision': 0.3224043715846995, 'macro avg_recall': 0.2489451476793249, 'macro avg_f1-score': 0.28095238095238095, 'macro avg_support': 237.0, 'weighted avg_precision': 0.3224043715846995, 'weighted avg_recall': 0.2489451476793249, 'weighted avg_f1-score': 0.28095238095238095, 'weighted avg_support': 237.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 5}, {'micro_f1': 0.8365983467330993, 'Appeal_to_Fear-Prejudice_precision': 0.34972677595628415, 'Appeal_to_Fear-Prejudice_recall': 0.26229508196721313, 'Appeal_to_Fear-Prejudice_f1-score': 0.2997658079625293, 'Appeal_to_Fear-Prejudice_support': 244.0, 'micro avg_precision': 0.34972677595628415, 'micro avg_recall': 0.26229508196721313, 'micro avg_f1-score': 0.2997658079625293, 'micro avg_support': 244.0, 'macro avg_precision': 0.34972677595628415, 'macro avg_recall': 0.26229508196721313, 'macro avg_f1-score': 0.2997658079625293, 'macro avg_support': 244.0, 'weighted avg_precision': 0.34972677595628415, 'weighted avg_recall': 0.26229508196721313, 'weighted avg_f1-score': 0.2997658079625293, 'weighted avg_support': 244.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 6}, {'micro_f1': 0.8355792096025365, 'Appeal_to_Fear-Prejudice_precision': 0.366120218579235, 'Appeal_to_Fear-Prejudice_recall': 0.2838983050847458, 'Appeal_to_Fear-Prejudice_f1-score': 0.3198090692124105, 'Appeal_to_Fear-Prejudice_support': 236.0, 'micro avg_precision': 0.366120218579235, 'micro avg_recall': 0.2838983050847458, 'micro avg_f1-score': 0.3198090692124105, 'micro avg_support': 236.0, 'macro avg_precision': 0.366120218579235, 'macro avg_recall': 0.2838983050847458, 'macro avg_f1-score': 0.3198090692124105, 'macro avg_support': 236.0, 'weighted avg_precision': 0.366120218579235, 'weighted avg_recall': 0.2838983050847458, 'weighted avg_f1-score': 0.3198090692124105, 'weighted avg_support': 236.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 7}, {'micro_f1': 0.8548295776242781, 'Appeal_to_Fear-Prejudice_precision': 0.37158469945355194, 'Appeal_to_Fear-Prejudice_recall': 0.29694323144104806, 'Appeal_to_Fear-Prejudice_f1-score': 0.33009708737864085, 'Appeal_to_Fear-Prejudice_support': 229.0, 'micro avg_precision': 0.37158469945355194, 'micro avg_recall': 0.29694323144104806, 'micro avg_f1-score': 0.33009708737864085, 'micro avg_support': 229.0, 'macro avg_precision': 0.37158469945355194, 'macro avg_recall': 0.29694323144104806, 'macro avg_f1-score': 0.33009708737864085, 'macro avg_support': 229.0, 'weighted avg_precision': 0.37158469945355194, 'weighted avg_recall': 0.29694323144104806, 'weighted avg_f1-score': 0.33009708737864085, 'weighted avg_support': 229.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 8}]}
Best model updated: current epoch macro f1 = 0.33009708737864085
{'micro_f1': 0.8159891292039406, 'Appeal_to_Fear-Prejudice_precision': 0.3770491803278688, 'Appeal_to_Fear-Prejudice_recall': 0.24555160142348753, 'Appeal_to_Fear-Prejudice_f1-score': 0.2974137931034483, 'Appeal_to_Fear-Prejudice_support': 281.0, 'micro avg_precision': 0.3770491803278688, 'micro avg_recall': 0.24555160142348753, 'micro avg_f1-score': 0.2974137931034483, 'micro avg_support': 281.0, 'macro avg_precision': 0.3770491803278688, 'macro avg_recall': 0.24555160142348753, 'macro avg_f1-score': 0.2974137931034483, 'macro avg_support': 281.0, 'weighted avg_precision': 0.3770491803278688, 'weighted avg_recall': 0.24555160142348753, 'weighted avg_f1-score': 0.2974137931034483, 'weighted avg_support': 281.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 9}
{'results': [{'micro_f1': 0.7984373230664704, 'Appeal_to_Fear-Prejudice_precision': 0.12568306010928962, 'Appeal_to_Fear-Prejudice_recall': 0.0756578947368421, 'Appeal_to_Fear-Prejudice_f1-score': 0.0944558521560575, 'Appeal_to_Fear-Prejudice_support': 304.0, 'micro avg_precision': 0.12568306010928962, 'micro avg_recall': 0.0756578947368421, 'micro avg_f1-score': 0.0944558521560575, 'micro avg_support': 304.0, 'macro avg_precision': 0.12568306010928962, 'macro avg_recall': 0.0756578947368421, 'macro avg_f1-score': 0.0944558521560575, 'macro avg_support': 304.0, 'weighted avg_precision': 0.12568306010928962, 'weighted avg_recall': 0.0756578947368421, 'weighted avg_f1-score': 0.0944558521560575, 'weighted avg_support': 304.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 0}, {'micro_f1': 0.8399954705016419, 'Appeal_to_Fear-Prejudice_precision': 0.2677595628415301, 'Appeal_to_Fear-Prejudice_recall': 0.1801470588235294, 'Appeal_to_Fear-Prejudice_f1-score': 0.2153846153846154, 'Appeal_to_Fear-Prejudice_support': 272.0, 'micro avg_precision': 0.2677595628415301, 'micro avg_recall': 0.1801470588235294, 'micro avg_f1-score': 0.2153846153846154, 'micro avg_support': 272.0, 'macro avg_precision': 0.2677595628415301, 'macro avg_recall': 0.1801470588235294, 'macro avg_f1-score': 0.2153846153846154, 'macro avg_support': 272.0, 'weighted avg_precision': 0.2677595628415301, 'weighted avg_recall': 0.1801470588235294, 'weighted avg_f1-score': 0.2153846153846154, 'weighted avg_support': 272.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 1}, {'micro_f1': 0.8286717246064998, 'Appeal_to_Fear-Prejudice_precision': 0.273224043715847, 'Appeal_to_Fear-Prejudice_recall': 0.20080321285140562, 'Appeal_to_Fear-Prejudice_f1-score': 0.23148148148148148, 'Appeal_to_Fear-Prejudice_support': 249.0, 'micro avg_precision': 0.273224043715847, 'micro avg_recall': 0.20080321285140562, 'micro avg_f1-score': 0.23148148148148148, 'micro avg_support': 249.0, 'macro avg_precision': 0.273224043715847, 'macro avg_recall': 0.20080321285140562, 'macro avg_f1-score': 0.23148148148148148, 'macro avg_support': 249.0, 'weighted avg_precision': 0.273224043715847, 'weighted avg_recall': 0.20080321285140562, 'weighted avg_f1-score': 0.23148148148148148, 'weighted avg_support': 249.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 2}, {'micro_f1': 0.8425999320575246, 'Appeal_to_Fear-Prejudice_precision': 0.30601092896174864, 'Appeal_to_Fear-Prejudice_recall': 0.2196078431372549, 'Appeal_to_Fear-Prejudice_f1-score': 0.2557077625570776, 'Appeal_to_Fear-Prejudice_support': 255.0, 'micro avg_precision': 0.30601092896174864, 'micro avg_recall': 0.2196078431372549, 'micro avg_f1-score': 0.2557077625570776, 'micro avg_support': 255.0, 'macro avg_precision': 0.30601092896174864, 'macro avg_recall': 0.2196078431372549, 'macro avg_f1-score': 0.2557077625570776, 'macro avg_support': 255.0, 'weighted avg_precision': 0.30601092896174864, 'weighted avg_recall': 0.2196078431372549, 'weighted avg_f1-score': 0.2557077625570776, 'weighted avg_support': 255.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 3}, {'micro_f1': 0.822783376741026, 'Appeal_to_Fear-Prejudice_precision': 0.366120218579235, 'Appeal_to_Fear-Prejudice_recall': 0.24814814814814815, 'Appeal_to_Fear-Prejudice_f1-score': 0.2958057395143488, 'Appeal_to_Fear-Prejudice_support': 270.0, 'micro avg_precision': 0.366120218579235, 'micro avg_recall': 0.24814814814814815, 'micro avg_f1-score': 0.2958057395143488, 'micro avg_support': 270.0, 'macro avg_precision': 0.366120218579235, 'macro avg_recall': 0.24814814814814815, 'macro avg_f1-score': 0.2958057395143488, 'macro avg_support': 270.0, 'weighted avg_precision': 0.366120218579235, 'weighted avg_recall': 0.24814814814814815, 'weighted avg_f1-score': 0.2958057395143488, 'weighted avg_support': 270.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 4}, {'micro_f1': 0.8425999320575246, 'Appeal_to_Fear-Prejudice_precision': 0.3224043715846995, 'Appeal_to_Fear-Prejudice_recall': 0.2489451476793249, 'Appeal_to_Fear-Prejudice_f1-score': 0.28095238095238095, 'Appeal_to_Fear-Prejudice_support': 237.0, 'micro avg_precision': 0.3224043715846995, 'micro avg_recall': 0.2489451476793249, 'micro avg_f1-score': 0.28095238095238095, 'micro avg_support': 237.0, 'macro avg_precision': 0.3224043715846995, 'macro avg_recall': 0.2489451476793249, 'macro avg_f1-score': 0.28095238095238095, 'macro avg_support': 237.0, 'weighted avg_precision': 0.3224043715846995, 'weighted avg_recall': 0.2489451476793249, 'weighted avg_f1-score': 0.28095238095238095, 'weighted avg_support': 237.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 5}, {'micro_f1': 0.8365983467330993, 'Appeal_to_Fear-Prejudice_precision': 0.34972677595628415, 'Appeal_to_Fear-Prejudice_recall': 0.26229508196721313, 'Appeal_to_Fear-Prejudice_f1-score': 0.2997658079625293, 'Appeal_to_Fear-Prejudice_support': 244.0, 'micro avg_precision': 0.34972677595628415, 'micro avg_recall': 0.26229508196721313, 'micro avg_f1-score': 0.2997658079625293, 'micro avg_support': 244.0, 'macro avg_precision': 0.34972677595628415, 'macro avg_recall': 0.26229508196721313, 'macro avg_f1-score': 0.2997658079625293, 'macro avg_support': 244.0, 'weighted avg_precision': 0.34972677595628415, 'weighted avg_recall': 0.26229508196721313, 'weighted avg_f1-score': 0.2997658079625293, 'weighted avg_support': 244.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 6}, {'micro_f1': 0.8355792096025365, 'Appeal_to_Fear-Prejudice_precision': 0.366120218579235, 'Appeal_to_Fear-Prejudice_recall': 0.2838983050847458, 'Appeal_to_Fear-Prejudice_f1-score': 0.3198090692124105, 'Appeal_to_Fear-Prejudice_support': 236.0, 'micro avg_precision': 0.366120218579235, 'micro avg_recall': 0.2838983050847458, 'micro avg_f1-score': 0.3198090692124105, 'micro avg_support': 236.0, 'macro avg_precision': 0.366120218579235, 'macro avg_recall': 0.2838983050847458, 'macro avg_f1-score': 0.3198090692124105, 'macro avg_support': 236.0, 'weighted avg_precision': 0.366120218579235, 'weighted avg_recall': 0.2838983050847458, 'weighted avg_f1-score': 0.3198090692124105, 'weighted avg_support': 236.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 7}, {'micro_f1': 0.8548295776242781, 'Appeal_to_Fear-Prejudice_precision': 0.37158469945355194, 'Appeal_to_Fear-Prejudice_recall': 0.29694323144104806, 'Appeal_to_Fear-Prejudice_f1-score': 0.33009708737864085, 'Appeal_to_Fear-Prejudice_support': 229.0, 'micro avg_precision': 0.37158469945355194, 'micro avg_recall': 0.29694323144104806, 'micro avg_f1-score': 0.33009708737864085, 'micro avg_support': 229.0, 'macro avg_precision': 0.37158469945355194, 'macro avg_recall': 0.29694323144104806, 'macro avg_f1-score': 0.33009708737864085, 'macro avg_support': 229.0, 'weighted avg_precision': 0.37158469945355194, 'weighted avg_recall': 0.29694323144104806, 'weighted avg_f1-score': 0.33009708737864085, 'weighted avg_support': 229.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 8}, {'micro_f1': 0.8159891292039406, 'Appeal_to_Fear-Prejudice_precision': 0.3770491803278688, 'Appeal_to_Fear-Prejudice_recall': 0.24555160142348753, 'Appeal_to_Fear-Prejudice_f1-score': 0.2974137931034483, 'Appeal_to_Fear-Prejudice_support': 281.0, 'micro avg_precision': 0.3770491803278688, 'micro avg_recall': 0.24555160142348753, 'micro avg_f1-score': 0.2974137931034483, 'micro avg_support': 281.0, 'macro avg_precision': 0.3770491803278688, 'macro avg_recall': 0.24555160142348753, 'macro avg_f1-score': 0.2974137931034483, 'macro avg_support': 281.0, 'weighted avg_precision': 0.3770491803278688, 'weighted avg_recall': 0.24555160142348753, 'weighted avg_f1-score': 0.2974137931034483, 'weighted avg_support': 281.0, 'B-Appeal_to_Fear-Prejudice_support': 183, 'I-Appeal_to_Fear-Prejudice_support': 2741, 'O_support': 5907, 'epoch': 9}]}
Saving model to directory: ./models/M2/2024-05-12-17-42-10_aug/mdeberta-v3-base_3_ME10_target=Appeal_to_Fear-Prejudice_SUBSAMPLED_2024-05-12-17-42-10
Training model no. 4 of 23 for (4, 'Flag_Waving') persuasion technique...
{'micro_f1': 0.7987452948557089, 'Flag_Waving_precision': 0.10989010989010989, 'Flag_Waving_recall': 0.08547008547008547, 'Flag_Waving_f1-score': 0.09615384615384615, 'Flag_Waving_support': 117.0, 'micro avg_precision': 0.10989010989010989, 'micro avg_recall': 0.08547008547008547, 'micro avg_f1-score': 0.09615384615384615, 'micro avg_support': 117.0, 'macro avg_precision': 0.10989010989010989, 'macro avg_recall': 0.08547008547008547, 'macro avg_f1-score': 0.09615384615384615, 'macro avg_support': 117.0, 'weighted avg_precision': 0.10989010989010989, 'weighted avg_recall': 0.08547008547008547, 'weighted avg_f1-score': 0.09615384615384615, 'weighted avg_support': 117.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 0}
{'results': [{'micro_f1': 0.7987452948557089, 'Flag_Waving_precision': 0.10989010989010989, 'Flag_Waving_recall': 0.08547008547008547, 'Flag_Waving_f1-score': 0.09615384615384615, 'Flag_Waving_support': 117.0, 'micro avg_precision': 0.10989010989010989, 'micro avg_recall': 0.08547008547008547, 'micro avg_f1-score': 0.09615384615384615, 'micro avg_support': 117.0, 'macro avg_precision': 0.10989010989010989, 'macro avg_recall': 0.08547008547008547, 'macro avg_f1-score': 0.09615384615384615, 'macro avg_support': 117.0, 'weighted avg_precision': 0.10989010989010989, 'weighted avg_recall': 0.08547008547008547, 'weighted avg_f1-score': 0.09615384615384615, 'weighted avg_support': 117.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 0}]}
Best model updated: current epoch macro f1 = 0.09615384615384615
{'micro_f1': 0.8371392722710164, 'Flag_Waving_precision': 0.32967032967032966, 'Flag_Waving_recall': 0.24, 'Flag_Waving_f1-score': 0.2777777777777778, 'Flag_Waving_support': 125.0, 'micro avg_precision': 0.32967032967032966, 'micro avg_recall': 0.24, 'micro avg_f1-score': 0.2777777777777778, 'micro avg_support': 125.0, 'macro avg_precision': 0.32967032967032966, 'macro avg_recall': 0.24, 'macro avg_f1-score': 0.2777777777777778, 'macro avg_support': 125.0, 'weighted avg_precision': 0.3296703296703297, 'weighted avg_recall': 0.24, 'weighted avg_f1-score': 0.2777777777777778, 'weighted avg_support': 125.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 1}
{'results': [{'micro_f1': 0.7987452948557089, 'Flag_Waving_precision': 0.10989010989010989, 'Flag_Waving_recall': 0.08547008547008547, 'Flag_Waving_f1-score': 0.09615384615384615, 'Flag_Waving_support': 117.0, 'micro avg_precision': 0.10989010989010989, 'micro avg_recall': 0.08547008547008547, 'micro avg_f1-score': 0.09615384615384615, 'micro avg_support': 117.0, 'macro avg_precision': 0.10989010989010989, 'macro avg_recall': 0.08547008547008547, 'macro avg_f1-score': 0.09615384615384615, 'macro avg_support': 117.0, 'weighted avg_precision': 0.10989010989010989, 'weighted avg_recall': 0.08547008547008547, 'weighted avg_f1-score': 0.09615384615384615, 'weighted avg_support': 117.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 0}, {'micro_f1': 0.8371392722710164, 'Flag_Waving_precision': 0.32967032967032966, 'Flag_Waving_recall': 0.24, 'Flag_Waving_f1-score': 0.2777777777777778, 'Flag_Waving_support': 125.0, 'micro avg_precision': 0.32967032967032966, 'micro avg_recall': 0.24, 'micro avg_f1-score': 0.2777777777777778, 'micro avg_support': 125.0, 'macro avg_precision': 0.32967032967032966, 'macro avg_recall': 0.24, 'macro avg_f1-score': 0.2777777777777778, 'macro avg_support': 125.0, 'weighted avg_precision': 0.3296703296703297, 'weighted avg_recall': 0.24, 'weighted avg_f1-score': 0.2777777777777778, 'weighted avg_support': 125.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 1}]}
Best model updated: current epoch macro f1 = 0.2777777777777778
{'micro_f1': 0.8358845671267252, 'Flag_Waving_precision': 0.38461538461538464, 'Flag_Waving_recall': 0.2517985611510791, 'Flag_Waving_f1-score': 0.30434782608695654, 'Flag_Waving_support': 139.0, 'micro avg_precision': 0.38461538461538464, 'micro avg_recall': 0.2517985611510791, 'micro avg_f1-score': 0.30434782608695654, 'micro avg_support': 139.0, 'macro avg_precision': 0.38461538461538464, 'macro avg_recall': 0.2517985611510791, 'macro avg_f1-score': 0.30434782608695654, 'macro avg_support': 139.0, 'weighted avg_precision': 0.38461538461538464, 'weighted avg_recall': 0.2517985611510791, 'weighted avg_f1-score': 0.30434782608695654, 'weighted avg_support': 139.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 2}
{'results': [{'micro_f1': 0.7987452948557089, 'Flag_Waving_precision': 0.10989010989010989, 'Flag_Waving_recall': 0.08547008547008547, 'Flag_Waving_f1-score': 0.09615384615384615, 'Flag_Waving_support': 117.0, 'micro avg_precision': 0.10989010989010989, 'micro avg_recall': 0.08547008547008547, 'micro avg_f1-score': 0.09615384615384615, 'micro avg_support': 117.0, 'macro avg_precision': 0.10989010989010989, 'macro avg_recall': 0.08547008547008547, 'macro avg_f1-score': 0.09615384615384615, 'macro avg_support': 117.0, 'weighted avg_precision': 0.10989010989010989, 'weighted avg_recall': 0.08547008547008547, 'weighted avg_f1-score': 0.09615384615384615, 'weighted avg_support': 117.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 0}, {'micro_f1': 0.8371392722710164, 'Flag_Waving_precision': 0.32967032967032966, 'Flag_Waving_recall': 0.24, 'Flag_Waving_f1-score': 0.2777777777777778, 'Flag_Waving_support': 125.0, 'micro avg_precision': 0.32967032967032966, 'micro avg_recall': 0.24, 'micro avg_f1-score': 0.2777777777777778, 'micro avg_support': 125.0, 'macro avg_precision': 0.32967032967032966, 'macro avg_recall': 0.24, 'macro avg_f1-score': 0.2777777777777778, 'macro avg_support': 125.0, 'weighted avg_precision': 0.3296703296703297, 'weighted avg_recall': 0.24, 'weighted avg_f1-score': 0.2777777777777778, 'weighted avg_support': 125.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 1}, {'micro_f1': 0.8358845671267252, 'Flag_Waving_precision': 0.38461538461538464, 'Flag_Waving_recall': 0.2517985611510791, 'Flag_Waving_f1-score': 0.30434782608695654, 'Flag_Waving_support': 139.0, 'micro avg_precision': 0.38461538461538464, 'micro avg_recall': 0.2517985611510791, 'micro avg_f1-score': 0.30434782608695654, 'micro avg_support': 139.0, 'macro avg_precision': 0.38461538461538464, 'macro avg_recall': 0.2517985611510791, 'macro avg_f1-score': 0.30434782608695654, 'macro avg_support': 139.0, 'weighted avg_precision': 0.38461538461538464, 'weighted avg_recall': 0.2517985611510791, 'weighted avg_f1-score': 0.30434782608695654, 'weighted avg_support': 139.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 2}]}
Best model updated: current epoch macro f1 = 0.30434782608695654
{'micro_f1': 0.8476787954830615, 'Flag_Waving_precision': 0.4175824175824176, 'Flag_Waving_recall': 0.336283185840708, 'Flag_Waving_f1-score': 0.37254901960784315, 'Flag_Waving_support': 113.0, 'micro avg_precision': 0.4175824175824176, 'micro avg_recall': 0.336283185840708, 'micro avg_f1-score': 0.37254901960784315, 'micro avg_support': 113.0, 'macro avg_precision': 0.4175824175824176, 'macro avg_recall': 0.336283185840708, 'macro avg_f1-score': 0.37254901960784315, 'macro avg_support': 113.0, 'weighted avg_precision': 0.4175824175824176, 'weighted avg_recall': 0.336283185840708, 'weighted avg_f1-score': 0.37254901960784315, 'weighted avg_support': 113.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 3}
{'results': [{'micro_f1': 0.7987452948557089, 'Flag_Waving_precision': 0.10989010989010989, 'Flag_Waving_recall': 0.08547008547008547, 'Flag_Waving_f1-score': 0.09615384615384615, 'Flag_Waving_support': 117.0, 'micro avg_precision': 0.10989010989010989, 'micro avg_recall': 0.08547008547008547, 'micro avg_f1-score': 0.09615384615384615, 'micro avg_support': 117.0, 'macro avg_precision': 0.10989010989010989, 'macro avg_recall': 0.08547008547008547, 'macro avg_f1-score': 0.09615384615384615, 'macro avg_support': 117.0, 'weighted avg_precision': 0.10989010989010989, 'weighted avg_recall': 0.08547008547008547, 'weighted avg_f1-score': 0.09615384615384615, 'weighted avg_support': 117.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 0}, {'micro_f1': 0.8371392722710164, 'Flag_Waving_precision': 0.32967032967032966, 'Flag_Waving_recall': 0.24, 'Flag_Waving_f1-score': 0.2777777777777778, 'Flag_Waving_support': 125.0, 'micro avg_precision': 0.32967032967032966, 'micro avg_recall': 0.24, 'micro avg_f1-score': 0.2777777777777778, 'micro avg_support': 125.0, 'macro avg_precision': 0.32967032967032966, 'macro avg_recall': 0.24, 'macro avg_f1-score': 0.2777777777777778, 'macro avg_support': 125.0, 'weighted avg_precision': 0.3296703296703297, 'weighted avg_recall': 0.24, 'weighted avg_f1-score': 0.2777777777777778, 'weighted avg_support': 125.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 1}, {'micro_f1': 0.8358845671267252, 'Flag_Waving_precision': 0.38461538461538464, 'Flag_Waving_recall': 0.2517985611510791, 'Flag_Waving_f1-score': 0.30434782608695654, 'Flag_Waving_support': 139.0, 'micro avg_precision': 0.38461538461538464, 'micro avg_recall': 0.2517985611510791, 'micro avg_f1-score': 0.30434782608695654, 'micro avg_support': 139.0, 'macro avg_precision': 0.38461538461538464, 'macro avg_recall': 0.2517985611510791, 'macro avg_f1-score': 0.30434782608695654, 'macro avg_support': 139.0, 'weighted avg_precision': 0.38461538461538464, 'weighted avg_recall': 0.2517985611510791, 'weighted avg_f1-score': 0.30434782608695654, 'weighted avg_support': 139.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 2}, {'micro_f1': 0.8476787954830615, 'Flag_Waving_precision': 0.4175824175824176, 'Flag_Waving_recall': 0.336283185840708, 'Flag_Waving_f1-score': 0.37254901960784315, 'Flag_Waving_support': 113.0, 'micro avg_precision': 0.4175824175824176, 'micro avg_recall': 0.336283185840708, 'micro avg_f1-score': 0.37254901960784315, 'micro avg_support': 113.0, 'macro avg_precision': 0.4175824175824176, 'macro avg_recall': 0.336283185840708, 'macro avg_f1-score': 0.37254901960784315, 'macro avg_support': 113.0, 'weighted avg_precision': 0.4175824175824176, 'weighted avg_recall': 0.336283185840708, 'weighted avg_f1-score': 0.37254901960784315, 'weighted avg_support': 113.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 3}]}
Best model updated: current epoch macro f1 = 0.37254901960784315
{'micro_f1': 0.8326223337515684, 'Flag_Waving_precision': 0.4175824175824176, 'Flag_Waving_recall': 0.2857142857142857, 'Flag_Waving_f1-score': 0.3392857142857143, 'Flag_Waving_support': 133.0, 'micro avg_precision': 0.4175824175824176, 'micro avg_recall': 0.2857142857142857, 'micro avg_f1-score': 0.3392857142857143, 'micro avg_support': 133.0, 'macro avg_precision': 0.4175824175824176, 'macro avg_recall': 0.2857142857142857, 'macro avg_f1-score': 0.3392857142857143, 'macro avg_support': 133.0, 'weighted avg_precision': 0.4175824175824176, 'weighted avg_recall': 0.2857142857142857, 'weighted avg_f1-score': 0.3392857142857143, 'weighted avg_support': 133.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 4}
{'results': [{'micro_f1': 0.7987452948557089, 'Flag_Waving_precision': 0.10989010989010989, 'Flag_Waving_recall': 0.08547008547008547, 'Flag_Waving_f1-score': 0.09615384615384615, 'Flag_Waving_support': 117.0, 'micro avg_precision': 0.10989010989010989, 'micro avg_recall': 0.08547008547008547, 'micro avg_f1-score': 0.09615384615384615, 'micro avg_support': 117.0, 'macro avg_precision': 0.10989010989010989, 'macro avg_recall': 0.08547008547008547, 'macro avg_f1-score': 0.09615384615384615, 'macro avg_support': 117.0, 'weighted avg_precision': 0.10989010989010989, 'weighted avg_recall': 0.08547008547008547, 'weighted avg_f1-score': 0.09615384615384615, 'weighted avg_support': 117.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 0}, {'micro_f1': 0.8371392722710164, 'Flag_Waving_precision': 0.32967032967032966, 'Flag_Waving_recall': 0.24, 'Flag_Waving_f1-score': 0.2777777777777778, 'Flag_Waving_support': 125.0, 'micro avg_precision': 0.32967032967032966, 'micro avg_recall': 0.24, 'micro avg_f1-score': 0.2777777777777778, 'micro avg_support': 125.0, 'macro avg_precision': 0.32967032967032966, 'macro avg_recall': 0.24, 'macro avg_f1-score': 0.2777777777777778, 'macro avg_support': 125.0, 'weighted avg_precision': 0.3296703296703297, 'weighted avg_recall': 0.24, 'weighted avg_f1-score': 0.2777777777777778, 'weighted avg_support': 125.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 1}, {'micro_f1': 0.8358845671267252, 'Flag_Waving_precision': 0.38461538461538464, 'Flag_Waving_recall': 0.2517985611510791, 'Flag_Waving_f1-score': 0.30434782608695654, 'Flag_Waving_support': 139.0, 'micro avg_precision': 0.38461538461538464, 'micro avg_recall': 0.2517985611510791, 'micro avg_f1-score': 0.30434782608695654, 'micro avg_support': 139.0, 'macro avg_precision': 0.38461538461538464, 'macro avg_recall': 0.2517985611510791, 'macro avg_f1-score': 0.30434782608695654, 'macro avg_support': 139.0, 'weighted avg_precision': 0.38461538461538464, 'weighted avg_recall': 0.2517985611510791, 'weighted avg_f1-score': 0.30434782608695654, 'weighted avg_support': 139.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 2}, {'micro_f1': 0.8476787954830615, 'Flag_Waving_precision': 0.4175824175824176, 'Flag_Waving_recall': 0.336283185840708, 'Flag_Waving_f1-score': 0.37254901960784315, 'Flag_Waving_support': 113.0, 'micro avg_precision': 0.4175824175824176, 'micro avg_recall': 0.336283185840708, 'micro avg_f1-score': 0.37254901960784315, 'micro avg_support': 113.0, 'macro avg_precision': 0.4175824175824176, 'macro avg_recall': 0.336283185840708, 'macro avg_f1-score': 0.37254901960784315, 'macro avg_support': 113.0, 'weighted avg_precision': 0.4175824175824176, 'weighted avg_recall': 0.336283185840708, 'weighted avg_f1-score': 0.37254901960784315, 'weighted avg_support': 113.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 3}, {'micro_f1': 0.8326223337515684, 'Flag_Waving_precision': 0.4175824175824176, 'Flag_Waving_recall': 0.2857142857142857, 'Flag_Waving_f1-score': 0.3392857142857143, 'Flag_Waving_support': 133.0, 'micro avg_precision': 0.4175824175824176, 'micro avg_recall': 0.2857142857142857, 'micro avg_f1-score': 0.3392857142857143, 'micro avg_support': 133.0, 'macro avg_precision': 0.4175824175824176, 'macro avg_recall': 0.2857142857142857, 'macro avg_f1-score': 0.3392857142857143, 'macro avg_support': 133.0, 'weighted avg_precision': 0.4175824175824176, 'weighted avg_recall': 0.2857142857142857, 'weighted avg_f1-score': 0.3392857142857143, 'weighted avg_support': 133.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 4}]}
{'micro_f1': 0.8449184441656211, 'Flag_Waving_precision': 0.45054945054945056, 'Flag_Waving_recall': 0.3253968253968254, 'Flag_Waving_f1-score': 0.37788018433179726, 'Flag_Waving_support': 126.0, 'micro avg_precision': 0.45054945054945056, 'micro avg_recall': 0.3253968253968254, 'micro avg_f1-score': 0.37788018433179726, 'micro avg_support': 126.0, 'macro avg_precision': 0.45054945054945056, 'macro avg_recall': 0.3253968253968254, 'macro avg_f1-score': 0.37788018433179726, 'macro avg_support': 126.0, 'weighted avg_precision': 0.45054945054945056, 'weighted avg_recall': 0.3253968253968254, 'weighted avg_f1-score': 0.37788018433179726, 'weighted avg_support': 126.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 5}
{'results': [{'micro_f1': 0.7987452948557089, 'Flag_Waving_precision': 0.10989010989010989, 'Flag_Waving_recall': 0.08547008547008547, 'Flag_Waving_f1-score': 0.09615384615384615, 'Flag_Waving_support': 117.0, 'micro avg_precision': 0.10989010989010989, 'micro avg_recall': 0.08547008547008547, 'micro avg_f1-score': 0.09615384615384615, 'micro avg_support': 117.0, 'macro avg_precision': 0.10989010989010989, 'macro avg_recall': 0.08547008547008547, 'macro avg_f1-score': 0.09615384615384615, 'macro avg_support': 117.0, 'weighted avg_precision': 0.10989010989010989, 'weighted avg_recall': 0.08547008547008547, 'weighted avg_f1-score': 0.09615384615384615, 'weighted avg_support': 117.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 0}, {'micro_f1': 0.8371392722710164, 'Flag_Waving_precision': 0.32967032967032966, 'Flag_Waving_recall': 0.24, 'Flag_Waving_f1-score': 0.2777777777777778, 'Flag_Waving_support': 125.0, 'micro avg_precision': 0.32967032967032966, 'micro avg_recall': 0.24, 'micro avg_f1-score': 0.2777777777777778, 'micro avg_support': 125.0, 'macro avg_precision': 0.32967032967032966, 'macro avg_recall': 0.24, 'macro avg_f1-score': 0.2777777777777778, 'macro avg_support': 125.0, 'weighted avg_precision': 0.3296703296703297, 'weighted avg_recall': 0.24, 'weighted avg_f1-score': 0.2777777777777778, 'weighted avg_support': 125.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 1}, {'micro_f1': 0.8358845671267252, 'Flag_Waving_precision': 0.38461538461538464, 'Flag_Waving_recall': 0.2517985611510791, 'Flag_Waving_f1-score': 0.30434782608695654, 'Flag_Waving_support': 139.0, 'micro avg_precision': 0.38461538461538464, 'micro avg_recall': 0.2517985611510791, 'micro avg_f1-score': 0.30434782608695654, 'micro avg_support': 139.0, 'macro avg_precision': 0.38461538461538464, 'macro avg_recall': 0.2517985611510791, 'macro avg_f1-score': 0.30434782608695654, 'macro avg_support': 139.0, 'weighted avg_precision': 0.38461538461538464, 'weighted avg_recall': 0.2517985611510791, 'weighted avg_f1-score': 0.30434782608695654, 'weighted avg_support': 139.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 2}, {'micro_f1': 0.8476787954830615, 'Flag_Waving_precision': 0.4175824175824176, 'Flag_Waving_recall': 0.336283185840708, 'Flag_Waving_f1-score': 0.37254901960784315, 'Flag_Waving_support': 113.0, 'micro avg_precision': 0.4175824175824176, 'micro avg_recall': 0.336283185840708, 'micro avg_f1-score': 0.37254901960784315, 'micro avg_support': 113.0, 'macro avg_precision': 0.4175824175824176, 'macro avg_recall': 0.336283185840708, 'macro avg_f1-score': 0.37254901960784315, 'macro avg_support': 113.0, 'weighted avg_precision': 0.4175824175824176, 'weighted avg_recall': 0.336283185840708, 'weighted avg_f1-score': 0.37254901960784315, 'weighted avg_support': 113.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 3}, {'micro_f1': 0.8326223337515684, 'Flag_Waving_precision': 0.4175824175824176, 'Flag_Waving_recall': 0.2857142857142857, 'Flag_Waving_f1-score': 0.3392857142857143, 'Flag_Waving_support': 133.0, 'micro avg_precision': 0.4175824175824176, 'micro avg_recall': 0.2857142857142857, 'micro avg_f1-score': 0.3392857142857143, 'micro avg_support': 133.0, 'macro avg_precision': 0.4175824175824176, 'macro avg_recall': 0.2857142857142857, 'macro avg_f1-score': 0.3392857142857143, 'macro avg_support': 133.0, 'weighted avg_precision': 0.4175824175824176, 'weighted avg_recall': 0.2857142857142857, 'weighted avg_f1-score': 0.3392857142857143, 'weighted avg_support': 133.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 4}, {'micro_f1': 0.8449184441656211, 'Flag_Waving_precision': 0.45054945054945056, 'Flag_Waving_recall': 0.3253968253968254, 'Flag_Waving_f1-score': 0.37788018433179726, 'Flag_Waving_support': 126.0, 'micro avg_precision': 0.45054945054945056, 'micro avg_recall': 0.3253968253968254, 'micro avg_f1-score': 0.37788018433179726, 'micro avg_support': 126.0, 'macro avg_precision': 0.45054945054945056, 'macro avg_recall': 0.3253968253968254, 'macro avg_f1-score': 0.37788018433179726, 'macro avg_support': 126.0, 'weighted avg_precision': 0.45054945054945056, 'weighted avg_recall': 0.3253968253968254, 'weighted avg_f1-score': 0.37788018433179726, 'weighted avg_support': 126.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 5}]}
Best model updated: current epoch macro f1 = 0.37788018433179726
{'micro_f1': 0.8398996235884567, 'Flag_Waving_precision': 0.4065934065934066, 'Flag_Waving_recall': 0.2890625, 'Flag_Waving_f1-score': 0.3378995433789954, 'Flag_Waving_support': 128.0, 'micro avg_precision': 0.4065934065934066, 'micro avg_recall': 0.2890625, 'micro avg_f1-score': 0.3378995433789954, 'micro avg_support': 128.0, 'macro avg_precision': 0.4065934065934066, 'macro avg_recall': 0.2890625, 'macro avg_f1-score': 0.3378995433789954, 'macro avg_support': 128.0, 'weighted avg_precision': 0.4065934065934066, 'weighted avg_recall': 0.2890625, 'weighted avg_f1-score': 0.3378995433789954, 'weighted avg_support': 128.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 6}
{'results': [{'micro_f1': 0.7987452948557089, 'Flag_Waving_precision': 0.10989010989010989, 'Flag_Waving_recall': 0.08547008547008547, 'Flag_Waving_f1-score': 0.09615384615384615, 'Flag_Waving_support': 117.0, 'micro avg_precision': 0.10989010989010989, 'micro avg_recall': 0.08547008547008547, 'micro avg_f1-score': 0.09615384615384615, 'micro avg_support': 117.0, 'macro avg_precision': 0.10989010989010989, 'macro avg_recall': 0.08547008547008547, 'macro avg_f1-score': 0.09615384615384615, 'macro avg_support': 117.0, 'weighted avg_precision': 0.10989010989010989, 'weighted avg_recall': 0.08547008547008547, 'weighted avg_f1-score': 0.09615384615384615, 'weighted avg_support': 117.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 0}, {'micro_f1': 0.8371392722710164, 'Flag_Waving_precision': 0.32967032967032966, 'Flag_Waving_recall': 0.24, 'Flag_Waving_f1-score': 0.2777777777777778, 'Flag_Waving_support': 125.0, 'micro avg_precision': 0.32967032967032966, 'micro avg_recall': 0.24, 'micro avg_f1-score': 0.2777777777777778, 'micro avg_support': 125.0, 'macro avg_precision': 0.32967032967032966, 'macro avg_recall': 0.24, 'macro avg_f1-score': 0.2777777777777778, 'macro avg_support': 125.0, 'weighted avg_precision': 0.3296703296703297, 'weighted avg_recall': 0.24, 'weighted avg_f1-score': 0.2777777777777778, 'weighted avg_support': 125.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 1}, {'micro_f1': 0.8358845671267252, 'Flag_Waving_precision': 0.38461538461538464, 'Flag_Waving_recall': 0.2517985611510791, 'Flag_Waving_f1-score': 0.30434782608695654, 'Flag_Waving_support': 139.0, 'micro avg_precision': 0.38461538461538464, 'micro avg_recall': 0.2517985611510791, 'micro avg_f1-score': 0.30434782608695654, 'micro avg_support': 139.0, 'macro avg_precision': 0.38461538461538464, 'macro avg_recall': 0.2517985611510791, 'macro avg_f1-score': 0.30434782608695654, 'macro avg_support': 139.0, 'weighted avg_precision': 0.38461538461538464, 'weighted avg_recall': 0.2517985611510791, 'weighted avg_f1-score': 0.30434782608695654, 'weighted avg_support': 139.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 2}, {'micro_f1': 0.8476787954830615, 'Flag_Waving_precision': 0.4175824175824176, 'Flag_Waving_recall': 0.336283185840708, 'Flag_Waving_f1-score': 0.37254901960784315, 'Flag_Waving_support': 113.0, 'micro avg_precision': 0.4175824175824176, 'micro avg_recall': 0.336283185840708, 'micro avg_f1-score': 0.37254901960784315, 'micro avg_support': 113.0, 'macro avg_precision': 0.4175824175824176, 'macro avg_recall': 0.336283185840708, 'macro avg_f1-score': 0.37254901960784315, 'macro avg_support': 113.0, 'weighted avg_precision': 0.4175824175824176, 'weighted avg_recall': 0.336283185840708, 'weighted avg_f1-score': 0.37254901960784315, 'weighted avg_support': 113.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 3}, {'micro_f1': 0.8326223337515684, 'Flag_Waving_precision': 0.4175824175824176, 'Flag_Waving_recall': 0.2857142857142857, 'Flag_Waving_f1-score': 0.3392857142857143, 'Flag_Waving_support': 133.0, 'micro avg_precision': 0.4175824175824176, 'micro avg_recall': 0.2857142857142857, 'micro avg_f1-score': 0.3392857142857143, 'micro avg_support': 133.0, 'macro avg_precision': 0.4175824175824176, 'macro avg_recall': 0.2857142857142857, 'macro avg_f1-score': 0.3392857142857143, 'macro avg_support': 133.0, 'weighted avg_precision': 0.4175824175824176, 'weighted avg_recall': 0.2857142857142857, 'weighted avg_f1-score': 0.3392857142857143, 'weighted avg_support': 133.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 4}, {'micro_f1': 0.8449184441656211, 'Flag_Waving_precision': 0.45054945054945056, 'Flag_Waving_recall': 0.3253968253968254, 'Flag_Waving_f1-score': 0.37788018433179726, 'Flag_Waving_support': 126.0, 'micro avg_precision': 0.45054945054945056, 'micro avg_recall': 0.3253968253968254, 'micro avg_f1-score': 0.37788018433179726, 'micro avg_support': 126.0, 'macro avg_precision': 0.45054945054945056, 'macro avg_recall': 0.3253968253968254, 'macro avg_f1-score': 0.37788018433179726, 'macro avg_support': 126.0, 'weighted avg_precision': 0.45054945054945056, 'weighted avg_recall': 0.3253968253968254, 'weighted avg_f1-score': 0.37788018433179726, 'weighted avg_support': 126.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 5}, {'micro_f1': 0.8398996235884567, 'Flag_Waving_precision': 0.4065934065934066, 'Flag_Waving_recall': 0.2890625, 'Flag_Waving_f1-score': 0.3378995433789954, 'Flag_Waving_support': 128.0, 'micro avg_precision': 0.4065934065934066, 'micro avg_recall': 0.2890625, 'micro avg_f1-score': 0.3378995433789954, 'micro avg_support': 128.0, 'macro avg_precision': 0.4065934065934066, 'macro avg_recall': 0.2890625, 'macro avg_f1-score': 0.3378995433789954, 'macro avg_support': 128.0, 'weighted avg_precision': 0.4065934065934066, 'weighted avg_recall': 0.2890625, 'weighted avg_f1-score': 0.3378995433789954, 'weighted avg_support': 128.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 6}]}
{'micro_f1': 0.8664993726474278, 'Flag_Waving_precision': 0.42857142857142855, 'Flag_Waving_recall': 0.3391304347826087, 'Flag_Waving_f1-score': 0.3786407766990291, 'Flag_Waving_support': 115.0, 'micro avg_precision': 0.42857142857142855, 'micro avg_recall': 0.3391304347826087, 'micro avg_f1-score': 0.3786407766990291, 'micro avg_support': 115.0, 'macro avg_precision': 0.42857142857142855, 'macro avg_recall': 0.3391304347826087, 'macro avg_f1-score': 0.3786407766990291, 'macro avg_support': 115.0, 'weighted avg_precision': 0.42857142857142855, 'weighted avg_recall': 0.3391304347826087, 'weighted avg_f1-score': 0.3786407766990292, 'weighted avg_support': 115.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 7}
{'results': [{'micro_f1': 0.7987452948557089, 'Flag_Waving_precision': 0.10989010989010989, 'Flag_Waving_recall': 0.08547008547008547, 'Flag_Waving_f1-score': 0.09615384615384615, 'Flag_Waving_support': 117.0, 'micro avg_precision': 0.10989010989010989, 'micro avg_recall': 0.08547008547008547, 'micro avg_f1-score': 0.09615384615384615, 'micro avg_support': 117.0, 'macro avg_precision': 0.10989010989010989, 'macro avg_recall': 0.08547008547008547, 'macro avg_f1-score': 0.09615384615384615, 'macro avg_support': 117.0, 'weighted avg_precision': 0.10989010989010989, 'weighted avg_recall': 0.08547008547008547, 'weighted avg_f1-score': 0.09615384615384615, 'weighted avg_support': 117.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 0}, {'micro_f1': 0.8371392722710164, 'Flag_Waving_precision': 0.32967032967032966, 'Flag_Waving_recall': 0.24, 'Flag_Waving_f1-score': 0.2777777777777778, 'Flag_Waving_support': 125.0, 'micro avg_precision': 0.32967032967032966, 'micro avg_recall': 0.24, 'micro avg_f1-score': 0.2777777777777778, 'micro avg_support': 125.0, 'macro avg_precision': 0.32967032967032966, 'macro avg_recall': 0.24, 'macro avg_f1-score': 0.2777777777777778, 'macro avg_support': 125.0, 'weighted avg_precision': 0.3296703296703297, 'weighted avg_recall': 0.24, 'weighted avg_f1-score': 0.2777777777777778, 'weighted avg_support': 125.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 1}, {'micro_f1': 0.8358845671267252, 'Flag_Waving_precision': 0.38461538461538464, 'Flag_Waving_recall': 0.2517985611510791, 'Flag_Waving_f1-score': 0.30434782608695654, 'Flag_Waving_support': 139.0, 'micro avg_precision': 0.38461538461538464, 'micro avg_recall': 0.2517985611510791, 'micro avg_f1-score': 0.30434782608695654, 'micro avg_support': 139.0, 'macro avg_precision': 0.38461538461538464, 'macro avg_recall': 0.2517985611510791, 'macro avg_f1-score': 0.30434782608695654, 'macro avg_support': 139.0, 'weighted avg_precision': 0.38461538461538464, 'weighted avg_recall': 0.2517985611510791, 'weighted avg_f1-score': 0.30434782608695654, 'weighted avg_support': 139.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 2}, {'micro_f1': 0.8476787954830615, 'Flag_Waving_precision': 0.4175824175824176, 'Flag_Waving_recall': 0.336283185840708, 'Flag_Waving_f1-score': 0.37254901960784315, 'Flag_Waving_support': 113.0, 'micro avg_precision': 0.4175824175824176, 'micro avg_recall': 0.336283185840708, 'micro avg_f1-score': 0.37254901960784315, 'micro avg_support': 113.0, 'macro avg_precision': 0.4175824175824176, 'macro avg_recall': 0.336283185840708, 'macro avg_f1-score': 0.37254901960784315, 'macro avg_support': 113.0, 'weighted avg_precision': 0.4175824175824176, 'weighted avg_recall': 0.336283185840708, 'weighted avg_f1-score': 0.37254901960784315, 'weighted avg_support': 113.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 3}, {'micro_f1': 0.8326223337515684, 'Flag_Waving_precision': 0.4175824175824176, 'Flag_Waving_recall': 0.2857142857142857, 'Flag_Waving_f1-score': 0.3392857142857143, 'Flag_Waving_support': 133.0, 'micro avg_precision': 0.4175824175824176, 'micro avg_recall': 0.2857142857142857, 'micro avg_f1-score': 0.3392857142857143, 'micro avg_support': 133.0, 'macro avg_precision': 0.4175824175824176, 'macro avg_recall': 0.2857142857142857, 'macro avg_f1-score': 0.3392857142857143, 'macro avg_support': 133.0, 'weighted avg_precision': 0.4175824175824176, 'weighted avg_recall': 0.2857142857142857, 'weighted avg_f1-score': 0.3392857142857143, 'weighted avg_support': 133.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 4}, {'micro_f1': 0.8449184441656211, 'Flag_Waving_precision': 0.45054945054945056, 'Flag_Waving_recall': 0.3253968253968254, 'Flag_Waving_f1-score': 0.37788018433179726, 'Flag_Waving_support': 126.0, 'micro avg_precision': 0.45054945054945056, 'micro avg_recall': 0.3253968253968254, 'micro avg_f1-score': 0.37788018433179726, 'micro avg_support': 126.0, 'macro avg_precision': 0.45054945054945056, 'macro avg_recall': 0.3253968253968254, 'macro avg_f1-score': 0.37788018433179726, 'macro avg_support': 126.0, 'weighted avg_precision': 0.45054945054945056, 'weighted avg_recall': 0.3253968253968254, 'weighted avg_f1-score': 0.37788018433179726, 'weighted avg_support': 126.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 5}, {'micro_f1': 0.8398996235884567, 'Flag_Waving_precision': 0.4065934065934066, 'Flag_Waving_recall': 0.2890625, 'Flag_Waving_f1-score': 0.3378995433789954, 'Flag_Waving_support': 128.0, 'micro avg_precision': 0.4065934065934066, 'micro avg_recall': 0.2890625, 'micro avg_f1-score': 0.3378995433789954, 'micro avg_support': 128.0, 'macro avg_precision': 0.4065934065934066, 'macro avg_recall': 0.2890625, 'macro avg_f1-score': 0.3378995433789954, 'macro avg_support': 128.0, 'weighted avg_precision': 0.4065934065934066, 'weighted avg_recall': 0.2890625, 'weighted avg_f1-score': 0.3378995433789954, 'weighted avg_support': 128.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 6}, {'micro_f1': 0.8664993726474278, 'Flag_Waving_precision': 0.42857142857142855, 'Flag_Waving_recall': 0.3391304347826087, 'Flag_Waving_f1-score': 0.3786407766990291, 'Flag_Waving_support': 115.0, 'micro avg_precision': 0.42857142857142855, 'micro avg_recall': 0.3391304347826087, 'micro avg_f1-score': 0.3786407766990291, 'micro avg_support': 115.0, 'macro avg_precision': 0.42857142857142855, 'macro avg_recall': 0.3391304347826087, 'macro avg_f1-score': 0.3786407766990291, 'macro avg_support': 115.0, 'weighted avg_precision': 0.42857142857142855, 'weighted avg_recall': 0.3391304347826087, 'weighted avg_f1-score': 0.3786407766990292, 'weighted avg_support': 115.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 7}]}
Best model updated: current epoch macro f1 = 0.3786407766990291
{'micro_f1': 0.8602258469259724, 'Flag_Waving_precision': 0.4065934065934066, 'Flag_Waving_recall': 0.32456140350877194, 'Flag_Waving_f1-score': 0.3609756097560976, 'Flag_Waving_support': 114.0, 'micro avg_precision': 0.4065934065934066, 'micro avg_recall': 0.32456140350877194, 'micro avg_f1-score': 0.3609756097560976, 'micro avg_support': 114.0, 'macro avg_precision': 0.4065934065934066, 'macro avg_recall': 0.32456140350877194, 'macro avg_f1-score': 0.3609756097560976, 'macro avg_support': 114.0, 'weighted avg_precision': 0.4065934065934066, 'weighted avg_recall': 0.32456140350877194, 'weighted avg_f1-score': 0.3609756097560976, 'weighted avg_support': 114.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 8}
{'results': [{'micro_f1': 0.7987452948557089, 'Flag_Waving_precision': 0.10989010989010989, 'Flag_Waving_recall': 0.08547008547008547, 'Flag_Waving_f1-score': 0.09615384615384615, 'Flag_Waving_support': 117.0, 'micro avg_precision': 0.10989010989010989, 'micro avg_recall': 0.08547008547008547, 'micro avg_f1-score': 0.09615384615384615, 'micro avg_support': 117.0, 'macro avg_precision': 0.10989010989010989, 'macro avg_recall': 0.08547008547008547, 'macro avg_f1-score': 0.09615384615384615, 'macro avg_support': 117.0, 'weighted avg_precision': 0.10989010989010989, 'weighted avg_recall': 0.08547008547008547, 'weighted avg_f1-score': 0.09615384615384615, 'weighted avg_support': 117.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 0}, {'micro_f1': 0.8371392722710164, 'Flag_Waving_precision': 0.32967032967032966, 'Flag_Waving_recall': 0.24, 'Flag_Waving_f1-score': 0.2777777777777778, 'Flag_Waving_support': 125.0, 'micro avg_precision': 0.32967032967032966, 'micro avg_recall': 0.24, 'micro avg_f1-score': 0.2777777777777778, 'micro avg_support': 125.0, 'macro avg_precision': 0.32967032967032966, 'macro avg_recall': 0.24, 'macro avg_f1-score': 0.2777777777777778, 'macro avg_support': 125.0, 'weighted avg_precision': 0.3296703296703297, 'weighted avg_recall': 0.24, 'weighted avg_f1-score': 0.2777777777777778, 'weighted avg_support': 125.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 1}, {'micro_f1': 0.8358845671267252, 'Flag_Waving_precision': 0.38461538461538464, 'Flag_Waving_recall': 0.2517985611510791, 'Flag_Waving_f1-score': 0.30434782608695654, 'Flag_Waving_support': 139.0, 'micro avg_precision': 0.38461538461538464, 'micro avg_recall': 0.2517985611510791, 'micro avg_f1-score': 0.30434782608695654, 'micro avg_support': 139.0, 'macro avg_precision': 0.38461538461538464, 'macro avg_recall': 0.2517985611510791, 'macro avg_f1-score': 0.30434782608695654, 'macro avg_support': 139.0, 'weighted avg_precision': 0.38461538461538464, 'weighted avg_recall': 0.2517985611510791, 'weighted avg_f1-score': 0.30434782608695654, 'weighted avg_support': 139.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 2}, {'micro_f1': 0.8476787954830615, 'Flag_Waving_precision': 0.4175824175824176, 'Flag_Waving_recall': 0.336283185840708, 'Flag_Waving_f1-score': 0.37254901960784315, 'Flag_Waving_support': 113.0, 'micro avg_precision': 0.4175824175824176, 'micro avg_recall': 0.336283185840708, 'micro avg_f1-score': 0.37254901960784315, 'micro avg_support': 113.0, 'macro avg_precision': 0.4175824175824176, 'macro avg_recall': 0.336283185840708, 'macro avg_f1-score': 0.37254901960784315, 'macro avg_support': 113.0, 'weighted avg_precision': 0.4175824175824176, 'weighted avg_recall': 0.336283185840708, 'weighted avg_f1-score': 0.37254901960784315, 'weighted avg_support': 113.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 3}, {'micro_f1': 0.8326223337515684, 'Flag_Waving_precision': 0.4175824175824176, 'Flag_Waving_recall': 0.2857142857142857, 'Flag_Waving_f1-score': 0.3392857142857143, 'Flag_Waving_support': 133.0, 'micro avg_precision': 0.4175824175824176, 'micro avg_recall': 0.2857142857142857, 'micro avg_f1-score': 0.3392857142857143, 'micro avg_support': 133.0, 'macro avg_precision': 0.4175824175824176, 'macro avg_recall': 0.2857142857142857, 'macro avg_f1-score': 0.3392857142857143, 'macro avg_support': 133.0, 'weighted avg_precision': 0.4175824175824176, 'weighted avg_recall': 0.2857142857142857, 'weighted avg_f1-score': 0.3392857142857143, 'weighted avg_support': 133.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 4}, {'micro_f1': 0.8449184441656211, 'Flag_Waving_precision': 0.45054945054945056, 'Flag_Waving_recall': 0.3253968253968254, 'Flag_Waving_f1-score': 0.37788018433179726, 'Flag_Waving_support': 126.0, 'micro avg_precision': 0.45054945054945056, 'micro avg_recall': 0.3253968253968254, 'micro avg_f1-score': 0.37788018433179726, 'micro avg_support': 126.0, 'macro avg_precision': 0.45054945054945056, 'macro avg_recall': 0.3253968253968254, 'macro avg_f1-score': 0.37788018433179726, 'macro avg_support': 126.0, 'weighted avg_precision': 0.45054945054945056, 'weighted avg_recall': 0.3253968253968254, 'weighted avg_f1-score': 0.37788018433179726, 'weighted avg_support': 126.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 5}, {'micro_f1': 0.8398996235884567, 'Flag_Waving_precision': 0.4065934065934066, 'Flag_Waving_recall': 0.2890625, 'Flag_Waving_f1-score': 0.3378995433789954, 'Flag_Waving_support': 128.0, 'micro avg_precision': 0.4065934065934066, 'micro avg_recall': 0.2890625, 'micro avg_f1-score': 0.3378995433789954, 'micro avg_support': 128.0, 'macro avg_precision': 0.4065934065934066, 'macro avg_recall': 0.2890625, 'macro avg_f1-score': 0.3378995433789954, 'macro avg_support': 128.0, 'weighted avg_precision': 0.4065934065934066, 'weighted avg_recall': 0.2890625, 'weighted avg_f1-score': 0.3378995433789954, 'weighted avg_support': 128.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 6}, {'micro_f1': 0.8664993726474278, 'Flag_Waving_precision': 0.42857142857142855, 'Flag_Waving_recall': 0.3391304347826087, 'Flag_Waving_f1-score': 0.3786407766990291, 'Flag_Waving_support': 115.0, 'micro avg_precision': 0.42857142857142855, 'micro avg_recall': 0.3391304347826087, 'micro avg_f1-score': 0.3786407766990291, 'micro avg_support': 115.0, 'macro avg_precision': 0.42857142857142855, 'macro avg_recall': 0.3391304347826087, 'macro avg_f1-score': 0.3786407766990291, 'macro avg_support': 115.0, 'weighted avg_precision': 0.42857142857142855, 'weighted avg_recall': 0.3391304347826087, 'weighted avg_f1-score': 0.3786407766990292, 'weighted avg_support': 115.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 7}, {'micro_f1': 0.8602258469259724, 'Flag_Waving_precision': 0.4065934065934066, 'Flag_Waving_recall': 0.32456140350877194, 'Flag_Waving_f1-score': 0.3609756097560976, 'Flag_Waving_support': 114.0, 'micro avg_precision': 0.4065934065934066, 'micro avg_recall': 0.32456140350877194, 'micro avg_f1-score': 0.3609756097560976, 'micro avg_support': 114.0, 'macro avg_precision': 0.4065934065934066, 'macro avg_recall': 0.32456140350877194, 'macro avg_f1-score': 0.3609756097560976, 'macro avg_support': 114.0, 'weighted avg_precision': 0.4065934065934066, 'weighted avg_recall': 0.32456140350877194, 'weighted avg_f1-score': 0.3609756097560976, 'weighted avg_support': 114.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 8}]}
{'micro_f1': 0.8378920953575909, 'Flag_Waving_precision': 0.45054945054945056, 'Flag_Waving_recall': 0.3474576271186441, 'Flag_Waving_f1-score': 0.39234449760765555, 'Flag_Waving_support': 118.0, 'micro avg_precision': 0.45054945054945056, 'micro avg_recall': 0.3474576271186441, 'micro avg_f1-score': 0.39234449760765555, 'micro avg_support': 118.0, 'macro avg_precision': 0.45054945054945056, 'macro avg_recall': 0.3474576271186441, 'macro avg_f1-score': 0.39234449760765555, 'macro avg_support': 118.0, 'weighted avg_precision': 0.45054945054945056, 'weighted avg_recall': 0.3474576271186441, 'weighted avg_f1-score': 0.39234449760765555, 'weighted avg_support': 118.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 9}
{'results': [{'micro_f1': 0.7987452948557089, 'Flag_Waving_precision': 0.10989010989010989, 'Flag_Waving_recall': 0.08547008547008547, 'Flag_Waving_f1-score': 0.09615384615384615, 'Flag_Waving_support': 117.0, 'micro avg_precision': 0.10989010989010989, 'micro avg_recall': 0.08547008547008547, 'micro avg_f1-score': 0.09615384615384615, 'micro avg_support': 117.0, 'macro avg_precision': 0.10989010989010989, 'macro avg_recall': 0.08547008547008547, 'macro avg_f1-score': 0.09615384615384615, 'macro avg_support': 117.0, 'weighted avg_precision': 0.10989010989010989, 'weighted avg_recall': 0.08547008547008547, 'weighted avg_f1-score': 0.09615384615384615, 'weighted avg_support': 117.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 0}, {'micro_f1': 0.8371392722710164, 'Flag_Waving_precision': 0.32967032967032966, 'Flag_Waving_recall': 0.24, 'Flag_Waving_f1-score': 0.2777777777777778, 'Flag_Waving_support': 125.0, 'micro avg_precision': 0.32967032967032966, 'micro avg_recall': 0.24, 'micro avg_f1-score': 0.2777777777777778, 'micro avg_support': 125.0, 'macro avg_precision': 0.32967032967032966, 'macro avg_recall': 0.24, 'macro avg_f1-score': 0.2777777777777778, 'macro avg_support': 125.0, 'weighted avg_precision': 0.3296703296703297, 'weighted avg_recall': 0.24, 'weighted avg_f1-score': 0.2777777777777778, 'weighted avg_support': 125.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 1}, {'micro_f1': 0.8358845671267252, 'Flag_Waving_precision': 0.38461538461538464, 'Flag_Waving_recall': 0.2517985611510791, 'Flag_Waving_f1-score': 0.30434782608695654, 'Flag_Waving_support': 139.0, 'micro avg_precision': 0.38461538461538464, 'micro avg_recall': 0.2517985611510791, 'micro avg_f1-score': 0.30434782608695654, 'micro avg_support': 139.0, 'macro avg_precision': 0.38461538461538464, 'macro avg_recall': 0.2517985611510791, 'macro avg_f1-score': 0.30434782608695654, 'macro avg_support': 139.0, 'weighted avg_precision': 0.38461538461538464, 'weighted avg_recall': 0.2517985611510791, 'weighted avg_f1-score': 0.30434782608695654, 'weighted avg_support': 139.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 2}, {'micro_f1': 0.8476787954830615, 'Flag_Waving_precision': 0.4175824175824176, 'Flag_Waving_recall': 0.336283185840708, 'Flag_Waving_f1-score': 0.37254901960784315, 'Flag_Waving_support': 113.0, 'micro avg_precision': 0.4175824175824176, 'micro avg_recall': 0.336283185840708, 'micro avg_f1-score': 0.37254901960784315, 'micro avg_support': 113.0, 'macro avg_precision': 0.4175824175824176, 'macro avg_recall': 0.336283185840708, 'macro avg_f1-score': 0.37254901960784315, 'macro avg_support': 113.0, 'weighted avg_precision': 0.4175824175824176, 'weighted avg_recall': 0.336283185840708, 'weighted avg_f1-score': 0.37254901960784315, 'weighted avg_support': 113.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 3}, {'micro_f1': 0.8326223337515684, 'Flag_Waving_precision': 0.4175824175824176, 'Flag_Waving_recall': 0.2857142857142857, 'Flag_Waving_f1-score': 0.3392857142857143, 'Flag_Waving_support': 133.0, 'micro avg_precision': 0.4175824175824176, 'micro avg_recall': 0.2857142857142857, 'micro avg_f1-score': 0.3392857142857143, 'micro avg_support': 133.0, 'macro avg_precision': 0.4175824175824176, 'macro avg_recall': 0.2857142857142857, 'macro avg_f1-score': 0.3392857142857143, 'macro avg_support': 133.0, 'weighted avg_precision': 0.4175824175824176, 'weighted avg_recall': 0.2857142857142857, 'weighted avg_f1-score': 0.3392857142857143, 'weighted avg_support': 133.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 4}, {'micro_f1': 0.8449184441656211, 'Flag_Waving_precision': 0.45054945054945056, 'Flag_Waving_recall': 0.3253968253968254, 'Flag_Waving_f1-score': 0.37788018433179726, 'Flag_Waving_support': 126.0, 'micro avg_precision': 0.45054945054945056, 'micro avg_recall': 0.3253968253968254, 'micro avg_f1-score': 0.37788018433179726, 'micro avg_support': 126.0, 'macro avg_precision': 0.45054945054945056, 'macro avg_recall': 0.3253968253968254, 'macro avg_f1-score': 0.37788018433179726, 'macro avg_support': 126.0, 'weighted avg_precision': 0.45054945054945056, 'weighted avg_recall': 0.3253968253968254, 'weighted avg_f1-score': 0.37788018433179726, 'weighted avg_support': 126.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 5}, {'micro_f1': 0.8398996235884567, 'Flag_Waving_precision': 0.4065934065934066, 'Flag_Waving_recall': 0.2890625, 'Flag_Waving_f1-score': 0.3378995433789954, 'Flag_Waving_support': 128.0, 'micro avg_precision': 0.4065934065934066, 'micro avg_recall': 0.2890625, 'micro avg_f1-score': 0.3378995433789954, 'micro avg_support': 128.0, 'macro avg_precision': 0.4065934065934066, 'macro avg_recall': 0.2890625, 'macro avg_f1-score': 0.3378995433789954, 'macro avg_support': 128.0, 'weighted avg_precision': 0.4065934065934066, 'weighted avg_recall': 0.2890625, 'weighted avg_f1-score': 0.3378995433789954, 'weighted avg_support': 128.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 6}, {'micro_f1': 0.8664993726474278, 'Flag_Waving_precision': 0.42857142857142855, 'Flag_Waving_recall': 0.3391304347826087, 'Flag_Waving_f1-score': 0.3786407766990291, 'Flag_Waving_support': 115.0, 'micro avg_precision': 0.42857142857142855, 'micro avg_recall': 0.3391304347826087, 'micro avg_f1-score': 0.3786407766990291, 'micro avg_support': 115.0, 'macro avg_precision': 0.42857142857142855, 'macro avg_recall': 0.3391304347826087, 'macro avg_f1-score': 0.3786407766990291, 'macro avg_support': 115.0, 'weighted avg_precision': 0.42857142857142855, 'weighted avg_recall': 0.3391304347826087, 'weighted avg_f1-score': 0.3786407766990292, 'weighted avg_support': 115.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 7}, {'micro_f1': 0.8602258469259724, 'Flag_Waving_precision': 0.4065934065934066, 'Flag_Waving_recall': 0.32456140350877194, 'Flag_Waving_f1-score': 0.3609756097560976, 'Flag_Waving_support': 114.0, 'micro avg_precision': 0.4065934065934066, 'micro avg_recall': 0.32456140350877194, 'micro avg_f1-score': 0.3609756097560976, 'micro avg_support': 114.0, 'macro avg_precision': 0.4065934065934066, 'macro avg_recall': 0.32456140350877194, 'macro avg_f1-score': 0.3609756097560976, 'macro avg_support': 114.0, 'weighted avg_precision': 0.4065934065934066, 'weighted avg_recall': 0.32456140350877194, 'weighted avg_f1-score': 0.3609756097560976, 'weighted avg_support': 114.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 8}, {'micro_f1': 0.8378920953575909, 'Flag_Waving_precision': 0.45054945054945056, 'Flag_Waving_recall': 0.3474576271186441, 'Flag_Waving_f1-score': 0.39234449760765555, 'Flag_Waving_support': 118.0, 'micro avg_precision': 0.45054945054945056, 'micro avg_recall': 0.3474576271186441, 'micro avg_f1-score': 0.39234449760765555, 'micro avg_support': 118.0, 'macro avg_precision': 0.45054945054945056, 'macro avg_recall': 0.3474576271186441, 'macro avg_f1-score': 0.39234449760765555, 'macro avg_support': 118.0, 'weighted avg_precision': 0.45054945054945056, 'weighted avg_recall': 0.3474576271186441, 'weighted avg_f1-score': 0.39234449760765555, 'weighted avg_support': 118.0, 'B-Flag_Waving_support': 91, 'I-Flag_Waving_support': 1049, 'O_support': 2845, 'epoch': 9}]}
Best model updated: current epoch macro f1 = 0.39234449760765555
Saving model to directory: ./models/M2/2024-05-12-17-42-10_aug/mdeberta-v3-base_4_ME10_target=Flag_Waving_SUBSAMPLED_2024-05-12-17-42-10
Training model no. 5 of 23 for (5, 'Causal_Oversimplification') persuasion technique...
{'micro_f1': 0.7687991021324355, 'Causal_Oversimplification_precision': 0.3181818181818182, 'Causal_Oversimplification_recall': 0.17721518987341772, 'Causal_Oversimplification_f1-score': 0.22764227642276422, 'Causal_Oversimplification_support': 158.0, 'micro avg_precision': 0.3181818181818182, 'micro avg_recall': 0.17721518987341772, 'micro avg_f1-score': 0.22764227642276422, 'micro avg_support': 158.0, 'macro avg_precision': 0.3181818181818182, 'macro avg_recall': 0.17721518987341772, 'macro avg_f1-score': 0.22764227642276422, 'macro avg_support': 158.0, 'weighted avg_precision': 0.3181818181818182, 'weighted avg_recall': 0.17721518987341772, 'weighted avg_f1-score': 0.22764227642276424, 'weighted avg_support': 158.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1590, 'epoch': 0}
{'results': [{'micro_f1': 0.7687991021324355, 'Causal_Oversimplification_precision': 0.3181818181818182, 'Causal_Oversimplification_recall': 0.17721518987341772, 'Causal_Oversimplification_f1-score': 0.22764227642276422, 'Causal_Oversimplification_support': 158.0, 'micro avg_precision': 0.3181818181818182, 'micro avg_recall': 0.17721518987341772, 'micro avg_f1-score': 0.22764227642276422, 'micro avg_support': 158.0, 'macro avg_precision': 0.3181818181818182, 'macro avg_recall': 0.17721518987341772, 'macro avg_f1-score': 0.22764227642276422, 'macro avg_support': 158.0, 'weighted avg_precision': 0.3181818181818182, 'weighted avg_recall': 0.17721518987341772, 'weighted avg_f1-score': 0.22764227642276424, 'weighted avg_support': 158.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1590, 'epoch': 0}]}
Best model updated: current epoch macro f1 = 0.22764227642276422
{'micro_f1': 0.8237934904601572, 'Causal_Oversimplification_precision': 0.42045454545454547, 'Causal_Oversimplification_recall': 0.22560975609756098, 'Causal_Oversimplification_f1-score': 0.29365079365079366, 'Causal_Oversimplification_support': 164.0, 'micro avg_precision': 0.42045454545454547, 'micro avg_recall': 0.22560975609756098, 'micro avg_f1-score': 0.29365079365079366, 'micro avg_support': 164.0, 'macro avg_precision': 0.42045454545454547, 'macro avg_recall': 0.22560975609756098, 'macro avg_f1-score': 0.29365079365079366, 'macro avg_support': 164.0, 'weighted avg_precision': 0.42045454545454547, 'weighted avg_recall': 0.22560975609756098, 'weighted avg_f1-score': 0.29365079365079366, 'weighted avg_support': 164.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1590, 'epoch': 1}
{'results': [{'micro_f1': 0.7687991021324355, 'Causal_Oversimplification_precision': 0.3181818181818182, 'Causal_Oversimplification_recall': 0.17721518987341772, 'Causal_Oversimplification_f1-score': 0.22764227642276422, 'Causal_Oversimplification_support': 158.0, 'micro avg_precision': 0.3181818181818182, 'micro avg_recall': 0.17721518987341772, 'micro avg_f1-score': 0.22764227642276422, 'micro avg_support': 158.0, 'macro avg_precision': 0.3181818181818182, 'macro avg_recall': 0.17721518987341772, 'macro avg_f1-score': 0.22764227642276422, 'macro avg_support': 158.0, 'weighted avg_precision': 0.3181818181818182, 'weighted avg_recall': 0.17721518987341772, 'weighted avg_f1-score': 0.22764227642276424, 'weighted avg_support': 158.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1590, 'epoch': 0}, {'micro_f1': 0.8237934904601572, 'Causal_Oversimplification_precision': 0.42045454545454547, 'Causal_Oversimplification_recall': 0.22560975609756098, 'Causal_Oversimplification_f1-score': 0.29365079365079366, 'Causal_Oversimplification_support': 164.0, 'micro avg_precision': 0.42045454545454547, 'micro avg_recall': 0.22560975609756098, 'micro avg_f1-score': 0.29365079365079366, 'micro avg_support': 164.0, 'macro avg_precision': 0.42045454545454547, 'macro avg_recall': 0.22560975609756098, 'macro avg_f1-score': 0.29365079365079366, 'macro avg_support': 164.0, 'weighted avg_precision': 0.42045454545454547, 'weighted avg_recall': 0.22560975609756098, 'weighted avg_f1-score': 0.29365079365079366, 'weighted avg_support': 164.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1590, 'epoch': 1}]}
Best model updated: current epoch macro f1 = 0.29365079365079366
{'micro_f1': 0.7943322109988776, 'Causal_Oversimplification_precision': 0.3181818181818182, 'Causal_Oversimplification_recall': 0.27450980392156865, 'Causal_Oversimplification_f1-score': 0.2947368421052632, 'Causal_Oversimplification_support': 102.0, 'micro avg_precision': 0.3181818181818182, 'micro avg_recall': 0.27450980392156865, 'micro avg_f1-score': 0.2947368421052632, 'micro avg_support': 102.0, 'macro avg_precision': 0.3181818181818182, 'macro avg_recall': 0.27450980392156865, 'macro avg_f1-score': 0.2947368421052632, 'macro avg_support': 102.0, 'weighted avg_precision': 0.3181818181818182, 'weighted avg_recall': 0.27450980392156865, 'weighted avg_f1-score': 0.2947368421052632, 'weighted avg_support': 102.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1590, 'epoch': 2}
{'results': [{'micro_f1': 0.7687991021324355, 'Causal_Oversimplification_precision': 0.3181818181818182, 'Causal_Oversimplification_recall': 0.17721518987341772, 'Causal_Oversimplification_f1-score': 0.22764227642276422, 'Causal_Oversimplification_support': 158.0, 'micro avg_precision': 0.3181818181818182, 'micro avg_recall': 0.17721518987341772, 'micro avg_f1-score': 0.22764227642276422, 'micro avg_support': 158.0, 'macro avg_precision': 0.3181818181818182, 'macro avg_recall': 0.17721518987341772, 'macro avg_f1-score': 0.22764227642276422, 'macro avg_support': 158.0, 'weighted avg_precision': 0.3181818181818182, 'weighted avg_recall': 0.17721518987341772, 'weighted avg_f1-score': 0.22764227642276424, 'weighted avg_support': 158.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1590, 'epoch': 0}, {'micro_f1': 0.8237934904601572, 'Causal_Oversimplification_precision': 0.42045454545454547, 'Causal_Oversimplification_recall': 0.22560975609756098, 'Causal_Oversimplification_f1-score': 0.29365079365079366, 'Causal_Oversimplification_support': 164.0, 'micro avg_precision': 0.42045454545454547, 'micro avg_recall': 0.22560975609756098, 'micro avg_f1-score': 0.29365079365079366, 'micro avg_support': 164.0, 'macro avg_precision': 0.42045454545454547, 'macro avg_recall': 0.22560975609756098, 'macro avg_f1-score': 0.29365079365079366, 'macro avg_support': 164.0, 'weighted avg_precision': 0.42045454545454547, 'weighted avg_recall': 0.22560975609756098, 'weighted avg_f1-score': 0.29365079365079366, 'weighted avg_support': 164.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1590, 'epoch': 1}, {'micro_f1': 0.7943322109988776, 'Causal_Oversimplification_precision': 0.3181818181818182, 'Causal_Oversimplification_recall': 0.27450980392156865, 'Causal_Oversimplification_f1-score': 0.2947368421052632, 'Causal_Oversimplification_support': 102.0, 'micro avg_precision': 0.3181818181818182, 'micro avg_recall': 0.27450980392156865, 'micro avg_f1-score': 0.2947368421052632, 'micro avg_support': 102.0, 'macro avg_precision': 0.3181818181818182, 'macro avg_recall': 0.27450980392156865, 'macro avg_f1-score': 0.2947368421052632, 'macro avg_support': 102.0, 'weighted avg_precision': 0.3181818181818182, 'weighted avg_recall': 0.27450980392156865, 'weighted avg_f1-score': 0.2947368421052632, 'weighted avg_support': 102.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1590, 'epoch': 2}]}
Best model updated: current epoch macro f1 = 0.2947368421052632
{'micro_f1': 0.8414702581369247, 'Causal_Oversimplification_precision': 0.4659090909090909, 'Causal_Oversimplification_recall': 0.2887323943661972, 'Causal_Oversimplification_f1-score': 0.3565217391304348, 'Causal_Oversimplification_support': 142.0, 'micro avg_precision': 0.4659090909090909, 'micro avg_recall': 0.2887323943661972, 'micro avg_f1-score': 0.3565217391304348, 'micro avg_support': 142.0, 'macro avg_precision': 0.4659090909090909, 'macro avg_recall': 0.2887323943661972, 'macro avg_f1-score': 0.3565217391304348, 'macro avg_support': 142.0, 'weighted avg_precision': 0.4659090909090909, 'weighted avg_recall': 0.2887323943661972, 'weighted avg_f1-score': 0.3565217391304348, 'weighted avg_support': 142.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1590, 'epoch': 3}
{'results': [{'micro_f1': 0.7687991021324355, 'Causal_Oversimplification_precision': 0.3181818181818182, 'Causal_Oversimplification_recall': 0.17721518987341772, 'Causal_Oversimplification_f1-score': 0.22764227642276422, 'Causal_Oversimplification_support': 158.0, 'micro avg_precision': 0.3181818181818182, 'micro avg_recall': 0.17721518987341772, 'micro avg_f1-score': 0.22764227642276422, 'micro avg_support': 158.0, 'macro avg_precision': 0.3181818181818182, 'macro avg_recall': 0.17721518987341772, 'macro avg_f1-score': 0.22764227642276422, 'macro avg_support': 158.0, 'weighted avg_precision': 0.3181818181818182, 'weighted avg_recall': 0.17721518987341772, 'weighted avg_f1-score': 0.22764227642276424, 'weighted avg_support': 158.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1590, 'epoch': 0}, {'micro_f1': 0.8237934904601572, 'Causal_Oversimplification_precision': 0.42045454545454547, 'Causal_Oversimplification_recall': 0.22560975609756098, 'Causal_Oversimplification_f1-score': 0.29365079365079366, 'Causal_Oversimplification_support': 164.0, 'micro avg_precision': 0.42045454545454547, 'micro avg_recall': 0.22560975609756098, 'micro avg_f1-score': 0.29365079365079366, 'micro avg_support': 164.0, 'macro avg_precision': 0.42045454545454547, 'macro avg_recall': 0.22560975609756098, 'macro avg_f1-score': 0.29365079365079366, 'macro avg_support': 164.0, 'weighted avg_precision': 0.42045454545454547, 'weighted avg_recall': 0.22560975609756098, 'weighted avg_f1-score': 0.29365079365079366, 'weighted avg_support': 164.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1590, 'epoch': 1}, {'micro_f1': 0.7943322109988776, 'Causal_Oversimplification_precision': 0.3181818181818182, 'Causal_Oversimplification_recall': 0.27450980392156865, 'Causal_Oversimplification_f1-score': 0.2947368421052632, 'Causal_Oversimplification_support': 102.0, 'micro avg_precision': 0.3181818181818182, 'micro avg_recall': 0.27450980392156865, 'micro avg_f1-score': 0.2947368421052632, 'micro avg_support': 102.0, 'macro avg_precision': 0.3181818181818182, 'macro avg_recall': 0.27450980392156865, 'macro avg_f1-score': 0.2947368421052632, 'macro avg_support': 102.0, 'weighted avg_precision': 0.3181818181818182, 'weighted avg_recall': 0.27450980392156865, 'weighted avg_f1-score': 0.2947368421052632, 'weighted avg_support': 102.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1590, 'epoch': 2}, {'micro_f1': 0.8414702581369247, 'Causal_Oversimplification_precision': 0.4659090909090909, 'Causal_Oversimplification_recall': 0.2887323943661972, 'Causal_Oversimplification_f1-score': 0.3565217391304348, 'Causal_Oversimplification_support': 142.0, 'micro avg_precision': 0.4659090909090909, 'micro avg_recall': 0.2887323943661972, 'micro avg_f1-score': 0.3565217391304348, 'micro avg_support': 142.0, 'macro avg_precision': 0.4659090909090909, 'macro avg_recall': 0.2887323943661972, 'macro avg_f1-score': 0.3565217391304348, 'macro avg_support': 142.0, 'weighted avg_precision': 0.4659090909090909, 'weighted avg_recall': 0.2887323943661972, 'weighted avg_f1-score': 0.3565217391304348, 'weighted avg_support': 142.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1590, 'epoch': 3}]}
Best model updated: current epoch macro f1 = 0.3565217391304348
{'micro_f1': 0.8148148148148148, 'Causal_Oversimplification_precision': 0.5227272727272727, 'Causal_Oversimplification_recall': 0.304635761589404, 'Causal_Oversimplification_f1-score': 0.38493723849372385, 'Causal_Oversimplification_support': 151.0, 'micro avg_precision': 0.5227272727272727, 'micro avg_recall': 0.304635761589404, 'micro avg_f1-score': 0.38493723849372385, 'micro avg_support': 151.0, 'macro avg_precision': 0.5227272727272727, 'macro avg_recall': 0.304635761589404, 'macro avg_f1-score': 0.38493723849372385, 'macro avg_support': 151.0, 'weighted avg_precision': 0.5227272727272727, 'weighted avg_recall': 0.304635761589404, 'weighted avg_f1-score': 0.38493723849372385, 'weighted avg_support': 151.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1590, 'epoch': 4}
{'results': [{'micro_f1': 0.7687991021324355, 'Causal_Oversimplification_precision': 0.3181818181818182, 'Causal_Oversimplification_recall': 0.17721518987341772, 'Causal_Oversimplification_f1-score': 0.22764227642276422, 'Causal_Oversimplification_support': 158.0, 'micro avg_precision': 0.3181818181818182, 'micro avg_recall': 0.17721518987341772, 'micro avg_f1-score': 0.22764227642276422, 'micro avg_support': 158.0, 'macro avg_precision': 0.3181818181818182, 'macro avg_recall': 0.17721518987341772, 'macro avg_f1-score': 0.22764227642276422, 'macro avg_support': 158.0, 'weighted avg_precision': 0.3181818181818182, 'weighted avg_recall': 0.17721518987341772, 'weighted avg_f1-score': 0.22764227642276424, 'weighted avg_support': 158.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1590, 'epoch': 0}, {'micro_f1': 0.8237934904601572, 'Causal_Oversimplification_precision': 0.42045454545454547, 'Causal_Oversimplification_recall': 0.22560975609756098, 'Causal_Oversimplification_f1-score': 0.29365079365079366, 'Causal_Oversimplification_support': 164.0, 'micro avg_precision': 0.42045454545454547, 'micro avg_recall': 0.22560975609756098, 'micro avg_f1-score': 0.29365079365079366, 'micro avg_support': 164.0, 'macro avg_precision': 0.42045454545454547, 'macro avg_recall': 0.22560975609756098, 'macro avg_f1-score': 0.29365079365079366, 'macro avg_support': 164.0, 'weighted avg_precision': 0.42045454545454547, 'weighted avg_recall': 0.22560975609756098, 'weighted avg_f1-score': 0.29365079365079366, 'weighted avg_support': 164.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1590, 'epoch': 1}, {'micro_f1': 0.7943322109988776, 'Causal_Oversimplification_precision': 0.3181818181818182, 'Causal_Oversimplification_recall': 0.27450980392156865, 'Causal_Oversimplification_f1-score': 0.2947368421052632, 'Causal_Oversimplification_support': 102.0, 'micro avg_precision': 0.3181818181818182, 'micro avg_recall': 0.27450980392156865, 'micro avg_f1-score': 0.2947368421052632, 'micro avg_support': 102.0, 'macro avg_precision': 0.3181818181818182, 'macro avg_recall': 0.27450980392156865, 'macro avg_f1-score': 0.2947368421052632, 'macro avg_support': 102.0, 'weighted avg_precision': 0.3181818181818182, 'weighted avg_recall': 0.27450980392156865, 'weighted avg_f1-score': 0.2947368421052632, 'weighted avg_support': 102.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1590, 'epoch': 2}, {'micro_f1': 0.8414702581369247, 'Causal_Oversimplification_precision': 0.4659090909090909, 'Causal_Oversimplification_recall': 0.2887323943661972, 'Causal_Oversimplification_f1-score': 0.3565217391304348, 'Causal_Oversimplification_support': 142.0, 'micro avg_precision': 0.4659090909090909, 'micro avg_recall': 0.2887323943661972, 'micro avg_f1-score': 0.3565217391304348, 'micro avg_support': 142.0, 'macro avg_precision': 0.4659090909090909, 'macro avg_recall': 0.2887323943661972, 'macro avg_f1-score': 0.3565217391304348, 'macro avg_support': 142.0, 'weighted avg_precision': 0.4659090909090909, 'weighted avg_recall': 0.2887323943661972, 'weighted avg_f1-score': 0.3565217391304348, 'weighted avg_support': 142.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1590, 'epoch': 3}, {'micro_f1': 0.8148148148148148, 'Causal_Oversimplification_precision': 0.5227272727272727, 'Causal_Oversimplification_recall': 0.304635761589404, 'Causal_Oversimplification_f1-score': 0.38493723849372385, 'Causal_Oversimplification_support': 151.0, 'micro avg_precision': 0.5227272727272727, 'micro avg_recall': 0.304635761589404, 'micro avg_f1-score': 0.38493723849372385, 'micro avg_support': 151.0, 'macro avg_precision': 0.5227272727272727, 'macro avg_recall': 0.304635761589404, 'macro avg_f1-score': 0.38493723849372385, 'macro avg_support': 151.0, 'weighted avg_precision': 0.5227272727272727, 'weighted avg_recall': 0.304635761589404, 'weighted avg_f1-score': 0.38493723849372385, 'weighted avg_support': 151.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1590, 'epoch': 4}]}
Best model updated: current epoch macro f1 = 0.38493723849372385
{'micro_f1': 0.8344556677890012, 'Causal_Oversimplification_precision': 0.5795454545454546, 'Causal_Oversimplification_recall': 0.3805970149253731, 'Causal_Oversimplification_f1-score': 0.45945945945945943, 'Causal_Oversimplification_support': 134.0, 'micro avg_precision': 0.5795454545454546, 'micro avg_recall': 0.3805970149253731, 'micro avg_f1-score': 0.45945945945945943, 'micro avg_support': 134.0, 'macro avg_precision': 0.5795454545454546, 'macro avg_recall': 0.3805970149253731, 'macro avg_f1-score': 0.45945945945945943, 'macro avg_support': 134.0, 'weighted avg_precision': 0.5795454545454546, 'weighted avg_recall': 0.3805970149253731, 'weighted avg_f1-score': 0.45945945945945943, 'weighted avg_support': 134.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1590, 'epoch': 5}
{'results': [{'micro_f1': 0.7687991021324355, 'Causal_Oversimplification_precision': 0.3181818181818182, 'Causal_Oversimplification_recall': 0.17721518987341772, 'Causal_Oversimplification_f1-score': 0.22764227642276422, 'Causal_Oversimplification_support': 158.0, 'micro avg_precision': 0.3181818181818182, 'micro avg_recall': 0.17721518987341772, 'micro avg_f1-score': 0.22764227642276422, 'micro avg_support': 158.0, 'macro avg_precision': 0.3181818181818182, 'macro avg_recall': 0.17721518987341772, 'macro avg_f1-score': 0.22764227642276422, 'macro avg_support': 158.0, 'weighted avg_precision': 0.3181818181818182, 'weighted avg_recall': 0.17721518987341772, 'weighted avg_f1-score': 0.22764227642276424, 'weighted avg_support': 158.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1590, 'epoch': 0}, {'micro_f1': 0.8237934904601572, 'Causal_Oversimplification_precision': 0.42045454545454547, 'Causal_Oversimplification_recall': 0.22560975609756098, 'Causal_Oversimplification_f1-score': 0.29365079365079366, 'Causal_Oversimplification_support': 164.0, 'micro avg_precision': 0.42045454545454547, 'micro avg_recall': 0.22560975609756098, 'micro avg_f1-score': 0.29365079365079366, 'micro avg_support': 164.0, 'macro avg_precision': 0.42045454545454547, 'macro avg_recall': 0.22560975609756098, 'macro avg_f1-score': 0.29365079365079366, 'macro avg_support': 164.0, 'weighted avg_precision': 0.42045454545454547, 'weighted avg_recall': 0.22560975609756098, 'weighted avg_f1-score': 0.29365079365079366, 'weighted avg_support': 164.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1590, 'epoch': 1}, {'micro_f1': 0.7943322109988776, 'Causal_Oversimplification_precision': 0.3181818181818182, 'Causal_Oversimplification_recall': 0.27450980392156865, 'Causal_Oversimplification_f1-score': 0.2947368421052632, 'Causal_Oversimplification_support': 102.0, 'micro avg_precision': 0.3181818181818182, 'micro avg_recall': 0.27450980392156865, 'micro avg_f1-score': 0.2947368421052632, 'micro avg_support': 102.0, 'macro avg_precision': 0.3181818181818182, 'macro avg_recall': 0.27450980392156865, 'macro avg_f1-score': 0.2947368421052632, 'macro avg_support': 102.0, 'weighted avg_precision': 0.3181818181818182, 'weighted avg_recall': 0.27450980392156865, 'weighted avg_f1-score': 0.2947368421052632, 'weighted avg_support': 102.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1590, 'epoch': 2}, {'micro_f1': 0.8414702581369247, 'Causal_Oversimplification_precision': 0.4659090909090909, 'Causal_Oversimplification_recall': 0.2887323943661972, 'Causal_Oversimplification_f1-score': 0.3565217391304348, 'Causal_Oversimplification_support': 142.0, 'micro avg_precision': 0.4659090909090909, 'micro avg_recall': 0.2887323943661972, 'micro avg_f1-score': 0.3565217391304348, 'micro avg_support': 142.0, 'macro avg_precision': 0.4659090909090909, 'macro avg_recall': 0.2887323943661972, 'macro avg_f1-score': 0.3565217391304348, 'macro avg_support': 142.0, 'weighted avg_precision': 0.4659090909090909, 'weighted avg_recall': 0.2887323943661972, 'weighted avg_f1-score': 0.3565217391304348, 'weighted avg_support': 142.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1590, 'epoch': 3}, {'micro_f1': 0.8148148148148148, 'Causal_Oversimplification_precision': 0.5227272727272727, 'Causal_Oversimplification_recall': 0.304635761589404, 'Causal_Oversimplification_f1-score': 0.38493723849372385, 'Causal_Oversimplification_support': 151.0, 'micro avg_precision': 0.5227272727272727, 'micro avg_recall': 0.304635761589404, 'micro avg_f1-score': 0.38493723849372385, 'micro avg_support': 151.0, 'macro avg_precision': 0.5227272727272727, 'macro avg_recall': 0.304635761589404, 'macro avg_f1-score': 0.38493723849372385, 'macro avg_support': 151.0, 'weighted avg_precision': 0.5227272727272727, 'weighted avg_recall': 0.304635761589404, 'weighted avg_f1-score': 0.38493723849372385, 'weighted avg_support': 151.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1590, 'epoch': 4}, {'micro_f1': 0.8344556677890012, 'Causal_Oversimplification_precision': 0.5795454545454546, 'Causal_Oversimplification_recall': 0.3805970149253731, 'Causal_Oversimplification_f1-score': 0.45945945945945943, 'Causal_Oversimplification_support': 134.0, 'micro avg_precision': 0.5795454545454546, 'micro avg_recall': 0.3805970149253731, 'micro avg_f1-score': 0.45945945945945943, 'micro avg_support': 134.0, 'macro avg_precision': 0.5795454545454546, 'macro avg_recall': 0.3805970149253731, 'macro avg_f1-score': 0.45945945945945943, 'macro avg_support': 134.0, 'weighted avg_precision': 0.5795454545454546, 'weighted avg_recall': 0.3805970149253731, 'weighted avg_f1-score': 0.45945945945945943, 'weighted avg_support': 134.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1590, 'epoch': 5}]}
Best model updated: current epoch macro f1 = 0.45945945945945943
{'micro_f1': 0.8310886644219978, 'Causal_Oversimplification_precision': 0.5454545454545454, 'Causal_Oversimplification_recall': 0.35036496350364965, 'Causal_Oversimplification_f1-score': 0.4266666666666667, 'Causal_Oversimplification_support': 137.0, 'micro avg_precision': 0.5454545454545454, 'micro avg_recall': 0.35036496350364965, 'micro avg_f1-score': 0.4266666666666667, 'micro avg_support': 137.0, 'macro avg_precision': 0.5454545454545454, 'macro avg_recall': 0.35036496350364965, 'macro avg_f1-score': 0.4266666666666667, 'macro avg_support': 137.0, 'weighted avg_precision': 0.5454545454545454, 'weighted avg_recall': 0.35036496350364965, 'weighted avg_f1-score': 0.4266666666666667, 'weighted avg_support': 137.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1590, 'epoch': 6}
{'results': [{'micro_f1': 0.7687991021324355, 'Causal_Oversimplification_precision': 0.3181818181818182, 'Causal_Oversimplification_recall': 0.17721518987341772, 'Causal_Oversimplification_f1-score': 0.22764227642276422, 'Causal_Oversimplification_support': 158.0, 'micro avg_precision': 0.3181818181818182, 'micro avg_recall': 0.17721518987341772, 'micro avg_f1-score': 0.22764227642276422, 'micro avg_support': 158.0, 'macro avg_precision': 0.3181818181818182, 'macro avg_recall': 0.17721518987341772, 'macro avg_f1-score': 0.22764227642276422, 'macro avg_support': 158.0, 'weighted avg_precision': 0.3181818181818182, 'weighted avg_recall': 0.17721518987341772, 'weighted avg_f1-score': 0.22764227642276424, 'weighted avg_support': 158.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1590, 'epoch': 0}, {'micro_f1': 0.8237934904601572, 'Causal_Oversimplification_precision': 0.42045454545454547, 'Causal_Oversimplification_recall': 0.22560975609756098, 'Causal_Oversimplification_f1-score': 0.29365079365079366, 'Causal_Oversimplification_support': 164.0, 'micro avg_precision': 0.42045454545454547, 'micro avg_recall': 0.22560975609756098, 'micro avg_f1-score': 0.29365079365079366, 'micro avg_support': 164.0, 'macro avg_precision': 0.42045454545454547, 'macro avg_recall': 0.22560975609756098, 'macro avg_f1-score': 0.29365079365079366, 'macro avg_support': 164.0, 'weighted avg_precision': 0.42045454545454547, 'weighted avg_recall': 0.22560975609756098, 'weighted avg_f1-score': 0.29365079365079366, 'weighted avg_support': 164.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1590, 'epoch': 1}, {'micro_f1': 0.7943322109988776, 'Causal_Oversimplification_precision': 0.3181818181818182, 'Causal_Oversimplification_recall': 0.27450980392156865, 'Causal_Oversimplification_f1-score': 0.2947368421052632, 'Causal_Oversimplification_support': 102.0, 'micro avg_precision': 0.3181818181818182, 'micro avg_recall': 0.27450980392156865, 'micro avg_f1-score': 0.2947368421052632, 'micro avg_support': 102.0, 'macro avg_precision': 0.3181818181818182, 'macro avg_recall': 0.27450980392156865, 'macro avg_f1-score': 0.2947368421052632, 'macro avg_support': 102.0, 'weighted avg_precision': 0.3181818181818182, 'weighted avg_recall': 0.27450980392156865, 'weighted avg_f1-score': 0.2947368421052632, 'weighted avg_support': 102.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1590, 'epoch': 2}, {'micro_f1': 0.8414702581369247, 'Causal_Oversimplification_precision': 0.4659090909090909, 'Causal_Oversimplification_recall': 0.2887323943661972, 'Causal_Oversimplification_f1-score': 0.3565217391304348, 'Causal_Oversimplification_support': 142.0, 'micro avg_precision': 0.4659090909090909, 'micro avg_recall': 0.2887323943661972, 'micro avg_f1-score': 0.3565217391304348, 'micro avg_support': 142.0, 'macro avg_precision': 0.4659090909090909, 'macro avg_recall': 0.2887323943661972, 'macro avg_f1-score': 0.3565217391304348, 'macro avg_support': 142.0, 'weighted avg_precision': 0.4659090909090909, 'weighted avg_recall': 0.2887323943661972, 'weighted avg_f1-score': 0.3565217391304348, 'weighted avg_support': 142.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1590, 'epoch': 3}, {'micro_f1': 0.8148148148148148, 'Causal_Oversimplification_precision': 0.5227272727272727, 'Causal_Oversimplification_recall': 0.304635761589404, 'Causal_Oversimplification_f1-score': 0.38493723849372385, 'Causal_Oversimplification_support': 151.0, 'micro avg_precision': 0.5227272727272727, 'micro avg_recall': 0.304635761589404, 'micro avg_f1-score': 0.38493723849372385, 'micro avg_support': 151.0, 'macro avg_precision': 0.5227272727272727, 'macro avg_recall': 0.304635761589404, 'macro avg_f1-score': 0.38493723849372385, 'macro avg_support': 151.0, 'weighted avg_precision': 0.5227272727272727, 'weighted avg_recall': 0.304635761589404, 'weighted avg_f1-score': 0.38493723849372385, 'weighted avg_support': 151.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1590, 'epoch': 4}, {'micro_f1': 0.8344556677890012, 'Causal_Oversimplification_precision': 0.5795454545454546, 'Causal_Oversimplification_recall': 0.3805970149253731, 'Causal_Oversimplification_f1-score': 0.45945945945945943, 'Causal_Oversimplification_support': 134.0, 'micro avg_precision': 0.5795454545454546, 'micro avg_recall': 0.3805970149253731, 'micro avg_f1-score': 0.45945945945945943, 'micro avg_support': 134.0, 'macro avg_precision': 0.5795454545454546, 'macro avg_recall': 0.3805970149253731, 'macro avg_f1-score': 0.45945945945945943, 'macro avg_support': 134.0, 'weighted avg_precision': 0.5795454545454546, 'weighted avg_recall': 0.3805970149253731, 'weighted avg_f1-score': 0.45945945945945943, 'weighted avg_support': 134.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1590, 'epoch': 5}, {'micro_f1': 0.8310886644219978, 'Causal_Oversimplification_precision': 0.5454545454545454, 'Causal_Oversimplification_recall': 0.35036496350364965, 'Causal_Oversimplification_f1-score': 0.4266666666666667, 'Causal_Oversimplification_support': 137.0, 'micro avg_precision': 0.5454545454545454, 'micro avg_recall': 0.35036496350364965, 'micro avg_f1-score': 0.4266666666666667, 'micro avg_support': 137.0, 'macro avg_precision': 0.5454545454545454, 'macro avg_recall': 0.35036496350364965, 'macro avg_f1-score': 0.4266666666666667, 'macro avg_support': 137.0, 'weighted avg_precision': 0.5454545454545454, 'weighted avg_recall': 0.35036496350364965, 'weighted avg_f1-score': 0.4266666666666667, 'weighted avg_support': 137.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1590, 'epoch': 6}]}
{'micro_f1': 0.8482042648709316, 'Causal_Oversimplification_precision': 0.5340909090909091, 'Causal_Oversimplification_recall': 0.3671875, 'Causal_Oversimplification_f1-score': 0.4351851851851852, 'Causal_Oversimplification_support': 128.0, 'micro avg_precision': 0.5340909090909091, 'micro avg_recall': 0.3671875, 'micro avg_f1-score': 0.4351851851851852, 'micro avg_support': 128.0, 'macro avg_precision': 0.5340909090909091, 'macro avg_recall': 0.3671875, 'macro avg_f1-score': 0.4351851851851852, 'macro avg_support': 128.0, 'weighted avg_precision': 0.5340909090909091, 'weighted avg_recall': 0.3671875, 'weighted avg_f1-score': 0.4351851851851852, 'weighted avg_support': 128.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1590, 'epoch': 7}
{'results': [{'micro_f1': 0.7687991021324355, 'Causal_Oversimplification_precision': 0.3181818181818182, 'Causal_Oversimplification_recall': 0.17721518987341772, 'Causal_Oversimplification_f1-score': 0.22764227642276422, 'Causal_Oversimplification_support': 158.0, 'micro avg_precision': 0.3181818181818182, 'micro avg_recall': 0.17721518987341772, 'micro avg_f1-score': 0.22764227642276422, 'micro avg_support': 158.0, 'macro avg_precision': 0.3181818181818182, 'macro avg_recall': 0.17721518987341772, 'macro avg_f1-score': 0.22764227642276422, 'macro avg_support': 158.0, 'weighted avg_precision': 0.3181818181818182, 'weighted avg_recall': 0.17721518987341772, 'weighted avg_f1-score': 0.22764227642276424, 'weighted avg_support': 158.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1590, 'epoch': 0}, {'micro_f1': 0.8237934904601572, 'Causal_Oversimplification_precision': 0.42045454545454547, 'Causal_Oversimplification_recall': 0.22560975609756098, 'Causal_Oversimplification_f1-score': 0.29365079365079366, 'Causal_Oversimplification_support': 164.0, 'micro avg_precision': 0.42045454545454547, 'micro avg_recall': 0.22560975609756098, 'micro avg_f1-score': 0.29365079365079366, 'micro avg_support': 164.0, 'macro avg_precision': 0.42045454545454547, 'macro avg_recall': 0.22560975609756098, 'macro avg_f1-score': 0.29365079365079366, 'macro avg_support': 164.0, 'weighted avg_precision': 0.42045454545454547, 'weighted avg_recall': 0.22560975609756098, 'weighted avg_f1-score': 0.29365079365079366, 'weighted avg_support': 164.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1590, 'epoch': 1}, {'micro_f1': 0.7943322109988776, 'Causal_Oversimplification_precision': 0.3181818181818182, 'Causal_Oversimplification_recall': 0.27450980392156865, 'Causal_Oversimplification_f1-score': 0.2947368421052632, 'Causal_Oversimplification_support': 102.0, 'micro avg_precision': 0.3181818181818182, 'micro avg_recall': 0.27450980392156865, 'micro avg_f1-score': 0.2947368421052632, 'micro avg_support': 102.0, 'macro avg_precision': 0.3181818181818182, 'macro avg_recall': 0.27450980392156865, 'macro avg_f1-score': 0.2947368421052632, 'macro avg_support': 102.0, 'weighted avg_precision': 0.3181818181818182, 'weighted avg_recall': 0.27450980392156865, 'weighted avg_f1-score': 0.2947368421052632, 'weighted avg_support': 102.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1590, 'epoch': 2}, {'micro_f1': 0.8414702581369247, 'Causal_Oversimplification_precision': 0.4659090909090909, 'Causal_Oversimplification_recall': 0.2887323943661972, 'Causal_Oversimplification_f1-score': 0.3565217391304348, 'Causal_Oversimplification_support': 142.0, 'micro avg_precision': 0.4659090909090909, 'micro avg_recall': 0.2887323943661972, 'micro avg_f1-score': 0.3565217391304348, 'micro avg_support': 142.0, 'macro avg_precision': 0.4659090909090909, 'macro avg_recall': 0.2887323943661972, 'macro avg_f1-score': 0.3565217391304348, 'macro avg_support': 142.0, 'weighted avg_precision': 0.4659090909090909, 'weighted avg_recall': 0.2887323943661972, 'weighted avg_f1-score': 0.3565217391304348, 'weighted avg_support': 142.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1590, 'epoch': 3}, {'micro_f1': 0.8148148148148148, 'Causal_Oversimplification_precision': 0.5227272727272727, 'Causal_Oversimplification_recall': 0.304635761589404, 'Causal_Oversimplification_f1-score': 0.38493723849372385, 'Causal_Oversimplification_support': 151.0, 'micro avg_precision': 0.5227272727272727, 'micro avg_recall': 0.304635761589404, 'micro avg_f1-score': 0.38493723849372385, 'micro avg_support': 151.0, 'macro avg_precision': 0.5227272727272727, 'macro avg_recall': 0.304635761589404, 'macro avg_f1-score': 0.38493723849372385, 'macro avg_support': 151.0, 'weighted avg_precision': 0.5227272727272727, 'weighted avg_recall': 0.304635761589404, 'weighted avg_f1-score': 0.38493723849372385, 'weighted avg_support': 151.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1590, 'epoch': 4}, {'micro_f1': 0.8344556677890012, 'Causal_Oversimplification_precision': 0.5795454545454546, 'Causal_Oversimplification_recall': 0.3805970149253731, 'Causal_Oversimplification_f1-score': 0.45945945945945943, 'Causal_Oversimplification_support': 134.0, 'micro avg_precision': 0.5795454545454546, 'micro avg_recall': 0.3805970149253731, 'micro avg_f1-score': 0.45945945945945943, 'micro avg_support': 134.0, 'macro avg_precision': 0.5795454545454546, 'macro avg_recall': 0.3805970149253731, 'macro avg_f1-score': 0.45945945945945943, 'macro avg_support': 134.0, 'weighted avg_precision': 0.5795454545454546, 'weighted avg_recall': 0.3805970149253731, 'weighted avg_f1-score': 0.45945945945945943, 'weighted avg_support': 134.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1590, 'epoch': 5}, {'micro_f1': 0.8310886644219978, 'Causal_Oversimplification_precision': 0.5454545454545454, 'Causal_Oversimplification_recall': 0.35036496350364965, 'Causal_Oversimplification_f1-score': 0.4266666666666667, 'Causal_Oversimplification_support': 137.0, 'micro avg_precision': 0.5454545454545454, 'micro avg_recall': 0.35036496350364965, 'micro avg_f1-score': 0.4266666666666667, 'micro avg_support': 137.0, 'macro avg_precision': 0.5454545454545454, 'macro avg_recall': 0.35036496350364965, 'macro avg_f1-score': 0.4266666666666667, 'macro avg_support': 137.0, 'weighted avg_precision': 0.5454545454545454, 'weighted avg_recall': 0.35036496350364965, 'weighted avg_f1-score': 0.4266666666666667, 'weighted avg_support': 137.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1590, 'epoch': 6}, {'micro_f1': 0.8482042648709316, 'Causal_Oversimplification_precision': 0.5340909090909091, 'Causal_Oversimplification_recall': 0.3671875, 'Causal_Oversimplification_f1-score': 0.4351851851851852, 'Causal_Oversimplification_support': 128.0, 'micro avg_precision': 0.5340909090909091, 'micro avg_recall': 0.3671875, 'micro avg_f1-score': 0.4351851851851852, 'micro avg_support': 128.0, 'macro avg_precision': 0.5340909090909091, 'macro avg_recall': 0.3671875, 'macro avg_f1-score': 0.4351851851851852, 'macro avg_support': 128.0, 'weighted avg_precision': 0.5340909090909091, 'weighted avg_recall': 0.3671875, 'weighted avg_f1-score': 0.4351851851851852, 'weighted avg_support': 128.0, 'B-Causal_Oversimplification_support': 88, 'I-Causal_Oversimplification_support': 1886, 'O_support': 1590, 'epoch': 7}]}
Early stopping triggered.
Saving model to directory: ./models/M2/2024-05-12-17-42-10_aug/mdeberta-v3-base_5_ME10_target=Causal_Oversimplification_SUBSAMPLED_2024-05-12-17-42-10
Training model no. 6 of 23 for (6, 'False_Dilemma-No_Choice') persuasion technique...
{'micro_f1': 0.740655737704918, 'False_Dilemma-No_Choice_precision': 0.3333333333333333, 'False_Dilemma-No_Choice_recall': 0.1958041958041958, 'False_Dilemma-No_Choice_f1-score': 0.24669603524229075, 'False_Dilemma-No_Choice_support': 143.0, 'micro avg_precision': 0.3333333333333333, 'micro avg_recall': 0.1958041958041958, 'micro avg_f1-score': 0.24669603524229075, 'micro avg_support': 143.0, 'macro avg_precision': 0.3333333333333333, 'macro avg_recall': 0.1958041958041958, 'macro avg_f1-score': 0.24669603524229075, 'macro avg_support': 143.0, 'weighted avg_precision': 0.3333333333333333, 'weighted avg_recall': 0.1958041958041958, 'weighted avg_f1-score': 0.24669603524229078, 'weighted avg_support': 143.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 1622, 'epoch': 0}
{'results': [{'micro_f1': 0.740655737704918, 'False_Dilemma-No_Choice_precision': 0.3333333333333333, 'False_Dilemma-No_Choice_recall': 0.1958041958041958, 'False_Dilemma-No_Choice_f1-score': 0.24669603524229075, 'False_Dilemma-No_Choice_support': 143.0, 'micro avg_precision': 0.3333333333333333, 'micro avg_recall': 0.1958041958041958, 'micro avg_f1-score': 0.24669603524229075, 'micro avg_support': 143.0, 'macro avg_precision': 0.3333333333333333, 'macro avg_recall': 0.1958041958041958, 'macro avg_f1-score': 0.24669603524229075, 'macro avg_support': 143.0, 'weighted avg_precision': 0.3333333333333333, 'weighted avg_recall': 0.1958041958041958, 'weighted avg_f1-score': 0.24669603524229078, 'weighted avg_support': 143.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 1622, 'epoch': 0}]}
Best model updated: current epoch macro f1 = 0.24669603524229075
{'micro_f1': 0.8111475409836064, 'False_Dilemma-No_Choice_precision': 0.32142857142857145, 'False_Dilemma-No_Choice_recall': 0.23684210526315788, 'False_Dilemma-No_Choice_f1-score': 0.2727272727272727, 'False_Dilemma-No_Choice_support': 114.0, 'micro avg_precision': 0.32142857142857145, 'micro avg_recall': 0.23684210526315788, 'micro avg_f1-score': 0.2727272727272727, 'micro avg_support': 114.0, 'macro avg_precision': 0.32142857142857145, 'macro avg_recall': 0.23684210526315788, 'macro avg_f1-score': 0.2727272727272727, 'macro avg_support': 114.0, 'weighted avg_precision': 0.32142857142857145, 'weighted avg_recall': 0.23684210526315788, 'weighted avg_f1-score': 0.2727272727272727, 'weighted avg_support': 114.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 1622, 'epoch': 1}
{'results': [{'micro_f1': 0.740655737704918, 'False_Dilemma-No_Choice_precision': 0.3333333333333333, 'False_Dilemma-No_Choice_recall': 0.1958041958041958, 'False_Dilemma-No_Choice_f1-score': 0.24669603524229075, 'False_Dilemma-No_Choice_support': 143.0, 'micro avg_precision': 0.3333333333333333, 'micro avg_recall': 0.1958041958041958, 'micro avg_f1-score': 0.24669603524229075, 'micro avg_support': 143.0, 'macro avg_precision': 0.3333333333333333, 'macro avg_recall': 0.1958041958041958, 'macro avg_f1-score': 0.24669603524229075, 'macro avg_support': 143.0, 'weighted avg_precision': 0.3333333333333333, 'weighted avg_recall': 0.1958041958041958, 'weighted avg_f1-score': 0.24669603524229078, 'weighted avg_support': 143.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 1622, 'epoch': 0}, {'micro_f1': 0.8111475409836064, 'False_Dilemma-No_Choice_precision': 0.32142857142857145, 'False_Dilemma-No_Choice_recall': 0.23684210526315788, 'False_Dilemma-No_Choice_f1-score': 0.2727272727272727, 'False_Dilemma-No_Choice_support': 114.0, 'micro avg_precision': 0.32142857142857145, 'micro avg_recall': 0.23684210526315788, 'micro avg_f1-score': 0.2727272727272727, 'micro avg_support': 114.0, 'macro avg_precision': 0.32142857142857145, 'macro avg_recall': 0.23684210526315788, 'macro avg_f1-score': 0.2727272727272727, 'macro avg_support': 114.0, 'weighted avg_precision': 0.32142857142857145, 'weighted avg_recall': 0.23684210526315788, 'weighted avg_f1-score': 0.2727272727272727, 'weighted avg_support': 114.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 1622, 'epoch': 1}]}
Best model updated: current epoch macro f1 = 0.2727272727272727
{'micro_f1': 0.8268852459016394, 'False_Dilemma-No_Choice_precision': 0.3333333333333333, 'False_Dilemma-No_Choice_recall': 0.23140495867768596, 'False_Dilemma-No_Choice_f1-score': 0.27317073170731704, 'False_Dilemma-No_Choice_support': 121.0, 'micro avg_precision': 0.3333333333333333, 'micro avg_recall': 0.23140495867768596, 'micro avg_f1-score': 0.27317073170731704, 'micro avg_support': 121.0, 'macro avg_precision': 0.3333333333333333, 'macro avg_recall': 0.23140495867768596, 'macro avg_f1-score': 0.27317073170731704, 'macro avg_support': 121.0, 'weighted avg_precision': 0.3333333333333333, 'weighted avg_recall': 0.23140495867768596, 'weighted avg_f1-score': 0.27317073170731704, 'weighted avg_support': 121.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 1622, 'epoch': 2}
{'results': [{'micro_f1': 0.740655737704918, 'False_Dilemma-No_Choice_precision': 0.3333333333333333, 'False_Dilemma-No_Choice_recall': 0.1958041958041958, 'False_Dilemma-No_Choice_f1-score': 0.24669603524229075, 'False_Dilemma-No_Choice_support': 143.0, 'micro avg_precision': 0.3333333333333333, 'micro avg_recall': 0.1958041958041958, 'micro avg_f1-score': 0.24669603524229075, 'micro avg_support': 143.0, 'macro avg_precision': 0.3333333333333333, 'macro avg_recall': 0.1958041958041958, 'macro avg_f1-score': 0.24669603524229075, 'macro avg_support': 143.0, 'weighted avg_precision': 0.3333333333333333, 'weighted avg_recall': 0.1958041958041958, 'weighted avg_f1-score': 0.24669603524229078, 'weighted avg_support': 143.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 1622, 'epoch': 0}, {'micro_f1': 0.8111475409836064, 'False_Dilemma-No_Choice_precision': 0.32142857142857145, 'False_Dilemma-No_Choice_recall': 0.23684210526315788, 'False_Dilemma-No_Choice_f1-score': 0.2727272727272727, 'False_Dilemma-No_Choice_support': 114.0, 'micro avg_precision': 0.32142857142857145, 'micro avg_recall': 0.23684210526315788, 'micro avg_f1-score': 0.2727272727272727, 'micro avg_support': 114.0, 'macro avg_precision': 0.32142857142857145, 'macro avg_recall': 0.23684210526315788, 'macro avg_f1-score': 0.2727272727272727, 'macro avg_support': 114.0, 'weighted avg_precision': 0.32142857142857145, 'weighted avg_recall': 0.23684210526315788, 'weighted avg_f1-score': 0.2727272727272727, 'weighted avg_support': 114.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 1622, 'epoch': 1}, {'micro_f1': 0.8268852459016394, 'False_Dilemma-No_Choice_precision': 0.3333333333333333, 'False_Dilemma-No_Choice_recall': 0.23140495867768596, 'False_Dilemma-No_Choice_f1-score': 0.27317073170731704, 'False_Dilemma-No_Choice_support': 121.0, 'micro avg_precision': 0.3333333333333333, 'micro avg_recall': 0.23140495867768596, 'micro avg_f1-score': 0.27317073170731704, 'micro avg_support': 121.0, 'macro avg_precision': 0.3333333333333333, 'macro avg_recall': 0.23140495867768596, 'macro avg_f1-score': 0.27317073170731704, 'macro avg_support': 121.0, 'weighted avg_precision': 0.3333333333333333, 'weighted avg_recall': 0.23140495867768596, 'weighted avg_f1-score': 0.27317073170731704, 'weighted avg_support': 121.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 1622, 'epoch': 2}]}
Best model updated: current epoch macro f1 = 0.27317073170731704
{'micro_f1': 0.8459016393442624, 'False_Dilemma-No_Choice_precision': 0.47619047619047616, 'False_Dilemma-No_Choice_recall': 0.36036036036036034, 'False_Dilemma-No_Choice_f1-score': 0.41025641025641024, 'False_Dilemma-No_Choice_support': 111.0, 'micro avg_precision': 0.47619047619047616, 'micro avg_recall': 0.36036036036036034, 'micro avg_f1-score': 0.41025641025641024, 'micro avg_support': 111.0, 'macro avg_precision': 0.47619047619047616, 'macro avg_recall': 0.36036036036036034, 'macro avg_f1-score': 0.41025641025641024, 'macro avg_support': 111.0, 'weighted avg_precision': 0.47619047619047616, 'weighted avg_recall': 0.36036036036036034, 'weighted avg_f1-score': 0.4102564102564103, 'weighted avg_support': 111.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 1622, 'epoch': 3}
{'results': [{'micro_f1': 0.740655737704918, 'False_Dilemma-No_Choice_precision': 0.3333333333333333, 'False_Dilemma-No_Choice_recall': 0.1958041958041958, 'False_Dilemma-No_Choice_f1-score': 0.24669603524229075, 'False_Dilemma-No_Choice_support': 143.0, 'micro avg_precision': 0.3333333333333333, 'micro avg_recall': 0.1958041958041958, 'micro avg_f1-score': 0.24669603524229075, 'micro avg_support': 143.0, 'macro avg_precision': 0.3333333333333333, 'macro avg_recall': 0.1958041958041958, 'macro avg_f1-score': 0.24669603524229075, 'macro avg_support': 143.0, 'weighted avg_precision': 0.3333333333333333, 'weighted avg_recall': 0.1958041958041958, 'weighted avg_f1-score': 0.24669603524229078, 'weighted avg_support': 143.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 1622, 'epoch': 0}, {'micro_f1': 0.8111475409836064, 'False_Dilemma-No_Choice_precision': 0.32142857142857145, 'False_Dilemma-No_Choice_recall': 0.23684210526315788, 'False_Dilemma-No_Choice_f1-score': 0.2727272727272727, 'False_Dilemma-No_Choice_support': 114.0, 'micro avg_precision': 0.32142857142857145, 'micro avg_recall': 0.23684210526315788, 'micro avg_f1-score': 0.2727272727272727, 'micro avg_support': 114.0, 'macro avg_precision': 0.32142857142857145, 'macro avg_recall': 0.23684210526315788, 'macro avg_f1-score': 0.2727272727272727, 'macro avg_support': 114.0, 'weighted avg_precision': 0.32142857142857145, 'weighted avg_recall': 0.23684210526315788, 'weighted avg_f1-score': 0.2727272727272727, 'weighted avg_support': 114.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 1622, 'epoch': 1}, {'micro_f1': 0.8268852459016394, 'False_Dilemma-No_Choice_precision': 0.3333333333333333, 'False_Dilemma-No_Choice_recall': 0.23140495867768596, 'False_Dilemma-No_Choice_f1-score': 0.27317073170731704, 'False_Dilemma-No_Choice_support': 121.0, 'micro avg_precision': 0.3333333333333333, 'micro avg_recall': 0.23140495867768596, 'micro avg_f1-score': 0.27317073170731704, 'micro avg_support': 121.0, 'macro avg_precision': 0.3333333333333333, 'macro avg_recall': 0.23140495867768596, 'macro avg_f1-score': 0.27317073170731704, 'macro avg_support': 121.0, 'weighted avg_precision': 0.3333333333333333, 'weighted avg_recall': 0.23140495867768596, 'weighted avg_f1-score': 0.27317073170731704, 'weighted avg_support': 121.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 1622, 'epoch': 2}, {'micro_f1': 0.8459016393442624, 'False_Dilemma-No_Choice_precision': 0.47619047619047616, 'False_Dilemma-No_Choice_recall': 0.36036036036036034, 'False_Dilemma-No_Choice_f1-score': 0.41025641025641024, 'False_Dilemma-No_Choice_support': 111.0, 'micro avg_precision': 0.47619047619047616, 'micro avg_recall': 0.36036036036036034, 'micro avg_f1-score': 0.41025641025641024, 'micro avg_support': 111.0, 'macro avg_precision': 0.47619047619047616, 'macro avg_recall': 0.36036036036036034, 'macro avg_f1-score': 0.41025641025641024, 'macro avg_support': 111.0, 'weighted avg_precision': 0.47619047619047616, 'weighted avg_recall': 0.36036036036036034, 'weighted avg_f1-score': 0.4102564102564103, 'weighted avg_support': 111.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 1622, 'epoch': 3}]}
Best model updated: current epoch macro f1 = 0.41025641025641024
{'micro_f1': 0.8567213114754099, 'False_Dilemma-No_Choice_precision': 0.42857142857142855, 'False_Dilemma-No_Choice_recall': 0.32432432432432434, 'False_Dilemma-No_Choice_f1-score': 0.3692307692307692, 'False_Dilemma-No_Choice_support': 111.0, 'micro avg_precision': 0.42857142857142855, 'micro avg_recall': 0.32432432432432434, 'micro avg_f1-score': 0.3692307692307692, 'micro avg_support': 111.0, 'macro avg_precision': 0.42857142857142855, 'macro avg_recall': 0.32432432432432434, 'macro avg_f1-score': 0.3692307692307692, 'macro avg_support': 111.0, 'weighted avg_precision': 0.42857142857142855, 'weighted avg_recall': 0.32432432432432434, 'weighted avg_f1-score': 0.3692307692307692, 'weighted avg_support': 111.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 1622, 'epoch': 4}
{'results': [{'micro_f1': 0.740655737704918, 'False_Dilemma-No_Choice_precision': 0.3333333333333333, 'False_Dilemma-No_Choice_recall': 0.1958041958041958, 'False_Dilemma-No_Choice_f1-score': 0.24669603524229075, 'False_Dilemma-No_Choice_support': 143.0, 'micro avg_precision': 0.3333333333333333, 'micro avg_recall': 0.1958041958041958, 'micro avg_f1-score': 0.24669603524229075, 'micro avg_support': 143.0, 'macro avg_precision': 0.3333333333333333, 'macro avg_recall': 0.1958041958041958, 'macro avg_f1-score': 0.24669603524229075, 'macro avg_support': 143.0, 'weighted avg_precision': 0.3333333333333333, 'weighted avg_recall': 0.1958041958041958, 'weighted avg_f1-score': 0.24669603524229078, 'weighted avg_support': 143.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 1622, 'epoch': 0}, {'micro_f1': 0.8111475409836064, 'False_Dilemma-No_Choice_precision': 0.32142857142857145, 'False_Dilemma-No_Choice_recall': 0.23684210526315788, 'False_Dilemma-No_Choice_f1-score': 0.2727272727272727, 'False_Dilemma-No_Choice_support': 114.0, 'micro avg_precision': 0.32142857142857145, 'micro avg_recall': 0.23684210526315788, 'micro avg_f1-score': 0.2727272727272727, 'micro avg_support': 114.0, 'macro avg_precision': 0.32142857142857145, 'macro avg_recall': 0.23684210526315788, 'macro avg_f1-score': 0.2727272727272727, 'macro avg_support': 114.0, 'weighted avg_precision': 0.32142857142857145, 'weighted avg_recall': 0.23684210526315788, 'weighted avg_f1-score': 0.2727272727272727, 'weighted avg_support': 114.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 1622, 'epoch': 1}, {'micro_f1': 0.8268852459016394, 'False_Dilemma-No_Choice_precision': 0.3333333333333333, 'False_Dilemma-No_Choice_recall': 0.23140495867768596, 'False_Dilemma-No_Choice_f1-score': 0.27317073170731704, 'False_Dilemma-No_Choice_support': 121.0, 'micro avg_precision': 0.3333333333333333, 'micro avg_recall': 0.23140495867768596, 'micro avg_f1-score': 0.27317073170731704, 'micro avg_support': 121.0, 'macro avg_precision': 0.3333333333333333, 'macro avg_recall': 0.23140495867768596, 'macro avg_f1-score': 0.27317073170731704, 'macro avg_support': 121.0, 'weighted avg_precision': 0.3333333333333333, 'weighted avg_recall': 0.23140495867768596, 'weighted avg_f1-score': 0.27317073170731704, 'weighted avg_support': 121.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 1622, 'epoch': 2}, {'micro_f1': 0.8459016393442624, 'False_Dilemma-No_Choice_precision': 0.47619047619047616, 'False_Dilemma-No_Choice_recall': 0.36036036036036034, 'False_Dilemma-No_Choice_f1-score': 0.41025641025641024, 'False_Dilemma-No_Choice_support': 111.0, 'micro avg_precision': 0.47619047619047616, 'micro avg_recall': 0.36036036036036034, 'micro avg_f1-score': 0.41025641025641024, 'micro avg_support': 111.0, 'macro avg_precision': 0.47619047619047616, 'macro avg_recall': 0.36036036036036034, 'macro avg_f1-score': 0.41025641025641024, 'macro avg_support': 111.0, 'weighted avg_precision': 0.47619047619047616, 'weighted avg_recall': 0.36036036036036034, 'weighted avg_f1-score': 0.4102564102564103, 'weighted avg_support': 111.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 1622, 'epoch': 3}, {'micro_f1': 0.8567213114754099, 'False_Dilemma-No_Choice_precision': 0.42857142857142855, 'False_Dilemma-No_Choice_recall': 0.32432432432432434, 'False_Dilemma-No_Choice_f1-score': 0.3692307692307692, 'False_Dilemma-No_Choice_support': 111.0, 'micro avg_precision': 0.42857142857142855, 'micro avg_recall': 0.32432432432432434, 'micro avg_f1-score': 0.3692307692307692, 'micro avg_support': 111.0, 'macro avg_precision': 0.42857142857142855, 'macro avg_recall': 0.32432432432432434, 'macro avg_f1-score': 0.3692307692307692, 'macro avg_support': 111.0, 'weighted avg_precision': 0.42857142857142855, 'weighted avg_recall': 0.32432432432432434, 'weighted avg_f1-score': 0.3692307692307692, 'weighted avg_support': 111.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 1622, 'epoch': 4}]}
{'micro_f1': 0.8508196721311475, 'False_Dilemma-No_Choice_precision': 0.40476190476190477, 'False_Dilemma-No_Choice_recall': 0.3655913978494624, 'False_Dilemma-No_Choice_f1-score': 0.384180790960452, 'False_Dilemma-No_Choice_support': 93.0, 'micro avg_precision': 0.40476190476190477, 'micro avg_recall': 0.3655913978494624, 'micro avg_f1-score': 0.384180790960452, 'micro avg_support': 93.0, 'macro avg_precision': 0.40476190476190477, 'macro avg_recall': 0.3655913978494624, 'macro avg_f1-score': 0.384180790960452, 'macro avg_support': 93.0, 'weighted avg_precision': 0.40476190476190477, 'weighted avg_recall': 0.3655913978494624, 'weighted avg_f1-score': 0.384180790960452, 'weighted avg_support': 93.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 1622, 'epoch': 5}
{'results': [{'micro_f1': 0.740655737704918, 'False_Dilemma-No_Choice_precision': 0.3333333333333333, 'False_Dilemma-No_Choice_recall': 0.1958041958041958, 'False_Dilemma-No_Choice_f1-score': 0.24669603524229075, 'False_Dilemma-No_Choice_support': 143.0, 'micro avg_precision': 0.3333333333333333, 'micro avg_recall': 0.1958041958041958, 'micro avg_f1-score': 0.24669603524229075, 'micro avg_support': 143.0, 'macro avg_precision': 0.3333333333333333, 'macro avg_recall': 0.1958041958041958, 'macro avg_f1-score': 0.24669603524229075, 'macro avg_support': 143.0, 'weighted avg_precision': 0.3333333333333333, 'weighted avg_recall': 0.1958041958041958, 'weighted avg_f1-score': 0.24669603524229078, 'weighted avg_support': 143.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 1622, 'epoch': 0}, {'micro_f1': 0.8111475409836064, 'False_Dilemma-No_Choice_precision': 0.32142857142857145, 'False_Dilemma-No_Choice_recall': 0.23684210526315788, 'False_Dilemma-No_Choice_f1-score': 0.2727272727272727, 'False_Dilemma-No_Choice_support': 114.0, 'micro avg_precision': 0.32142857142857145, 'micro avg_recall': 0.23684210526315788, 'micro avg_f1-score': 0.2727272727272727, 'micro avg_support': 114.0, 'macro avg_precision': 0.32142857142857145, 'macro avg_recall': 0.23684210526315788, 'macro avg_f1-score': 0.2727272727272727, 'macro avg_support': 114.0, 'weighted avg_precision': 0.32142857142857145, 'weighted avg_recall': 0.23684210526315788, 'weighted avg_f1-score': 0.2727272727272727, 'weighted avg_support': 114.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 1622, 'epoch': 1}, {'micro_f1': 0.8268852459016394, 'False_Dilemma-No_Choice_precision': 0.3333333333333333, 'False_Dilemma-No_Choice_recall': 0.23140495867768596, 'False_Dilemma-No_Choice_f1-score': 0.27317073170731704, 'False_Dilemma-No_Choice_support': 121.0, 'micro avg_precision': 0.3333333333333333, 'micro avg_recall': 0.23140495867768596, 'micro avg_f1-score': 0.27317073170731704, 'micro avg_support': 121.0, 'macro avg_precision': 0.3333333333333333, 'macro avg_recall': 0.23140495867768596, 'macro avg_f1-score': 0.27317073170731704, 'macro avg_support': 121.0, 'weighted avg_precision': 0.3333333333333333, 'weighted avg_recall': 0.23140495867768596, 'weighted avg_f1-score': 0.27317073170731704, 'weighted avg_support': 121.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 1622, 'epoch': 2}, {'micro_f1': 0.8459016393442624, 'False_Dilemma-No_Choice_precision': 0.47619047619047616, 'False_Dilemma-No_Choice_recall': 0.36036036036036034, 'False_Dilemma-No_Choice_f1-score': 0.41025641025641024, 'False_Dilemma-No_Choice_support': 111.0, 'micro avg_precision': 0.47619047619047616, 'micro avg_recall': 0.36036036036036034, 'micro avg_f1-score': 0.41025641025641024, 'micro avg_support': 111.0, 'macro avg_precision': 0.47619047619047616, 'macro avg_recall': 0.36036036036036034, 'macro avg_f1-score': 0.41025641025641024, 'macro avg_support': 111.0, 'weighted avg_precision': 0.47619047619047616, 'weighted avg_recall': 0.36036036036036034, 'weighted avg_f1-score': 0.4102564102564103, 'weighted avg_support': 111.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 1622, 'epoch': 3}, {'micro_f1': 0.8567213114754099, 'False_Dilemma-No_Choice_precision': 0.42857142857142855, 'False_Dilemma-No_Choice_recall': 0.32432432432432434, 'False_Dilemma-No_Choice_f1-score': 0.3692307692307692, 'False_Dilemma-No_Choice_support': 111.0, 'micro avg_precision': 0.42857142857142855, 'micro avg_recall': 0.32432432432432434, 'micro avg_f1-score': 0.3692307692307692, 'micro avg_support': 111.0, 'macro avg_precision': 0.42857142857142855, 'macro avg_recall': 0.32432432432432434, 'macro avg_f1-score': 0.3692307692307692, 'macro avg_support': 111.0, 'weighted avg_precision': 0.42857142857142855, 'weighted avg_recall': 0.32432432432432434, 'weighted avg_f1-score': 0.3692307692307692, 'weighted avg_support': 111.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 1622, 'epoch': 4}, {'micro_f1': 0.8508196721311475, 'False_Dilemma-No_Choice_precision': 0.40476190476190477, 'False_Dilemma-No_Choice_recall': 0.3655913978494624, 'False_Dilemma-No_Choice_f1-score': 0.384180790960452, 'False_Dilemma-No_Choice_support': 93.0, 'micro avg_precision': 0.40476190476190477, 'micro avg_recall': 0.3655913978494624, 'micro avg_f1-score': 0.384180790960452, 'micro avg_support': 93.0, 'macro avg_precision': 0.40476190476190477, 'macro avg_recall': 0.3655913978494624, 'macro avg_f1-score': 0.384180790960452, 'macro avg_support': 93.0, 'weighted avg_precision': 0.40476190476190477, 'weighted avg_recall': 0.3655913978494624, 'weighted avg_f1-score': 0.384180790960452, 'weighted avg_support': 93.0, 'B-False_Dilemma-No_Choice_support': 84, 'I-False_Dilemma-No_Choice_support': 1344, 'O_support': 1622, 'epoch': 5}]}
Early stopping triggered.
Saving model to directory: ./models/M2/2024-05-12-17-42-10_aug/mdeberta-v3-base_6_ME10_target=False_Dilemma-No_Choice_SUBSAMPLED_2024-05-12-17-42-10
Training model no. 7 of 23 for (7, 'Consequential_Oversimplification') persuasion technique...
{'micro_f1': 0.8384185646755479, 'Consequential_Oversimplification_precision': 0.27450980392156865, 'Consequential_Oversimplification_recall': 0.13725490196078433, 'Consequential_Oversimplification_f1-score': 0.18300653594771246, 'Consequential_Oversimplification_support': 102.0, 'micro avg_precision': 0.27450980392156865, 'micro avg_recall': 0.13725490196078433, 'micro avg_f1-score': 0.18300653594771246, 'micro avg_support': 102.0, 'macro avg_precision': 0.27450980392156865, 'macro avg_recall': 0.13725490196078433, 'macro avg_f1-score': 0.18300653594771246, 'macro avg_support': 102.0, 'weighted avg_precision': 0.27450980392156865, 'weighted avg_recall': 0.13725490196078433, 'weighted avg_f1-score': 0.18300653594771246, 'weighted avg_support': 102.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 0}
{'results': [{'micro_f1': 0.8384185646755479, 'Consequential_Oversimplification_precision': 0.27450980392156865, 'Consequential_Oversimplification_recall': 0.13725490196078433, 'Consequential_Oversimplification_f1-score': 0.18300653594771246, 'Consequential_Oversimplification_support': 102.0, 'micro avg_precision': 0.27450980392156865, 'micro avg_recall': 0.13725490196078433, 'micro avg_f1-score': 0.18300653594771246, 'micro avg_support': 102.0, 'macro avg_precision': 0.27450980392156865, 'macro avg_recall': 0.13725490196078433, 'macro avg_f1-score': 0.18300653594771246, 'macro avg_support': 102.0, 'weighted avg_precision': 0.27450980392156865, 'weighted avg_recall': 0.13725490196078433, 'weighted avg_f1-score': 0.18300653594771246, 'weighted avg_support': 102.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 0}]}
Best model updated: current epoch macro f1 = 0.18300653594771246
{'micro_f1': 0.7782552642887838, 'Consequential_Oversimplification_precision': 0.17647058823529413, 'Consequential_Oversimplification_recall': 0.10975609756097561, 'Consequential_Oversimplification_f1-score': 0.13533834586466165, 'Consequential_Oversimplification_support': 82.0, 'micro avg_precision': 0.17647058823529413, 'micro avg_recall': 0.10975609756097561, 'micro avg_f1-score': 0.13533834586466165, 'micro avg_support': 82.0, 'macro avg_precision': 0.17647058823529413, 'macro avg_recall': 0.10975609756097561, 'macro avg_f1-score': 0.13533834586466165, 'macro avg_support': 82.0, 'weighted avg_precision': 0.17647058823529413, 'weighted avg_recall': 0.10975609756097561, 'weighted avg_f1-score': 0.13533834586466165, 'weighted avg_support': 82.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 1}
{'results': [{'micro_f1': 0.8384185646755479, 'Consequential_Oversimplification_precision': 0.27450980392156865, 'Consequential_Oversimplification_recall': 0.13725490196078433, 'Consequential_Oversimplification_f1-score': 0.18300653594771246, 'Consequential_Oversimplification_support': 102.0, 'micro avg_precision': 0.27450980392156865, 'micro avg_recall': 0.13725490196078433, 'micro avg_f1-score': 0.18300653594771246, 'micro avg_support': 102.0, 'macro avg_precision': 0.27450980392156865, 'macro avg_recall': 0.13725490196078433, 'macro avg_f1-score': 0.18300653594771246, 'macro avg_support': 102.0, 'weighted avg_precision': 0.27450980392156865, 'weighted avg_recall': 0.13725490196078433, 'weighted avg_f1-score': 0.18300653594771246, 'weighted avg_support': 102.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 0}, {'micro_f1': 0.7782552642887838, 'Consequential_Oversimplification_precision': 0.17647058823529413, 'Consequential_Oversimplification_recall': 0.10975609756097561, 'Consequential_Oversimplification_f1-score': 0.13533834586466165, 'Consequential_Oversimplification_support': 82.0, 'micro avg_precision': 0.17647058823529413, 'micro avg_recall': 0.10975609756097561, 'micro avg_f1-score': 0.13533834586466165, 'micro avg_support': 82.0, 'macro avg_precision': 0.17647058823529413, 'macro avg_recall': 0.10975609756097561, 'macro avg_f1-score': 0.13533834586466165, 'macro avg_support': 82.0, 'weighted avg_precision': 0.17647058823529413, 'weighted avg_recall': 0.10975609756097561, 'weighted avg_f1-score': 0.13533834586466165, 'weighted avg_support': 82.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 1}]}
{'micro_f1': 0.8242372152986678, 'Consequential_Oversimplification_precision': 0.29411764705882354, 'Consequential_Oversimplification_recall': 0.16129032258064516, 'Consequential_Oversimplification_f1-score': 0.20833333333333331, 'Consequential_Oversimplification_support': 93.0, 'micro avg_precision': 0.29411764705882354, 'micro avg_recall': 0.16129032258064516, 'micro avg_f1-score': 0.20833333333333331, 'micro avg_support': 93.0, 'macro avg_precision': 0.29411764705882354, 'macro avg_recall': 0.16129032258064516, 'macro avg_f1-score': 0.20833333333333331, 'macro avg_support': 93.0, 'weighted avg_precision': 0.29411764705882354, 'weighted avg_recall': 0.16129032258064516, 'weighted avg_f1-score': 0.20833333333333334, 'weighted avg_support': 93.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 2}
{'results': [{'micro_f1': 0.8384185646755479, 'Consequential_Oversimplification_precision': 0.27450980392156865, 'Consequential_Oversimplification_recall': 0.13725490196078433, 'Consequential_Oversimplification_f1-score': 0.18300653594771246, 'Consequential_Oversimplification_support': 102.0, 'micro avg_precision': 0.27450980392156865, 'micro avg_recall': 0.13725490196078433, 'micro avg_f1-score': 0.18300653594771246, 'micro avg_support': 102.0, 'macro avg_precision': 0.27450980392156865, 'macro avg_recall': 0.13725490196078433, 'macro avg_f1-score': 0.18300653594771246, 'macro avg_support': 102.0, 'weighted avg_precision': 0.27450980392156865, 'weighted avg_recall': 0.13725490196078433, 'weighted avg_f1-score': 0.18300653594771246, 'weighted avg_support': 102.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 0}, {'micro_f1': 0.7782552642887838, 'Consequential_Oversimplification_precision': 0.17647058823529413, 'Consequential_Oversimplification_recall': 0.10975609756097561, 'Consequential_Oversimplification_f1-score': 0.13533834586466165, 'Consequential_Oversimplification_support': 82.0, 'micro avg_precision': 0.17647058823529413, 'micro avg_recall': 0.10975609756097561, 'micro avg_f1-score': 0.13533834586466165, 'micro avg_support': 82.0, 'macro avg_precision': 0.17647058823529413, 'macro avg_recall': 0.10975609756097561, 'macro avg_f1-score': 0.13533834586466165, 'macro avg_support': 82.0, 'weighted avg_precision': 0.17647058823529413, 'weighted avg_recall': 0.10975609756097561, 'weighted avg_f1-score': 0.13533834586466165, 'weighted avg_support': 82.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 1}, {'micro_f1': 0.8242372152986678, 'Consequential_Oversimplification_precision': 0.29411764705882354, 'Consequential_Oversimplification_recall': 0.16129032258064516, 'Consequential_Oversimplification_f1-score': 0.20833333333333331, 'Consequential_Oversimplification_support': 93.0, 'micro avg_precision': 0.29411764705882354, 'micro avg_recall': 0.16129032258064516, 'micro avg_f1-score': 0.20833333333333331, 'micro avg_support': 93.0, 'macro avg_precision': 0.29411764705882354, 'macro avg_recall': 0.16129032258064516, 'macro avg_f1-score': 0.20833333333333331, 'macro avg_support': 93.0, 'weighted avg_precision': 0.29411764705882354, 'weighted avg_recall': 0.16129032258064516, 'weighted avg_f1-score': 0.20833333333333334, 'weighted avg_support': 93.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 2}]}
Best model updated: current epoch macro f1 = 0.20833333333333331
{'micro_f1': 0.8384185646755479, 'Consequential_Oversimplification_precision': 0.35294117647058826, 'Consequential_Oversimplification_recall': 0.1978021978021978, 'Consequential_Oversimplification_f1-score': 0.2535211267605634, 'Consequential_Oversimplification_support': 91.0, 'micro avg_precision': 0.35294117647058826, 'micro avg_recall': 0.1978021978021978, 'micro avg_f1-score': 0.2535211267605634, 'micro avg_support': 91.0, 'macro avg_precision': 0.35294117647058826, 'macro avg_recall': 0.1978021978021978, 'macro avg_f1-score': 0.2535211267605634, 'macro avg_support': 91.0, 'weighted avg_precision': 0.35294117647058826, 'weighted avg_recall': 0.1978021978021978, 'weighted avg_f1-score': 0.2535211267605634, 'weighted avg_support': 91.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 3}
{'results': [{'micro_f1': 0.8384185646755479, 'Consequential_Oversimplification_precision': 0.27450980392156865, 'Consequential_Oversimplification_recall': 0.13725490196078433, 'Consequential_Oversimplification_f1-score': 0.18300653594771246, 'Consequential_Oversimplification_support': 102.0, 'micro avg_precision': 0.27450980392156865, 'micro avg_recall': 0.13725490196078433, 'micro avg_f1-score': 0.18300653594771246, 'micro avg_support': 102.0, 'macro avg_precision': 0.27450980392156865, 'macro avg_recall': 0.13725490196078433, 'macro avg_f1-score': 0.18300653594771246, 'macro avg_support': 102.0, 'weighted avg_precision': 0.27450980392156865, 'weighted avg_recall': 0.13725490196078433, 'weighted avg_f1-score': 0.18300653594771246, 'weighted avg_support': 102.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 0}, {'micro_f1': 0.7782552642887838, 'Consequential_Oversimplification_precision': 0.17647058823529413, 'Consequential_Oversimplification_recall': 0.10975609756097561, 'Consequential_Oversimplification_f1-score': 0.13533834586466165, 'Consequential_Oversimplification_support': 82.0, 'micro avg_precision': 0.17647058823529413, 'micro avg_recall': 0.10975609756097561, 'micro avg_f1-score': 0.13533834586466165, 'micro avg_support': 82.0, 'macro avg_precision': 0.17647058823529413, 'macro avg_recall': 0.10975609756097561, 'macro avg_f1-score': 0.13533834586466165, 'macro avg_support': 82.0, 'weighted avg_precision': 0.17647058823529413, 'weighted avg_recall': 0.10975609756097561, 'weighted avg_f1-score': 0.13533834586466165, 'weighted avg_support': 82.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 1}, {'micro_f1': 0.8242372152986678, 'Consequential_Oversimplification_precision': 0.29411764705882354, 'Consequential_Oversimplification_recall': 0.16129032258064516, 'Consequential_Oversimplification_f1-score': 0.20833333333333331, 'Consequential_Oversimplification_support': 93.0, 'micro avg_precision': 0.29411764705882354, 'micro avg_recall': 0.16129032258064516, 'micro avg_f1-score': 0.20833333333333331, 'micro avg_support': 93.0, 'macro avg_precision': 0.29411764705882354, 'macro avg_recall': 0.16129032258064516, 'macro avg_f1-score': 0.20833333333333331, 'macro avg_support': 93.0, 'weighted avg_precision': 0.29411764705882354, 'weighted avg_recall': 0.16129032258064516, 'weighted avg_f1-score': 0.20833333333333334, 'weighted avg_support': 93.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 2}, {'micro_f1': 0.8384185646755479, 'Consequential_Oversimplification_precision': 0.35294117647058826, 'Consequential_Oversimplification_recall': 0.1978021978021978, 'Consequential_Oversimplification_f1-score': 0.2535211267605634, 'Consequential_Oversimplification_support': 91.0, 'micro avg_precision': 0.35294117647058826, 'micro avg_recall': 0.1978021978021978, 'micro avg_f1-score': 0.2535211267605634, 'micro avg_support': 91.0, 'macro avg_precision': 0.35294117647058826, 'macro avg_recall': 0.1978021978021978, 'macro avg_f1-score': 0.2535211267605634, 'macro avg_support': 91.0, 'weighted avg_precision': 0.35294117647058826, 'weighted avg_recall': 0.1978021978021978, 'weighted avg_f1-score': 0.2535211267605634, 'weighted avg_support': 91.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 3}]}
Best model updated: current epoch macro f1 = 0.2535211267605634
{'micro_f1': 0.8336914482165879, 'Consequential_Oversimplification_precision': 0.43137254901960786, 'Consequential_Oversimplification_recall': 0.25882352941176473, 'Consequential_Oversimplification_f1-score': 0.32352941176470595, 'Consequential_Oversimplification_support': 85.0, 'micro avg_precision': 0.43137254901960786, 'micro avg_recall': 0.25882352941176473, 'micro avg_f1-score': 0.32352941176470595, 'micro avg_support': 85.0, 'macro avg_precision': 0.43137254901960786, 'macro avg_recall': 0.25882352941176473, 'macro avg_f1-score': 0.32352941176470595, 'macro avg_support': 85.0, 'weighted avg_precision': 0.4313725490196079, 'weighted avg_recall': 0.25882352941176473, 'weighted avg_f1-score': 0.32352941176470595, 'weighted avg_support': 85.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 4}
{'results': [{'micro_f1': 0.8384185646755479, 'Consequential_Oversimplification_precision': 0.27450980392156865, 'Consequential_Oversimplification_recall': 0.13725490196078433, 'Consequential_Oversimplification_f1-score': 0.18300653594771246, 'Consequential_Oversimplification_support': 102.0, 'micro avg_precision': 0.27450980392156865, 'micro avg_recall': 0.13725490196078433, 'micro avg_f1-score': 0.18300653594771246, 'micro avg_support': 102.0, 'macro avg_precision': 0.27450980392156865, 'macro avg_recall': 0.13725490196078433, 'macro avg_f1-score': 0.18300653594771246, 'macro avg_support': 102.0, 'weighted avg_precision': 0.27450980392156865, 'weighted avg_recall': 0.13725490196078433, 'weighted avg_f1-score': 0.18300653594771246, 'weighted avg_support': 102.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 0}, {'micro_f1': 0.7782552642887838, 'Consequential_Oversimplification_precision': 0.17647058823529413, 'Consequential_Oversimplification_recall': 0.10975609756097561, 'Consequential_Oversimplification_f1-score': 0.13533834586466165, 'Consequential_Oversimplification_support': 82.0, 'micro avg_precision': 0.17647058823529413, 'micro avg_recall': 0.10975609756097561, 'micro avg_f1-score': 0.13533834586466165, 'micro avg_support': 82.0, 'macro avg_precision': 0.17647058823529413, 'macro avg_recall': 0.10975609756097561, 'macro avg_f1-score': 0.13533834586466165, 'macro avg_support': 82.0, 'weighted avg_precision': 0.17647058823529413, 'weighted avg_recall': 0.10975609756097561, 'weighted avg_f1-score': 0.13533834586466165, 'weighted avg_support': 82.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 1}, {'micro_f1': 0.8242372152986678, 'Consequential_Oversimplification_precision': 0.29411764705882354, 'Consequential_Oversimplification_recall': 0.16129032258064516, 'Consequential_Oversimplification_f1-score': 0.20833333333333331, 'Consequential_Oversimplification_support': 93.0, 'micro avg_precision': 0.29411764705882354, 'micro avg_recall': 0.16129032258064516, 'micro avg_f1-score': 0.20833333333333331, 'micro avg_support': 93.0, 'macro avg_precision': 0.29411764705882354, 'macro avg_recall': 0.16129032258064516, 'macro avg_f1-score': 0.20833333333333331, 'macro avg_support': 93.0, 'weighted avg_precision': 0.29411764705882354, 'weighted avg_recall': 0.16129032258064516, 'weighted avg_f1-score': 0.20833333333333334, 'weighted avg_support': 93.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 2}, {'micro_f1': 0.8384185646755479, 'Consequential_Oversimplification_precision': 0.35294117647058826, 'Consequential_Oversimplification_recall': 0.1978021978021978, 'Consequential_Oversimplification_f1-score': 0.2535211267605634, 'Consequential_Oversimplification_support': 91.0, 'micro avg_precision': 0.35294117647058826, 'micro avg_recall': 0.1978021978021978, 'micro avg_f1-score': 0.2535211267605634, 'micro avg_support': 91.0, 'macro avg_precision': 0.35294117647058826, 'macro avg_recall': 0.1978021978021978, 'macro avg_f1-score': 0.2535211267605634, 'macro avg_support': 91.0, 'weighted avg_precision': 0.35294117647058826, 'weighted avg_recall': 0.1978021978021978, 'weighted avg_f1-score': 0.2535211267605634, 'weighted avg_support': 91.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 3}, {'micro_f1': 0.8336914482165879, 'Consequential_Oversimplification_precision': 0.43137254901960786, 'Consequential_Oversimplification_recall': 0.25882352941176473, 'Consequential_Oversimplification_f1-score': 0.32352941176470595, 'Consequential_Oversimplification_support': 85.0, 'micro avg_precision': 0.43137254901960786, 'micro avg_recall': 0.25882352941176473, 'micro avg_f1-score': 0.32352941176470595, 'micro avg_support': 85.0, 'macro avg_precision': 0.43137254901960786, 'macro avg_recall': 0.25882352941176473, 'macro avg_f1-score': 0.32352941176470595, 'macro avg_support': 85.0, 'weighted avg_precision': 0.4313725490196079, 'weighted avg_recall': 0.25882352941176473, 'weighted avg_f1-score': 0.32352941176470595, 'weighted avg_support': 85.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 4}]}
Best model updated: current epoch macro f1 = 0.32352941176470595
{'micro_f1': 0.8250966910184787, 'Consequential_Oversimplification_precision': 0.37254901960784315, 'Consequential_Oversimplification_recall': 0.2111111111111111, 'Consequential_Oversimplification_f1-score': 0.2695035460992908, 'Consequential_Oversimplification_support': 90.0, 'micro avg_precision': 0.37254901960784315, 'micro avg_recall': 0.2111111111111111, 'micro avg_f1-score': 0.2695035460992908, 'micro avg_support': 90.0, 'macro avg_precision': 0.37254901960784315, 'macro avg_recall': 0.2111111111111111, 'macro avg_f1-score': 0.2695035460992908, 'macro avg_support': 90.0, 'weighted avg_precision': 0.37254901960784315, 'weighted avg_recall': 0.2111111111111111, 'weighted avg_f1-score': 0.2695035460992908, 'weighted avg_support': 90.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 5}
{'results': [{'micro_f1': 0.8384185646755479, 'Consequential_Oversimplification_precision': 0.27450980392156865, 'Consequential_Oversimplification_recall': 0.13725490196078433, 'Consequential_Oversimplification_f1-score': 0.18300653594771246, 'Consequential_Oversimplification_support': 102.0, 'micro avg_precision': 0.27450980392156865, 'micro avg_recall': 0.13725490196078433, 'micro avg_f1-score': 0.18300653594771246, 'micro avg_support': 102.0, 'macro avg_precision': 0.27450980392156865, 'macro avg_recall': 0.13725490196078433, 'macro avg_f1-score': 0.18300653594771246, 'macro avg_support': 102.0, 'weighted avg_precision': 0.27450980392156865, 'weighted avg_recall': 0.13725490196078433, 'weighted avg_f1-score': 0.18300653594771246, 'weighted avg_support': 102.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 0}, {'micro_f1': 0.7782552642887838, 'Consequential_Oversimplification_precision': 0.17647058823529413, 'Consequential_Oversimplification_recall': 0.10975609756097561, 'Consequential_Oversimplification_f1-score': 0.13533834586466165, 'Consequential_Oversimplification_support': 82.0, 'micro avg_precision': 0.17647058823529413, 'micro avg_recall': 0.10975609756097561, 'micro avg_f1-score': 0.13533834586466165, 'micro avg_support': 82.0, 'macro avg_precision': 0.17647058823529413, 'macro avg_recall': 0.10975609756097561, 'macro avg_f1-score': 0.13533834586466165, 'macro avg_support': 82.0, 'weighted avg_precision': 0.17647058823529413, 'weighted avg_recall': 0.10975609756097561, 'weighted avg_f1-score': 0.13533834586466165, 'weighted avg_support': 82.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 1}, {'micro_f1': 0.8242372152986678, 'Consequential_Oversimplification_precision': 0.29411764705882354, 'Consequential_Oversimplification_recall': 0.16129032258064516, 'Consequential_Oversimplification_f1-score': 0.20833333333333331, 'Consequential_Oversimplification_support': 93.0, 'micro avg_precision': 0.29411764705882354, 'micro avg_recall': 0.16129032258064516, 'micro avg_f1-score': 0.20833333333333331, 'micro avg_support': 93.0, 'macro avg_precision': 0.29411764705882354, 'macro avg_recall': 0.16129032258064516, 'macro avg_f1-score': 0.20833333333333331, 'macro avg_support': 93.0, 'weighted avg_precision': 0.29411764705882354, 'weighted avg_recall': 0.16129032258064516, 'weighted avg_f1-score': 0.20833333333333334, 'weighted avg_support': 93.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 2}, {'micro_f1': 0.8384185646755479, 'Consequential_Oversimplification_precision': 0.35294117647058826, 'Consequential_Oversimplification_recall': 0.1978021978021978, 'Consequential_Oversimplification_f1-score': 0.2535211267605634, 'Consequential_Oversimplification_support': 91.0, 'micro avg_precision': 0.35294117647058826, 'micro avg_recall': 0.1978021978021978, 'micro avg_f1-score': 0.2535211267605634, 'micro avg_support': 91.0, 'macro avg_precision': 0.35294117647058826, 'macro avg_recall': 0.1978021978021978, 'macro avg_f1-score': 0.2535211267605634, 'macro avg_support': 91.0, 'weighted avg_precision': 0.35294117647058826, 'weighted avg_recall': 0.1978021978021978, 'weighted avg_f1-score': 0.2535211267605634, 'weighted avg_support': 91.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 3}, {'micro_f1': 0.8336914482165879, 'Consequential_Oversimplification_precision': 0.43137254901960786, 'Consequential_Oversimplification_recall': 0.25882352941176473, 'Consequential_Oversimplification_f1-score': 0.32352941176470595, 'Consequential_Oversimplification_support': 85.0, 'micro avg_precision': 0.43137254901960786, 'micro avg_recall': 0.25882352941176473, 'micro avg_f1-score': 0.32352941176470595, 'micro avg_support': 85.0, 'macro avg_precision': 0.43137254901960786, 'macro avg_recall': 0.25882352941176473, 'macro avg_f1-score': 0.32352941176470595, 'macro avg_support': 85.0, 'weighted avg_precision': 0.4313725490196079, 'weighted avg_recall': 0.25882352941176473, 'weighted avg_f1-score': 0.32352941176470595, 'weighted avg_support': 85.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 4}, {'micro_f1': 0.8250966910184787, 'Consequential_Oversimplification_precision': 0.37254901960784315, 'Consequential_Oversimplification_recall': 0.2111111111111111, 'Consequential_Oversimplification_f1-score': 0.2695035460992908, 'Consequential_Oversimplification_support': 90.0, 'micro avg_precision': 0.37254901960784315, 'micro avg_recall': 0.2111111111111111, 'micro avg_f1-score': 0.2695035460992908, 'micro avg_support': 90.0, 'macro avg_precision': 0.37254901960784315, 'macro avg_recall': 0.2111111111111111, 'macro avg_f1-score': 0.2695035460992908, 'macro avg_support': 90.0, 'weighted avg_precision': 0.37254901960784315, 'weighted avg_recall': 0.2111111111111111, 'weighted avg_f1-score': 0.2695035460992908, 'weighted avg_support': 90.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 5}]}
{'micro_f1': 0.842286205414697, 'Consequential_Oversimplification_precision': 0.43137254901960786, 'Consequential_Oversimplification_recall': 0.2716049382716049, 'Consequential_Oversimplification_f1-score': 0.3333333333333333, 'Consequential_Oversimplification_support': 81.0, 'micro avg_precision': 0.43137254901960786, 'micro avg_recall': 0.2716049382716049, 'micro avg_f1-score': 0.3333333333333333, 'micro avg_support': 81.0, 'macro avg_precision': 0.43137254901960786, 'macro avg_recall': 0.2716049382716049, 'macro avg_f1-score': 0.3333333333333333, 'macro avg_support': 81.0, 'weighted avg_precision': 0.43137254901960786, 'weighted avg_recall': 0.2716049382716049, 'weighted avg_f1-score': 0.3333333333333333, 'weighted avg_support': 81.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 6}
{'results': [{'micro_f1': 0.8384185646755479, 'Consequential_Oversimplification_precision': 0.27450980392156865, 'Consequential_Oversimplification_recall': 0.13725490196078433, 'Consequential_Oversimplification_f1-score': 0.18300653594771246, 'Consequential_Oversimplification_support': 102.0, 'micro avg_precision': 0.27450980392156865, 'micro avg_recall': 0.13725490196078433, 'micro avg_f1-score': 0.18300653594771246, 'micro avg_support': 102.0, 'macro avg_precision': 0.27450980392156865, 'macro avg_recall': 0.13725490196078433, 'macro avg_f1-score': 0.18300653594771246, 'macro avg_support': 102.0, 'weighted avg_precision': 0.27450980392156865, 'weighted avg_recall': 0.13725490196078433, 'weighted avg_f1-score': 0.18300653594771246, 'weighted avg_support': 102.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 0}, {'micro_f1': 0.7782552642887838, 'Consequential_Oversimplification_precision': 0.17647058823529413, 'Consequential_Oversimplification_recall': 0.10975609756097561, 'Consequential_Oversimplification_f1-score': 0.13533834586466165, 'Consequential_Oversimplification_support': 82.0, 'micro avg_precision': 0.17647058823529413, 'micro avg_recall': 0.10975609756097561, 'micro avg_f1-score': 0.13533834586466165, 'micro avg_support': 82.0, 'macro avg_precision': 0.17647058823529413, 'macro avg_recall': 0.10975609756097561, 'macro avg_f1-score': 0.13533834586466165, 'macro avg_support': 82.0, 'weighted avg_precision': 0.17647058823529413, 'weighted avg_recall': 0.10975609756097561, 'weighted avg_f1-score': 0.13533834586466165, 'weighted avg_support': 82.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 1}, {'micro_f1': 0.8242372152986678, 'Consequential_Oversimplification_precision': 0.29411764705882354, 'Consequential_Oversimplification_recall': 0.16129032258064516, 'Consequential_Oversimplification_f1-score': 0.20833333333333331, 'Consequential_Oversimplification_support': 93.0, 'micro avg_precision': 0.29411764705882354, 'micro avg_recall': 0.16129032258064516, 'micro avg_f1-score': 0.20833333333333331, 'micro avg_support': 93.0, 'macro avg_precision': 0.29411764705882354, 'macro avg_recall': 0.16129032258064516, 'macro avg_f1-score': 0.20833333333333331, 'macro avg_support': 93.0, 'weighted avg_precision': 0.29411764705882354, 'weighted avg_recall': 0.16129032258064516, 'weighted avg_f1-score': 0.20833333333333334, 'weighted avg_support': 93.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 2}, {'micro_f1': 0.8384185646755479, 'Consequential_Oversimplification_precision': 0.35294117647058826, 'Consequential_Oversimplification_recall': 0.1978021978021978, 'Consequential_Oversimplification_f1-score': 0.2535211267605634, 'Consequential_Oversimplification_support': 91.0, 'micro avg_precision': 0.35294117647058826, 'micro avg_recall': 0.1978021978021978, 'micro avg_f1-score': 0.2535211267605634, 'micro avg_support': 91.0, 'macro avg_precision': 0.35294117647058826, 'macro avg_recall': 0.1978021978021978, 'macro avg_f1-score': 0.2535211267605634, 'macro avg_support': 91.0, 'weighted avg_precision': 0.35294117647058826, 'weighted avg_recall': 0.1978021978021978, 'weighted avg_f1-score': 0.2535211267605634, 'weighted avg_support': 91.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 3}, {'micro_f1': 0.8336914482165879, 'Consequential_Oversimplification_precision': 0.43137254901960786, 'Consequential_Oversimplification_recall': 0.25882352941176473, 'Consequential_Oversimplification_f1-score': 0.32352941176470595, 'Consequential_Oversimplification_support': 85.0, 'micro avg_precision': 0.43137254901960786, 'micro avg_recall': 0.25882352941176473, 'micro avg_f1-score': 0.32352941176470595, 'micro avg_support': 85.0, 'macro avg_precision': 0.43137254901960786, 'macro avg_recall': 0.25882352941176473, 'macro avg_f1-score': 0.32352941176470595, 'macro avg_support': 85.0, 'weighted avg_precision': 0.4313725490196079, 'weighted avg_recall': 0.25882352941176473, 'weighted avg_f1-score': 0.32352941176470595, 'weighted avg_support': 85.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 4}, {'micro_f1': 0.8250966910184787, 'Consequential_Oversimplification_precision': 0.37254901960784315, 'Consequential_Oversimplification_recall': 0.2111111111111111, 'Consequential_Oversimplification_f1-score': 0.2695035460992908, 'Consequential_Oversimplification_support': 90.0, 'micro avg_precision': 0.37254901960784315, 'micro avg_recall': 0.2111111111111111, 'micro avg_f1-score': 0.2695035460992908, 'micro avg_support': 90.0, 'macro avg_precision': 0.37254901960784315, 'macro avg_recall': 0.2111111111111111, 'macro avg_f1-score': 0.2695035460992908, 'macro avg_support': 90.0, 'weighted avg_precision': 0.37254901960784315, 'weighted avg_recall': 0.2111111111111111, 'weighted avg_f1-score': 0.2695035460992908, 'weighted avg_support': 90.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 5}, {'micro_f1': 0.842286205414697, 'Consequential_Oversimplification_precision': 0.43137254901960786, 'Consequential_Oversimplification_recall': 0.2716049382716049, 'Consequential_Oversimplification_f1-score': 0.3333333333333333, 'Consequential_Oversimplification_support': 81.0, 'micro avg_precision': 0.43137254901960786, 'micro avg_recall': 0.2716049382716049, 'micro avg_f1-score': 0.3333333333333333, 'micro avg_support': 81.0, 'macro avg_precision': 0.43137254901960786, 'macro avg_recall': 0.2716049382716049, 'macro avg_f1-score': 0.3333333333333333, 'macro avg_support': 81.0, 'weighted avg_precision': 0.43137254901960786, 'weighted avg_recall': 0.2716049382716049, 'weighted avg_f1-score': 0.3333333333333333, 'weighted avg_support': 81.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 6}]}
Best model updated: current epoch macro f1 = 0.3333333333333333
{'micro_f1': 0.8285345938977224, 'Consequential_Oversimplification_precision': 0.39215686274509803, 'Consequential_Oversimplification_recall': 0.23255813953488372, 'Consequential_Oversimplification_f1-score': 0.291970802919708, 'Consequential_Oversimplification_support': 86.0, 'micro avg_precision': 0.39215686274509803, 'micro avg_recall': 0.23255813953488372, 'micro avg_f1-score': 0.291970802919708, 'micro avg_support': 86.0, 'macro avg_precision': 0.39215686274509803, 'macro avg_recall': 0.23255813953488372, 'macro avg_f1-score': 0.291970802919708, 'macro avg_support': 86.0, 'weighted avg_precision': 0.39215686274509803, 'weighted avg_recall': 0.23255813953488372, 'weighted avg_f1-score': 0.291970802919708, 'weighted avg_support': 86.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 7}
{'results': [{'micro_f1': 0.8384185646755479, 'Consequential_Oversimplification_precision': 0.27450980392156865, 'Consequential_Oversimplification_recall': 0.13725490196078433, 'Consequential_Oversimplification_f1-score': 0.18300653594771246, 'Consequential_Oversimplification_support': 102.0, 'micro avg_precision': 0.27450980392156865, 'micro avg_recall': 0.13725490196078433, 'micro avg_f1-score': 0.18300653594771246, 'micro avg_support': 102.0, 'macro avg_precision': 0.27450980392156865, 'macro avg_recall': 0.13725490196078433, 'macro avg_f1-score': 0.18300653594771246, 'macro avg_support': 102.0, 'weighted avg_precision': 0.27450980392156865, 'weighted avg_recall': 0.13725490196078433, 'weighted avg_f1-score': 0.18300653594771246, 'weighted avg_support': 102.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 0}, {'micro_f1': 0.7782552642887838, 'Consequential_Oversimplification_precision': 0.17647058823529413, 'Consequential_Oversimplification_recall': 0.10975609756097561, 'Consequential_Oversimplification_f1-score': 0.13533834586466165, 'Consequential_Oversimplification_support': 82.0, 'micro avg_precision': 0.17647058823529413, 'micro avg_recall': 0.10975609756097561, 'micro avg_f1-score': 0.13533834586466165, 'micro avg_support': 82.0, 'macro avg_precision': 0.17647058823529413, 'macro avg_recall': 0.10975609756097561, 'macro avg_f1-score': 0.13533834586466165, 'macro avg_support': 82.0, 'weighted avg_precision': 0.17647058823529413, 'weighted avg_recall': 0.10975609756097561, 'weighted avg_f1-score': 0.13533834586466165, 'weighted avg_support': 82.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 1}, {'micro_f1': 0.8242372152986678, 'Consequential_Oversimplification_precision': 0.29411764705882354, 'Consequential_Oversimplification_recall': 0.16129032258064516, 'Consequential_Oversimplification_f1-score': 0.20833333333333331, 'Consequential_Oversimplification_support': 93.0, 'micro avg_precision': 0.29411764705882354, 'micro avg_recall': 0.16129032258064516, 'micro avg_f1-score': 0.20833333333333331, 'micro avg_support': 93.0, 'macro avg_precision': 0.29411764705882354, 'macro avg_recall': 0.16129032258064516, 'macro avg_f1-score': 0.20833333333333331, 'macro avg_support': 93.0, 'weighted avg_precision': 0.29411764705882354, 'weighted avg_recall': 0.16129032258064516, 'weighted avg_f1-score': 0.20833333333333334, 'weighted avg_support': 93.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 2}, {'micro_f1': 0.8384185646755479, 'Consequential_Oversimplification_precision': 0.35294117647058826, 'Consequential_Oversimplification_recall': 0.1978021978021978, 'Consequential_Oversimplification_f1-score': 0.2535211267605634, 'Consequential_Oversimplification_support': 91.0, 'micro avg_precision': 0.35294117647058826, 'micro avg_recall': 0.1978021978021978, 'micro avg_f1-score': 0.2535211267605634, 'micro avg_support': 91.0, 'macro avg_precision': 0.35294117647058826, 'macro avg_recall': 0.1978021978021978, 'macro avg_f1-score': 0.2535211267605634, 'macro avg_support': 91.0, 'weighted avg_precision': 0.35294117647058826, 'weighted avg_recall': 0.1978021978021978, 'weighted avg_f1-score': 0.2535211267605634, 'weighted avg_support': 91.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 3}, {'micro_f1': 0.8336914482165879, 'Consequential_Oversimplification_precision': 0.43137254901960786, 'Consequential_Oversimplification_recall': 0.25882352941176473, 'Consequential_Oversimplification_f1-score': 0.32352941176470595, 'Consequential_Oversimplification_support': 85.0, 'micro avg_precision': 0.43137254901960786, 'micro avg_recall': 0.25882352941176473, 'micro avg_f1-score': 0.32352941176470595, 'micro avg_support': 85.0, 'macro avg_precision': 0.43137254901960786, 'macro avg_recall': 0.25882352941176473, 'macro avg_f1-score': 0.32352941176470595, 'macro avg_support': 85.0, 'weighted avg_precision': 0.4313725490196079, 'weighted avg_recall': 0.25882352941176473, 'weighted avg_f1-score': 0.32352941176470595, 'weighted avg_support': 85.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 4}, {'micro_f1': 0.8250966910184787, 'Consequential_Oversimplification_precision': 0.37254901960784315, 'Consequential_Oversimplification_recall': 0.2111111111111111, 'Consequential_Oversimplification_f1-score': 0.2695035460992908, 'Consequential_Oversimplification_support': 90.0, 'micro avg_precision': 0.37254901960784315, 'micro avg_recall': 0.2111111111111111, 'micro avg_f1-score': 0.2695035460992908, 'micro avg_support': 90.0, 'macro avg_precision': 0.37254901960784315, 'macro avg_recall': 0.2111111111111111, 'macro avg_f1-score': 0.2695035460992908, 'macro avg_support': 90.0, 'weighted avg_precision': 0.37254901960784315, 'weighted avg_recall': 0.2111111111111111, 'weighted avg_f1-score': 0.2695035460992908, 'weighted avg_support': 90.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 5}, {'micro_f1': 0.842286205414697, 'Consequential_Oversimplification_precision': 0.43137254901960786, 'Consequential_Oversimplification_recall': 0.2716049382716049, 'Consequential_Oversimplification_f1-score': 0.3333333333333333, 'Consequential_Oversimplification_support': 81.0, 'micro avg_precision': 0.43137254901960786, 'micro avg_recall': 0.2716049382716049, 'micro avg_f1-score': 0.3333333333333333, 'micro avg_support': 81.0, 'macro avg_precision': 0.43137254901960786, 'macro avg_recall': 0.2716049382716049, 'macro avg_f1-score': 0.3333333333333333, 'macro avg_support': 81.0, 'weighted avg_precision': 0.43137254901960786, 'weighted avg_recall': 0.2716049382716049, 'weighted avg_f1-score': 0.3333333333333333, 'weighted avg_support': 81.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 6}, {'micro_f1': 0.8285345938977224, 'Consequential_Oversimplification_precision': 0.39215686274509803, 'Consequential_Oversimplification_recall': 0.23255813953488372, 'Consequential_Oversimplification_f1-score': 0.291970802919708, 'Consequential_Oversimplification_support': 86.0, 'micro avg_precision': 0.39215686274509803, 'micro avg_recall': 0.23255813953488372, 'micro avg_f1-score': 0.291970802919708, 'micro avg_support': 86.0, 'macro avg_precision': 0.39215686274509803, 'macro avg_recall': 0.23255813953488372, 'macro avg_f1-score': 0.291970802919708, 'macro avg_support': 86.0, 'weighted avg_precision': 0.39215686274509803, 'weighted avg_recall': 0.23255813953488372, 'weighted avg_f1-score': 0.291970802919708, 'weighted avg_support': 86.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 7}]}
{'micro_f1': 0.8379888268156425, 'Consequential_Oversimplification_precision': 0.49019607843137253, 'Consequential_Oversimplification_recall': 0.29069767441860467, 'Consequential_Oversimplification_f1-score': 0.36496350364963503, 'Consequential_Oversimplification_support': 86.0, 'micro avg_precision': 0.49019607843137253, 'micro avg_recall': 0.29069767441860467, 'micro avg_f1-score': 0.36496350364963503, 'micro avg_support': 86.0, 'macro avg_precision': 0.49019607843137253, 'macro avg_recall': 0.29069767441860467, 'macro avg_f1-score': 0.36496350364963503, 'macro avg_support': 86.0, 'weighted avg_precision': 0.49019607843137253, 'weighted avg_recall': 0.29069767441860467, 'weighted avg_f1-score': 0.36496350364963503, 'weighted avg_support': 86.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 8}
{'results': [{'micro_f1': 0.8384185646755479, 'Consequential_Oversimplification_precision': 0.27450980392156865, 'Consequential_Oversimplification_recall': 0.13725490196078433, 'Consequential_Oversimplification_f1-score': 0.18300653594771246, 'Consequential_Oversimplification_support': 102.0, 'micro avg_precision': 0.27450980392156865, 'micro avg_recall': 0.13725490196078433, 'micro avg_f1-score': 0.18300653594771246, 'micro avg_support': 102.0, 'macro avg_precision': 0.27450980392156865, 'macro avg_recall': 0.13725490196078433, 'macro avg_f1-score': 0.18300653594771246, 'macro avg_support': 102.0, 'weighted avg_precision': 0.27450980392156865, 'weighted avg_recall': 0.13725490196078433, 'weighted avg_f1-score': 0.18300653594771246, 'weighted avg_support': 102.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 0}, {'micro_f1': 0.7782552642887838, 'Consequential_Oversimplification_precision': 0.17647058823529413, 'Consequential_Oversimplification_recall': 0.10975609756097561, 'Consequential_Oversimplification_f1-score': 0.13533834586466165, 'Consequential_Oversimplification_support': 82.0, 'micro avg_precision': 0.17647058823529413, 'micro avg_recall': 0.10975609756097561, 'micro avg_f1-score': 0.13533834586466165, 'micro avg_support': 82.0, 'macro avg_precision': 0.17647058823529413, 'macro avg_recall': 0.10975609756097561, 'macro avg_f1-score': 0.13533834586466165, 'macro avg_support': 82.0, 'weighted avg_precision': 0.17647058823529413, 'weighted avg_recall': 0.10975609756097561, 'weighted avg_f1-score': 0.13533834586466165, 'weighted avg_support': 82.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 1}, {'micro_f1': 0.8242372152986678, 'Consequential_Oversimplification_precision': 0.29411764705882354, 'Consequential_Oversimplification_recall': 0.16129032258064516, 'Consequential_Oversimplification_f1-score': 0.20833333333333331, 'Consequential_Oversimplification_support': 93.0, 'micro avg_precision': 0.29411764705882354, 'micro avg_recall': 0.16129032258064516, 'micro avg_f1-score': 0.20833333333333331, 'micro avg_support': 93.0, 'macro avg_precision': 0.29411764705882354, 'macro avg_recall': 0.16129032258064516, 'macro avg_f1-score': 0.20833333333333331, 'macro avg_support': 93.0, 'weighted avg_precision': 0.29411764705882354, 'weighted avg_recall': 0.16129032258064516, 'weighted avg_f1-score': 0.20833333333333334, 'weighted avg_support': 93.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 2}, {'micro_f1': 0.8384185646755479, 'Consequential_Oversimplification_precision': 0.35294117647058826, 'Consequential_Oversimplification_recall': 0.1978021978021978, 'Consequential_Oversimplification_f1-score': 0.2535211267605634, 'Consequential_Oversimplification_support': 91.0, 'micro avg_precision': 0.35294117647058826, 'micro avg_recall': 0.1978021978021978, 'micro avg_f1-score': 0.2535211267605634, 'micro avg_support': 91.0, 'macro avg_precision': 0.35294117647058826, 'macro avg_recall': 0.1978021978021978, 'macro avg_f1-score': 0.2535211267605634, 'macro avg_support': 91.0, 'weighted avg_precision': 0.35294117647058826, 'weighted avg_recall': 0.1978021978021978, 'weighted avg_f1-score': 0.2535211267605634, 'weighted avg_support': 91.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 3}, {'micro_f1': 0.8336914482165879, 'Consequential_Oversimplification_precision': 0.43137254901960786, 'Consequential_Oversimplification_recall': 0.25882352941176473, 'Consequential_Oversimplification_f1-score': 0.32352941176470595, 'Consequential_Oversimplification_support': 85.0, 'micro avg_precision': 0.43137254901960786, 'micro avg_recall': 0.25882352941176473, 'micro avg_f1-score': 0.32352941176470595, 'micro avg_support': 85.0, 'macro avg_precision': 0.43137254901960786, 'macro avg_recall': 0.25882352941176473, 'macro avg_f1-score': 0.32352941176470595, 'macro avg_support': 85.0, 'weighted avg_precision': 0.4313725490196079, 'weighted avg_recall': 0.25882352941176473, 'weighted avg_f1-score': 0.32352941176470595, 'weighted avg_support': 85.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 4}, {'micro_f1': 0.8250966910184787, 'Consequential_Oversimplification_precision': 0.37254901960784315, 'Consequential_Oversimplification_recall': 0.2111111111111111, 'Consequential_Oversimplification_f1-score': 0.2695035460992908, 'Consequential_Oversimplification_support': 90.0, 'micro avg_precision': 0.37254901960784315, 'micro avg_recall': 0.2111111111111111, 'micro avg_f1-score': 0.2695035460992908, 'micro avg_support': 90.0, 'macro avg_precision': 0.37254901960784315, 'macro avg_recall': 0.2111111111111111, 'macro avg_f1-score': 0.2695035460992908, 'macro avg_support': 90.0, 'weighted avg_precision': 0.37254901960784315, 'weighted avg_recall': 0.2111111111111111, 'weighted avg_f1-score': 0.2695035460992908, 'weighted avg_support': 90.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 5}, {'micro_f1': 0.842286205414697, 'Consequential_Oversimplification_precision': 0.43137254901960786, 'Consequential_Oversimplification_recall': 0.2716049382716049, 'Consequential_Oversimplification_f1-score': 0.3333333333333333, 'Consequential_Oversimplification_support': 81.0, 'micro avg_precision': 0.43137254901960786, 'micro avg_recall': 0.2716049382716049, 'micro avg_f1-score': 0.3333333333333333, 'micro avg_support': 81.0, 'macro avg_precision': 0.43137254901960786, 'macro avg_recall': 0.2716049382716049, 'macro avg_f1-score': 0.3333333333333333, 'macro avg_support': 81.0, 'weighted avg_precision': 0.43137254901960786, 'weighted avg_recall': 0.2716049382716049, 'weighted avg_f1-score': 0.3333333333333333, 'weighted avg_support': 81.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 6}, {'micro_f1': 0.8285345938977224, 'Consequential_Oversimplification_precision': 0.39215686274509803, 'Consequential_Oversimplification_recall': 0.23255813953488372, 'Consequential_Oversimplification_f1-score': 0.291970802919708, 'Consequential_Oversimplification_support': 86.0, 'micro avg_precision': 0.39215686274509803, 'micro avg_recall': 0.23255813953488372, 'micro avg_f1-score': 0.291970802919708, 'micro avg_support': 86.0, 'macro avg_precision': 0.39215686274509803, 'macro avg_recall': 0.23255813953488372, 'macro avg_f1-score': 0.291970802919708, 'macro avg_support': 86.0, 'weighted avg_precision': 0.39215686274509803, 'weighted avg_recall': 0.23255813953488372, 'weighted avg_f1-score': 0.291970802919708, 'weighted avg_support': 86.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 7}, {'micro_f1': 0.8379888268156425, 'Consequential_Oversimplification_precision': 0.49019607843137253, 'Consequential_Oversimplification_recall': 0.29069767441860467, 'Consequential_Oversimplification_f1-score': 0.36496350364963503, 'Consequential_Oversimplification_support': 86.0, 'micro avg_precision': 0.49019607843137253, 'micro avg_recall': 0.29069767441860467, 'micro avg_f1-score': 0.36496350364963503, 'micro avg_support': 86.0, 'macro avg_precision': 0.49019607843137253, 'macro avg_recall': 0.29069767441860467, 'macro avg_f1-score': 0.36496350364963503, 'macro avg_support': 86.0, 'weighted avg_precision': 0.49019607843137253, 'weighted avg_recall': 0.29069767441860467, 'weighted avg_f1-score': 0.36496350364963503, 'weighted avg_support': 86.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 8}]}
Best model updated: current epoch macro f1 = 0.36496350364963503
{'micro_f1': 0.8349806617963043, 'Consequential_Oversimplification_precision': 0.5098039215686274, 'Consequential_Oversimplification_recall': 0.3132530120481928, 'Consequential_Oversimplification_f1-score': 0.3880597014925373, 'Consequential_Oversimplification_support': 83.0, 'micro avg_precision': 0.5098039215686274, 'micro avg_recall': 0.3132530120481928, 'micro avg_f1-score': 0.3880597014925373, 'micro avg_support': 83.0, 'macro avg_precision': 0.5098039215686274, 'macro avg_recall': 0.3132530120481928, 'macro avg_f1-score': 0.3880597014925373, 'macro avg_support': 83.0, 'weighted avg_precision': 0.5098039215686274, 'weighted avg_recall': 0.3132530120481928, 'weighted avg_f1-score': 0.3880597014925374, 'weighted avg_support': 83.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 9}
{'results': [{'micro_f1': 0.8384185646755479, 'Consequential_Oversimplification_precision': 0.27450980392156865, 'Consequential_Oversimplification_recall': 0.13725490196078433, 'Consequential_Oversimplification_f1-score': 0.18300653594771246, 'Consequential_Oversimplification_support': 102.0, 'micro avg_precision': 0.27450980392156865, 'micro avg_recall': 0.13725490196078433, 'micro avg_f1-score': 0.18300653594771246, 'micro avg_support': 102.0, 'macro avg_precision': 0.27450980392156865, 'macro avg_recall': 0.13725490196078433, 'macro avg_f1-score': 0.18300653594771246, 'macro avg_support': 102.0, 'weighted avg_precision': 0.27450980392156865, 'weighted avg_recall': 0.13725490196078433, 'weighted avg_f1-score': 0.18300653594771246, 'weighted avg_support': 102.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 0}, {'micro_f1': 0.7782552642887838, 'Consequential_Oversimplification_precision': 0.17647058823529413, 'Consequential_Oversimplification_recall': 0.10975609756097561, 'Consequential_Oversimplification_f1-score': 0.13533834586466165, 'Consequential_Oversimplification_support': 82.0, 'micro avg_precision': 0.17647058823529413, 'micro avg_recall': 0.10975609756097561, 'micro avg_f1-score': 0.13533834586466165, 'micro avg_support': 82.0, 'macro avg_precision': 0.17647058823529413, 'macro avg_recall': 0.10975609756097561, 'macro avg_f1-score': 0.13533834586466165, 'macro avg_support': 82.0, 'weighted avg_precision': 0.17647058823529413, 'weighted avg_recall': 0.10975609756097561, 'weighted avg_f1-score': 0.13533834586466165, 'weighted avg_support': 82.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 1}, {'micro_f1': 0.8242372152986678, 'Consequential_Oversimplification_precision': 0.29411764705882354, 'Consequential_Oversimplification_recall': 0.16129032258064516, 'Consequential_Oversimplification_f1-score': 0.20833333333333331, 'Consequential_Oversimplification_support': 93.0, 'micro avg_precision': 0.29411764705882354, 'micro avg_recall': 0.16129032258064516, 'micro avg_f1-score': 0.20833333333333331, 'micro avg_support': 93.0, 'macro avg_precision': 0.29411764705882354, 'macro avg_recall': 0.16129032258064516, 'macro avg_f1-score': 0.20833333333333331, 'macro avg_support': 93.0, 'weighted avg_precision': 0.29411764705882354, 'weighted avg_recall': 0.16129032258064516, 'weighted avg_f1-score': 0.20833333333333334, 'weighted avg_support': 93.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 2}, {'micro_f1': 0.8384185646755479, 'Consequential_Oversimplification_precision': 0.35294117647058826, 'Consequential_Oversimplification_recall': 0.1978021978021978, 'Consequential_Oversimplification_f1-score': 0.2535211267605634, 'Consequential_Oversimplification_support': 91.0, 'micro avg_precision': 0.35294117647058826, 'micro avg_recall': 0.1978021978021978, 'micro avg_f1-score': 0.2535211267605634, 'micro avg_support': 91.0, 'macro avg_precision': 0.35294117647058826, 'macro avg_recall': 0.1978021978021978, 'macro avg_f1-score': 0.2535211267605634, 'macro avg_support': 91.0, 'weighted avg_precision': 0.35294117647058826, 'weighted avg_recall': 0.1978021978021978, 'weighted avg_f1-score': 0.2535211267605634, 'weighted avg_support': 91.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 3}, {'micro_f1': 0.8336914482165879, 'Consequential_Oversimplification_precision': 0.43137254901960786, 'Consequential_Oversimplification_recall': 0.25882352941176473, 'Consequential_Oversimplification_f1-score': 0.32352941176470595, 'Consequential_Oversimplification_support': 85.0, 'micro avg_precision': 0.43137254901960786, 'micro avg_recall': 0.25882352941176473, 'micro avg_f1-score': 0.32352941176470595, 'micro avg_support': 85.0, 'macro avg_precision': 0.43137254901960786, 'macro avg_recall': 0.25882352941176473, 'macro avg_f1-score': 0.32352941176470595, 'macro avg_support': 85.0, 'weighted avg_precision': 0.4313725490196079, 'weighted avg_recall': 0.25882352941176473, 'weighted avg_f1-score': 0.32352941176470595, 'weighted avg_support': 85.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 4}, {'micro_f1': 0.8250966910184787, 'Consequential_Oversimplification_precision': 0.37254901960784315, 'Consequential_Oversimplification_recall': 0.2111111111111111, 'Consequential_Oversimplification_f1-score': 0.2695035460992908, 'Consequential_Oversimplification_support': 90.0, 'micro avg_precision': 0.37254901960784315, 'micro avg_recall': 0.2111111111111111, 'micro avg_f1-score': 0.2695035460992908, 'micro avg_support': 90.0, 'macro avg_precision': 0.37254901960784315, 'macro avg_recall': 0.2111111111111111, 'macro avg_f1-score': 0.2695035460992908, 'macro avg_support': 90.0, 'weighted avg_precision': 0.37254901960784315, 'weighted avg_recall': 0.2111111111111111, 'weighted avg_f1-score': 0.2695035460992908, 'weighted avg_support': 90.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 5}, {'micro_f1': 0.842286205414697, 'Consequential_Oversimplification_precision': 0.43137254901960786, 'Consequential_Oversimplification_recall': 0.2716049382716049, 'Consequential_Oversimplification_f1-score': 0.3333333333333333, 'Consequential_Oversimplification_support': 81.0, 'micro avg_precision': 0.43137254901960786, 'micro avg_recall': 0.2716049382716049, 'micro avg_f1-score': 0.3333333333333333, 'micro avg_support': 81.0, 'macro avg_precision': 0.43137254901960786, 'macro avg_recall': 0.2716049382716049, 'macro avg_f1-score': 0.3333333333333333, 'macro avg_support': 81.0, 'weighted avg_precision': 0.43137254901960786, 'weighted avg_recall': 0.2716049382716049, 'weighted avg_f1-score': 0.3333333333333333, 'weighted avg_support': 81.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 6}, {'micro_f1': 0.8285345938977224, 'Consequential_Oversimplification_precision': 0.39215686274509803, 'Consequential_Oversimplification_recall': 0.23255813953488372, 'Consequential_Oversimplification_f1-score': 0.291970802919708, 'Consequential_Oversimplification_support': 86.0, 'micro avg_precision': 0.39215686274509803, 'micro avg_recall': 0.23255813953488372, 'micro avg_f1-score': 0.291970802919708, 'micro avg_support': 86.0, 'macro avg_precision': 0.39215686274509803, 'macro avg_recall': 0.23255813953488372, 'macro avg_f1-score': 0.291970802919708, 'macro avg_support': 86.0, 'weighted avg_precision': 0.39215686274509803, 'weighted avg_recall': 0.23255813953488372, 'weighted avg_f1-score': 0.291970802919708, 'weighted avg_support': 86.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 7}, {'micro_f1': 0.8379888268156425, 'Consequential_Oversimplification_precision': 0.49019607843137253, 'Consequential_Oversimplification_recall': 0.29069767441860467, 'Consequential_Oversimplification_f1-score': 0.36496350364963503, 'Consequential_Oversimplification_support': 86.0, 'micro avg_precision': 0.49019607843137253, 'micro avg_recall': 0.29069767441860467, 'micro avg_f1-score': 0.36496350364963503, 'micro avg_support': 86.0, 'macro avg_precision': 0.49019607843137253, 'macro avg_recall': 0.29069767441860467, 'macro avg_f1-score': 0.36496350364963503, 'macro avg_support': 86.0, 'weighted avg_precision': 0.49019607843137253, 'weighted avg_recall': 0.29069767441860467, 'weighted avg_f1-score': 0.36496350364963503, 'weighted avg_support': 86.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 8}, {'micro_f1': 0.8349806617963043, 'Consequential_Oversimplification_precision': 0.5098039215686274, 'Consequential_Oversimplification_recall': 0.3132530120481928, 'Consequential_Oversimplification_f1-score': 0.3880597014925373, 'Consequential_Oversimplification_support': 83.0, 'micro avg_precision': 0.5098039215686274, 'micro avg_recall': 0.3132530120481928, 'micro avg_f1-score': 0.3880597014925373, 'micro avg_support': 83.0, 'macro avg_precision': 0.5098039215686274, 'macro avg_recall': 0.3132530120481928, 'macro avg_f1-score': 0.3880597014925373, 'macro avg_support': 83.0, 'weighted avg_precision': 0.5098039215686274, 'weighted avg_recall': 0.3132530120481928, 'weighted avg_f1-score': 0.3880597014925374, 'weighted avg_support': 83.0, 'O_support': 976, 'B-Consequential_Oversimplification_support': 51, 'I-Consequential_Oversimplification_support': 1300, 'epoch': 9}]}
Best model updated: current epoch macro f1 = 0.3880597014925373
Saving model to directory: ./models/M2/2024-05-12-17-42-10_aug/mdeberta-v3-base_7_ME10_target=Consequential_Oversimplification_SUBSAMPLED_2024-05-12-17-42-10
Training model no. 8 of 23 for (8, 'Straw_Man') persuasion technique...
{'micro_f1': 0.7465488680287135, 'Straw_Man_precision': 0.044444444444444446, 'Straw_Man_recall': 0.02040816326530612, 'Straw_Man_f1-score': 0.02797202797202797, 'Straw_Man_support': 98.0, 'micro avg_precision': 0.044444444444444446, 'micro avg_recall': 0.02040816326530612, 'micro avg_f1-score': 0.02797202797202797, 'micro avg_support': 98.0, 'macro avg_precision': 0.044444444444444446, 'macro avg_recall': 0.02040816326530612, 'macro avg_f1-score': 0.02797202797202797, 'macro avg_support': 98.0, 'weighted avg_precision': 0.04444444444444445, 'weighted avg_recall': 0.02040816326530612, 'weighted avg_f1-score': 0.02797202797202797, 'weighted avg_support': 98.0, 'B-Straw_Man_support': 45, 'I-Straw_Man_support': 728, 'O_support': 1038, 'epoch': 0}
{'results': [{'micro_f1': 0.7465488680287135, 'Straw_Man_precision': 0.044444444444444446, 'Straw_Man_recall': 0.02040816326530612, 'Straw_Man_f1-score': 0.02797202797202797, 'Straw_Man_support': 98.0, 'micro avg_precision': 0.044444444444444446, 'micro avg_recall': 0.02040816326530612, 'micro avg_f1-score': 0.02797202797202797, 'micro avg_support': 98.0, 'macro avg_precision': 0.044444444444444446, 'macro avg_recall': 0.02040816326530612, 'macro avg_f1-score': 0.02797202797202797, 'macro avg_support': 98.0, 'weighted avg_precision': 0.04444444444444445, 'weighted avg_recall': 0.02040816326530612, 'weighted avg_f1-score': 0.02797202797202797, 'weighted avg_support': 98.0, 'B-Straw_Man_support': 45, 'I-Straw_Man_support': 728, 'O_support': 1038, 'epoch': 0}]}
Best model updated: current epoch macro f1 = 0.02797202797202797
{'micro_f1': 0.7498619547211486, 'Straw_Man_precision': 0.13333333333333333, 'Straw_Man_recall': 0.05405405405405406, 'Straw_Man_f1-score': 0.07692307692307693, 'Straw_Man_support': 111.0, 'micro avg_precision': 0.13333333333333333, 'micro avg_recall': 0.05405405405405406, 'micro avg_f1-score': 0.07692307692307693, 'micro avg_support': 111.0, 'macro avg_precision': 0.13333333333333333, 'macro avg_recall': 0.05405405405405406, 'macro avg_f1-score': 0.07692307692307693, 'macro avg_support': 111.0, 'weighted avg_precision': 0.13333333333333333, 'weighted avg_recall': 0.05405405405405406, 'weighted avg_f1-score': 0.07692307692307693, 'weighted avg_support': 111.0, 'B-Straw_Man_support': 45, 'I-Straw_Man_support': 728, 'O_support': 1038, 'epoch': 1}
{'results': [{'micro_f1': 0.7465488680287135, 'Straw_Man_precision': 0.044444444444444446, 'Straw_Man_recall': 0.02040816326530612, 'Straw_Man_f1-score': 0.02797202797202797, 'Straw_Man_support': 98.0, 'micro avg_precision': 0.044444444444444446, 'micro avg_recall': 0.02040816326530612, 'micro avg_f1-score': 0.02797202797202797, 'micro avg_support': 98.0, 'macro avg_precision': 0.044444444444444446, 'macro avg_recall': 0.02040816326530612, 'macro avg_f1-score': 0.02797202797202797, 'macro avg_support': 98.0, 'weighted avg_precision': 0.04444444444444445, 'weighted avg_recall': 0.02040816326530612, 'weighted avg_f1-score': 0.02797202797202797, 'weighted avg_support': 98.0, 'B-Straw_Man_support': 45, 'I-Straw_Man_support': 728, 'O_support': 1038, 'epoch': 0}, {'micro_f1': 0.7498619547211486, 'Straw_Man_precision': 0.13333333333333333, 'Straw_Man_recall': 0.05405405405405406, 'Straw_Man_f1-score': 0.07692307692307693, 'Straw_Man_support': 111.0, 'micro avg_precision': 0.13333333333333333, 'micro avg_recall': 0.05405405405405406, 'micro avg_f1-score': 0.07692307692307693, 'micro avg_support': 111.0, 'macro avg_precision': 0.13333333333333333, 'macro avg_recall': 0.05405405405405406, 'macro avg_f1-score': 0.07692307692307693, 'macro avg_support': 111.0, 'weighted avg_precision': 0.13333333333333333, 'weighted avg_recall': 0.05405405405405406, 'weighted avg_f1-score': 0.07692307692307693, 'weighted avg_support': 111.0, 'B-Straw_Man_support': 45, 'I-Straw_Man_support': 728, 'O_support': 1038, 'epoch': 1}]}
Best model updated: current epoch macro f1 = 0.07692307692307693
{'micro_f1': 0.7537272225289895, 'Straw_Man_precision': 0.2, 'Straw_Man_recall': 0.1323529411764706, 'Straw_Man_f1-score': 0.1592920353982301, 'Straw_Man_support': 68.0, 'micro avg_precision': 0.2, 'micro avg_recall': 0.1323529411764706, 'micro avg_f1-score': 0.1592920353982301, 'micro avg_support': 68.0, 'macro avg_precision': 0.2, 'macro avg_recall': 0.1323529411764706, 'macro avg_f1-score': 0.1592920353982301, 'macro avg_support': 68.0, 'weighted avg_precision': 0.2, 'weighted avg_recall': 0.1323529411764706, 'weighted avg_f1-score': 0.1592920353982301, 'weighted avg_support': 68.0, 'B-Straw_Man_support': 45, 'I-Straw_Man_support': 728, 'O_support': 1038, 'epoch': 2}
{'results': [{'micro_f1': 0.7465488680287135, 'Straw_Man_precision': 0.044444444444444446, 'Straw_Man_recall': 0.02040816326530612, 'Straw_Man_f1-score': 0.02797202797202797, 'Straw_Man_support': 98.0, 'micro avg_precision': 0.044444444444444446, 'micro avg_recall': 0.02040816326530612, 'micro avg_f1-score': 0.02797202797202797, 'micro avg_support': 98.0, 'macro avg_precision': 0.044444444444444446, 'macro avg_recall': 0.02040816326530612, 'macro avg_f1-score': 0.02797202797202797, 'macro avg_support': 98.0, 'weighted avg_precision': 0.04444444444444445, 'weighted avg_recall': 0.02040816326530612, 'weighted avg_f1-score': 0.02797202797202797, 'weighted avg_support': 98.0, 'B-Straw_Man_support': 45, 'I-Straw_Man_support': 728, 'O_support': 1038, 'epoch': 0}, {'micro_f1': 0.7498619547211486, 'Straw_Man_precision': 0.13333333333333333, 'Straw_Man_recall': 0.05405405405405406, 'Straw_Man_f1-score': 0.07692307692307693, 'Straw_Man_support': 111.0, 'micro avg_precision': 0.13333333333333333, 'micro avg_recall': 0.05405405405405406, 'micro avg_f1-score': 0.07692307692307693, 'micro avg_support': 111.0, 'macro avg_precision': 0.13333333333333333, 'macro avg_recall': 0.05405405405405406, 'macro avg_f1-score': 0.07692307692307693, 'macro avg_support': 111.0, 'weighted avg_precision': 0.13333333333333333, 'weighted avg_recall': 0.05405405405405406, 'weighted avg_f1-score': 0.07692307692307693, 'weighted avg_support': 111.0, 'B-Straw_Man_support': 45, 'I-Straw_Man_support': 728, 'O_support': 1038, 'epoch': 1}, {'micro_f1': 0.7537272225289895, 'Straw_Man_precision': 0.2, 'Straw_Man_recall': 0.1323529411764706, 'Straw_Man_f1-score': 0.1592920353982301, 'Straw_Man_support': 68.0, 'micro avg_precision': 0.2, 'micro avg_recall': 0.1323529411764706, 'micro avg_f1-score': 0.1592920353982301, 'micro avg_support': 68.0, 'macro avg_precision': 0.2, 'macro avg_recall': 0.1323529411764706, 'macro avg_f1-score': 0.1592920353982301, 'macro avg_support': 68.0, 'weighted avg_precision': 0.2, 'weighted avg_recall': 0.1323529411764706, 'weighted avg_f1-score': 0.1592920353982301, 'weighted avg_support': 68.0, 'B-Straw_Man_support': 45, 'I-Straw_Man_support': 728, 'O_support': 1038, 'epoch': 2}]}
Best model updated: current epoch macro f1 = 0.1592920353982301
{'micro_f1': 0.7725013804527885, 'Straw_Man_precision': 0.24444444444444444, 'Straw_Man_recall': 0.1506849315068493, 'Straw_Man_f1-score': 0.1864406779661017, 'Straw_Man_support': 73.0, 'micro avg_precision': 0.24444444444444444, 'micro avg_recall': 0.1506849315068493, 'micro avg_f1-score': 0.1864406779661017, 'micro avg_support': 73.0, 'macro avg_precision': 0.24444444444444444, 'macro avg_recall': 0.1506849315068493, 'macro avg_f1-score': 0.1864406779661017, 'macro avg_support': 73.0, 'weighted avg_precision': 0.24444444444444446, 'weighted avg_recall': 0.1506849315068493, 'weighted avg_f1-score': 0.1864406779661017, 'weighted avg_support': 73.0, 'B-Straw_Man_support': 45, 'I-Straw_Man_support': 728, 'O_support': 1038, 'epoch': 3}
{'results': [{'micro_f1': 0.7465488680287135, 'Straw_Man_precision': 0.044444444444444446, 'Straw_Man_recall': 0.02040816326530612, 'Straw_Man_f1-score': 0.02797202797202797, 'Straw_Man_support': 98.0, 'micro avg_precision': 0.044444444444444446, 'micro avg_recall': 0.02040816326530612, 'micro avg_f1-score': 0.02797202797202797, 'micro avg_support': 98.0, 'macro avg_precision': 0.044444444444444446, 'macro avg_recall': 0.02040816326530612, 'macro avg_f1-score': 0.02797202797202797, 'macro avg_support': 98.0, 'weighted avg_precision': 0.04444444444444445, 'weighted avg_recall': 0.02040816326530612, 'weighted avg_f1-score': 0.02797202797202797, 'weighted avg_support': 98.0, 'B-Straw_Man_support': 45, 'I-Straw_Man_support': 728, 'O_support': 1038, 'epoch': 0}, {'micro_f1': 0.7498619547211486, 'Straw_Man_precision': 0.13333333333333333, 'Straw_Man_recall': 0.05405405405405406, 'Straw_Man_f1-score': 0.07692307692307693, 'Straw_Man_support': 111.0, 'micro avg_precision': 0.13333333333333333, 'micro avg_recall': 0.05405405405405406, 'micro avg_f1-score': 0.07692307692307693, 'micro avg_support': 111.0, 'macro avg_precision': 0.13333333333333333, 'macro avg_recall': 0.05405405405405406, 'macro avg_f1-score': 0.07692307692307693, 'macro avg_support': 111.0, 'weighted avg_precision': 0.13333333333333333, 'weighted avg_recall': 0.05405405405405406, 'weighted avg_f1-score': 0.07692307692307693, 'weighted avg_support': 111.0, 'B-Straw_Man_support': 45, 'I-Straw_Man_support': 728, 'O_support': 1038, 'epoch': 1}, {'micro_f1': 0.7537272225289895, 'Straw_Man_precision': 0.2, 'Straw_Man_recall': 0.1323529411764706, 'Straw_Man_f1-score': 0.1592920353982301, 'Straw_Man_support': 68.0, 'micro avg_precision': 0.2, 'micro avg_recall': 0.1323529411764706, 'micro avg_f1-score': 0.1592920353982301, 'micro avg_support': 68.0, 'macro avg_precision': 0.2, 'macro avg_recall': 0.1323529411764706, 'macro avg_f1-score': 0.1592920353982301, 'macro avg_support': 68.0, 'weighted avg_precision': 0.2, 'weighted avg_recall': 0.1323529411764706, 'weighted avg_f1-score': 0.1592920353982301, 'weighted avg_support': 68.0, 'B-Straw_Man_support': 45, 'I-Straw_Man_support': 728, 'O_support': 1038, 'epoch': 2}, {'micro_f1': 0.7725013804527885, 'Straw_Man_precision': 0.24444444444444444, 'Straw_Man_recall': 0.1506849315068493, 'Straw_Man_f1-score': 0.1864406779661017, 'Straw_Man_support': 73.0, 'micro avg_precision': 0.24444444444444444, 'micro avg_recall': 0.1506849315068493, 'micro avg_f1-score': 0.1864406779661017, 'micro avg_support': 73.0, 'macro avg_precision': 0.24444444444444444, 'macro avg_recall': 0.1506849315068493, 'macro avg_f1-score': 0.1864406779661017, 'macro avg_support': 73.0, 'weighted avg_precision': 0.24444444444444446, 'weighted avg_recall': 0.1506849315068493, 'weighted avg_f1-score': 0.1864406779661017, 'weighted avg_support': 73.0, 'B-Straw_Man_support': 45, 'I-Straw_Man_support': 728, 'O_support': 1038, 'epoch': 3}]}
Best model updated: current epoch macro f1 = 0.1864406779661017
{'micro_f1': 0.7885146327995582, 'Straw_Man_precision': 0.2222222222222222, 'Straw_Man_recall': 0.15384615384615385, 'Straw_Man_f1-score': 0.18181818181818185, 'Straw_Man_support': 65.0, 'micro avg_precision': 0.2222222222222222, 'micro avg_recall': 0.15384615384615385, 'micro avg_f1-score': 0.18181818181818185, 'micro avg_support': 65.0, 'macro avg_precision': 0.2222222222222222, 'macro avg_recall': 0.15384615384615385, 'macro avg_f1-score': 0.18181818181818185, 'macro avg_support': 65.0, 'weighted avg_precision': 0.2222222222222222, 'weighted avg_recall': 0.15384615384615385, 'weighted avg_f1-score': 0.18181818181818185, 'weighted avg_support': 65.0, 'B-Straw_Man_support': 45, 'I-Straw_Man_support': 728, 'O_support': 1038, 'epoch': 4}
{'results': [{'micro_f1': 0.7465488680287135, 'Straw_Man_precision': 0.044444444444444446, 'Straw_Man_recall': 0.02040816326530612, 'Straw_Man_f1-score': 0.02797202797202797, 'Straw_Man_support': 98.0, 'micro avg_precision': 0.044444444444444446, 'micro avg_recall': 0.02040816326530612, 'micro avg_f1-score': 0.02797202797202797, 'micro avg_support': 98.0, 'macro avg_precision': 0.044444444444444446, 'macro avg_recall': 0.02040816326530612, 'macro avg_f1-score': 0.02797202797202797, 'macro avg_support': 98.0, 'weighted avg_precision': 0.04444444444444445, 'weighted avg_recall': 0.02040816326530612, 'weighted avg_f1-score': 0.02797202797202797, 'weighted avg_support': 98.0, 'B-Straw_Man_support': 45, 'I-Straw_Man_support': 728, 'O_support': 1038, 'epoch': 0}, {'micro_f1': 0.7498619547211486, 'Straw_Man_precision': 0.13333333333333333, 'Straw_Man_recall': 0.05405405405405406, 'Straw_Man_f1-score': 0.07692307692307693, 'Straw_Man_support': 111.0, 'micro avg_precision': 0.13333333333333333, 'micro avg_recall': 0.05405405405405406, 'micro avg_f1-score': 0.07692307692307693, 'micro avg_support': 111.0, 'macro avg_precision': 0.13333333333333333, 'macro avg_recall': 0.05405405405405406, 'macro avg_f1-score': 0.07692307692307693, 'macro avg_support': 111.0, 'weighted avg_precision': 0.13333333333333333, 'weighted avg_recall': 0.05405405405405406, 'weighted avg_f1-score': 0.07692307692307693, 'weighted avg_support': 111.0, 'B-Straw_Man_support': 45, 'I-Straw_Man_support': 728, 'O_support': 1038, 'epoch': 1}, {'micro_f1': 0.7537272225289895, 'Straw_Man_precision': 0.2, 'Straw_Man_recall': 0.1323529411764706, 'Straw_Man_f1-score': 0.1592920353982301, 'Straw_Man_support': 68.0, 'micro avg_precision': 0.2, 'micro avg_recall': 0.1323529411764706, 'micro avg_f1-score': 0.1592920353982301, 'micro avg_support': 68.0, 'macro avg_precision': 0.2, 'macro avg_recall': 0.1323529411764706, 'macro avg_f1-score': 0.1592920353982301, 'macro avg_support': 68.0, 'weighted avg_precision': 0.2, 'weighted avg_recall': 0.1323529411764706, 'weighted avg_f1-score': 0.1592920353982301, 'weighted avg_support': 68.0, 'B-Straw_Man_support': 45, 'I-Straw_Man_support': 728, 'O_support': 1038, 'epoch': 2}, {'micro_f1': 0.7725013804527885, 'Straw_Man_precision': 0.24444444444444444, 'Straw_Man_recall': 0.1506849315068493, 'Straw_Man_f1-score': 0.1864406779661017, 'Straw_Man_support': 73.0, 'micro avg_precision': 0.24444444444444444, 'micro avg_recall': 0.1506849315068493, 'micro avg_f1-score': 0.1864406779661017, 'micro avg_support': 73.0, 'macro avg_precision': 0.24444444444444444, 'macro avg_recall': 0.1506849315068493, 'macro avg_f1-score': 0.1864406779661017, 'macro avg_support': 73.0, 'weighted avg_precision': 0.24444444444444446, 'weighted avg_recall': 0.1506849315068493, 'weighted avg_f1-score': 0.1864406779661017, 'weighted avg_support': 73.0, 'B-Straw_Man_support': 45, 'I-Straw_Man_support': 728, 'O_support': 1038, 'epoch': 3}, {'micro_f1': 0.7885146327995582, 'Straw_Man_precision': 0.2222222222222222, 'Straw_Man_recall': 0.15384615384615385, 'Straw_Man_f1-score': 0.18181818181818185, 'Straw_Man_support': 65.0, 'micro avg_precision': 0.2222222222222222, 'micro avg_recall': 0.15384615384615385, 'micro avg_f1-score': 0.18181818181818185, 'micro avg_support': 65.0, 'macro avg_precision': 0.2222222222222222, 'macro avg_recall': 0.15384615384615385, 'macro avg_f1-score': 0.18181818181818185, 'macro avg_support': 65.0, 'weighted avg_precision': 0.2222222222222222, 'weighted avg_recall': 0.15384615384615385, 'weighted avg_f1-score': 0.18181818181818185, 'weighted avg_support': 65.0, 'B-Straw_Man_support': 45, 'I-Straw_Man_support': 728, 'O_support': 1038, 'epoch': 4}]}
{'micro_f1': 0.7454445057979017, 'Straw_Man_precision': 0.2, 'Straw_Man_recall': 0.15517241379310345, 'Straw_Man_f1-score': 0.17475728155339806, 'Straw_Man_support': 58.0, 'micro avg_precision': 0.2, 'micro avg_recall': 0.15517241379310345, 'micro avg_f1-score': 0.17475728155339806, 'micro avg_support': 58.0, 'macro avg_precision': 0.2, 'macro avg_recall': 0.15517241379310345, 'macro avg_f1-score': 0.17475728155339806, 'macro avg_support': 58.0, 'weighted avg_precision': 0.2, 'weighted avg_recall': 0.15517241379310345, 'weighted avg_f1-score': 0.17475728155339806, 'weighted avg_support': 58.0, 'B-Straw_Man_support': 45, 'I-Straw_Man_support': 728, 'O_support': 1038, 'epoch': 5}
{'results': [{'micro_f1': 0.7465488680287135, 'Straw_Man_precision': 0.044444444444444446, 'Straw_Man_recall': 0.02040816326530612, 'Straw_Man_f1-score': 0.02797202797202797, 'Straw_Man_support': 98.0, 'micro avg_precision': 0.044444444444444446, 'micro avg_recall': 0.02040816326530612, 'micro avg_f1-score': 0.02797202797202797, 'micro avg_support': 98.0, 'macro avg_precision': 0.044444444444444446, 'macro avg_recall': 0.02040816326530612, 'macro avg_f1-score': 0.02797202797202797, 'macro avg_support': 98.0, 'weighted avg_precision': 0.04444444444444445, 'weighted avg_recall': 0.02040816326530612, 'weighted avg_f1-score': 0.02797202797202797, 'weighted avg_support': 98.0, 'B-Straw_Man_support': 45, 'I-Straw_Man_support': 728, 'O_support': 1038, 'epoch': 0}, {'micro_f1': 0.7498619547211486, 'Straw_Man_precision': 0.13333333333333333, 'Straw_Man_recall': 0.05405405405405406, 'Straw_Man_f1-score': 0.07692307692307693, 'Straw_Man_support': 111.0, 'micro avg_precision': 0.13333333333333333, 'micro avg_recall': 0.05405405405405406, 'micro avg_f1-score': 0.07692307692307693, 'micro avg_support': 111.0, 'macro avg_precision': 0.13333333333333333, 'macro avg_recall': 0.05405405405405406, 'macro avg_f1-score': 0.07692307692307693, 'macro avg_support': 111.0, 'weighted avg_precision': 0.13333333333333333, 'weighted avg_recall': 0.05405405405405406, 'weighted avg_f1-score': 0.07692307692307693, 'weighted avg_support': 111.0, 'B-Straw_Man_support': 45, 'I-Straw_Man_support': 728, 'O_support': 1038, 'epoch': 1}, {'micro_f1': 0.7537272225289895, 'Straw_Man_precision': 0.2, 'Straw_Man_recall': 0.1323529411764706, 'Straw_Man_f1-score': 0.1592920353982301, 'Straw_Man_support': 68.0, 'micro avg_precision': 0.2, 'micro avg_recall': 0.1323529411764706, 'micro avg_f1-score': 0.1592920353982301, 'micro avg_support': 68.0, 'macro avg_precision': 0.2, 'macro avg_recall': 0.1323529411764706, 'macro avg_f1-score': 0.1592920353982301, 'macro avg_support': 68.0, 'weighted avg_precision': 0.2, 'weighted avg_recall': 0.1323529411764706, 'weighted avg_f1-score': 0.1592920353982301, 'weighted avg_support': 68.0, 'B-Straw_Man_support': 45, 'I-Straw_Man_support': 728, 'O_support': 1038, 'epoch': 2}, {'micro_f1': 0.7725013804527885, 'Straw_Man_precision': 0.24444444444444444, 'Straw_Man_recall': 0.1506849315068493, 'Straw_Man_f1-score': 0.1864406779661017, 'Straw_Man_support': 73.0, 'micro avg_precision': 0.24444444444444444, 'micro avg_recall': 0.1506849315068493, 'micro avg_f1-score': 0.1864406779661017, 'micro avg_support': 73.0, 'macro avg_precision': 0.24444444444444444, 'macro avg_recall': 0.1506849315068493, 'macro avg_f1-score': 0.1864406779661017, 'macro avg_support': 73.0, 'weighted avg_precision': 0.24444444444444446, 'weighted avg_recall': 0.1506849315068493, 'weighted avg_f1-score': 0.1864406779661017, 'weighted avg_support': 73.0, 'B-Straw_Man_support': 45, 'I-Straw_Man_support': 728, 'O_support': 1038, 'epoch': 3}, {'micro_f1': 0.7885146327995582, 'Straw_Man_precision': 0.2222222222222222, 'Straw_Man_recall': 0.15384615384615385, 'Straw_Man_f1-score': 0.18181818181818185, 'Straw_Man_support': 65.0, 'micro avg_precision': 0.2222222222222222, 'micro avg_recall': 0.15384615384615385, 'micro avg_f1-score': 0.18181818181818185, 'micro avg_support': 65.0, 'macro avg_precision': 0.2222222222222222, 'macro avg_recall': 0.15384615384615385, 'macro avg_f1-score': 0.18181818181818185, 'macro avg_support': 65.0, 'weighted avg_precision': 0.2222222222222222, 'weighted avg_recall': 0.15384615384615385, 'weighted avg_f1-score': 0.18181818181818185, 'weighted avg_support': 65.0, 'B-Straw_Man_support': 45, 'I-Straw_Man_support': 728, 'O_support': 1038, 'epoch': 4}, {'micro_f1': 0.7454445057979017, 'Straw_Man_precision': 0.2, 'Straw_Man_recall': 0.15517241379310345, 'Straw_Man_f1-score': 0.17475728155339806, 'Straw_Man_support': 58.0, 'micro avg_precision': 0.2, 'micro avg_recall': 0.15517241379310345, 'micro avg_f1-score': 0.17475728155339806, 'micro avg_support': 58.0, 'macro avg_precision': 0.2, 'macro avg_recall': 0.15517241379310345, 'macro avg_f1-score': 0.17475728155339806, 'macro avg_support': 58.0, 'weighted avg_precision': 0.2, 'weighted avg_recall': 0.15517241379310345, 'weighted avg_f1-score': 0.17475728155339806, 'weighted avg_support': 58.0, 'B-Straw_Man_support': 45, 'I-Straw_Man_support': 728, 'O_support': 1038, 'epoch': 5}]}
Early stopping triggered.
Saving model to directory: ./models/M2/2024-05-12-17-42-10_aug/mdeberta-v3-base_8_ME10_target=Straw_Man_SUBSAMPLED_2024-05-12-17-42-10
Training model no. 9 of 23 for (9, 'Red_Herring') persuasion technique...
{'micro_f1': 0.7690397350993378, 'Red_Herring_precision': 0.043478260869565216, 'Red_Herring_recall': 0.013513513513513514, 'Red_Herring_f1-score': 0.020618556701030927, 'Red_Herring_support': 74.0, 'micro avg_precision': 0.043478260869565216, 'micro avg_recall': 0.013513513513513514, 'micro avg_f1-score': 0.020618556701030927, 'micro avg_support': 74.0, 'macro avg_precision': 0.043478260869565216, 'macro avg_recall': 0.013513513513513514, 'macro avg_f1-score': 0.020618556701030927, 'macro avg_support': 74.0, 'weighted avg_precision': 0.043478260869565216, 'weighted avg_recall': 0.013513513513513514, 'weighted avg_f1-score': 0.020618556701030927, 'weighted avg_support': 74.0, 'O_support': 812, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 0}
{'results': [{'micro_f1': 0.7690397350993378, 'Red_Herring_precision': 0.043478260869565216, 'Red_Herring_recall': 0.013513513513513514, 'Red_Herring_f1-score': 0.020618556701030927, 'Red_Herring_support': 74.0, 'micro avg_precision': 0.043478260869565216, 'micro avg_recall': 0.013513513513513514, 'micro avg_f1-score': 0.020618556701030927, 'micro avg_support': 74.0, 'macro avg_precision': 0.043478260869565216, 'macro avg_recall': 0.013513513513513514, 'macro avg_f1-score': 0.020618556701030927, 'macro avg_support': 74.0, 'weighted avg_precision': 0.043478260869565216, 'weighted avg_recall': 0.013513513513513514, 'weighted avg_f1-score': 0.020618556701030927, 'weighted avg_support': 74.0, 'O_support': 812, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 0}]}
Best model updated: current epoch macro f1 = 0.020618556701030927
{'micro_f1': 0.6597682119205298, 'Red_Herring_precision': 0.30434782608695654, 'Red_Herring_recall': 0.0958904109589041, 'Red_Herring_f1-score': 0.14583333333333331, 'Red_Herring_support': 73.0, 'micro avg_precision': 0.30434782608695654, 'micro avg_recall': 0.0958904109589041, 'micro avg_f1-score': 0.14583333333333331, 'micro avg_support': 73.0, 'macro avg_precision': 0.30434782608695654, 'macro avg_recall': 0.0958904109589041, 'macro avg_f1-score': 0.14583333333333331, 'macro avg_support': 73.0, 'weighted avg_precision': 0.30434782608695654, 'weighted avg_recall': 0.0958904109589041, 'weighted avg_f1-score': 0.14583333333333331, 'weighted avg_support': 73.0, 'O_support': 812, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 1}
{'results': [{'micro_f1': 0.7690397350993378, 'Red_Herring_precision': 0.043478260869565216, 'Red_Herring_recall': 0.013513513513513514, 'Red_Herring_f1-score': 0.020618556701030927, 'Red_Herring_support': 74.0, 'micro avg_precision': 0.043478260869565216, 'micro avg_recall': 0.013513513513513514, 'micro avg_f1-score': 0.020618556701030927, 'micro avg_support': 74.0, 'macro avg_precision': 0.043478260869565216, 'macro avg_recall': 0.013513513513513514, 'macro avg_f1-score': 0.020618556701030927, 'macro avg_support': 74.0, 'weighted avg_precision': 0.043478260869565216, 'weighted avg_recall': 0.013513513513513514, 'weighted avg_f1-score': 0.020618556701030927, 'weighted avg_support': 74.0, 'O_support': 812, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 0}, {'micro_f1': 0.6597682119205298, 'Red_Herring_precision': 0.30434782608695654, 'Red_Herring_recall': 0.0958904109589041, 'Red_Herring_f1-score': 0.14583333333333331, 'Red_Herring_support': 73.0, 'micro avg_precision': 0.30434782608695654, 'micro avg_recall': 0.0958904109589041, 'micro avg_f1-score': 0.14583333333333331, 'micro avg_support': 73.0, 'macro avg_precision': 0.30434782608695654, 'macro avg_recall': 0.0958904109589041, 'macro avg_f1-score': 0.14583333333333331, 'macro avg_support': 73.0, 'weighted avg_precision': 0.30434782608695654, 'weighted avg_recall': 0.0958904109589041, 'weighted avg_f1-score': 0.14583333333333331, 'weighted avg_support': 73.0, 'O_support': 812, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 1}]}
Best model updated: current epoch macro f1 = 0.14583333333333331
{'micro_f1': 0.7864238410596026, 'Red_Herring_precision': 0.34782608695652173, 'Red_Herring_recall': 0.125, 'Red_Herring_f1-score': 0.1839080459770115, 'Red_Herring_support': 64.0, 'micro avg_precision': 0.34782608695652173, 'micro avg_recall': 0.125, 'micro avg_f1-score': 0.1839080459770115, 'micro avg_support': 64.0, 'macro avg_precision': 0.34782608695652173, 'macro avg_recall': 0.125, 'macro avg_f1-score': 0.1839080459770115, 'macro avg_support': 64.0, 'weighted avg_precision': 0.34782608695652173, 'weighted avg_recall': 0.125, 'weighted avg_f1-score': 0.1839080459770115, 'weighted avg_support': 64.0, 'O_support': 812, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 2}
{'results': [{'micro_f1': 0.7690397350993378, 'Red_Herring_precision': 0.043478260869565216, 'Red_Herring_recall': 0.013513513513513514, 'Red_Herring_f1-score': 0.020618556701030927, 'Red_Herring_support': 74.0, 'micro avg_precision': 0.043478260869565216, 'micro avg_recall': 0.013513513513513514, 'micro avg_f1-score': 0.020618556701030927, 'micro avg_support': 74.0, 'macro avg_precision': 0.043478260869565216, 'macro avg_recall': 0.013513513513513514, 'macro avg_f1-score': 0.020618556701030927, 'macro avg_support': 74.0, 'weighted avg_precision': 0.043478260869565216, 'weighted avg_recall': 0.013513513513513514, 'weighted avg_f1-score': 0.020618556701030927, 'weighted avg_support': 74.0, 'O_support': 812, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 0}, {'micro_f1': 0.6597682119205298, 'Red_Herring_precision': 0.30434782608695654, 'Red_Herring_recall': 0.0958904109589041, 'Red_Herring_f1-score': 0.14583333333333331, 'Red_Herring_support': 73.0, 'micro avg_precision': 0.30434782608695654, 'micro avg_recall': 0.0958904109589041, 'micro avg_f1-score': 0.14583333333333331, 'micro avg_support': 73.0, 'macro avg_precision': 0.30434782608695654, 'macro avg_recall': 0.0958904109589041, 'macro avg_f1-score': 0.14583333333333331, 'macro avg_support': 73.0, 'weighted avg_precision': 0.30434782608695654, 'weighted avg_recall': 0.0958904109589041, 'weighted avg_f1-score': 0.14583333333333331, 'weighted avg_support': 73.0, 'O_support': 812, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 1}, {'micro_f1': 0.7864238410596026, 'Red_Herring_precision': 0.34782608695652173, 'Red_Herring_recall': 0.125, 'Red_Herring_f1-score': 0.1839080459770115, 'Red_Herring_support': 64.0, 'micro avg_precision': 0.34782608695652173, 'micro avg_recall': 0.125, 'micro avg_f1-score': 0.1839080459770115, 'micro avg_support': 64.0, 'macro avg_precision': 0.34782608695652173, 'macro avg_recall': 0.125, 'macro avg_f1-score': 0.1839080459770115, 'macro avg_support': 64.0, 'weighted avg_precision': 0.34782608695652173, 'weighted avg_recall': 0.125, 'weighted avg_f1-score': 0.1839080459770115, 'weighted avg_support': 64.0, 'O_support': 812, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 2}]}
Best model updated: current epoch macro f1 = 0.1839080459770115
{'micro_f1': 0.814569536423841, 'Red_Herring_precision': 0.2608695652173913, 'Red_Herring_recall': 0.1875, 'Red_Herring_f1-score': 0.21818181818181817, 'Red_Herring_support': 32.0, 'micro avg_precision': 0.2608695652173913, 'micro avg_recall': 0.1875, 'micro avg_f1-score': 0.21818181818181817, 'micro avg_support': 32.0, 'macro avg_precision': 0.2608695652173913, 'macro avg_recall': 0.1875, 'macro avg_f1-score': 0.21818181818181817, 'macro avg_support': 32.0, 'weighted avg_precision': 0.2608695652173913, 'weighted avg_recall': 0.1875, 'weighted avg_f1-score': 0.21818181818181817, 'weighted avg_support': 32.0, 'O_support': 812, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 3}
{'results': [{'micro_f1': 0.7690397350993378, 'Red_Herring_precision': 0.043478260869565216, 'Red_Herring_recall': 0.013513513513513514, 'Red_Herring_f1-score': 0.020618556701030927, 'Red_Herring_support': 74.0, 'micro avg_precision': 0.043478260869565216, 'micro avg_recall': 0.013513513513513514, 'micro avg_f1-score': 0.020618556701030927, 'micro avg_support': 74.0, 'macro avg_precision': 0.043478260869565216, 'macro avg_recall': 0.013513513513513514, 'macro avg_f1-score': 0.020618556701030927, 'macro avg_support': 74.0, 'weighted avg_precision': 0.043478260869565216, 'weighted avg_recall': 0.013513513513513514, 'weighted avg_f1-score': 0.020618556701030927, 'weighted avg_support': 74.0, 'O_support': 812, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 0}, {'micro_f1': 0.6597682119205298, 'Red_Herring_precision': 0.30434782608695654, 'Red_Herring_recall': 0.0958904109589041, 'Red_Herring_f1-score': 0.14583333333333331, 'Red_Herring_support': 73.0, 'micro avg_precision': 0.30434782608695654, 'micro avg_recall': 0.0958904109589041, 'micro avg_f1-score': 0.14583333333333331, 'micro avg_support': 73.0, 'macro avg_precision': 0.30434782608695654, 'macro avg_recall': 0.0958904109589041, 'macro avg_f1-score': 0.14583333333333331, 'macro avg_support': 73.0, 'weighted avg_precision': 0.30434782608695654, 'weighted avg_recall': 0.0958904109589041, 'weighted avg_f1-score': 0.14583333333333331, 'weighted avg_support': 73.0, 'O_support': 812, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 1}, {'micro_f1': 0.7864238410596026, 'Red_Herring_precision': 0.34782608695652173, 'Red_Herring_recall': 0.125, 'Red_Herring_f1-score': 0.1839080459770115, 'Red_Herring_support': 64.0, 'micro avg_precision': 0.34782608695652173, 'micro avg_recall': 0.125, 'micro avg_f1-score': 0.1839080459770115, 'micro avg_support': 64.0, 'macro avg_precision': 0.34782608695652173, 'macro avg_recall': 0.125, 'macro avg_f1-score': 0.1839080459770115, 'macro avg_support': 64.0, 'weighted avg_precision': 0.34782608695652173, 'weighted avg_recall': 0.125, 'weighted avg_f1-score': 0.1839080459770115, 'weighted avg_support': 64.0, 'O_support': 812, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 2}, {'micro_f1': 0.814569536423841, 'Red_Herring_precision': 0.2608695652173913, 'Red_Herring_recall': 0.1875, 'Red_Herring_f1-score': 0.21818181818181817, 'Red_Herring_support': 32.0, 'micro avg_precision': 0.2608695652173913, 'micro avg_recall': 0.1875, 'micro avg_f1-score': 0.21818181818181817, 'micro avg_support': 32.0, 'macro avg_precision': 0.2608695652173913, 'macro avg_recall': 0.1875, 'macro avg_f1-score': 0.21818181818181817, 'macro avg_support': 32.0, 'weighted avg_precision': 0.2608695652173913, 'weighted avg_recall': 0.1875, 'weighted avg_f1-score': 0.21818181818181817, 'weighted avg_support': 32.0, 'O_support': 812, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 3}]}
Best model updated: current epoch macro f1 = 0.21818181818181817
{'micro_f1': 0.8021523178807947, 'Red_Herring_precision': 0.43478260869565216, 'Red_Herring_recall': 0.2857142857142857, 'Red_Herring_f1-score': 0.3448275862068965, 'Red_Herring_support': 35.0, 'micro avg_precision': 0.43478260869565216, 'micro avg_recall': 0.2857142857142857, 'micro avg_f1-score': 0.3448275862068965, 'micro avg_support': 35.0, 'macro avg_precision': 0.43478260869565216, 'macro avg_recall': 0.2857142857142857, 'macro avg_f1-score': 0.3448275862068965, 'macro avg_support': 35.0, 'weighted avg_precision': 0.43478260869565216, 'weighted avg_recall': 0.2857142857142857, 'weighted avg_f1-score': 0.3448275862068965, 'weighted avg_support': 35.0, 'O_support': 812, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 4}
{'results': [{'micro_f1': 0.7690397350993378, 'Red_Herring_precision': 0.043478260869565216, 'Red_Herring_recall': 0.013513513513513514, 'Red_Herring_f1-score': 0.020618556701030927, 'Red_Herring_support': 74.0, 'micro avg_precision': 0.043478260869565216, 'micro avg_recall': 0.013513513513513514, 'micro avg_f1-score': 0.020618556701030927, 'micro avg_support': 74.0, 'macro avg_precision': 0.043478260869565216, 'macro avg_recall': 0.013513513513513514, 'macro avg_f1-score': 0.020618556701030927, 'macro avg_support': 74.0, 'weighted avg_precision': 0.043478260869565216, 'weighted avg_recall': 0.013513513513513514, 'weighted avg_f1-score': 0.020618556701030927, 'weighted avg_support': 74.0, 'O_support': 812, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 0}, {'micro_f1': 0.6597682119205298, 'Red_Herring_precision': 0.30434782608695654, 'Red_Herring_recall': 0.0958904109589041, 'Red_Herring_f1-score': 0.14583333333333331, 'Red_Herring_support': 73.0, 'micro avg_precision': 0.30434782608695654, 'micro avg_recall': 0.0958904109589041, 'micro avg_f1-score': 0.14583333333333331, 'micro avg_support': 73.0, 'macro avg_precision': 0.30434782608695654, 'macro avg_recall': 0.0958904109589041, 'macro avg_f1-score': 0.14583333333333331, 'macro avg_support': 73.0, 'weighted avg_precision': 0.30434782608695654, 'weighted avg_recall': 0.0958904109589041, 'weighted avg_f1-score': 0.14583333333333331, 'weighted avg_support': 73.0, 'O_support': 812, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 1}, {'micro_f1': 0.7864238410596026, 'Red_Herring_precision': 0.34782608695652173, 'Red_Herring_recall': 0.125, 'Red_Herring_f1-score': 0.1839080459770115, 'Red_Herring_support': 64.0, 'micro avg_precision': 0.34782608695652173, 'micro avg_recall': 0.125, 'micro avg_f1-score': 0.1839080459770115, 'micro avg_support': 64.0, 'macro avg_precision': 0.34782608695652173, 'macro avg_recall': 0.125, 'macro avg_f1-score': 0.1839080459770115, 'macro avg_support': 64.0, 'weighted avg_precision': 0.34782608695652173, 'weighted avg_recall': 0.125, 'weighted avg_f1-score': 0.1839080459770115, 'weighted avg_support': 64.0, 'O_support': 812, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 2}, {'micro_f1': 0.814569536423841, 'Red_Herring_precision': 0.2608695652173913, 'Red_Herring_recall': 0.1875, 'Red_Herring_f1-score': 0.21818181818181817, 'Red_Herring_support': 32.0, 'micro avg_precision': 0.2608695652173913, 'micro avg_recall': 0.1875, 'micro avg_f1-score': 0.21818181818181817, 'micro avg_support': 32.0, 'macro avg_precision': 0.2608695652173913, 'macro avg_recall': 0.1875, 'macro avg_f1-score': 0.21818181818181817, 'macro avg_support': 32.0, 'weighted avg_precision': 0.2608695652173913, 'weighted avg_recall': 0.1875, 'weighted avg_f1-score': 0.21818181818181817, 'weighted avg_support': 32.0, 'O_support': 812, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 3}, {'micro_f1': 0.8021523178807947, 'Red_Herring_precision': 0.43478260869565216, 'Red_Herring_recall': 0.2857142857142857, 'Red_Herring_f1-score': 0.3448275862068965, 'Red_Herring_support': 35.0, 'micro avg_precision': 0.43478260869565216, 'micro avg_recall': 0.2857142857142857, 'micro avg_f1-score': 0.3448275862068965, 'micro avg_support': 35.0, 'macro avg_precision': 0.43478260869565216, 'macro avg_recall': 0.2857142857142857, 'macro avg_f1-score': 0.3448275862068965, 'macro avg_support': 35.0, 'weighted avg_precision': 0.43478260869565216, 'weighted avg_recall': 0.2857142857142857, 'weighted avg_f1-score': 0.3448275862068965, 'weighted avg_support': 35.0, 'O_support': 812, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 4}]}
Best model updated: current epoch macro f1 = 0.3448275862068965
{'micro_f1': 0.8369205298013245, 'Red_Herring_precision': 0.43478260869565216, 'Red_Herring_recall': 0.23809523809523808, 'Red_Herring_f1-score': 0.30769230769230765, 'Red_Herring_support': 42.0, 'micro avg_precision': 0.43478260869565216, 'micro avg_recall': 0.23809523809523808, 'micro avg_f1-score': 0.30769230769230765, 'micro avg_support': 42.0, 'macro avg_precision': 0.43478260869565216, 'macro avg_recall': 0.23809523809523808, 'macro avg_f1-score': 0.30769230769230765, 'macro avg_support': 42.0, 'weighted avg_precision': 0.43478260869565216, 'weighted avg_recall': 0.23809523809523808, 'weighted avg_f1-score': 0.30769230769230765, 'weighted avg_support': 42.0, 'O_support': 812, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 5}
{'results': [{'micro_f1': 0.7690397350993378, 'Red_Herring_precision': 0.043478260869565216, 'Red_Herring_recall': 0.013513513513513514, 'Red_Herring_f1-score': 0.020618556701030927, 'Red_Herring_support': 74.0, 'micro avg_precision': 0.043478260869565216, 'micro avg_recall': 0.013513513513513514, 'micro avg_f1-score': 0.020618556701030927, 'micro avg_support': 74.0, 'macro avg_precision': 0.043478260869565216, 'macro avg_recall': 0.013513513513513514, 'macro avg_f1-score': 0.020618556701030927, 'macro avg_support': 74.0, 'weighted avg_precision': 0.043478260869565216, 'weighted avg_recall': 0.013513513513513514, 'weighted avg_f1-score': 0.020618556701030927, 'weighted avg_support': 74.0, 'O_support': 812, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 0}, {'micro_f1': 0.6597682119205298, 'Red_Herring_precision': 0.30434782608695654, 'Red_Herring_recall': 0.0958904109589041, 'Red_Herring_f1-score': 0.14583333333333331, 'Red_Herring_support': 73.0, 'micro avg_precision': 0.30434782608695654, 'micro avg_recall': 0.0958904109589041, 'micro avg_f1-score': 0.14583333333333331, 'micro avg_support': 73.0, 'macro avg_precision': 0.30434782608695654, 'macro avg_recall': 0.0958904109589041, 'macro avg_f1-score': 0.14583333333333331, 'macro avg_support': 73.0, 'weighted avg_precision': 0.30434782608695654, 'weighted avg_recall': 0.0958904109589041, 'weighted avg_f1-score': 0.14583333333333331, 'weighted avg_support': 73.0, 'O_support': 812, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 1}, {'micro_f1': 0.7864238410596026, 'Red_Herring_precision': 0.34782608695652173, 'Red_Herring_recall': 0.125, 'Red_Herring_f1-score': 0.1839080459770115, 'Red_Herring_support': 64.0, 'micro avg_precision': 0.34782608695652173, 'micro avg_recall': 0.125, 'micro avg_f1-score': 0.1839080459770115, 'micro avg_support': 64.0, 'macro avg_precision': 0.34782608695652173, 'macro avg_recall': 0.125, 'macro avg_f1-score': 0.1839080459770115, 'macro avg_support': 64.0, 'weighted avg_precision': 0.34782608695652173, 'weighted avg_recall': 0.125, 'weighted avg_f1-score': 0.1839080459770115, 'weighted avg_support': 64.0, 'O_support': 812, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 2}, {'micro_f1': 0.814569536423841, 'Red_Herring_precision': 0.2608695652173913, 'Red_Herring_recall': 0.1875, 'Red_Herring_f1-score': 0.21818181818181817, 'Red_Herring_support': 32.0, 'micro avg_precision': 0.2608695652173913, 'micro avg_recall': 0.1875, 'micro avg_f1-score': 0.21818181818181817, 'micro avg_support': 32.0, 'macro avg_precision': 0.2608695652173913, 'macro avg_recall': 0.1875, 'macro avg_f1-score': 0.21818181818181817, 'macro avg_support': 32.0, 'weighted avg_precision': 0.2608695652173913, 'weighted avg_recall': 0.1875, 'weighted avg_f1-score': 0.21818181818181817, 'weighted avg_support': 32.0, 'O_support': 812, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 3}, {'micro_f1': 0.8021523178807947, 'Red_Herring_precision': 0.43478260869565216, 'Red_Herring_recall': 0.2857142857142857, 'Red_Herring_f1-score': 0.3448275862068965, 'Red_Herring_support': 35.0, 'micro avg_precision': 0.43478260869565216, 'micro avg_recall': 0.2857142857142857, 'micro avg_f1-score': 0.3448275862068965, 'micro avg_support': 35.0, 'macro avg_precision': 0.43478260869565216, 'macro avg_recall': 0.2857142857142857, 'macro avg_f1-score': 0.3448275862068965, 'macro avg_support': 35.0, 'weighted avg_precision': 0.43478260869565216, 'weighted avg_recall': 0.2857142857142857, 'weighted avg_f1-score': 0.3448275862068965, 'weighted avg_support': 35.0, 'O_support': 812, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 4}, {'micro_f1': 0.8369205298013245, 'Red_Herring_precision': 0.43478260869565216, 'Red_Herring_recall': 0.23809523809523808, 'Red_Herring_f1-score': 0.30769230769230765, 'Red_Herring_support': 42.0, 'micro avg_precision': 0.43478260869565216, 'micro avg_recall': 0.23809523809523808, 'micro avg_f1-score': 0.30769230769230765, 'micro avg_support': 42.0, 'macro avg_precision': 0.43478260869565216, 'macro avg_recall': 0.23809523809523808, 'macro avg_f1-score': 0.30769230769230765, 'macro avg_support': 42.0, 'weighted avg_precision': 0.43478260869565216, 'weighted avg_recall': 0.23809523809523808, 'weighted avg_f1-score': 0.30769230769230765, 'weighted avg_support': 42.0, 'O_support': 812, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 5}]}
{'micro_f1': 0.8137417218543046, 'Red_Herring_precision': 0.43478260869565216, 'Red_Herring_recall': 0.19607843137254902, 'Red_Herring_f1-score': 0.2702702702702703, 'Red_Herring_support': 51.0, 'micro avg_precision': 0.43478260869565216, 'micro avg_recall': 0.19607843137254902, 'micro avg_f1-score': 0.2702702702702703, 'micro avg_support': 51.0, 'macro avg_precision': 0.43478260869565216, 'macro avg_recall': 0.19607843137254902, 'macro avg_f1-score': 0.2702702702702703, 'macro avg_support': 51.0, 'weighted avg_precision': 0.43478260869565216, 'weighted avg_recall': 0.19607843137254902, 'weighted avg_f1-score': 0.2702702702702703, 'weighted avg_support': 51.0, 'O_support': 812, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 6}
{'results': [{'micro_f1': 0.7690397350993378, 'Red_Herring_precision': 0.043478260869565216, 'Red_Herring_recall': 0.013513513513513514, 'Red_Herring_f1-score': 0.020618556701030927, 'Red_Herring_support': 74.0, 'micro avg_precision': 0.043478260869565216, 'micro avg_recall': 0.013513513513513514, 'micro avg_f1-score': 0.020618556701030927, 'micro avg_support': 74.0, 'macro avg_precision': 0.043478260869565216, 'macro avg_recall': 0.013513513513513514, 'macro avg_f1-score': 0.020618556701030927, 'macro avg_support': 74.0, 'weighted avg_precision': 0.043478260869565216, 'weighted avg_recall': 0.013513513513513514, 'weighted avg_f1-score': 0.020618556701030927, 'weighted avg_support': 74.0, 'O_support': 812, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 0}, {'micro_f1': 0.6597682119205298, 'Red_Herring_precision': 0.30434782608695654, 'Red_Herring_recall': 0.0958904109589041, 'Red_Herring_f1-score': 0.14583333333333331, 'Red_Herring_support': 73.0, 'micro avg_precision': 0.30434782608695654, 'micro avg_recall': 0.0958904109589041, 'micro avg_f1-score': 0.14583333333333331, 'micro avg_support': 73.0, 'macro avg_precision': 0.30434782608695654, 'macro avg_recall': 0.0958904109589041, 'macro avg_f1-score': 0.14583333333333331, 'macro avg_support': 73.0, 'weighted avg_precision': 0.30434782608695654, 'weighted avg_recall': 0.0958904109589041, 'weighted avg_f1-score': 0.14583333333333331, 'weighted avg_support': 73.0, 'O_support': 812, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 1}, {'micro_f1': 0.7864238410596026, 'Red_Herring_precision': 0.34782608695652173, 'Red_Herring_recall': 0.125, 'Red_Herring_f1-score': 0.1839080459770115, 'Red_Herring_support': 64.0, 'micro avg_precision': 0.34782608695652173, 'micro avg_recall': 0.125, 'micro avg_f1-score': 0.1839080459770115, 'micro avg_support': 64.0, 'macro avg_precision': 0.34782608695652173, 'macro avg_recall': 0.125, 'macro avg_f1-score': 0.1839080459770115, 'macro avg_support': 64.0, 'weighted avg_precision': 0.34782608695652173, 'weighted avg_recall': 0.125, 'weighted avg_f1-score': 0.1839080459770115, 'weighted avg_support': 64.0, 'O_support': 812, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 2}, {'micro_f1': 0.814569536423841, 'Red_Herring_precision': 0.2608695652173913, 'Red_Herring_recall': 0.1875, 'Red_Herring_f1-score': 0.21818181818181817, 'Red_Herring_support': 32.0, 'micro avg_precision': 0.2608695652173913, 'micro avg_recall': 0.1875, 'micro avg_f1-score': 0.21818181818181817, 'micro avg_support': 32.0, 'macro avg_precision': 0.2608695652173913, 'macro avg_recall': 0.1875, 'macro avg_f1-score': 0.21818181818181817, 'macro avg_support': 32.0, 'weighted avg_precision': 0.2608695652173913, 'weighted avg_recall': 0.1875, 'weighted avg_f1-score': 0.21818181818181817, 'weighted avg_support': 32.0, 'O_support': 812, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 3}, {'micro_f1': 0.8021523178807947, 'Red_Herring_precision': 0.43478260869565216, 'Red_Herring_recall': 0.2857142857142857, 'Red_Herring_f1-score': 0.3448275862068965, 'Red_Herring_support': 35.0, 'micro avg_precision': 0.43478260869565216, 'micro avg_recall': 0.2857142857142857, 'micro avg_f1-score': 0.3448275862068965, 'micro avg_support': 35.0, 'macro avg_precision': 0.43478260869565216, 'macro avg_recall': 0.2857142857142857, 'macro avg_f1-score': 0.3448275862068965, 'macro avg_support': 35.0, 'weighted avg_precision': 0.43478260869565216, 'weighted avg_recall': 0.2857142857142857, 'weighted avg_f1-score': 0.3448275862068965, 'weighted avg_support': 35.0, 'O_support': 812, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 4}, {'micro_f1': 0.8369205298013245, 'Red_Herring_precision': 0.43478260869565216, 'Red_Herring_recall': 0.23809523809523808, 'Red_Herring_f1-score': 0.30769230769230765, 'Red_Herring_support': 42.0, 'micro avg_precision': 0.43478260869565216, 'micro avg_recall': 0.23809523809523808, 'micro avg_f1-score': 0.30769230769230765, 'micro avg_support': 42.0, 'macro avg_precision': 0.43478260869565216, 'macro avg_recall': 0.23809523809523808, 'macro avg_f1-score': 0.30769230769230765, 'macro avg_support': 42.0, 'weighted avg_precision': 0.43478260869565216, 'weighted avg_recall': 0.23809523809523808, 'weighted avg_f1-score': 0.30769230769230765, 'weighted avg_support': 42.0, 'O_support': 812, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 5}, {'micro_f1': 0.8137417218543046, 'Red_Herring_precision': 0.43478260869565216, 'Red_Herring_recall': 0.19607843137254902, 'Red_Herring_f1-score': 0.2702702702702703, 'Red_Herring_support': 51.0, 'micro avg_precision': 0.43478260869565216, 'micro avg_recall': 0.19607843137254902, 'micro avg_f1-score': 0.2702702702702703, 'micro avg_support': 51.0, 'macro avg_precision': 0.43478260869565216, 'macro avg_recall': 0.19607843137254902, 'macro avg_f1-score': 0.2702702702702703, 'macro avg_support': 51.0, 'weighted avg_precision': 0.43478260869565216, 'weighted avg_recall': 0.19607843137254902, 'weighted avg_f1-score': 0.2702702702702703, 'weighted avg_support': 51.0, 'O_support': 812, 'B-Red_Herring_support': 23, 'I-Red_Herring_support': 373, 'epoch': 6}]}
Early stopping triggered.
Saving model to directory: ./models/M2/2024-05-12-17-42-10_aug/mdeberta-v3-base_9_ME10_target=Red_Herring_SUBSAMPLED_2024-05-12-17-42-10
Training model no. 10 of 23 for (10, 'Whataboutism') persuasion technique...
{'micro_f1': 0.6976241900647948, 'Whataboutism_precision': 0.17391304347826086, 'Whataboutism_recall': 0.09302325581395349, 'Whataboutism_f1-score': 0.12121212121212122, 'Whataboutism_support': 43.0, 'micro avg_precision': 0.17391304347826086, 'micro avg_recall': 0.09302325581395349, 'micro avg_f1-score': 0.12121212121212122, 'micro avg_support': 43.0, 'macro avg_precision': 0.17391304347826086, 'macro avg_recall': 0.09302325581395349, 'macro avg_f1-score': 0.12121212121212122, 'macro avg_support': 43.0, 'weighted avg_precision': 0.17391304347826086, 'weighted avg_recall': 0.09302325581395349, 'weighted avg_f1-score': 0.1212121212121212, 'weighted avg_support': 43.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 0}
{'results': [{'micro_f1': 0.6976241900647948, 'Whataboutism_precision': 0.17391304347826086, 'Whataboutism_recall': 0.09302325581395349, 'Whataboutism_f1-score': 0.12121212121212122, 'Whataboutism_support': 43.0, 'micro avg_precision': 0.17391304347826086, 'micro avg_recall': 0.09302325581395349, 'micro avg_f1-score': 0.12121212121212122, 'micro avg_support': 43.0, 'macro avg_precision': 0.17391304347826086, 'macro avg_recall': 0.09302325581395349, 'macro avg_f1-score': 0.12121212121212122, 'macro avg_support': 43.0, 'weighted avg_precision': 0.17391304347826086, 'weighted avg_recall': 0.09302325581395349, 'weighted avg_f1-score': 0.1212121212121212, 'weighted avg_support': 43.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 0}]}
Best model updated: current epoch macro f1 = 0.12121212121212122
{'micro_f1': 0.8347732181425485, 'Whataboutism_precision': 0.391304347826087, 'Whataboutism_recall': 0.17307692307692307, 'Whataboutism_f1-score': 0.24, 'Whataboutism_support': 52.0, 'micro avg_precision': 0.391304347826087, 'micro avg_recall': 0.17307692307692307, 'micro avg_f1-score': 0.24, 'micro avg_support': 52.0, 'macro avg_precision': 0.391304347826087, 'macro avg_recall': 0.17307692307692307, 'macro avg_f1-score': 0.24, 'macro avg_support': 52.0, 'weighted avg_precision': 0.391304347826087, 'weighted avg_recall': 0.17307692307692307, 'weighted avg_f1-score': 0.24000000000000002, 'weighted avg_support': 52.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 1}
{'results': [{'micro_f1': 0.6976241900647948, 'Whataboutism_precision': 0.17391304347826086, 'Whataboutism_recall': 0.09302325581395349, 'Whataboutism_f1-score': 0.12121212121212122, 'Whataboutism_support': 43.0, 'micro avg_precision': 0.17391304347826086, 'micro avg_recall': 0.09302325581395349, 'micro avg_f1-score': 0.12121212121212122, 'micro avg_support': 43.0, 'macro avg_precision': 0.17391304347826086, 'macro avg_recall': 0.09302325581395349, 'macro avg_f1-score': 0.12121212121212122, 'macro avg_support': 43.0, 'weighted avg_precision': 0.17391304347826086, 'weighted avg_recall': 0.09302325581395349, 'weighted avg_f1-score': 0.1212121212121212, 'weighted avg_support': 43.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 0}, {'micro_f1': 0.8347732181425485, 'Whataboutism_precision': 0.391304347826087, 'Whataboutism_recall': 0.17307692307692307, 'Whataboutism_f1-score': 0.24, 'Whataboutism_support': 52.0, 'micro avg_precision': 0.391304347826087, 'micro avg_recall': 0.17307692307692307, 'micro avg_f1-score': 0.24, 'micro avg_support': 52.0, 'macro avg_precision': 0.391304347826087, 'macro avg_recall': 0.17307692307692307, 'macro avg_f1-score': 0.24, 'macro avg_support': 52.0, 'weighted avg_precision': 0.391304347826087, 'weighted avg_recall': 0.17307692307692307, 'weighted avg_f1-score': 0.24000000000000002, 'weighted avg_support': 52.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 1}]}
Best model updated: current epoch macro f1 = 0.24
{'micro_f1': 0.7624190064794818, 'Whataboutism_precision': 0.08695652173913043, 'Whataboutism_recall': 0.03225806451612903, 'Whataboutism_f1-score': 0.047058823529411764, 'Whataboutism_support': 62.0, 'micro avg_precision': 0.08695652173913043, 'micro avg_recall': 0.03225806451612903, 'micro avg_f1-score': 0.047058823529411764, 'micro avg_support': 62.0, 'macro avg_precision': 0.08695652173913043, 'macro avg_recall': 0.03225806451612903, 'macro avg_f1-score': 0.047058823529411764, 'macro avg_support': 62.0, 'weighted avg_precision': 0.08695652173913043, 'weighted avg_recall': 0.03225806451612903, 'weighted avg_f1-score': 0.047058823529411764, 'weighted avg_support': 62.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 2}
{'results': [{'micro_f1': 0.6976241900647948, 'Whataboutism_precision': 0.17391304347826086, 'Whataboutism_recall': 0.09302325581395349, 'Whataboutism_f1-score': 0.12121212121212122, 'Whataboutism_support': 43.0, 'micro avg_precision': 0.17391304347826086, 'micro avg_recall': 0.09302325581395349, 'micro avg_f1-score': 0.12121212121212122, 'micro avg_support': 43.0, 'macro avg_precision': 0.17391304347826086, 'macro avg_recall': 0.09302325581395349, 'macro avg_f1-score': 0.12121212121212122, 'macro avg_support': 43.0, 'weighted avg_precision': 0.17391304347826086, 'weighted avg_recall': 0.09302325581395349, 'weighted avg_f1-score': 0.1212121212121212, 'weighted avg_support': 43.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 0}, {'micro_f1': 0.8347732181425485, 'Whataboutism_precision': 0.391304347826087, 'Whataboutism_recall': 0.17307692307692307, 'Whataboutism_f1-score': 0.24, 'Whataboutism_support': 52.0, 'micro avg_precision': 0.391304347826087, 'micro avg_recall': 0.17307692307692307, 'micro avg_f1-score': 0.24, 'micro avg_support': 52.0, 'macro avg_precision': 0.391304347826087, 'macro avg_recall': 0.17307692307692307, 'macro avg_f1-score': 0.24, 'macro avg_support': 52.0, 'weighted avg_precision': 0.391304347826087, 'weighted avg_recall': 0.17307692307692307, 'weighted avg_f1-score': 0.24000000000000002, 'weighted avg_support': 52.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 1}, {'micro_f1': 0.7624190064794818, 'Whataboutism_precision': 0.08695652173913043, 'Whataboutism_recall': 0.03225806451612903, 'Whataboutism_f1-score': 0.047058823529411764, 'Whataboutism_support': 62.0, 'micro avg_precision': 0.08695652173913043, 'micro avg_recall': 0.03225806451612903, 'micro avg_f1-score': 0.047058823529411764, 'micro avg_support': 62.0, 'macro avg_precision': 0.08695652173913043, 'macro avg_recall': 0.03225806451612903, 'macro avg_f1-score': 0.047058823529411764, 'macro avg_support': 62.0, 'weighted avg_precision': 0.08695652173913043, 'weighted avg_recall': 0.03225806451612903, 'weighted avg_f1-score': 0.047058823529411764, 'weighted avg_support': 62.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 2}]}
{'micro_f1': 0.7775377969762419, 'Whataboutism_precision': 0.391304347826087, 'Whataboutism_recall': 0.19148936170212766, 'Whataboutism_f1-score': 0.2571428571428572, 'Whataboutism_support': 47.0, 'micro avg_precision': 0.391304347826087, 'micro avg_recall': 0.19148936170212766, 'micro avg_f1-score': 0.2571428571428572, 'micro avg_support': 47.0, 'macro avg_precision': 0.391304347826087, 'macro avg_recall': 0.19148936170212766, 'macro avg_f1-score': 0.2571428571428572, 'macro avg_support': 47.0, 'weighted avg_precision': 0.3913043478260869, 'weighted avg_recall': 0.19148936170212766, 'weighted avg_f1-score': 0.2571428571428572, 'weighted avg_support': 47.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 3}
{'results': [{'micro_f1': 0.6976241900647948, 'Whataboutism_precision': 0.17391304347826086, 'Whataboutism_recall': 0.09302325581395349, 'Whataboutism_f1-score': 0.12121212121212122, 'Whataboutism_support': 43.0, 'micro avg_precision': 0.17391304347826086, 'micro avg_recall': 0.09302325581395349, 'micro avg_f1-score': 0.12121212121212122, 'micro avg_support': 43.0, 'macro avg_precision': 0.17391304347826086, 'macro avg_recall': 0.09302325581395349, 'macro avg_f1-score': 0.12121212121212122, 'macro avg_support': 43.0, 'weighted avg_precision': 0.17391304347826086, 'weighted avg_recall': 0.09302325581395349, 'weighted avg_f1-score': 0.1212121212121212, 'weighted avg_support': 43.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 0}, {'micro_f1': 0.8347732181425485, 'Whataboutism_precision': 0.391304347826087, 'Whataboutism_recall': 0.17307692307692307, 'Whataboutism_f1-score': 0.24, 'Whataboutism_support': 52.0, 'micro avg_precision': 0.391304347826087, 'micro avg_recall': 0.17307692307692307, 'micro avg_f1-score': 0.24, 'micro avg_support': 52.0, 'macro avg_precision': 0.391304347826087, 'macro avg_recall': 0.17307692307692307, 'macro avg_f1-score': 0.24, 'macro avg_support': 52.0, 'weighted avg_precision': 0.391304347826087, 'weighted avg_recall': 0.17307692307692307, 'weighted avg_f1-score': 0.24000000000000002, 'weighted avg_support': 52.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 1}, {'micro_f1': 0.7624190064794818, 'Whataboutism_precision': 0.08695652173913043, 'Whataboutism_recall': 0.03225806451612903, 'Whataboutism_f1-score': 0.047058823529411764, 'Whataboutism_support': 62.0, 'micro avg_precision': 0.08695652173913043, 'micro avg_recall': 0.03225806451612903, 'micro avg_f1-score': 0.047058823529411764, 'micro avg_support': 62.0, 'macro avg_precision': 0.08695652173913043, 'macro avg_recall': 0.03225806451612903, 'macro avg_f1-score': 0.047058823529411764, 'macro avg_support': 62.0, 'weighted avg_precision': 0.08695652173913043, 'weighted avg_recall': 0.03225806451612903, 'weighted avg_f1-score': 0.047058823529411764, 'weighted avg_support': 62.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 2}, {'micro_f1': 0.7775377969762419, 'Whataboutism_precision': 0.391304347826087, 'Whataboutism_recall': 0.19148936170212766, 'Whataboutism_f1-score': 0.2571428571428572, 'Whataboutism_support': 47.0, 'micro avg_precision': 0.391304347826087, 'micro avg_recall': 0.19148936170212766, 'micro avg_f1-score': 0.2571428571428572, 'micro avg_support': 47.0, 'macro avg_precision': 0.391304347826087, 'macro avg_recall': 0.19148936170212766, 'macro avg_f1-score': 0.2571428571428572, 'macro avg_support': 47.0, 'weighted avg_precision': 0.3913043478260869, 'weighted avg_recall': 0.19148936170212766, 'weighted avg_f1-score': 0.2571428571428572, 'weighted avg_support': 47.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 3}]}
Best model updated: current epoch macro f1 = 0.2571428571428572
{'micro_f1': 0.7807775377969762, 'Whataboutism_precision': 0.30434782608695654, 'Whataboutism_recall': 0.16666666666666666, 'Whataboutism_f1-score': 0.2153846153846154, 'Whataboutism_support': 42.0, 'micro avg_precision': 0.30434782608695654, 'micro avg_recall': 0.16666666666666666, 'micro avg_f1-score': 0.2153846153846154, 'micro avg_support': 42.0, 'macro avg_precision': 0.30434782608695654, 'macro avg_recall': 0.16666666666666666, 'macro avg_f1-score': 0.2153846153846154, 'macro avg_support': 42.0, 'weighted avg_precision': 0.30434782608695654, 'weighted avg_recall': 0.16666666666666666, 'weighted avg_f1-score': 0.21538461538461537, 'weighted avg_support': 42.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 4}
{'results': [{'micro_f1': 0.6976241900647948, 'Whataboutism_precision': 0.17391304347826086, 'Whataboutism_recall': 0.09302325581395349, 'Whataboutism_f1-score': 0.12121212121212122, 'Whataboutism_support': 43.0, 'micro avg_precision': 0.17391304347826086, 'micro avg_recall': 0.09302325581395349, 'micro avg_f1-score': 0.12121212121212122, 'micro avg_support': 43.0, 'macro avg_precision': 0.17391304347826086, 'macro avg_recall': 0.09302325581395349, 'macro avg_f1-score': 0.12121212121212122, 'macro avg_support': 43.0, 'weighted avg_precision': 0.17391304347826086, 'weighted avg_recall': 0.09302325581395349, 'weighted avg_f1-score': 0.1212121212121212, 'weighted avg_support': 43.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 0}, {'micro_f1': 0.8347732181425485, 'Whataboutism_precision': 0.391304347826087, 'Whataboutism_recall': 0.17307692307692307, 'Whataboutism_f1-score': 0.24, 'Whataboutism_support': 52.0, 'micro avg_precision': 0.391304347826087, 'micro avg_recall': 0.17307692307692307, 'micro avg_f1-score': 0.24, 'micro avg_support': 52.0, 'macro avg_precision': 0.391304347826087, 'macro avg_recall': 0.17307692307692307, 'macro avg_f1-score': 0.24, 'macro avg_support': 52.0, 'weighted avg_precision': 0.391304347826087, 'weighted avg_recall': 0.17307692307692307, 'weighted avg_f1-score': 0.24000000000000002, 'weighted avg_support': 52.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 1}, {'micro_f1': 0.7624190064794818, 'Whataboutism_precision': 0.08695652173913043, 'Whataboutism_recall': 0.03225806451612903, 'Whataboutism_f1-score': 0.047058823529411764, 'Whataboutism_support': 62.0, 'micro avg_precision': 0.08695652173913043, 'micro avg_recall': 0.03225806451612903, 'micro avg_f1-score': 0.047058823529411764, 'micro avg_support': 62.0, 'macro avg_precision': 0.08695652173913043, 'macro avg_recall': 0.03225806451612903, 'macro avg_f1-score': 0.047058823529411764, 'macro avg_support': 62.0, 'weighted avg_precision': 0.08695652173913043, 'weighted avg_recall': 0.03225806451612903, 'weighted avg_f1-score': 0.047058823529411764, 'weighted avg_support': 62.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 2}, {'micro_f1': 0.7775377969762419, 'Whataboutism_precision': 0.391304347826087, 'Whataboutism_recall': 0.19148936170212766, 'Whataboutism_f1-score': 0.2571428571428572, 'Whataboutism_support': 47.0, 'micro avg_precision': 0.391304347826087, 'micro avg_recall': 0.19148936170212766, 'micro avg_f1-score': 0.2571428571428572, 'micro avg_support': 47.0, 'macro avg_precision': 0.391304347826087, 'macro avg_recall': 0.19148936170212766, 'macro avg_f1-score': 0.2571428571428572, 'macro avg_support': 47.0, 'weighted avg_precision': 0.3913043478260869, 'weighted avg_recall': 0.19148936170212766, 'weighted avg_f1-score': 0.2571428571428572, 'weighted avg_support': 47.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 3}, {'micro_f1': 0.7807775377969762, 'Whataboutism_precision': 0.30434782608695654, 'Whataboutism_recall': 0.16666666666666666, 'Whataboutism_f1-score': 0.2153846153846154, 'Whataboutism_support': 42.0, 'micro avg_precision': 0.30434782608695654, 'micro avg_recall': 0.16666666666666666, 'micro avg_f1-score': 0.2153846153846154, 'micro avg_support': 42.0, 'macro avg_precision': 0.30434782608695654, 'macro avg_recall': 0.16666666666666666, 'macro avg_f1-score': 0.2153846153846154, 'macro avg_support': 42.0, 'weighted avg_precision': 0.30434782608695654, 'weighted avg_recall': 0.16666666666666666, 'weighted avg_f1-score': 0.21538461538461537, 'weighted avg_support': 42.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 4}]}
{'micro_f1': 0.7958963282937366, 'Whataboutism_precision': 0.391304347826087, 'Whataboutism_recall': 0.20454545454545456, 'Whataboutism_f1-score': 0.2686567164179105, 'Whataboutism_support': 44.0, 'micro avg_precision': 0.391304347826087, 'micro avg_recall': 0.20454545454545456, 'micro avg_f1-score': 0.2686567164179105, 'micro avg_support': 44.0, 'macro avg_precision': 0.391304347826087, 'macro avg_recall': 0.20454545454545456, 'macro avg_f1-score': 0.2686567164179105, 'macro avg_support': 44.0, 'weighted avg_precision': 0.391304347826087, 'weighted avg_recall': 0.20454545454545456, 'weighted avg_f1-score': 0.2686567164179105, 'weighted avg_support': 44.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 5}
{'results': [{'micro_f1': 0.6976241900647948, 'Whataboutism_precision': 0.17391304347826086, 'Whataboutism_recall': 0.09302325581395349, 'Whataboutism_f1-score': 0.12121212121212122, 'Whataboutism_support': 43.0, 'micro avg_precision': 0.17391304347826086, 'micro avg_recall': 0.09302325581395349, 'micro avg_f1-score': 0.12121212121212122, 'micro avg_support': 43.0, 'macro avg_precision': 0.17391304347826086, 'macro avg_recall': 0.09302325581395349, 'macro avg_f1-score': 0.12121212121212122, 'macro avg_support': 43.0, 'weighted avg_precision': 0.17391304347826086, 'weighted avg_recall': 0.09302325581395349, 'weighted avg_f1-score': 0.1212121212121212, 'weighted avg_support': 43.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 0}, {'micro_f1': 0.8347732181425485, 'Whataboutism_precision': 0.391304347826087, 'Whataboutism_recall': 0.17307692307692307, 'Whataboutism_f1-score': 0.24, 'Whataboutism_support': 52.0, 'micro avg_precision': 0.391304347826087, 'micro avg_recall': 0.17307692307692307, 'micro avg_f1-score': 0.24, 'micro avg_support': 52.0, 'macro avg_precision': 0.391304347826087, 'macro avg_recall': 0.17307692307692307, 'macro avg_f1-score': 0.24, 'macro avg_support': 52.0, 'weighted avg_precision': 0.391304347826087, 'weighted avg_recall': 0.17307692307692307, 'weighted avg_f1-score': 0.24000000000000002, 'weighted avg_support': 52.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 1}, {'micro_f1': 0.7624190064794818, 'Whataboutism_precision': 0.08695652173913043, 'Whataboutism_recall': 0.03225806451612903, 'Whataboutism_f1-score': 0.047058823529411764, 'Whataboutism_support': 62.0, 'micro avg_precision': 0.08695652173913043, 'micro avg_recall': 0.03225806451612903, 'micro avg_f1-score': 0.047058823529411764, 'micro avg_support': 62.0, 'macro avg_precision': 0.08695652173913043, 'macro avg_recall': 0.03225806451612903, 'macro avg_f1-score': 0.047058823529411764, 'macro avg_support': 62.0, 'weighted avg_precision': 0.08695652173913043, 'weighted avg_recall': 0.03225806451612903, 'weighted avg_f1-score': 0.047058823529411764, 'weighted avg_support': 62.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 2}, {'micro_f1': 0.7775377969762419, 'Whataboutism_precision': 0.391304347826087, 'Whataboutism_recall': 0.19148936170212766, 'Whataboutism_f1-score': 0.2571428571428572, 'Whataboutism_support': 47.0, 'micro avg_precision': 0.391304347826087, 'micro avg_recall': 0.19148936170212766, 'micro avg_f1-score': 0.2571428571428572, 'micro avg_support': 47.0, 'macro avg_precision': 0.391304347826087, 'macro avg_recall': 0.19148936170212766, 'macro avg_f1-score': 0.2571428571428572, 'macro avg_support': 47.0, 'weighted avg_precision': 0.3913043478260869, 'weighted avg_recall': 0.19148936170212766, 'weighted avg_f1-score': 0.2571428571428572, 'weighted avg_support': 47.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 3}, {'micro_f1': 0.7807775377969762, 'Whataboutism_precision': 0.30434782608695654, 'Whataboutism_recall': 0.16666666666666666, 'Whataboutism_f1-score': 0.2153846153846154, 'Whataboutism_support': 42.0, 'micro avg_precision': 0.30434782608695654, 'micro avg_recall': 0.16666666666666666, 'micro avg_f1-score': 0.2153846153846154, 'micro avg_support': 42.0, 'macro avg_precision': 0.30434782608695654, 'macro avg_recall': 0.16666666666666666, 'macro avg_f1-score': 0.2153846153846154, 'macro avg_support': 42.0, 'weighted avg_precision': 0.30434782608695654, 'weighted avg_recall': 0.16666666666666666, 'weighted avg_f1-score': 0.21538461538461537, 'weighted avg_support': 42.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 4}, {'micro_f1': 0.7958963282937366, 'Whataboutism_precision': 0.391304347826087, 'Whataboutism_recall': 0.20454545454545456, 'Whataboutism_f1-score': 0.2686567164179105, 'Whataboutism_support': 44.0, 'micro avg_precision': 0.391304347826087, 'micro avg_recall': 0.20454545454545456, 'micro avg_f1-score': 0.2686567164179105, 'micro avg_support': 44.0, 'macro avg_precision': 0.391304347826087, 'macro avg_recall': 0.20454545454545456, 'macro avg_f1-score': 0.2686567164179105, 'macro avg_support': 44.0, 'weighted avg_precision': 0.391304347826087, 'weighted avg_recall': 0.20454545454545456, 'weighted avg_f1-score': 0.2686567164179105, 'weighted avg_support': 44.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 5}]}
Best model updated: current epoch macro f1 = 0.2686567164179105
{'micro_f1': 0.7462203023758099, 'Whataboutism_precision': 0.34782608695652173, 'Whataboutism_recall': 0.19047619047619047, 'Whataboutism_f1-score': 0.24615384615384614, 'Whataboutism_support': 42.0, 'micro avg_precision': 0.34782608695652173, 'micro avg_recall': 0.19047619047619047, 'micro avg_f1-score': 0.24615384615384614, 'micro avg_support': 42.0, 'macro avg_precision': 0.34782608695652173, 'macro avg_recall': 0.19047619047619047, 'macro avg_f1-score': 0.24615384615384614, 'macro avg_support': 42.0, 'weighted avg_precision': 0.34782608695652173, 'weighted avg_recall': 0.19047619047619047, 'weighted avg_f1-score': 0.2461538461538461, 'weighted avg_support': 42.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 6}
{'results': [{'micro_f1': 0.6976241900647948, 'Whataboutism_precision': 0.17391304347826086, 'Whataboutism_recall': 0.09302325581395349, 'Whataboutism_f1-score': 0.12121212121212122, 'Whataboutism_support': 43.0, 'micro avg_precision': 0.17391304347826086, 'micro avg_recall': 0.09302325581395349, 'micro avg_f1-score': 0.12121212121212122, 'micro avg_support': 43.0, 'macro avg_precision': 0.17391304347826086, 'macro avg_recall': 0.09302325581395349, 'macro avg_f1-score': 0.12121212121212122, 'macro avg_support': 43.0, 'weighted avg_precision': 0.17391304347826086, 'weighted avg_recall': 0.09302325581395349, 'weighted avg_f1-score': 0.1212121212121212, 'weighted avg_support': 43.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 0}, {'micro_f1': 0.8347732181425485, 'Whataboutism_precision': 0.391304347826087, 'Whataboutism_recall': 0.17307692307692307, 'Whataboutism_f1-score': 0.24, 'Whataboutism_support': 52.0, 'micro avg_precision': 0.391304347826087, 'micro avg_recall': 0.17307692307692307, 'micro avg_f1-score': 0.24, 'micro avg_support': 52.0, 'macro avg_precision': 0.391304347826087, 'macro avg_recall': 0.17307692307692307, 'macro avg_f1-score': 0.24, 'macro avg_support': 52.0, 'weighted avg_precision': 0.391304347826087, 'weighted avg_recall': 0.17307692307692307, 'weighted avg_f1-score': 0.24000000000000002, 'weighted avg_support': 52.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 1}, {'micro_f1': 0.7624190064794818, 'Whataboutism_precision': 0.08695652173913043, 'Whataboutism_recall': 0.03225806451612903, 'Whataboutism_f1-score': 0.047058823529411764, 'Whataboutism_support': 62.0, 'micro avg_precision': 0.08695652173913043, 'micro avg_recall': 0.03225806451612903, 'micro avg_f1-score': 0.047058823529411764, 'micro avg_support': 62.0, 'macro avg_precision': 0.08695652173913043, 'macro avg_recall': 0.03225806451612903, 'macro avg_f1-score': 0.047058823529411764, 'macro avg_support': 62.0, 'weighted avg_precision': 0.08695652173913043, 'weighted avg_recall': 0.03225806451612903, 'weighted avg_f1-score': 0.047058823529411764, 'weighted avg_support': 62.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 2}, {'micro_f1': 0.7775377969762419, 'Whataboutism_precision': 0.391304347826087, 'Whataboutism_recall': 0.19148936170212766, 'Whataboutism_f1-score': 0.2571428571428572, 'Whataboutism_support': 47.0, 'micro avg_precision': 0.391304347826087, 'micro avg_recall': 0.19148936170212766, 'micro avg_f1-score': 0.2571428571428572, 'micro avg_support': 47.0, 'macro avg_precision': 0.391304347826087, 'macro avg_recall': 0.19148936170212766, 'macro avg_f1-score': 0.2571428571428572, 'macro avg_support': 47.0, 'weighted avg_precision': 0.3913043478260869, 'weighted avg_recall': 0.19148936170212766, 'weighted avg_f1-score': 0.2571428571428572, 'weighted avg_support': 47.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 3}, {'micro_f1': 0.7807775377969762, 'Whataboutism_precision': 0.30434782608695654, 'Whataboutism_recall': 0.16666666666666666, 'Whataboutism_f1-score': 0.2153846153846154, 'Whataboutism_support': 42.0, 'micro avg_precision': 0.30434782608695654, 'micro avg_recall': 0.16666666666666666, 'micro avg_f1-score': 0.2153846153846154, 'micro avg_support': 42.0, 'macro avg_precision': 0.30434782608695654, 'macro avg_recall': 0.16666666666666666, 'macro avg_f1-score': 0.2153846153846154, 'macro avg_support': 42.0, 'weighted avg_precision': 0.30434782608695654, 'weighted avg_recall': 0.16666666666666666, 'weighted avg_f1-score': 0.21538461538461537, 'weighted avg_support': 42.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 4}, {'micro_f1': 0.7958963282937366, 'Whataboutism_precision': 0.391304347826087, 'Whataboutism_recall': 0.20454545454545456, 'Whataboutism_f1-score': 0.2686567164179105, 'Whataboutism_support': 44.0, 'micro avg_precision': 0.391304347826087, 'micro avg_recall': 0.20454545454545456, 'micro avg_f1-score': 0.2686567164179105, 'micro avg_support': 44.0, 'macro avg_precision': 0.391304347826087, 'macro avg_recall': 0.20454545454545456, 'macro avg_f1-score': 0.2686567164179105, 'macro avg_support': 44.0, 'weighted avg_precision': 0.391304347826087, 'weighted avg_recall': 0.20454545454545456, 'weighted avg_f1-score': 0.2686567164179105, 'weighted avg_support': 44.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 5}, {'micro_f1': 0.7462203023758099, 'Whataboutism_precision': 0.34782608695652173, 'Whataboutism_recall': 0.19047619047619047, 'Whataboutism_f1-score': 0.24615384615384614, 'Whataboutism_support': 42.0, 'micro avg_precision': 0.34782608695652173, 'micro avg_recall': 0.19047619047619047, 'micro avg_f1-score': 0.24615384615384614, 'micro avg_support': 42.0, 'macro avg_precision': 0.34782608695652173, 'macro avg_recall': 0.19047619047619047, 'macro avg_f1-score': 0.24615384615384614, 'macro avg_support': 42.0, 'weighted avg_precision': 0.34782608695652173, 'weighted avg_recall': 0.19047619047619047, 'weighted avg_f1-score': 0.2461538461538461, 'weighted avg_support': 42.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 6}]}
{'micro_f1': 0.8358531317494601, 'Whataboutism_precision': 0.4782608695652174, 'Whataboutism_recall': 0.3142857142857143, 'Whataboutism_f1-score': 0.3793103448275862, 'Whataboutism_support': 35.0, 'micro avg_precision': 0.4782608695652174, 'micro avg_recall': 0.3142857142857143, 'micro avg_f1-score': 0.3793103448275862, 'micro avg_support': 35.0, 'macro avg_precision': 0.4782608695652174, 'macro avg_recall': 0.3142857142857143, 'macro avg_f1-score': 0.3793103448275862, 'macro avg_support': 35.0, 'weighted avg_precision': 0.4782608695652174, 'weighted avg_recall': 0.3142857142857143, 'weighted avg_f1-score': 0.3793103448275862, 'weighted avg_support': 35.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 7}
{'results': [{'micro_f1': 0.6976241900647948, 'Whataboutism_precision': 0.17391304347826086, 'Whataboutism_recall': 0.09302325581395349, 'Whataboutism_f1-score': 0.12121212121212122, 'Whataboutism_support': 43.0, 'micro avg_precision': 0.17391304347826086, 'micro avg_recall': 0.09302325581395349, 'micro avg_f1-score': 0.12121212121212122, 'micro avg_support': 43.0, 'macro avg_precision': 0.17391304347826086, 'macro avg_recall': 0.09302325581395349, 'macro avg_f1-score': 0.12121212121212122, 'macro avg_support': 43.0, 'weighted avg_precision': 0.17391304347826086, 'weighted avg_recall': 0.09302325581395349, 'weighted avg_f1-score': 0.1212121212121212, 'weighted avg_support': 43.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 0}, {'micro_f1': 0.8347732181425485, 'Whataboutism_precision': 0.391304347826087, 'Whataboutism_recall': 0.17307692307692307, 'Whataboutism_f1-score': 0.24, 'Whataboutism_support': 52.0, 'micro avg_precision': 0.391304347826087, 'micro avg_recall': 0.17307692307692307, 'micro avg_f1-score': 0.24, 'micro avg_support': 52.0, 'macro avg_precision': 0.391304347826087, 'macro avg_recall': 0.17307692307692307, 'macro avg_f1-score': 0.24, 'macro avg_support': 52.0, 'weighted avg_precision': 0.391304347826087, 'weighted avg_recall': 0.17307692307692307, 'weighted avg_f1-score': 0.24000000000000002, 'weighted avg_support': 52.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 1}, {'micro_f1': 0.7624190064794818, 'Whataboutism_precision': 0.08695652173913043, 'Whataboutism_recall': 0.03225806451612903, 'Whataboutism_f1-score': 0.047058823529411764, 'Whataboutism_support': 62.0, 'micro avg_precision': 0.08695652173913043, 'micro avg_recall': 0.03225806451612903, 'micro avg_f1-score': 0.047058823529411764, 'micro avg_support': 62.0, 'macro avg_precision': 0.08695652173913043, 'macro avg_recall': 0.03225806451612903, 'macro avg_f1-score': 0.047058823529411764, 'macro avg_support': 62.0, 'weighted avg_precision': 0.08695652173913043, 'weighted avg_recall': 0.03225806451612903, 'weighted avg_f1-score': 0.047058823529411764, 'weighted avg_support': 62.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 2}, {'micro_f1': 0.7775377969762419, 'Whataboutism_precision': 0.391304347826087, 'Whataboutism_recall': 0.19148936170212766, 'Whataboutism_f1-score': 0.2571428571428572, 'Whataboutism_support': 47.0, 'micro avg_precision': 0.391304347826087, 'micro avg_recall': 0.19148936170212766, 'micro avg_f1-score': 0.2571428571428572, 'micro avg_support': 47.0, 'macro avg_precision': 0.391304347826087, 'macro avg_recall': 0.19148936170212766, 'macro avg_f1-score': 0.2571428571428572, 'macro avg_support': 47.0, 'weighted avg_precision': 0.3913043478260869, 'weighted avg_recall': 0.19148936170212766, 'weighted avg_f1-score': 0.2571428571428572, 'weighted avg_support': 47.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 3}, {'micro_f1': 0.7807775377969762, 'Whataboutism_precision': 0.30434782608695654, 'Whataboutism_recall': 0.16666666666666666, 'Whataboutism_f1-score': 0.2153846153846154, 'Whataboutism_support': 42.0, 'micro avg_precision': 0.30434782608695654, 'micro avg_recall': 0.16666666666666666, 'micro avg_f1-score': 0.2153846153846154, 'micro avg_support': 42.0, 'macro avg_precision': 0.30434782608695654, 'macro avg_recall': 0.16666666666666666, 'macro avg_f1-score': 0.2153846153846154, 'macro avg_support': 42.0, 'weighted avg_precision': 0.30434782608695654, 'weighted avg_recall': 0.16666666666666666, 'weighted avg_f1-score': 0.21538461538461537, 'weighted avg_support': 42.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 4}, {'micro_f1': 0.7958963282937366, 'Whataboutism_precision': 0.391304347826087, 'Whataboutism_recall': 0.20454545454545456, 'Whataboutism_f1-score': 0.2686567164179105, 'Whataboutism_support': 44.0, 'micro avg_precision': 0.391304347826087, 'micro avg_recall': 0.20454545454545456, 'micro avg_f1-score': 0.2686567164179105, 'micro avg_support': 44.0, 'macro avg_precision': 0.391304347826087, 'macro avg_recall': 0.20454545454545456, 'macro avg_f1-score': 0.2686567164179105, 'macro avg_support': 44.0, 'weighted avg_precision': 0.391304347826087, 'weighted avg_recall': 0.20454545454545456, 'weighted avg_f1-score': 0.2686567164179105, 'weighted avg_support': 44.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 5}, {'micro_f1': 0.7462203023758099, 'Whataboutism_precision': 0.34782608695652173, 'Whataboutism_recall': 0.19047619047619047, 'Whataboutism_f1-score': 0.24615384615384614, 'Whataboutism_support': 42.0, 'micro avg_precision': 0.34782608695652173, 'micro avg_recall': 0.19047619047619047, 'micro avg_f1-score': 0.24615384615384614, 'micro avg_support': 42.0, 'macro avg_precision': 0.34782608695652173, 'macro avg_recall': 0.19047619047619047, 'macro avg_f1-score': 0.24615384615384614, 'macro avg_support': 42.0, 'weighted avg_precision': 0.34782608695652173, 'weighted avg_recall': 0.19047619047619047, 'weighted avg_f1-score': 0.2461538461538461, 'weighted avg_support': 42.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 6}, {'micro_f1': 0.8358531317494601, 'Whataboutism_precision': 0.4782608695652174, 'Whataboutism_recall': 0.3142857142857143, 'Whataboutism_f1-score': 0.3793103448275862, 'Whataboutism_support': 35.0, 'micro avg_precision': 0.4782608695652174, 'micro avg_recall': 0.3142857142857143, 'micro avg_f1-score': 0.3793103448275862, 'micro avg_support': 35.0, 'macro avg_precision': 0.4782608695652174, 'macro avg_recall': 0.3142857142857143, 'macro avg_f1-score': 0.3793103448275862, 'macro avg_support': 35.0, 'weighted avg_precision': 0.4782608695652174, 'weighted avg_recall': 0.3142857142857143, 'weighted avg_f1-score': 0.3793103448275862, 'weighted avg_support': 35.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 7}]}
Best model updated: current epoch macro f1 = 0.3793103448275862
{'micro_f1': 0.8304535637149028, 'Whataboutism_precision': 0.4782608695652174, 'Whataboutism_recall': 0.2972972972972973, 'Whataboutism_f1-score': 0.3666666666666667, 'Whataboutism_support': 37.0, 'micro avg_precision': 0.4782608695652174, 'micro avg_recall': 0.2972972972972973, 'micro avg_f1-score': 0.3666666666666667, 'micro avg_support': 37.0, 'macro avg_precision': 0.4782608695652174, 'macro avg_recall': 0.2972972972972973, 'macro avg_f1-score': 0.3666666666666667, 'macro avg_support': 37.0, 'weighted avg_precision': 0.4782608695652174, 'weighted avg_recall': 0.2972972972972973, 'weighted avg_f1-score': 0.3666666666666667, 'weighted avg_support': 37.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 8}
{'results': [{'micro_f1': 0.6976241900647948, 'Whataboutism_precision': 0.17391304347826086, 'Whataboutism_recall': 0.09302325581395349, 'Whataboutism_f1-score': 0.12121212121212122, 'Whataboutism_support': 43.0, 'micro avg_precision': 0.17391304347826086, 'micro avg_recall': 0.09302325581395349, 'micro avg_f1-score': 0.12121212121212122, 'micro avg_support': 43.0, 'macro avg_precision': 0.17391304347826086, 'macro avg_recall': 0.09302325581395349, 'macro avg_f1-score': 0.12121212121212122, 'macro avg_support': 43.0, 'weighted avg_precision': 0.17391304347826086, 'weighted avg_recall': 0.09302325581395349, 'weighted avg_f1-score': 0.1212121212121212, 'weighted avg_support': 43.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 0}, {'micro_f1': 0.8347732181425485, 'Whataboutism_precision': 0.391304347826087, 'Whataboutism_recall': 0.17307692307692307, 'Whataboutism_f1-score': 0.24, 'Whataboutism_support': 52.0, 'micro avg_precision': 0.391304347826087, 'micro avg_recall': 0.17307692307692307, 'micro avg_f1-score': 0.24, 'micro avg_support': 52.0, 'macro avg_precision': 0.391304347826087, 'macro avg_recall': 0.17307692307692307, 'macro avg_f1-score': 0.24, 'macro avg_support': 52.0, 'weighted avg_precision': 0.391304347826087, 'weighted avg_recall': 0.17307692307692307, 'weighted avg_f1-score': 0.24000000000000002, 'weighted avg_support': 52.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 1}, {'micro_f1': 0.7624190064794818, 'Whataboutism_precision': 0.08695652173913043, 'Whataboutism_recall': 0.03225806451612903, 'Whataboutism_f1-score': 0.047058823529411764, 'Whataboutism_support': 62.0, 'micro avg_precision': 0.08695652173913043, 'micro avg_recall': 0.03225806451612903, 'micro avg_f1-score': 0.047058823529411764, 'micro avg_support': 62.0, 'macro avg_precision': 0.08695652173913043, 'macro avg_recall': 0.03225806451612903, 'macro avg_f1-score': 0.047058823529411764, 'macro avg_support': 62.0, 'weighted avg_precision': 0.08695652173913043, 'weighted avg_recall': 0.03225806451612903, 'weighted avg_f1-score': 0.047058823529411764, 'weighted avg_support': 62.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 2}, {'micro_f1': 0.7775377969762419, 'Whataboutism_precision': 0.391304347826087, 'Whataboutism_recall': 0.19148936170212766, 'Whataboutism_f1-score': 0.2571428571428572, 'Whataboutism_support': 47.0, 'micro avg_precision': 0.391304347826087, 'micro avg_recall': 0.19148936170212766, 'micro avg_f1-score': 0.2571428571428572, 'micro avg_support': 47.0, 'macro avg_precision': 0.391304347826087, 'macro avg_recall': 0.19148936170212766, 'macro avg_f1-score': 0.2571428571428572, 'macro avg_support': 47.0, 'weighted avg_precision': 0.3913043478260869, 'weighted avg_recall': 0.19148936170212766, 'weighted avg_f1-score': 0.2571428571428572, 'weighted avg_support': 47.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 3}, {'micro_f1': 0.7807775377969762, 'Whataboutism_precision': 0.30434782608695654, 'Whataboutism_recall': 0.16666666666666666, 'Whataboutism_f1-score': 0.2153846153846154, 'Whataboutism_support': 42.0, 'micro avg_precision': 0.30434782608695654, 'micro avg_recall': 0.16666666666666666, 'micro avg_f1-score': 0.2153846153846154, 'micro avg_support': 42.0, 'macro avg_precision': 0.30434782608695654, 'macro avg_recall': 0.16666666666666666, 'macro avg_f1-score': 0.2153846153846154, 'macro avg_support': 42.0, 'weighted avg_precision': 0.30434782608695654, 'weighted avg_recall': 0.16666666666666666, 'weighted avg_f1-score': 0.21538461538461537, 'weighted avg_support': 42.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 4}, {'micro_f1': 0.7958963282937366, 'Whataboutism_precision': 0.391304347826087, 'Whataboutism_recall': 0.20454545454545456, 'Whataboutism_f1-score': 0.2686567164179105, 'Whataboutism_support': 44.0, 'micro avg_precision': 0.391304347826087, 'micro avg_recall': 0.20454545454545456, 'micro avg_f1-score': 0.2686567164179105, 'micro avg_support': 44.0, 'macro avg_precision': 0.391304347826087, 'macro avg_recall': 0.20454545454545456, 'macro avg_f1-score': 0.2686567164179105, 'macro avg_support': 44.0, 'weighted avg_precision': 0.391304347826087, 'weighted avg_recall': 0.20454545454545456, 'weighted avg_f1-score': 0.2686567164179105, 'weighted avg_support': 44.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 5}, {'micro_f1': 0.7462203023758099, 'Whataboutism_precision': 0.34782608695652173, 'Whataboutism_recall': 0.19047619047619047, 'Whataboutism_f1-score': 0.24615384615384614, 'Whataboutism_support': 42.0, 'micro avg_precision': 0.34782608695652173, 'micro avg_recall': 0.19047619047619047, 'micro avg_f1-score': 0.24615384615384614, 'micro avg_support': 42.0, 'macro avg_precision': 0.34782608695652173, 'macro avg_recall': 0.19047619047619047, 'macro avg_f1-score': 0.24615384615384614, 'macro avg_support': 42.0, 'weighted avg_precision': 0.34782608695652173, 'weighted avg_recall': 0.19047619047619047, 'weighted avg_f1-score': 0.2461538461538461, 'weighted avg_support': 42.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 6}, {'micro_f1': 0.8358531317494601, 'Whataboutism_precision': 0.4782608695652174, 'Whataboutism_recall': 0.3142857142857143, 'Whataboutism_f1-score': 0.3793103448275862, 'Whataboutism_support': 35.0, 'micro avg_precision': 0.4782608695652174, 'micro avg_recall': 0.3142857142857143, 'micro avg_f1-score': 0.3793103448275862, 'micro avg_support': 35.0, 'macro avg_precision': 0.4782608695652174, 'macro avg_recall': 0.3142857142857143, 'macro avg_f1-score': 0.3793103448275862, 'macro avg_support': 35.0, 'weighted avg_precision': 0.4782608695652174, 'weighted avg_recall': 0.3142857142857143, 'weighted avg_f1-score': 0.3793103448275862, 'weighted avg_support': 35.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 7}, {'micro_f1': 0.8304535637149028, 'Whataboutism_precision': 0.4782608695652174, 'Whataboutism_recall': 0.2972972972972973, 'Whataboutism_f1-score': 0.3666666666666667, 'Whataboutism_support': 37.0, 'micro avg_precision': 0.4782608695652174, 'micro avg_recall': 0.2972972972972973, 'micro avg_f1-score': 0.3666666666666667, 'micro avg_support': 37.0, 'macro avg_precision': 0.4782608695652174, 'macro avg_recall': 0.2972972972972973, 'macro avg_f1-score': 0.3666666666666667, 'macro avg_support': 37.0, 'weighted avg_precision': 0.4782608695652174, 'weighted avg_recall': 0.2972972972972973, 'weighted avg_f1-score': 0.3666666666666667, 'weighted avg_support': 37.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 8}]}
{'micro_f1': 0.8304535637149028, 'Whataboutism_precision': 0.4782608695652174, 'Whataboutism_recall': 0.3142857142857143, 'Whataboutism_f1-score': 0.3793103448275862, 'Whataboutism_support': 35.0, 'micro avg_precision': 0.4782608695652174, 'micro avg_recall': 0.3142857142857143, 'micro avg_f1-score': 0.3793103448275862, 'micro avg_support': 35.0, 'macro avg_precision': 0.4782608695652174, 'macro avg_recall': 0.3142857142857143, 'macro avg_f1-score': 0.3793103448275862, 'macro avg_support': 35.0, 'weighted avg_precision': 0.4782608695652174, 'weighted avg_recall': 0.3142857142857143, 'weighted avg_f1-score': 0.3793103448275862, 'weighted avg_support': 35.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 9}
{'results': [{'micro_f1': 0.6976241900647948, 'Whataboutism_precision': 0.17391304347826086, 'Whataboutism_recall': 0.09302325581395349, 'Whataboutism_f1-score': 0.12121212121212122, 'Whataboutism_support': 43.0, 'micro avg_precision': 0.17391304347826086, 'micro avg_recall': 0.09302325581395349, 'micro avg_f1-score': 0.12121212121212122, 'micro avg_support': 43.0, 'macro avg_precision': 0.17391304347826086, 'macro avg_recall': 0.09302325581395349, 'macro avg_f1-score': 0.12121212121212122, 'macro avg_support': 43.0, 'weighted avg_precision': 0.17391304347826086, 'weighted avg_recall': 0.09302325581395349, 'weighted avg_f1-score': 0.1212121212121212, 'weighted avg_support': 43.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 0}, {'micro_f1': 0.8347732181425485, 'Whataboutism_precision': 0.391304347826087, 'Whataboutism_recall': 0.17307692307692307, 'Whataboutism_f1-score': 0.24, 'Whataboutism_support': 52.0, 'micro avg_precision': 0.391304347826087, 'micro avg_recall': 0.17307692307692307, 'micro avg_f1-score': 0.24, 'micro avg_support': 52.0, 'macro avg_precision': 0.391304347826087, 'macro avg_recall': 0.17307692307692307, 'macro avg_f1-score': 0.24, 'macro avg_support': 52.0, 'weighted avg_precision': 0.391304347826087, 'weighted avg_recall': 0.17307692307692307, 'weighted avg_f1-score': 0.24000000000000002, 'weighted avg_support': 52.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 1}, {'micro_f1': 0.7624190064794818, 'Whataboutism_precision': 0.08695652173913043, 'Whataboutism_recall': 0.03225806451612903, 'Whataboutism_f1-score': 0.047058823529411764, 'Whataboutism_support': 62.0, 'micro avg_precision': 0.08695652173913043, 'micro avg_recall': 0.03225806451612903, 'micro avg_f1-score': 0.047058823529411764, 'micro avg_support': 62.0, 'macro avg_precision': 0.08695652173913043, 'macro avg_recall': 0.03225806451612903, 'macro avg_f1-score': 0.047058823529411764, 'macro avg_support': 62.0, 'weighted avg_precision': 0.08695652173913043, 'weighted avg_recall': 0.03225806451612903, 'weighted avg_f1-score': 0.047058823529411764, 'weighted avg_support': 62.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 2}, {'micro_f1': 0.7775377969762419, 'Whataboutism_precision': 0.391304347826087, 'Whataboutism_recall': 0.19148936170212766, 'Whataboutism_f1-score': 0.2571428571428572, 'Whataboutism_support': 47.0, 'micro avg_precision': 0.391304347826087, 'micro avg_recall': 0.19148936170212766, 'micro avg_f1-score': 0.2571428571428572, 'micro avg_support': 47.0, 'macro avg_precision': 0.391304347826087, 'macro avg_recall': 0.19148936170212766, 'macro avg_f1-score': 0.2571428571428572, 'macro avg_support': 47.0, 'weighted avg_precision': 0.3913043478260869, 'weighted avg_recall': 0.19148936170212766, 'weighted avg_f1-score': 0.2571428571428572, 'weighted avg_support': 47.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 3}, {'micro_f1': 0.7807775377969762, 'Whataboutism_precision': 0.30434782608695654, 'Whataboutism_recall': 0.16666666666666666, 'Whataboutism_f1-score': 0.2153846153846154, 'Whataboutism_support': 42.0, 'micro avg_precision': 0.30434782608695654, 'micro avg_recall': 0.16666666666666666, 'micro avg_f1-score': 0.2153846153846154, 'micro avg_support': 42.0, 'macro avg_precision': 0.30434782608695654, 'macro avg_recall': 0.16666666666666666, 'macro avg_f1-score': 0.2153846153846154, 'macro avg_support': 42.0, 'weighted avg_precision': 0.30434782608695654, 'weighted avg_recall': 0.16666666666666666, 'weighted avg_f1-score': 0.21538461538461537, 'weighted avg_support': 42.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 4}, {'micro_f1': 0.7958963282937366, 'Whataboutism_precision': 0.391304347826087, 'Whataboutism_recall': 0.20454545454545456, 'Whataboutism_f1-score': 0.2686567164179105, 'Whataboutism_support': 44.0, 'micro avg_precision': 0.391304347826087, 'micro avg_recall': 0.20454545454545456, 'micro avg_f1-score': 0.2686567164179105, 'micro avg_support': 44.0, 'macro avg_precision': 0.391304347826087, 'macro avg_recall': 0.20454545454545456, 'macro avg_f1-score': 0.2686567164179105, 'macro avg_support': 44.0, 'weighted avg_precision': 0.391304347826087, 'weighted avg_recall': 0.20454545454545456, 'weighted avg_f1-score': 0.2686567164179105, 'weighted avg_support': 44.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 5}, {'micro_f1': 0.7462203023758099, 'Whataboutism_precision': 0.34782608695652173, 'Whataboutism_recall': 0.19047619047619047, 'Whataboutism_f1-score': 0.24615384615384614, 'Whataboutism_support': 42.0, 'micro avg_precision': 0.34782608695652173, 'micro avg_recall': 0.19047619047619047, 'micro avg_f1-score': 0.24615384615384614, 'micro avg_support': 42.0, 'macro avg_precision': 0.34782608695652173, 'macro avg_recall': 0.19047619047619047, 'macro avg_f1-score': 0.24615384615384614, 'macro avg_support': 42.0, 'weighted avg_precision': 0.34782608695652173, 'weighted avg_recall': 0.19047619047619047, 'weighted avg_f1-score': 0.2461538461538461, 'weighted avg_support': 42.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 6}, {'micro_f1': 0.8358531317494601, 'Whataboutism_precision': 0.4782608695652174, 'Whataboutism_recall': 0.3142857142857143, 'Whataboutism_f1-score': 0.3793103448275862, 'Whataboutism_support': 35.0, 'micro avg_precision': 0.4782608695652174, 'micro avg_recall': 0.3142857142857143, 'micro avg_f1-score': 0.3793103448275862, 'micro avg_support': 35.0, 'macro avg_precision': 0.4782608695652174, 'macro avg_recall': 0.3142857142857143, 'macro avg_f1-score': 0.3793103448275862, 'macro avg_support': 35.0, 'weighted avg_precision': 0.4782608695652174, 'weighted avg_recall': 0.3142857142857143, 'weighted avg_f1-score': 0.3793103448275862, 'weighted avg_support': 35.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 7}, {'micro_f1': 0.8304535637149028, 'Whataboutism_precision': 0.4782608695652174, 'Whataboutism_recall': 0.2972972972972973, 'Whataboutism_f1-score': 0.3666666666666667, 'Whataboutism_support': 37.0, 'micro avg_precision': 0.4782608695652174, 'micro avg_recall': 0.2972972972972973, 'micro avg_f1-score': 0.3666666666666667, 'micro avg_support': 37.0, 'macro avg_precision': 0.4782608695652174, 'macro avg_recall': 0.2972972972972973, 'macro avg_f1-score': 0.3666666666666667, 'macro avg_support': 37.0, 'weighted avg_precision': 0.4782608695652174, 'weighted avg_recall': 0.2972972972972973, 'weighted avg_f1-score': 0.3666666666666667, 'weighted avg_support': 37.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 8}, {'micro_f1': 0.8304535637149028, 'Whataboutism_precision': 0.4782608695652174, 'Whataboutism_recall': 0.3142857142857143, 'Whataboutism_f1-score': 0.3793103448275862, 'Whataboutism_support': 35.0, 'micro avg_precision': 0.4782608695652174, 'micro avg_recall': 0.3142857142857143, 'micro avg_f1-score': 0.3793103448275862, 'micro avg_support': 35.0, 'macro avg_precision': 0.4782608695652174, 'macro avg_recall': 0.3142857142857143, 'macro avg_f1-score': 0.3793103448275862, 'macro avg_support': 35.0, 'weighted avg_precision': 0.4782608695652174, 'weighted avg_recall': 0.3142857142857143, 'weighted avg_f1-score': 0.3793103448275862, 'weighted avg_support': 35.0, 'B-Whataboutism_support': 23, 'I-Whataboutism_support': 593, 'O_support': 310, 'epoch': 9}]}
Early stopping triggered.
Saving model to directory: ./models/M2/2024-05-12-17-42-10_aug/mdeberta-v3-base_10_ME10_target=Whataboutism_SUBSAMPLED_2024-05-12-17-42-10
Training model no. 11 of 23 for (11, 'Slogans') persuasion technique...
{'micro_f1': 0.9128191900954347, 'Slogans_precision': 0.4536082474226804, 'Slogans_recall': 0.3055555555555556, 'Slogans_f1-score': 0.36514522821576767, 'Slogans_support': 144.0, 'micro avg_precision': 0.4536082474226804, 'micro avg_recall': 0.3055555555555556, 'micro avg_f1-score': 0.36514522821576767, 'micro avg_support': 144.0, 'macro avg_precision': 0.4536082474226804, 'macro avg_recall': 0.3055555555555556, 'macro avg_f1-score': 0.36514522821576767, 'macro avg_support': 144.0, 'weighted avg_precision': 0.45360824742268036, 'weighted avg_recall': 0.3055555555555556, 'weighted avg_f1-score': 0.36514522821576767, 'weighted avg_support': 144.0, 'O_support': 3221, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 0}
{'results': [{'micro_f1': 0.9128191900954347, 'Slogans_precision': 0.4536082474226804, 'Slogans_recall': 0.3055555555555556, 'Slogans_f1-score': 0.36514522821576767, 'Slogans_support': 144.0, 'micro avg_precision': 0.4536082474226804, 'micro avg_recall': 0.3055555555555556, 'micro avg_f1-score': 0.36514522821576767, 'micro avg_support': 144.0, 'macro avg_precision': 0.4536082474226804, 'macro avg_recall': 0.3055555555555556, 'macro avg_f1-score': 0.36514522821576767, 'macro avg_support': 144.0, 'weighted avg_precision': 0.45360824742268036, 'weighted avg_recall': 0.3055555555555556, 'weighted avg_f1-score': 0.36514522821576767, 'weighted avg_support': 144.0, 'O_support': 3221, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 0}]}
Best model updated: current epoch macro f1 = 0.36514522821576767
{'micro_f1': 0.9205571318029404, 'Slogans_precision': 0.44329896907216493, 'Slogans_recall': 0.39814814814814814, 'Slogans_f1-score': 0.41951219512195115, 'Slogans_support': 108.0, 'micro avg_precision': 0.44329896907216493, 'micro avg_recall': 0.39814814814814814, 'micro avg_f1-score': 0.41951219512195115, 'micro avg_support': 108.0, 'macro avg_precision': 0.44329896907216493, 'macro avg_recall': 0.39814814814814814, 'macro avg_f1-score': 0.41951219512195115, 'macro avg_support': 108.0, 'weighted avg_precision': 0.44329896907216493, 'weighted avg_recall': 0.39814814814814814, 'weighted avg_f1-score': 0.41951219512195115, 'weighted avg_support': 108.0, 'O_support': 3221, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 1}
{'results': [{'micro_f1': 0.9128191900954347, 'Slogans_precision': 0.4536082474226804, 'Slogans_recall': 0.3055555555555556, 'Slogans_f1-score': 0.36514522821576767, 'Slogans_support': 144.0, 'micro avg_precision': 0.4536082474226804, 'micro avg_recall': 0.3055555555555556, 'micro avg_f1-score': 0.36514522821576767, 'micro avg_support': 144.0, 'macro avg_precision': 0.4536082474226804, 'macro avg_recall': 0.3055555555555556, 'macro avg_f1-score': 0.36514522821576767, 'macro avg_support': 144.0, 'weighted avg_precision': 0.45360824742268036, 'weighted avg_recall': 0.3055555555555556, 'weighted avg_f1-score': 0.36514522821576767, 'weighted avg_support': 144.0, 'O_support': 3221, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 0}, {'micro_f1': 0.9205571318029404, 'Slogans_precision': 0.44329896907216493, 'Slogans_recall': 0.39814814814814814, 'Slogans_f1-score': 0.41951219512195115, 'Slogans_support': 108.0, 'micro avg_precision': 0.44329896907216493, 'micro avg_recall': 0.39814814814814814, 'micro avg_f1-score': 0.41951219512195115, 'micro avg_support': 108.0, 'macro avg_precision': 0.44329896907216493, 'macro avg_recall': 0.39814814814814814, 'macro avg_f1-score': 0.41951219512195115, 'macro avg_support': 108.0, 'weighted avg_precision': 0.44329896907216493, 'weighted avg_recall': 0.39814814814814814, 'weighted avg_f1-score': 0.41951219512195115, 'weighted avg_support': 108.0, 'O_support': 3221, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 1}]}
Best model updated: current epoch macro f1 = 0.41951219512195115
{'micro_f1': 0.9342274954862007, 'Slogans_precision': 0.4536082474226804, 'Slogans_recall': 0.44, 'Slogans_f1-score': 0.4467005076142132, 'Slogans_support': 100.0, 'micro avg_precision': 0.4536082474226804, 'micro avg_recall': 0.44, 'micro avg_f1-score': 0.4467005076142132, 'micro avg_support': 100.0, 'macro avg_precision': 0.4536082474226804, 'macro avg_recall': 0.44, 'macro avg_f1-score': 0.4467005076142132, 'macro avg_support': 100.0, 'weighted avg_precision': 0.4536082474226804, 'weighted avg_recall': 0.44, 'weighted avg_f1-score': 0.4467005076142132, 'weighted avg_support': 100.0, 'O_support': 3221, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 2}
{'results': [{'micro_f1': 0.9128191900954347, 'Slogans_precision': 0.4536082474226804, 'Slogans_recall': 0.3055555555555556, 'Slogans_f1-score': 0.36514522821576767, 'Slogans_support': 144.0, 'micro avg_precision': 0.4536082474226804, 'micro avg_recall': 0.3055555555555556, 'micro avg_f1-score': 0.36514522821576767, 'micro avg_support': 144.0, 'macro avg_precision': 0.4536082474226804, 'macro avg_recall': 0.3055555555555556, 'macro avg_f1-score': 0.36514522821576767, 'macro avg_support': 144.0, 'weighted avg_precision': 0.45360824742268036, 'weighted avg_recall': 0.3055555555555556, 'weighted avg_f1-score': 0.36514522821576767, 'weighted avg_support': 144.0, 'O_support': 3221, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 0}, {'micro_f1': 0.9205571318029404, 'Slogans_precision': 0.44329896907216493, 'Slogans_recall': 0.39814814814814814, 'Slogans_f1-score': 0.41951219512195115, 'Slogans_support': 108.0, 'micro avg_precision': 0.44329896907216493, 'micro avg_recall': 0.39814814814814814, 'micro avg_f1-score': 0.41951219512195115, 'micro avg_support': 108.0, 'macro avg_precision': 0.44329896907216493, 'macro avg_recall': 0.39814814814814814, 'macro avg_f1-score': 0.41951219512195115, 'macro avg_support': 108.0, 'weighted avg_precision': 0.44329896907216493, 'weighted avg_recall': 0.39814814814814814, 'weighted avg_f1-score': 0.41951219512195115, 'weighted avg_support': 108.0, 'O_support': 3221, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 1}, {'micro_f1': 0.9342274954862007, 'Slogans_precision': 0.4536082474226804, 'Slogans_recall': 0.44, 'Slogans_f1-score': 0.4467005076142132, 'Slogans_support': 100.0, 'micro avg_precision': 0.4536082474226804, 'micro avg_recall': 0.44, 'micro avg_f1-score': 0.4467005076142132, 'micro avg_support': 100.0, 'macro avg_precision': 0.4536082474226804, 'macro avg_recall': 0.44, 'macro avg_f1-score': 0.4467005076142132, 'macro avg_support': 100.0, 'weighted avg_precision': 0.4536082474226804, 'weighted avg_recall': 0.44, 'weighted avg_f1-score': 0.4467005076142132, 'weighted avg_support': 100.0, 'O_support': 3221, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 2}]}
Best model updated: current epoch macro f1 = 0.4467005076142132
{'micro_f1': 0.9290688676811968, 'Slogans_precision': 0.4948453608247423, 'Slogans_recall': 0.46153846153846156, 'Slogans_f1-score': 0.4776119402985075, 'Slogans_support': 104.0, 'micro avg_precision': 0.4948453608247423, 'micro avg_recall': 0.46153846153846156, 'micro avg_f1-score': 0.4776119402985075, 'micro avg_support': 104.0, 'macro avg_precision': 0.4948453608247423, 'macro avg_recall': 0.46153846153846156, 'macro avg_f1-score': 0.4776119402985075, 'macro avg_support': 104.0, 'weighted avg_precision': 0.4948453608247423, 'weighted avg_recall': 0.46153846153846156, 'weighted avg_f1-score': 0.47761194029850745, 'weighted avg_support': 104.0, 'O_support': 3221, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 3}
{'results': [{'micro_f1': 0.9128191900954347, 'Slogans_precision': 0.4536082474226804, 'Slogans_recall': 0.3055555555555556, 'Slogans_f1-score': 0.36514522821576767, 'Slogans_support': 144.0, 'micro avg_precision': 0.4536082474226804, 'micro avg_recall': 0.3055555555555556, 'micro avg_f1-score': 0.36514522821576767, 'micro avg_support': 144.0, 'macro avg_precision': 0.4536082474226804, 'macro avg_recall': 0.3055555555555556, 'macro avg_f1-score': 0.36514522821576767, 'macro avg_support': 144.0, 'weighted avg_precision': 0.45360824742268036, 'weighted avg_recall': 0.3055555555555556, 'weighted avg_f1-score': 0.36514522821576767, 'weighted avg_support': 144.0, 'O_support': 3221, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 0}, {'micro_f1': 0.9205571318029404, 'Slogans_precision': 0.44329896907216493, 'Slogans_recall': 0.39814814814814814, 'Slogans_f1-score': 0.41951219512195115, 'Slogans_support': 108.0, 'micro avg_precision': 0.44329896907216493, 'micro avg_recall': 0.39814814814814814, 'micro avg_f1-score': 0.41951219512195115, 'micro avg_support': 108.0, 'macro avg_precision': 0.44329896907216493, 'macro avg_recall': 0.39814814814814814, 'macro avg_f1-score': 0.41951219512195115, 'macro avg_support': 108.0, 'weighted avg_precision': 0.44329896907216493, 'weighted avg_recall': 0.39814814814814814, 'weighted avg_f1-score': 0.41951219512195115, 'weighted avg_support': 108.0, 'O_support': 3221, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 1}, {'micro_f1': 0.9342274954862007, 'Slogans_precision': 0.4536082474226804, 'Slogans_recall': 0.44, 'Slogans_f1-score': 0.4467005076142132, 'Slogans_support': 100.0, 'micro avg_precision': 0.4536082474226804, 'micro avg_recall': 0.44, 'micro avg_f1-score': 0.4467005076142132, 'micro avg_support': 100.0, 'macro avg_precision': 0.4536082474226804, 'macro avg_recall': 0.44, 'macro avg_f1-score': 0.4467005076142132, 'macro avg_support': 100.0, 'weighted avg_precision': 0.4536082474226804, 'weighted avg_recall': 0.44, 'weighted avg_f1-score': 0.4467005076142132, 'weighted avg_support': 100.0, 'O_support': 3221, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 2}, {'micro_f1': 0.9290688676811968, 'Slogans_precision': 0.4948453608247423, 'Slogans_recall': 0.46153846153846156, 'Slogans_f1-score': 0.4776119402985075, 'Slogans_support': 104.0, 'micro avg_precision': 0.4948453608247423, 'micro avg_recall': 0.46153846153846156, 'micro avg_f1-score': 0.4776119402985075, 'micro avg_support': 104.0, 'macro avg_precision': 0.4948453608247423, 'macro avg_recall': 0.46153846153846156, 'macro avg_f1-score': 0.4776119402985075, 'macro avg_support': 104.0, 'weighted avg_precision': 0.4948453608247423, 'weighted avg_recall': 0.46153846153846156, 'weighted avg_f1-score': 0.47761194029850745, 'weighted avg_support': 104.0, 'O_support': 3221, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 3}]}
Best model updated: current epoch macro f1 = 0.4776119402985075
{'micro_f1': 0.9143667784369358, 'Slogans_precision': 0.4742268041237113, 'Slogans_recall': 0.3898305084745763, 'Slogans_f1-score': 0.4279069767441861, 'Slogans_support': 118.0, 'micro avg_precision': 0.4742268041237113, 'micro avg_recall': 0.3898305084745763, 'micro avg_f1-score': 0.4279069767441861, 'micro avg_support': 118.0, 'macro avg_precision': 0.4742268041237113, 'macro avg_recall': 0.3898305084745763, 'macro avg_f1-score': 0.4279069767441861, 'macro avg_support': 118.0, 'weighted avg_precision': 0.4742268041237113, 'weighted avg_recall': 0.3898305084745763, 'weighted avg_f1-score': 0.4279069767441861, 'weighted avg_support': 118.0, 'O_support': 3221, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 4}
{'results': [{'micro_f1': 0.9128191900954347, 'Slogans_precision': 0.4536082474226804, 'Slogans_recall': 0.3055555555555556, 'Slogans_f1-score': 0.36514522821576767, 'Slogans_support': 144.0, 'micro avg_precision': 0.4536082474226804, 'micro avg_recall': 0.3055555555555556, 'micro avg_f1-score': 0.36514522821576767, 'micro avg_support': 144.0, 'macro avg_precision': 0.4536082474226804, 'macro avg_recall': 0.3055555555555556, 'macro avg_f1-score': 0.36514522821576767, 'macro avg_support': 144.0, 'weighted avg_precision': 0.45360824742268036, 'weighted avg_recall': 0.3055555555555556, 'weighted avg_f1-score': 0.36514522821576767, 'weighted avg_support': 144.0, 'O_support': 3221, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 0}, {'micro_f1': 0.9205571318029404, 'Slogans_precision': 0.44329896907216493, 'Slogans_recall': 0.39814814814814814, 'Slogans_f1-score': 0.41951219512195115, 'Slogans_support': 108.0, 'micro avg_precision': 0.44329896907216493, 'micro avg_recall': 0.39814814814814814, 'micro avg_f1-score': 0.41951219512195115, 'micro avg_support': 108.0, 'macro avg_precision': 0.44329896907216493, 'macro avg_recall': 0.39814814814814814, 'macro avg_f1-score': 0.41951219512195115, 'macro avg_support': 108.0, 'weighted avg_precision': 0.44329896907216493, 'weighted avg_recall': 0.39814814814814814, 'weighted avg_f1-score': 0.41951219512195115, 'weighted avg_support': 108.0, 'O_support': 3221, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 1}, {'micro_f1': 0.9342274954862007, 'Slogans_precision': 0.4536082474226804, 'Slogans_recall': 0.44, 'Slogans_f1-score': 0.4467005076142132, 'Slogans_support': 100.0, 'micro avg_precision': 0.4536082474226804, 'micro avg_recall': 0.44, 'micro avg_f1-score': 0.4467005076142132, 'micro avg_support': 100.0, 'macro avg_precision': 0.4536082474226804, 'macro avg_recall': 0.44, 'macro avg_f1-score': 0.4467005076142132, 'macro avg_support': 100.0, 'weighted avg_precision': 0.4536082474226804, 'weighted avg_recall': 0.44, 'weighted avg_f1-score': 0.4467005076142132, 'weighted avg_support': 100.0, 'O_support': 3221, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 2}, {'micro_f1': 0.9290688676811968, 'Slogans_precision': 0.4948453608247423, 'Slogans_recall': 0.46153846153846156, 'Slogans_f1-score': 0.4776119402985075, 'Slogans_support': 104.0, 'micro avg_precision': 0.4948453608247423, 'micro avg_recall': 0.46153846153846156, 'micro avg_f1-score': 0.4776119402985075, 'micro avg_support': 104.0, 'macro avg_precision': 0.4948453608247423, 'macro avg_recall': 0.46153846153846156, 'macro avg_f1-score': 0.4776119402985075, 'macro avg_support': 104.0, 'weighted avg_precision': 0.4948453608247423, 'weighted avg_recall': 0.46153846153846156, 'weighted avg_f1-score': 0.47761194029850745, 'weighted avg_support': 104.0, 'O_support': 3221, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 3}, {'micro_f1': 0.9143667784369358, 'Slogans_precision': 0.4742268041237113, 'Slogans_recall': 0.3898305084745763, 'Slogans_f1-score': 0.4279069767441861, 'Slogans_support': 118.0, 'micro avg_precision': 0.4742268041237113, 'micro avg_recall': 0.3898305084745763, 'micro avg_f1-score': 0.4279069767441861, 'micro avg_support': 118.0, 'macro avg_precision': 0.4742268041237113, 'macro avg_recall': 0.3898305084745763, 'macro avg_f1-score': 0.4279069767441861, 'macro avg_support': 118.0, 'weighted avg_precision': 0.4742268041237113, 'weighted avg_recall': 0.3898305084745763, 'weighted avg_f1-score': 0.4279069767441861, 'weighted avg_support': 118.0, 'O_support': 3221, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 4}]}
{'micro_f1': 0.9210729945834408, 'Slogans_precision': 0.5051546391752577, 'Slogans_recall': 0.4188034188034188, 'Slogans_f1-score': 0.45794392523364486, 'Slogans_support': 117.0, 'micro avg_precision': 0.5051546391752577, 'micro avg_recall': 0.4188034188034188, 'micro avg_f1-score': 0.45794392523364486, 'micro avg_support': 117.0, 'macro avg_precision': 0.5051546391752577, 'macro avg_recall': 0.4188034188034188, 'macro avg_f1-score': 0.45794392523364486, 'macro avg_support': 117.0, 'weighted avg_precision': 0.5051546391752577, 'weighted avg_recall': 0.4188034188034188, 'weighted avg_f1-score': 0.45794392523364486, 'weighted avg_support': 117.0, 'O_support': 3221, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 5}
{'results': [{'micro_f1': 0.9128191900954347, 'Slogans_precision': 0.4536082474226804, 'Slogans_recall': 0.3055555555555556, 'Slogans_f1-score': 0.36514522821576767, 'Slogans_support': 144.0, 'micro avg_precision': 0.4536082474226804, 'micro avg_recall': 0.3055555555555556, 'micro avg_f1-score': 0.36514522821576767, 'micro avg_support': 144.0, 'macro avg_precision': 0.4536082474226804, 'macro avg_recall': 0.3055555555555556, 'macro avg_f1-score': 0.36514522821576767, 'macro avg_support': 144.0, 'weighted avg_precision': 0.45360824742268036, 'weighted avg_recall': 0.3055555555555556, 'weighted avg_f1-score': 0.36514522821576767, 'weighted avg_support': 144.0, 'O_support': 3221, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 0}, {'micro_f1': 0.9205571318029404, 'Slogans_precision': 0.44329896907216493, 'Slogans_recall': 0.39814814814814814, 'Slogans_f1-score': 0.41951219512195115, 'Slogans_support': 108.0, 'micro avg_precision': 0.44329896907216493, 'micro avg_recall': 0.39814814814814814, 'micro avg_f1-score': 0.41951219512195115, 'micro avg_support': 108.0, 'macro avg_precision': 0.44329896907216493, 'macro avg_recall': 0.39814814814814814, 'macro avg_f1-score': 0.41951219512195115, 'macro avg_support': 108.0, 'weighted avg_precision': 0.44329896907216493, 'weighted avg_recall': 0.39814814814814814, 'weighted avg_f1-score': 0.41951219512195115, 'weighted avg_support': 108.0, 'O_support': 3221, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 1}, {'micro_f1': 0.9342274954862007, 'Slogans_precision': 0.4536082474226804, 'Slogans_recall': 0.44, 'Slogans_f1-score': 0.4467005076142132, 'Slogans_support': 100.0, 'micro avg_precision': 0.4536082474226804, 'micro avg_recall': 0.44, 'micro avg_f1-score': 0.4467005076142132, 'micro avg_support': 100.0, 'macro avg_precision': 0.4536082474226804, 'macro avg_recall': 0.44, 'macro avg_f1-score': 0.4467005076142132, 'macro avg_support': 100.0, 'weighted avg_precision': 0.4536082474226804, 'weighted avg_recall': 0.44, 'weighted avg_f1-score': 0.4467005076142132, 'weighted avg_support': 100.0, 'O_support': 3221, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 2}, {'micro_f1': 0.9290688676811968, 'Slogans_precision': 0.4948453608247423, 'Slogans_recall': 0.46153846153846156, 'Slogans_f1-score': 0.4776119402985075, 'Slogans_support': 104.0, 'micro avg_precision': 0.4948453608247423, 'micro avg_recall': 0.46153846153846156, 'micro avg_f1-score': 0.4776119402985075, 'micro avg_support': 104.0, 'macro avg_precision': 0.4948453608247423, 'macro avg_recall': 0.46153846153846156, 'macro avg_f1-score': 0.4776119402985075, 'macro avg_support': 104.0, 'weighted avg_precision': 0.4948453608247423, 'weighted avg_recall': 0.46153846153846156, 'weighted avg_f1-score': 0.47761194029850745, 'weighted avg_support': 104.0, 'O_support': 3221, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 3}, {'micro_f1': 0.9143667784369358, 'Slogans_precision': 0.4742268041237113, 'Slogans_recall': 0.3898305084745763, 'Slogans_f1-score': 0.4279069767441861, 'Slogans_support': 118.0, 'micro avg_precision': 0.4742268041237113, 'micro avg_recall': 0.3898305084745763, 'micro avg_f1-score': 0.4279069767441861, 'micro avg_support': 118.0, 'macro avg_precision': 0.4742268041237113, 'macro avg_recall': 0.3898305084745763, 'macro avg_f1-score': 0.4279069767441861, 'macro avg_support': 118.0, 'weighted avg_precision': 0.4742268041237113, 'weighted avg_recall': 0.3898305084745763, 'weighted avg_f1-score': 0.4279069767441861, 'weighted avg_support': 118.0, 'O_support': 3221, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 4}, {'micro_f1': 0.9210729945834408, 'Slogans_precision': 0.5051546391752577, 'Slogans_recall': 0.4188034188034188, 'Slogans_f1-score': 0.45794392523364486, 'Slogans_support': 117.0, 'micro avg_precision': 0.5051546391752577, 'micro avg_recall': 0.4188034188034188, 'micro avg_f1-score': 0.45794392523364486, 'micro avg_support': 117.0, 'macro avg_precision': 0.5051546391752577, 'macro avg_recall': 0.4188034188034188, 'macro avg_f1-score': 0.45794392523364486, 'macro avg_support': 117.0, 'weighted avg_precision': 0.5051546391752577, 'weighted avg_recall': 0.4188034188034188, 'weighted avg_f1-score': 0.45794392523364486, 'weighted avg_support': 117.0, 'O_support': 3221, 'B-Slogans_support': 97, 'I-Slogans_support': 559, 'epoch': 5}]}
Early stopping triggered.
Saving model to directory: ./models/M2/2024-05-12-17-42-10_aug/mdeberta-v3-base_11_ME10_target=Slogans_SUBSAMPLED_2024-05-12-17-42-10
Training model no. 12 of 23 for (12, 'Appeal_to_Time') persuasion technique...
{'micro_f1': 0.6632996632996633, 'Appeal_to_Time_precision': 0.0, 'Appeal_to_Time_recall': 0.0, 'Appeal_to_Time_f1-score': 0.0, 'Appeal_to_Time_support': 7.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 7.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 7.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 7.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 0}
{'results': [{'micro_f1': 0.6632996632996633, 'Appeal_to_Time_precision': 0.0, 'Appeal_to_Time_recall': 0.0, 'Appeal_to_Time_f1-score': 0.0, 'Appeal_to_Time_support': 7.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 7.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 7.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 7.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 0}]}
{'micro_f1': 0.6902356902356902, 'Appeal_to_Time_precision': 0.1111111111111111, 'Appeal_to_Time_recall': 0.04838709677419355, 'Appeal_to_Time_f1-score': 0.06741573033707865, 'Appeal_to_Time_support': 62.0, 'micro avg_precision': 0.1111111111111111, 'micro avg_recall': 0.04838709677419355, 'micro avg_f1-score': 0.06741573033707865, 'micro avg_support': 62.0, 'macro avg_precision': 0.1111111111111111, 'macro avg_recall': 0.04838709677419355, 'macro avg_f1-score': 0.06741573033707865, 'macro avg_support': 62.0, 'weighted avg_precision': 0.1111111111111111, 'weighted avg_recall': 0.04838709677419355, 'weighted avg_f1-score': 0.06741573033707865, 'weighted avg_support': 62.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 1}
{'results': [{'micro_f1': 0.6632996632996633, 'Appeal_to_Time_precision': 0.0, 'Appeal_to_Time_recall': 0.0, 'Appeal_to_Time_f1-score': 0.0, 'Appeal_to_Time_support': 7.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 7.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 7.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 7.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 0}, {'micro_f1': 0.6902356902356902, 'Appeal_to_Time_precision': 0.1111111111111111, 'Appeal_to_Time_recall': 0.04838709677419355, 'Appeal_to_Time_f1-score': 0.06741573033707865, 'Appeal_to_Time_support': 62.0, 'micro avg_precision': 0.1111111111111111, 'micro avg_recall': 0.04838709677419355, 'micro avg_f1-score': 0.06741573033707865, 'micro avg_support': 62.0, 'macro avg_precision': 0.1111111111111111, 'macro avg_recall': 0.04838709677419355, 'macro avg_f1-score': 0.06741573033707865, 'macro avg_support': 62.0, 'weighted avg_precision': 0.1111111111111111, 'weighted avg_recall': 0.04838709677419355, 'weighted avg_f1-score': 0.06741573033707865, 'weighted avg_support': 62.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 1}]}
Best model updated: current epoch macro f1 = 0.06741573033707865
{'micro_f1': 0.6857463524130191, 'Appeal_to_Time_precision': 0.14814814814814814, 'Appeal_to_Time_recall': 0.07142857142857142, 'Appeal_to_Time_f1-score': 0.0963855421686747, 'Appeal_to_Time_support': 56.0, 'micro avg_precision': 0.14814814814814814, 'micro avg_recall': 0.07142857142857142, 'micro avg_f1-score': 0.0963855421686747, 'micro avg_support': 56.0, 'macro avg_precision': 0.14814814814814814, 'macro avg_recall': 0.07142857142857142, 'macro avg_f1-score': 0.0963855421686747, 'macro avg_support': 56.0, 'weighted avg_precision': 0.14814814814814814, 'weighted avg_recall': 0.07142857142857142, 'weighted avg_f1-score': 0.0963855421686747, 'weighted avg_support': 56.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 2}
{'results': [{'micro_f1': 0.6632996632996633, 'Appeal_to_Time_precision': 0.0, 'Appeal_to_Time_recall': 0.0, 'Appeal_to_Time_f1-score': 0.0, 'Appeal_to_Time_support': 7.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 7.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 7.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 7.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 0}, {'micro_f1': 0.6902356902356902, 'Appeal_to_Time_precision': 0.1111111111111111, 'Appeal_to_Time_recall': 0.04838709677419355, 'Appeal_to_Time_f1-score': 0.06741573033707865, 'Appeal_to_Time_support': 62.0, 'micro avg_precision': 0.1111111111111111, 'micro avg_recall': 0.04838709677419355, 'micro avg_f1-score': 0.06741573033707865, 'micro avg_support': 62.0, 'macro avg_precision': 0.1111111111111111, 'macro avg_recall': 0.04838709677419355, 'macro avg_f1-score': 0.06741573033707865, 'macro avg_support': 62.0, 'weighted avg_precision': 0.1111111111111111, 'weighted avg_recall': 0.04838709677419355, 'weighted avg_f1-score': 0.06741573033707865, 'weighted avg_support': 62.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 1}, {'micro_f1': 0.6857463524130191, 'Appeal_to_Time_precision': 0.14814814814814814, 'Appeal_to_Time_recall': 0.07142857142857142, 'Appeal_to_Time_f1-score': 0.0963855421686747, 'Appeal_to_Time_support': 56.0, 'micro avg_precision': 0.14814814814814814, 'micro avg_recall': 0.07142857142857142, 'micro avg_f1-score': 0.0963855421686747, 'micro avg_support': 56.0, 'macro avg_precision': 0.14814814814814814, 'macro avg_recall': 0.07142857142857142, 'macro avg_f1-score': 0.0963855421686747, 'macro avg_support': 56.0, 'weighted avg_precision': 0.14814814814814814, 'weighted avg_recall': 0.07142857142857142, 'weighted avg_f1-score': 0.0963855421686747, 'weighted avg_support': 56.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 2}]}
Best model updated: current epoch macro f1 = 0.0963855421686747
{'micro_f1': 0.7227833894500563, 'Appeal_to_Time_precision': 0.1111111111111111, 'Appeal_to_Time_recall': 0.05172413793103448, 'Appeal_to_Time_f1-score': 0.07058823529411765, 'Appeal_to_Time_support': 58.0, 'micro avg_precision': 0.1111111111111111, 'micro avg_recall': 0.05172413793103448, 'micro avg_f1-score': 0.07058823529411765, 'micro avg_support': 58.0, 'macro avg_precision': 0.1111111111111111, 'macro avg_recall': 0.05172413793103448, 'macro avg_f1-score': 0.07058823529411765, 'macro avg_support': 58.0, 'weighted avg_precision': 0.1111111111111111, 'weighted avg_recall': 0.05172413793103448, 'weighted avg_f1-score': 0.07058823529411765, 'weighted avg_support': 58.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 3}
{'results': [{'micro_f1': 0.6632996632996633, 'Appeal_to_Time_precision': 0.0, 'Appeal_to_Time_recall': 0.0, 'Appeal_to_Time_f1-score': 0.0, 'Appeal_to_Time_support': 7.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 7.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 7.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 7.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 0}, {'micro_f1': 0.6902356902356902, 'Appeal_to_Time_precision': 0.1111111111111111, 'Appeal_to_Time_recall': 0.04838709677419355, 'Appeal_to_Time_f1-score': 0.06741573033707865, 'Appeal_to_Time_support': 62.0, 'micro avg_precision': 0.1111111111111111, 'micro avg_recall': 0.04838709677419355, 'micro avg_f1-score': 0.06741573033707865, 'micro avg_support': 62.0, 'macro avg_precision': 0.1111111111111111, 'macro avg_recall': 0.04838709677419355, 'macro avg_f1-score': 0.06741573033707865, 'macro avg_support': 62.0, 'weighted avg_precision': 0.1111111111111111, 'weighted avg_recall': 0.04838709677419355, 'weighted avg_f1-score': 0.06741573033707865, 'weighted avg_support': 62.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 1}, {'micro_f1': 0.6857463524130191, 'Appeal_to_Time_precision': 0.14814814814814814, 'Appeal_to_Time_recall': 0.07142857142857142, 'Appeal_to_Time_f1-score': 0.0963855421686747, 'Appeal_to_Time_support': 56.0, 'micro avg_precision': 0.14814814814814814, 'micro avg_recall': 0.07142857142857142, 'micro avg_f1-score': 0.0963855421686747, 'micro avg_support': 56.0, 'macro avg_precision': 0.14814814814814814, 'macro avg_recall': 0.07142857142857142, 'macro avg_f1-score': 0.0963855421686747, 'macro avg_support': 56.0, 'weighted avg_precision': 0.14814814814814814, 'weighted avg_recall': 0.07142857142857142, 'weighted avg_f1-score': 0.0963855421686747, 'weighted avg_support': 56.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 2}, {'micro_f1': 0.7227833894500563, 'Appeal_to_Time_precision': 0.1111111111111111, 'Appeal_to_Time_recall': 0.05172413793103448, 'Appeal_to_Time_f1-score': 0.07058823529411765, 'Appeal_to_Time_support': 58.0, 'micro avg_precision': 0.1111111111111111, 'micro avg_recall': 0.05172413793103448, 'micro avg_f1-score': 0.07058823529411765, 'micro avg_support': 58.0, 'macro avg_precision': 0.1111111111111111, 'macro avg_recall': 0.05172413793103448, 'macro avg_f1-score': 0.07058823529411765, 'macro avg_support': 58.0, 'weighted avg_precision': 0.1111111111111111, 'weighted avg_recall': 0.05172413793103448, 'weighted avg_f1-score': 0.07058823529411765, 'weighted avg_support': 58.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 3}]}
{'micro_f1': 0.744107744107744, 'Appeal_to_Time_precision': 0.1111111111111111, 'Appeal_to_Time_recall': 0.0625, 'Appeal_to_Time_f1-score': 0.08, 'Appeal_to_Time_support': 48.0, 'micro avg_precision': 0.1111111111111111, 'micro avg_recall': 0.0625, 'micro avg_f1-score': 0.08, 'micro avg_support': 48.0, 'macro avg_precision': 0.1111111111111111, 'macro avg_recall': 0.0625, 'macro avg_f1-score': 0.08, 'macro avg_support': 48.0, 'weighted avg_precision': 0.1111111111111111, 'weighted avg_recall': 0.0625, 'weighted avg_f1-score': 0.08, 'weighted avg_support': 48.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 4}
{'results': [{'micro_f1': 0.6632996632996633, 'Appeal_to_Time_precision': 0.0, 'Appeal_to_Time_recall': 0.0, 'Appeal_to_Time_f1-score': 0.0, 'Appeal_to_Time_support': 7.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 7.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 7.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 7.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 0}, {'micro_f1': 0.6902356902356902, 'Appeal_to_Time_precision': 0.1111111111111111, 'Appeal_to_Time_recall': 0.04838709677419355, 'Appeal_to_Time_f1-score': 0.06741573033707865, 'Appeal_to_Time_support': 62.0, 'micro avg_precision': 0.1111111111111111, 'micro avg_recall': 0.04838709677419355, 'micro avg_f1-score': 0.06741573033707865, 'micro avg_support': 62.0, 'macro avg_precision': 0.1111111111111111, 'macro avg_recall': 0.04838709677419355, 'macro avg_f1-score': 0.06741573033707865, 'macro avg_support': 62.0, 'weighted avg_precision': 0.1111111111111111, 'weighted avg_recall': 0.04838709677419355, 'weighted avg_f1-score': 0.06741573033707865, 'weighted avg_support': 62.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 1}, {'micro_f1': 0.6857463524130191, 'Appeal_to_Time_precision': 0.14814814814814814, 'Appeal_to_Time_recall': 0.07142857142857142, 'Appeal_to_Time_f1-score': 0.0963855421686747, 'Appeal_to_Time_support': 56.0, 'micro avg_precision': 0.14814814814814814, 'micro avg_recall': 0.07142857142857142, 'micro avg_f1-score': 0.0963855421686747, 'micro avg_support': 56.0, 'macro avg_precision': 0.14814814814814814, 'macro avg_recall': 0.07142857142857142, 'macro avg_f1-score': 0.0963855421686747, 'macro avg_support': 56.0, 'weighted avg_precision': 0.14814814814814814, 'weighted avg_recall': 0.07142857142857142, 'weighted avg_f1-score': 0.0963855421686747, 'weighted avg_support': 56.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 2}, {'micro_f1': 0.7227833894500563, 'Appeal_to_Time_precision': 0.1111111111111111, 'Appeal_to_Time_recall': 0.05172413793103448, 'Appeal_to_Time_f1-score': 0.07058823529411765, 'Appeal_to_Time_support': 58.0, 'micro avg_precision': 0.1111111111111111, 'micro avg_recall': 0.05172413793103448, 'micro avg_f1-score': 0.07058823529411765, 'micro avg_support': 58.0, 'macro avg_precision': 0.1111111111111111, 'macro avg_recall': 0.05172413793103448, 'macro avg_f1-score': 0.07058823529411765, 'macro avg_support': 58.0, 'weighted avg_precision': 0.1111111111111111, 'weighted avg_recall': 0.05172413793103448, 'weighted avg_f1-score': 0.07058823529411765, 'weighted avg_support': 58.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 3}, {'micro_f1': 0.744107744107744, 'Appeal_to_Time_precision': 0.1111111111111111, 'Appeal_to_Time_recall': 0.0625, 'Appeal_to_Time_f1-score': 0.08, 'Appeal_to_Time_support': 48.0, 'micro avg_precision': 0.1111111111111111, 'micro avg_recall': 0.0625, 'micro avg_f1-score': 0.08, 'micro avg_support': 48.0, 'macro avg_precision': 0.1111111111111111, 'macro avg_recall': 0.0625, 'macro avg_f1-score': 0.08, 'macro avg_support': 48.0, 'weighted avg_precision': 0.1111111111111111, 'weighted avg_recall': 0.0625, 'weighted avg_f1-score': 0.08, 'weighted avg_support': 48.0, 'O_support': 591, 'B-Appeal_to_Time_support': 27, 'I-Appeal_to_Time_support': 273, 'epoch': 4}]}
Early stopping triggered.
Saving model to directory: ./models/M2/2024-05-12-17-42-10_aug/mdeberta-v3-base_12_ME10_target=Appeal_to_Time_SUBSAMPLED_2024-05-12-17-42-10
Training model no. 13 of 23 for (13, 'Conversation_Killer') persuasion technique...
{'micro_f1': 0.8145161290322581, 'Conversation_Killer_precision': 0.2653061224489796, 'Conversation_Killer_recall': 0.15234375, 'Conversation_Killer_f1-score': 0.19354838709677422, 'Conversation_Killer_support': 256.0, 'micro avg_precision': 0.2653061224489796, 'micro avg_recall': 0.15234375, 'micro avg_f1-score': 0.19354838709677422, 'micro avg_support': 256.0, 'macro avg_precision': 0.2653061224489796, 'macro avg_recall': 0.15234375, 'macro avg_f1-score': 0.19354838709677422, 'macro avg_support': 256.0, 'weighted avg_precision': 0.2653061224489796, 'weighted avg_recall': 0.15234375, 'weighted avg_f1-score': 0.19354838709677422, 'weighted avg_support': 256.0, 'O_support': 3651, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 0}
{'results': [{'micro_f1': 0.8145161290322581, 'Conversation_Killer_precision': 0.2653061224489796, 'Conversation_Killer_recall': 0.15234375, 'Conversation_Killer_f1-score': 0.19354838709677422, 'Conversation_Killer_support': 256.0, 'micro avg_precision': 0.2653061224489796, 'micro avg_recall': 0.15234375, 'micro avg_f1-score': 0.19354838709677422, 'micro avg_support': 256.0, 'macro avg_precision': 0.2653061224489796, 'macro avg_recall': 0.15234375, 'macro avg_f1-score': 0.19354838709677422, 'macro avg_support': 256.0, 'weighted avg_precision': 0.2653061224489796, 'weighted avg_recall': 0.15234375, 'weighted avg_f1-score': 0.19354838709677422, 'weighted avg_support': 256.0, 'O_support': 3651, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 0}]}
Best model updated: current epoch macro f1 = 0.19354838709677422
{'micro_f1': 0.847394540942928, 'Conversation_Killer_precision': 0.2857142857142857, 'Conversation_Killer_recall': 0.1935483870967742, 'Conversation_Killer_f1-score': 0.23076923076923075, 'Conversation_Killer_support': 217.0, 'micro avg_precision': 0.2857142857142857, 'micro avg_recall': 0.1935483870967742, 'micro avg_f1-score': 0.23076923076923075, 'micro avg_support': 217.0, 'macro avg_precision': 0.2857142857142857, 'macro avg_recall': 0.1935483870967742, 'macro avg_f1-score': 0.23076923076923075, 'macro avg_support': 217.0, 'weighted avg_precision': 0.2857142857142857, 'weighted avg_recall': 0.1935483870967742, 'weighted avg_f1-score': 0.23076923076923075, 'weighted avg_support': 217.0, 'O_support': 3651, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 1}
{'results': [{'micro_f1': 0.8145161290322581, 'Conversation_Killer_precision': 0.2653061224489796, 'Conversation_Killer_recall': 0.15234375, 'Conversation_Killer_f1-score': 0.19354838709677422, 'Conversation_Killer_support': 256.0, 'micro avg_precision': 0.2653061224489796, 'micro avg_recall': 0.15234375, 'micro avg_f1-score': 0.19354838709677422, 'micro avg_support': 256.0, 'macro avg_precision': 0.2653061224489796, 'macro avg_recall': 0.15234375, 'macro avg_f1-score': 0.19354838709677422, 'macro avg_support': 256.0, 'weighted avg_precision': 0.2653061224489796, 'weighted avg_recall': 0.15234375, 'weighted avg_f1-score': 0.19354838709677422, 'weighted avg_support': 256.0, 'O_support': 3651, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 0}, {'micro_f1': 0.847394540942928, 'Conversation_Killer_precision': 0.2857142857142857, 'Conversation_Killer_recall': 0.1935483870967742, 'Conversation_Killer_f1-score': 0.23076923076923075, 'Conversation_Killer_support': 217.0, 'micro avg_precision': 0.2857142857142857, 'micro avg_recall': 0.1935483870967742, 'micro avg_f1-score': 0.23076923076923075, 'micro avg_support': 217.0, 'macro avg_precision': 0.2857142857142857, 'macro avg_recall': 0.1935483870967742, 'macro avg_f1-score': 0.23076923076923075, 'macro avg_support': 217.0, 'weighted avg_precision': 0.2857142857142857, 'weighted avg_recall': 0.1935483870967742, 'weighted avg_f1-score': 0.23076923076923075, 'weighted avg_support': 217.0, 'O_support': 3651, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 1}]}
Best model updated: current epoch macro f1 = 0.23076923076923075
{'micro_f1': 0.8012820512820514, 'Conversation_Killer_precision': 0.36054421768707484, 'Conversation_Killer_recall': 0.25, 'Conversation_Killer_f1-score': 0.2952646239554318, 'Conversation_Killer_support': 212.0, 'micro avg_precision': 0.36054421768707484, 'micro avg_recall': 0.25, 'micro avg_f1-score': 0.2952646239554318, 'micro avg_support': 212.0, 'macro avg_precision': 0.36054421768707484, 'macro avg_recall': 0.25, 'macro avg_f1-score': 0.2952646239554318, 'macro avg_support': 212.0, 'weighted avg_precision': 0.36054421768707484, 'weighted avg_recall': 0.25, 'weighted avg_f1-score': 0.2952646239554318, 'weighted avg_support': 212.0, 'O_support': 3651, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 2}
{'results': [{'micro_f1': 0.8145161290322581, 'Conversation_Killer_precision': 0.2653061224489796, 'Conversation_Killer_recall': 0.15234375, 'Conversation_Killer_f1-score': 0.19354838709677422, 'Conversation_Killer_support': 256.0, 'micro avg_precision': 0.2653061224489796, 'micro avg_recall': 0.15234375, 'micro avg_f1-score': 0.19354838709677422, 'micro avg_support': 256.0, 'macro avg_precision': 0.2653061224489796, 'macro avg_recall': 0.15234375, 'macro avg_f1-score': 0.19354838709677422, 'macro avg_support': 256.0, 'weighted avg_precision': 0.2653061224489796, 'weighted avg_recall': 0.15234375, 'weighted avg_f1-score': 0.19354838709677422, 'weighted avg_support': 256.0, 'O_support': 3651, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 0}, {'micro_f1': 0.847394540942928, 'Conversation_Killer_precision': 0.2857142857142857, 'Conversation_Killer_recall': 0.1935483870967742, 'Conversation_Killer_f1-score': 0.23076923076923075, 'Conversation_Killer_support': 217.0, 'micro avg_precision': 0.2857142857142857, 'micro avg_recall': 0.1935483870967742, 'micro avg_f1-score': 0.23076923076923075, 'micro avg_support': 217.0, 'macro avg_precision': 0.2857142857142857, 'macro avg_recall': 0.1935483870967742, 'macro avg_f1-score': 0.23076923076923075, 'macro avg_support': 217.0, 'weighted avg_precision': 0.2857142857142857, 'weighted avg_recall': 0.1935483870967742, 'weighted avg_f1-score': 0.23076923076923075, 'weighted avg_support': 217.0, 'O_support': 3651, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 1}, {'micro_f1': 0.8012820512820514, 'Conversation_Killer_precision': 0.36054421768707484, 'Conversation_Killer_recall': 0.25, 'Conversation_Killer_f1-score': 0.2952646239554318, 'Conversation_Killer_support': 212.0, 'micro avg_precision': 0.36054421768707484, 'micro avg_recall': 0.25, 'micro avg_f1-score': 0.2952646239554318, 'micro avg_support': 212.0, 'macro avg_precision': 0.36054421768707484, 'macro avg_recall': 0.25, 'macro avg_f1-score': 0.2952646239554318, 'macro avg_support': 212.0, 'weighted avg_precision': 0.36054421768707484, 'weighted avg_recall': 0.25, 'weighted avg_f1-score': 0.2952646239554318, 'weighted avg_support': 212.0, 'O_support': 3651, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 2}]}
Best model updated: current epoch macro f1 = 0.2952646239554318
{'micro_f1': 0.7892886683209264, 'Conversation_Killer_precision': 0.4217687074829932, 'Conversation_Killer_recall': 0.2421875, 'Conversation_Killer_f1-score': 0.3076923076923077, 'Conversation_Killer_support': 256.0, 'micro avg_precision': 0.4217687074829932, 'micro avg_recall': 0.2421875, 'micro avg_f1-score': 0.3076923076923077, 'micro avg_support': 256.0, 'macro avg_precision': 0.4217687074829932, 'macro avg_recall': 0.2421875, 'macro avg_f1-score': 0.3076923076923077, 'macro avg_support': 256.0, 'weighted avg_precision': 0.4217687074829932, 'weighted avg_recall': 0.2421875, 'weighted avg_f1-score': 0.3076923076923077, 'weighted avg_support': 256.0, 'O_support': 3651, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 3}
{'results': [{'micro_f1': 0.8145161290322581, 'Conversation_Killer_precision': 0.2653061224489796, 'Conversation_Killer_recall': 0.15234375, 'Conversation_Killer_f1-score': 0.19354838709677422, 'Conversation_Killer_support': 256.0, 'micro avg_precision': 0.2653061224489796, 'micro avg_recall': 0.15234375, 'micro avg_f1-score': 0.19354838709677422, 'micro avg_support': 256.0, 'macro avg_precision': 0.2653061224489796, 'macro avg_recall': 0.15234375, 'macro avg_f1-score': 0.19354838709677422, 'macro avg_support': 256.0, 'weighted avg_precision': 0.2653061224489796, 'weighted avg_recall': 0.15234375, 'weighted avg_f1-score': 0.19354838709677422, 'weighted avg_support': 256.0, 'O_support': 3651, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 0}, {'micro_f1': 0.847394540942928, 'Conversation_Killer_precision': 0.2857142857142857, 'Conversation_Killer_recall': 0.1935483870967742, 'Conversation_Killer_f1-score': 0.23076923076923075, 'Conversation_Killer_support': 217.0, 'micro avg_precision': 0.2857142857142857, 'micro avg_recall': 0.1935483870967742, 'micro avg_f1-score': 0.23076923076923075, 'micro avg_support': 217.0, 'macro avg_precision': 0.2857142857142857, 'macro avg_recall': 0.1935483870967742, 'macro avg_f1-score': 0.23076923076923075, 'macro avg_support': 217.0, 'weighted avg_precision': 0.2857142857142857, 'weighted avg_recall': 0.1935483870967742, 'weighted avg_f1-score': 0.23076923076923075, 'weighted avg_support': 217.0, 'O_support': 3651, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 1}, {'micro_f1': 0.8012820512820514, 'Conversation_Killer_precision': 0.36054421768707484, 'Conversation_Killer_recall': 0.25, 'Conversation_Killer_f1-score': 0.2952646239554318, 'Conversation_Killer_support': 212.0, 'micro avg_precision': 0.36054421768707484, 'micro avg_recall': 0.25, 'micro avg_f1-score': 0.2952646239554318, 'micro avg_support': 212.0, 'macro avg_precision': 0.36054421768707484, 'macro avg_recall': 0.25, 'macro avg_f1-score': 0.2952646239554318, 'macro avg_support': 212.0, 'weighted avg_precision': 0.36054421768707484, 'weighted avg_recall': 0.25, 'weighted avg_f1-score': 0.2952646239554318, 'weighted avg_support': 212.0, 'O_support': 3651, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 2}, {'micro_f1': 0.7892886683209264, 'Conversation_Killer_precision': 0.4217687074829932, 'Conversation_Killer_recall': 0.2421875, 'Conversation_Killer_f1-score': 0.3076923076923077, 'Conversation_Killer_support': 256.0, 'micro avg_precision': 0.4217687074829932, 'micro avg_recall': 0.2421875, 'micro avg_f1-score': 0.3076923076923077, 'micro avg_support': 256.0, 'macro avg_precision': 0.4217687074829932, 'macro avg_recall': 0.2421875, 'macro avg_f1-score': 0.3076923076923077, 'macro avg_support': 256.0, 'weighted avg_precision': 0.4217687074829932, 'weighted avg_recall': 0.2421875, 'weighted avg_f1-score': 0.3076923076923077, 'weighted avg_support': 256.0, 'O_support': 3651, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 3}]}
Best model updated: current epoch macro f1 = 0.3076923076923077
{'micro_f1': 0.847601323407775, 'Conversation_Killer_precision': 0.42857142857142855, 'Conversation_Killer_recall': 0.35, 'Conversation_Killer_f1-score': 0.3853211009174312, 'Conversation_Killer_support': 180.0, 'micro avg_precision': 0.42857142857142855, 'micro avg_recall': 0.35, 'micro avg_f1-score': 0.3853211009174312, 'micro avg_support': 180.0, 'macro avg_precision': 0.42857142857142855, 'macro avg_recall': 0.35, 'macro avg_f1-score': 0.3853211009174312, 'macro avg_support': 180.0, 'weighted avg_precision': 0.42857142857142855, 'weighted avg_recall': 0.35, 'weighted avg_f1-score': 0.3853211009174312, 'weighted avg_support': 180.0, 'O_support': 3651, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 4}
{'results': [{'micro_f1': 0.8145161290322581, 'Conversation_Killer_precision': 0.2653061224489796, 'Conversation_Killer_recall': 0.15234375, 'Conversation_Killer_f1-score': 0.19354838709677422, 'Conversation_Killer_support': 256.0, 'micro avg_precision': 0.2653061224489796, 'micro avg_recall': 0.15234375, 'micro avg_f1-score': 0.19354838709677422, 'micro avg_support': 256.0, 'macro avg_precision': 0.2653061224489796, 'macro avg_recall': 0.15234375, 'macro avg_f1-score': 0.19354838709677422, 'macro avg_support': 256.0, 'weighted avg_precision': 0.2653061224489796, 'weighted avg_recall': 0.15234375, 'weighted avg_f1-score': 0.19354838709677422, 'weighted avg_support': 256.0, 'O_support': 3651, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 0}, {'micro_f1': 0.847394540942928, 'Conversation_Killer_precision': 0.2857142857142857, 'Conversation_Killer_recall': 0.1935483870967742, 'Conversation_Killer_f1-score': 0.23076923076923075, 'Conversation_Killer_support': 217.0, 'micro avg_precision': 0.2857142857142857, 'micro avg_recall': 0.1935483870967742, 'micro avg_f1-score': 0.23076923076923075, 'micro avg_support': 217.0, 'macro avg_precision': 0.2857142857142857, 'macro avg_recall': 0.1935483870967742, 'macro avg_f1-score': 0.23076923076923075, 'macro avg_support': 217.0, 'weighted avg_precision': 0.2857142857142857, 'weighted avg_recall': 0.1935483870967742, 'weighted avg_f1-score': 0.23076923076923075, 'weighted avg_support': 217.0, 'O_support': 3651, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 1}, {'micro_f1': 0.8012820512820514, 'Conversation_Killer_precision': 0.36054421768707484, 'Conversation_Killer_recall': 0.25, 'Conversation_Killer_f1-score': 0.2952646239554318, 'Conversation_Killer_support': 212.0, 'micro avg_precision': 0.36054421768707484, 'micro avg_recall': 0.25, 'micro avg_f1-score': 0.2952646239554318, 'micro avg_support': 212.0, 'macro avg_precision': 0.36054421768707484, 'macro avg_recall': 0.25, 'macro avg_f1-score': 0.2952646239554318, 'macro avg_support': 212.0, 'weighted avg_precision': 0.36054421768707484, 'weighted avg_recall': 0.25, 'weighted avg_f1-score': 0.2952646239554318, 'weighted avg_support': 212.0, 'O_support': 3651, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 2}, {'micro_f1': 0.7892886683209264, 'Conversation_Killer_precision': 0.4217687074829932, 'Conversation_Killer_recall': 0.2421875, 'Conversation_Killer_f1-score': 0.3076923076923077, 'Conversation_Killer_support': 256.0, 'micro avg_precision': 0.4217687074829932, 'micro avg_recall': 0.2421875, 'micro avg_f1-score': 0.3076923076923077, 'micro avg_support': 256.0, 'macro avg_precision': 0.4217687074829932, 'macro avg_recall': 0.2421875, 'macro avg_f1-score': 0.3076923076923077, 'macro avg_support': 256.0, 'weighted avg_precision': 0.4217687074829932, 'weighted avg_recall': 0.2421875, 'weighted avg_f1-score': 0.3076923076923077, 'weighted avg_support': 256.0, 'O_support': 3651, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 3}, {'micro_f1': 0.847601323407775, 'Conversation_Killer_precision': 0.42857142857142855, 'Conversation_Killer_recall': 0.35, 'Conversation_Killer_f1-score': 0.3853211009174312, 'Conversation_Killer_support': 180.0, 'micro avg_precision': 0.42857142857142855, 'micro avg_recall': 0.35, 'micro avg_f1-score': 0.3853211009174312, 'micro avg_support': 180.0, 'macro avg_precision': 0.42857142857142855, 'macro avg_recall': 0.35, 'macro avg_f1-score': 0.3853211009174312, 'macro avg_support': 180.0, 'weighted avg_precision': 0.42857142857142855, 'weighted avg_recall': 0.35, 'weighted avg_f1-score': 0.3853211009174312, 'weighted avg_support': 180.0, 'O_support': 3651, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 4}]}
Best model updated: current epoch macro f1 = 0.3853211009174312
{'micro_f1': 0.847601323407775, 'Conversation_Killer_precision': 0.3877551020408163, 'Conversation_Killer_recall': 0.3584905660377358, 'Conversation_Killer_f1-score': 0.37254901960784315, 'Conversation_Killer_support': 159.0, 'micro avg_precision': 0.3877551020408163, 'micro avg_recall': 0.3584905660377358, 'micro avg_f1-score': 0.37254901960784315, 'micro avg_support': 159.0, 'macro avg_precision': 0.3877551020408163, 'macro avg_recall': 0.3584905660377358, 'macro avg_f1-score': 0.37254901960784315, 'macro avg_support': 159.0, 'weighted avg_precision': 0.3877551020408163, 'weighted avg_recall': 0.3584905660377358, 'weighted avg_f1-score': 0.37254901960784315, 'weighted avg_support': 159.0, 'O_support': 3651, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 5}
{'results': [{'micro_f1': 0.8145161290322581, 'Conversation_Killer_precision': 0.2653061224489796, 'Conversation_Killer_recall': 0.15234375, 'Conversation_Killer_f1-score': 0.19354838709677422, 'Conversation_Killer_support': 256.0, 'micro avg_precision': 0.2653061224489796, 'micro avg_recall': 0.15234375, 'micro avg_f1-score': 0.19354838709677422, 'micro avg_support': 256.0, 'macro avg_precision': 0.2653061224489796, 'macro avg_recall': 0.15234375, 'macro avg_f1-score': 0.19354838709677422, 'macro avg_support': 256.0, 'weighted avg_precision': 0.2653061224489796, 'weighted avg_recall': 0.15234375, 'weighted avg_f1-score': 0.19354838709677422, 'weighted avg_support': 256.0, 'O_support': 3651, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 0}, {'micro_f1': 0.847394540942928, 'Conversation_Killer_precision': 0.2857142857142857, 'Conversation_Killer_recall': 0.1935483870967742, 'Conversation_Killer_f1-score': 0.23076923076923075, 'Conversation_Killer_support': 217.0, 'micro avg_precision': 0.2857142857142857, 'micro avg_recall': 0.1935483870967742, 'micro avg_f1-score': 0.23076923076923075, 'micro avg_support': 217.0, 'macro avg_precision': 0.2857142857142857, 'macro avg_recall': 0.1935483870967742, 'macro avg_f1-score': 0.23076923076923075, 'macro avg_support': 217.0, 'weighted avg_precision': 0.2857142857142857, 'weighted avg_recall': 0.1935483870967742, 'weighted avg_f1-score': 0.23076923076923075, 'weighted avg_support': 217.0, 'O_support': 3651, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 1}, {'micro_f1': 0.8012820512820514, 'Conversation_Killer_precision': 0.36054421768707484, 'Conversation_Killer_recall': 0.25, 'Conversation_Killer_f1-score': 0.2952646239554318, 'Conversation_Killer_support': 212.0, 'micro avg_precision': 0.36054421768707484, 'micro avg_recall': 0.25, 'micro avg_f1-score': 0.2952646239554318, 'micro avg_support': 212.0, 'macro avg_precision': 0.36054421768707484, 'macro avg_recall': 0.25, 'macro avg_f1-score': 0.2952646239554318, 'macro avg_support': 212.0, 'weighted avg_precision': 0.36054421768707484, 'weighted avg_recall': 0.25, 'weighted avg_f1-score': 0.2952646239554318, 'weighted avg_support': 212.0, 'O_support': 3651, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 2}, {'micro_f1': 0.7892886683209264, 'Conversation_Killer_precision': 0.4217687074829932, 'Conversation_Killer_recall': 0.2421875, 'Conversation_Killer_f1-score': 0.3076923076923077, 'Conversation_Killer_support': 256.0, 'micro avg_precision': 0.4217687074829932, 'micro avg_recall': 0.2421875, 'micro avg_f1-score': 0.3076923076923077, 'micro avg_support': 256.0, 'macro avg_precision': 0.4217687074829932, 'macro avg_recall': 0.2421875, 'macro avg_f1-score': 0.3076923076923077, 'macro avg_support': 256.0, 'weighted avg_precision': 0.4217687074829932, 'weighted avg_recall': 0.2421875, 'weighted avg_f1-score': 0.3076923076923077, 'weighted avg_support': 256.0, 'O_support': 3651, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 3}, {'micro_f1': 0.847601323407775, 'Conversation_Killer_precision': 0.42857142857142855, 'Conversation_Killer_recall': 0.35, 'Conversation_Killer_f1-score': 0.3853211009174312, 'Conversation_Killer_support': 180.0, 'micro avg_precision': 0.42857142857142855, 'micro avg_recall': 0.35, 'micro avg_f1-score': 0.3853211009174312, 'micro avg_support': 180.0, 'macro avg_precision': 0.42857142857142855, 'macro avg_recall': 0.35, 'macro avg_f1-score': 0.3853211009174312, 'macro avg_support': 180.0, 'weighted avg_precision': 0.42857142857142855, 'weighted avg_recall': 0.35, 'weighted avg_f1-score': 0.3853211009174312, 'weighted avg_support': 180.0, 'O_support': 3651, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 4}, {'micro_f1': 0.847601323407775, 'Conversation_Killer_precision': 0.3877551020408163, 'Conversation_Killer_recall': 0.3584905660377358, 'Conversation_Killer_f1-score': 0.37254901960784315, 'Conversation_Killer_support': 159.0, 'micro avg_precision': 0.3877551020408163, 'micro avg_recall': 0.3584905660377358, 'micro avg_f1-score': 0.37254901960784315, 'micro avg_support': 159.0, 'macro avg_precision': 0.3877551020408163, 'macro avg_recall': 0.3584905660377358, 'macro avg_f1-score': 0.37254901960784315, 'macro avg_support': 159.0, 'weighted avg_precision': 0.3877551020408163, 'weighted avg_recall': 0.3584905660377358, 'weighted avg_f1-score': 0.37254901960784315, 'weighted avg_support': 159.0, 'O_support': 3651, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 5}]}
{'micro_f1': 0.824234904880066, 'Conversation_Killer_precision': 0.46258503401360546, 'Conversation_Killer_recall': 0.3119266055045872, 'Conversation_Killer_f1-score': 0.3726027397260275, 'Conversation_Killer_support': 218.0, 'micro avg_precision': 0.46258503401360546, 'micro avg_recall': 0.3119266055045872, 'micro avg_f1-score': 0.3726027397260275, 'micro avg_support': 218.0, 'macro avg_precision': 0.46258503401360546, 'macro avg_recall': 0.3119266055045872, 'macro avg_f1-score': 0.3726027397260275, 'macro avg_support': 218.0, 'weighted avg_precision': 0.46258503401360546, 'weighted avg_recall': 0.3119266055045872, 'weighted avg_f1-score': 0.3726027397260275, 'weighted avg_support': 218.0, 'O_support': 3651, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 6}
{'results': [{'micro_f1': 0.8145161290322581, 'Conversation_Killer_precision': 0.2653061224489796, 'Conversation_Killer_recall': 0.15234375, 'Conversation_Killer_f1-score': 0.19354838709677422, 'Conversation_Killer_support': 256.0, 'micro avg_precision': 0.2653061224489796, 'micro avg_recall': 0.15234375, 'micro avg_f1-score': 0.19354838709677422, 'micro avg_support': 256.0, 'macro avg_precision': 0.2653061224489796, 'macro avg_recall': 0.15234375, 'macro avg_f1-score': 0.19354838709677422, 'macro avg_support': 256.0, 'weighted avg_precision': 0.2653061224489796, 'weighted avg_recall': 0.15234375, 'weighted avg_f1-score': 0.19354838709677422, 'weighted avg_support': 256.0, 'O_support': 3651, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 0}, {'micro_f1': 0.847394540942928, 'Conversation_Killer_precision': 0.2857142857142857, 'Conversation_Killer_recall': 0.1935483870967742, 'Conversation_Killer_f1-score': 0.23076923076923075, 'Conversation_Killer_support': 217.0, 'micro avg_precision': 0.2857142857142857, 'micro avg_recall': 0.1935483870967742, 'micro avg_f1-score': 0.23076923076923075, 'micro avg_support': 217.0, 'macro avg_precision': 0.2857142857142857, 'macro avg_recall': 0.1935483870967742, 'macro avg_f1-score': 0.23076923076923075, 'macro avg_support': 217.0, 'weighted avg_precision': 0.2857142857142857, 'weighted avg_recall': 0.1935483870967742, 'weighted avg_f1-score': 0.23076923076923075, 'weighted avg_support': 217.0, 'O_support': 3651, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 1}, {'micro_f1': 0.8012820512820514, 'Conversation_Killer_precision': 0.36054421768707484, 'Conversation_Killer_recall': 0.25, 'Conversation_Killer_f1-score': 0.2952646239554318, 'Conversation_Killer_support': 212.0, 'micro avg_precision': 0.36054421768707484, 'micro avg_recall': 0.25, 'micro avg_f1-score': 0.2952646239554318, 'micro avg_support': 212.0, 'macro avg_precision': 0.36054421768707484, 'macro avg_recall': 0.25, 'macro avg_f1-score': 0.2952646239554318, 'macro avg_support': 212.0, 'weighted avg_precision': 0.36054421768707484, 'weighted avg_recall': 0.25, 'weighted avg_f1-score': 0.2952646239554318, 'weighted avg_support': 212.0, 'O_support': 3651, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 2}, {'micro_f1': 0.7892886683209264, 'Conversation_Killer_precision': 0.4217687074829932, 'Conversation_Killer_recall': 0.2421875, 'Conversation_Killer_f1-score': 0.3076923076923077, 'Conversation_Killer_support': 256.0, 'micro avg_precision': 0.4217687074829932, 'micro avg_recall': 0.2421875, 'micro avg_f1-score': 0.3076923076923077, 'micro avg_support': 256.0, 'macro avg_precision': 0.4217687074829932, 'macro avg_recall': 0.2421875, 'macro avg_f1-score': 0.3076923076923077, 'macro avg_support': 256.0, 'weighted avg_precision': 0.4217687074829932, 'weighted avg_recall': 0.2421875, 'weighted avg_f1-score': 0.3076923076923077, 'weighted avg_support': 256.0, 'O_support': 3651, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 3}, {'micro_f1': 0.847601323407775, 'Conversation_Killer_precision': 0.42857142857142855, 'Conversation_Killer_recall': 0.35, 'Conversation_Killer_f1-score': 0.3853211009174312, 'Conversation_Killer_support': 180.0, 'micro avg_precision': 0.42857142857142855, 'micro avg_recall': 0.35, 'micro avg_f1-score': 0.3853211009174312, 'micro avg_support': 180.0, 'macro avg_precision': 0.42857142857142855, 'macro avg_recall': 0.35, 'macro avg_f1-score': 0.3853211009174312, 'macro avg_support': 180.0, 'weighted avg_precision': 0.42857142857142855, 'weighted avg_recall': 0.35, 'weighted avg_f1-score': 0.3853211009174312, 'weighted avg_support': 180.0, 'O_support': 3651, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 4}, {'micro_f1': 0.847601323407775, 'Conversation_Killer_precision': 0.3877551020408163, 'Conversation_Killer_recall': 0.3584905660377358, 'Conversation_Killer_f1-score': 0.37254901960784315, 'Conversation_Killer_support': 159.0, 'micro avg_precision': 0.3877551020408163, 'micro avg_recall': 0.3584905660377358, 'micro avg_f1-score': 0.37254901960784315, 'micro avg_support': 159.0, 'macro avg_precision': 0.3877551020408163, 'macro avg_recall': 0.3584905660377358, 'macro avg_f1-score': 0.37254901960784315, 'macro avg_support': 159.0, 'weighted avg_precision': 0.3877551020408163, 'weighted avg_recall': 0.3584905660377358, 'weighted avg_f1-score': 0.37254901960784315, 'weighted avg_support': 159.0, 'O_support': 3651, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 5}, {'micro_f1': 0.824234904880066, 'Conversation_Killer_precision': 0.46258503401360546, 'Conversation_Killer_recall': 0.3119266055045872, 'Conversation_Killer_f1-score': 0.3726027397260275, 'Conversation_Killer_support': 218.0, 'micro avg_precision': 0.46258503401360546, 'micro avg_recall': 0.3119266055045872, 'micro avg_f1-score': 0.3726027397260275, 'micro avg_support': 218.0, 'macro avg_precision': 0.46258503401360546, 'macro avg_recall': 0.3119266055045872, 'macro avg_f1-score': 0.3726027397260275, 'macro avg_support': 218.0, 'weighted avg_precision': 0.46258503401360546, 'weighted avg_recall': 0.3119266055045872, 'weighted avg_f1-score': 0.3726027397260275, 'weighted avg_support': 218.0, 'O_support': 3651, 'B-Conversation_Killer_support': 147, 'I-Conversation_Killer_support': 1038, 'epoch': 6}]}
Early stopping triggered.
Saving model to directory: ./models/M2/2024-05-12-17-42-10_aug/mdeberta-v3-base_13_ME10_target=Conversation_Killer_SUBSAMPLED_2024-05-12-17-42-10
Training model no. 14 of 23 for (14, 'Loaded_Language') persuasion technique...
{'micro_f1': 0.9014381203159814, 'Loaded_Language_precision': 0.22019147084421237, 'Loaded_Language_recall': 0.20703764320785598, 'Loaded_Language_f1-score': 0.21341206242091948, 'Loaded_Language_support': 1222.0, 'micro avg_precision': 0.22019147084421237, 'micro avg_recall': 0.20703764320785598, 'micro avg_f1-score': 0.21341206242091948, 'micro avg_support': 1222.0, 'macro avg_precision': 0.22019147084421237, 'macro avg_recall': 0.20703764320785598, 'macro avg_f1-score': 0.21341206242091948, 'macro avg_support': 1222.0, 'weighted avg_precision': 0.22019147084421237, 'weighted avg_recall': 0.20703764320785598, 'weighted avg_f1-score': 0.2134120624209195, 'weighted avg_support': 1222.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 0}
{'results': [{'micro_f1': 0.9014381203159814, 'Loaded_Language_precision': 0.22019147084421237, 'Loaded_Language_recall': 0.20703764320785598, 'Loaded_Language_f1-score': 0.21341206242091948, 'Loaded_Language_support': 1222.0, 'micro avg_precision': 0.22019147084421237, 'micro avg_recall': 0.20703764320785598, 'micro avg_f1-score': 0.21341206242091948, 'micro avg_support': 1222.0, 'macro avg_precision': 0.22019147084421237, 'macro avg_recall': 0.20703764320785598, 'macro avg_f1-score': 0.21341206242091948, 'macro avg_support': 1222.0, 'weighted avg_precision': 0.22019147084421237, 'weighted avg_recall': 0.20703764320785598, 'weighted avg_f1-score': 0.2134120624209195, 'weighted avg_support': 1222.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 0}]}
Best model updated: current epoch macro f1 = 0.21341206242091948
{'micro_f1': 0.9154749848085882, 'Loaded_Language_precision': 0.27763272410791995, 'Loaded_Language_recall': 0.3136676499508358, 'Loaded_Language_f1-score': 0.2945521698984303, 'Loaded_Language_support': 1017.0, 'micro avg_precision': 0.27763272410791995, 'micro avg_recall': 0.3136676499508358, 'micro avg_f1-score': 0.2945521698984303, 'micro avg_support': 1017.0, 'macro avg_precision': 0.27763272410791995, 'macro avg_recall': 0.3136676499508358, 'macro avg_f1-score': 0.2945521698984303, 'macro avg_support': 1017.0, 'weighted avg_precision': 0.27763272410791995, 'weighted avg_recall': 0.3136676499508358, 'weighted avg_f1-score': 0.2945521698984303, 'weighted avg_support': 1017.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 1}
{'results': [{'micro_f1': 0.9014381203159814, 'Loaded_Language_precision': 0.22019147084421237, 'Loaded_Language_recall': 0.20703764320785598, 'Loaded_Language_f1-score': 0.21341206242091948, 'Loaded_Language_support': 1222.0, 'micro avg_precision': 0.22019147084421237, 'micro avg_recall': 0.20703764320785598, 'micro avg_f1-score': 0.21341206242091948, 'micro avg_support': 1222.0, 'macro avg_precision': 0.22019147084421237, 'macro avg_recall': 0.20703764320785598, 'macro avg_f1-score': 0.21341206242091948, 'macro avg_support': 1222.0, 'weighted avg_precision': 0.22019147084421237, 'weighted avg_recall': 0.20703764320785598, 'weighted avg_f1-score': 0.2134120624209195, 'weighted avg_support': 1222.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 0}, {'micro_f1': 0.9154749848085882, 'Loaded_Language_precision': 0.27763272410791995, 'Loaded_Language_recall': 0.3136676499508358, 'Loaded_Language_f1-score': 0.2945521698984303, 'Loaded_Language_support': 1017.0, 'micro avg_precision': 0.27763272410791995, 'micro avg_recall': 0.3136676499508358, 'micro avg_f1-score': 0.2945521698984303, 'micro avg_support': 1017.0, 'macro avg_precision': 0.27763272410791995, 'macro avg_recall': 0.3136676499508358, 'macro avg_f1-score': 0.2945521698984303, 'macro avg_support': 1017.0, 'weighted avg_precision': 0.27763272410791995, 'weighted avg_recall': 0.3136676499508358, 'weighted avg_f1-score': 0.2945521698984303, 'weighted avg_support': 1017.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 1}]}
Best model updated: current epoch macro f1 = 0.2945521698984303
{'micro_f1': 0.9165282560259267, 'Loaded_Language_precision': 0.35857267188859876, 'Loaded_Language_recall': 0.35093696763202725, 'Loaded_Language_f1-score': 0.3547137322427895, 'Loaded_Language_support': 1174.0, 'micro avg_precision': 0.35857267188859876, 'micro avg_recall': 0.35093696763202725, 'micro avg_f1-score': 0.3547137322427895, 'micro avg_support': 1174.0, 'macro avg_precision': 0.35857267188859876, 'macro avg_recall': 0.35093696763202725, 'macro avg_f1-score': 0.3547137322427895, 'macro avg_support': 1174.0, 'weighted avg_precision': 0.35857267188859876, 'weighted avg_recall': 0.35093696763202725, 'weighted avg_f1-score': 0.3547137322427895, 'weighted avg_support': 1174.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 2}
{'results': [{'micro_f1': 0.9014381203159814, 'Loaded_Language_precision': 0.22019147084421237, 'Loaded_Language_recall': 0.20703764320785598, 'Loaded_Language_f1-score': 0.21341206242091948, 'Loaded_Language_support': 1222.0, 'micro avg_precision': 0.22019147084421237, 'micro avg_recall': 0.20703764320785598, 'micro avg_f1-score': 0.21341206242091948, 'micro avg_support': 1222.0, 'macro avg_precision': 0.22019147084421237, 'macro avg_recall': 0.20703764320785598, 'macro avg_f1-score': 0.21341206242091948, 'macro avg_support': 1222.0, 'weighted avg_precision': 0.22019147084421237, 'weighted avg_recall': 0.20703764320785598, 'weighted avg_f1-score': 0.2134120624209195, 'weighted avg_support': 1222.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 0}, {'micro_f1': 0.9154749848085882, 'Loaded_Language_precision': 0.27763272410791995, 'Loaded_Language_recall': 0.3136676499508358, 'Loaded_Language_f1-score': 0.2945521698984303, 'Loaded_Language_support': 1017.0, 'micro avg_precision': 0.27763272410791995, 'micro avg_recall': 0.3136676499508358, 'micro avg_f1-score': 0.2945521698984303, 'micro avg_support': 1017.0, 'macro avg_precision': 0.27763272410791995, 'macro avg_recall': 0.3136676499508358, 'macro avg_f1-score': 0.2945521698984303, 'macro avg_support': 1017.0, 'weighted avg_precision': 0.27763272410791995, 'weighted avg_recall': 0.3136676499508358, 'weighted avg_f1-score': 0.2945521698984303, 'weighted avg_support': 1017.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 1}, {'micro_f1': 0.9165282560259267, 'Loaded_Language_precision': 0.35857267188859876, 'Loaded_Language_recall': 0.35093696763202725, 'Loaded_Language_f1-score': 0.3547137322427895, 'Loaded_Language_support': 1174.0, 'micro avg_precision': 0.35857267188859876, 'micro avg_recall': 0.35093696763202725, 'micro avg_f1-score': 0.3547137322427895, 'micro avg_support': 1174.0, 'macro avg_precision': 0.35857267188859876, 'macro avg_recall': 0.35093696763202725, 'macro avg_f1-score': 0.3547137322427895, 'macro avg_support': 1174.0, 'weighted avg_precision': 0.35857267188859876, 'weighted avg_recall': 0.35093696763202725, 'weighted avg_f1-score': 0.3547137322427895, 'weighted avg_support': 1174.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 2}]}
Best model updated: current epoch macro f1 = 0.3547137322427895
{'micro_f1': 0.9172169333603404, 'Loaded_Language_precision': 0.36118363794604, 'Loaded_Language_recall': 0.3728661275831087, 'Loaded_Language_f1-score': 0.3669319186560566, 'Loaded_Language_support': 1113.0, 'micro avg_precision': 0.36118363794604, 'micro avg_recall': 0.3728661275831087, 'micro avg_f1-score': 0.3669319186560566, 'micro avg_support': 1113.0, 'macro avg_precision': 0.36118363794604, 'macro avg_recall': 0.3728661275831087, 'macro avg_f1-score': 0.3669319186560566, 'macro avg_support': 1113.0, 'weighted avg_precision': 0.36118363794604, 'weighted avg_recall': 0.3728661275831087, 'weighted avg_f1-score': 0.3669319186560566, 'weighted avg_support': 1113.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 3}
{'results': [{'micro_f1': 0.9014381203159814, 'Loaded_Language_precision': 0.22019147084421237, 'Loaded_Language_recall': 0.20703764320785598, 'Loaded_Language_f1-score': 0.21341206242091948, 'Loaded_Language_support': 1222.0, 'micro avg_precision': 0.22019147084421237, 'micro avg_recall': 0.20703764320785598, 'micro avg_f1-score': 0.21341206242091948, 'micro avg_support': 1222.0, 'macro avg_precision': 0.22019147084421237, 'macro avg_recall': 0.20703764320785598, 'macro avg_f1-score': 0.21341206242091948, 'macro avg_support': 1222.0, 'weighted avg_precision': 0.22019147084421237, 'weighted avg_recall': 0.20703764320785598, 'weighted avg_f1-score': 0.2134120624209195, 'weighted avg_support': 1222.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 0}, {'micro_f1': 0.9154749848085882, 'Loaded_Language_precision': 0.27763272410791995, 'Loaded_Language_recall': 0.3136676499508358, 'Loaded_Language_f1-score': 0.2945521698984303, 'Loaded_Language_support': 1017.0, 'micro avg_precision': 0.27763272410791995, 'micro avg_recall': 0.3136676499508358, 'micro avg_f1-score': 0.2945521698984303, 'micro avg_support': 1017.0, 'macro avg_precision': 0.27763272410791995, 'macro avg_recall': 0.3136676499508358, 'macro avg_f1-score': 0.2945521698984303, 'macro avg_support': 1017.0, 'weighted avg_precision': 0.27763272410791995, 'weighted avg_recall': 0.3136676499508358, 'weighted avg_f1-score': 0.2945521698984303, 'weighted avg_support': 1017.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 1}, {'micro_f1': 0.9165282560259267, 'Loaded_Language_precision': 0.35857267188859876, 'Loaded_Language_recall': 0.35093696763202725, 'Loaded_Language_f1-score': 0.3547137322427895, 'Loaded_Language_support': 1174.0, 'micro avg_precision': 0.35857267188859876, 'micro avg_recall': 0.35093696763202725, 'micro avg_f1-score': 0.3547137322427895, 'micro avg_support': 1174.0, 'macro avg_precision': 0.35857267188859876, 'macro avg_recall': 0.35093696763202725, 'macro avg_f1-score': 0.3547137322427895, 'macro avg_support': 1174.0, 'weighted avg_precision': 0.35857267188859876, 'weighted avg_recall': 0.35093696763202725, 'weighted avg_f1-score': 0.3547137322427895, 'weighted avg_support': 1174.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 2}, {'micro_f1': 0.9172169333603404, 'Loaded_Language_precision': 0.36118363794604, 'Loaded_Language_recall': 0.3728661275831087, 'Loaded_Language_f1-score': 0.3669319186560566, 'Loaded_Language_support': 1113.0, 'micro avg_precision': 0.36118363794604, 'micro avg_recall': 0.3728661275831087, 'micro avg_f1-score': 0.3669319186560566, 'micro avg_support': 1113.0, 'macro avg_precision': 0.36118363794604, 'macro avg_recall': 0.3728661275831087, 'macro avg_f1-score': 0.3669319186560566, 'macro avg_support': 1113.0, 'weighted avg_precision': 0.36118363794604, 'weighted avg_recall': 0.3728661275831087, 'weighted avg_f1-score': 0.3669319186560566, 'weighted avg_support': 1113.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 3}]}
Best model updated: current epoch macro f1 = 0.3669319186560566
{'micro_f1': 0.9184930119505773, 'Loaded_Language_precision': 0.37684943429068757, 'Loaded_Language_recall': 0.3587406793703397, 'Loaded_Language_f1-score': 0.36757215619694406, 'Loaded_Language_support': 1207.0, 'micro avg_precision': 0.37684943429068757, 'micro avg_recall': 0.3587406793703397, 'micro avg_f1-score': 0.36757215619694406, 'micro avg_support': 1207.0, 'macro avg_precision': 0.37684943429068757, 'macro avg_recall': 0.3587406793703397, 'macro avg_f1-score': 0.36757215619694406, 'macro avg_support': 1207.0, 'weighted avg_precision': 0.37684943429068757, 'weighted avg_recall': 0.3587406793703397, 'weighted avg_f1-score': 0.36757215619694406, 'weighted avg_support': 1207.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 4}
{'results': [{'micro_f1': 0.9014381203159814, 'Loaded_Language_precision': 0.22019147084421237, 'Loaded_Language_recall': 0.20703764320785598, 'Loaded_Language_f1-score': 0.21341206242091948, 'Loaded_Language_support': 1222.0, 'micro avg_precision': 0.22019147084421237, 'micro avg_recall': 0.20703764320785598, 'micro avg_f1-score': 0.21341206242091948, 'micro avg_support': 1222.0, 'macro avg_precision': 0.22019147084421237, 'macro avg_recall': 0.20703764320785598, 'macro avg_f1-score': 0.21341206242091948, 'macro avg_support': 1222.0, 'weighted avg_precision': 0.22019147084421237, 'weighted avg_recall': 0.20703764320785598, 'weighted avg_f1-score': 0.2134120624209195, 'weighted avg_support': 1222.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 0}, {'micro_f1': 0.9154749848085882, 'Loaded_Language_precision': 0.27763272410791995, 'Loaded_Language_recall': 0.3136676499508358, 'Loaded_Language_f1-score': 0.2945521698984303, 'Loaded_Language_support': 1017.0, 'micro avg_precision': 0.27763272410791995, 'micro avg_recall': 0.3136676499508358, 'micro avg_f1-score': 0.2945521698984303, 'micro avg_support': 1017.0, 'macro avg_precision': 0.27763272410791995, 'macro avg_recall': 0.3136676499508358, 'macro avg_f1-score': 0.2945521698984303, 'macro avg_support': 1017.0, 'weighted avg_precision': 0.27763272410791995, 'weighted avg_recall': 0.3136676499508358, 'weighted avg_f1-score': 0.2945521698984303, 'weighted avg_support': 1017.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 1}, {'micro_f1': 0.9165282560259267, 'Loaded_Language_precision': 0.35857267188859876, 'Loaded_Language_recall': 0.35093696763202725, 'Loaded_Language_f1-score': 0.3547137322427895, 'Loaded_Language_support': 1174.0, 'micro avg_precision': 0.35857267188859876, 'micro avg_recall': 0.35093696763202725, 'micro avg_f1-score': 0.3547137322427895, 'micro avg_support': 1174.0, 'macro avg_precision': 0.35857267188859876, 'macro avg_recall': 0.35093696763202725, 'macro avg_f1-score': 0.3547137322427895, 'macro avg_support': 1174.0, 'weighted avg_precision': 0.35857267188859876, 'weighted avg_recall': 0.35093696763202725, 'weighted avg_f1-score': 0.3547137322427895, 'weighted avg_support': 1174.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 2}, {'micro_f1': 0.9172169333603404, 'Loaded_Language_precision': 0.36118363794604, 'Loaded_Language_recall': 0.3728661275831087, 'Loaded_Language_f1-score': 0.3669319186560566, 'Loaded_Language_support': 1113.0, 'micro avg_precision': 0.36118363794604, 'micro avg_recall': 0.3728661275831087, 'micro avg_f1-score': 0.3669319186560566, 'micro avg_support': 1113.0, 'macro avg_precision': 0.36118363794604, 'macro avg_recall': 0.3728661275831087, 'macro avg_f1-score': 0.3669319186560566, 'macro avg_support': 1113.0, 'weighted avg_precision': 0.36118363794604, 'weighted avg_recall': 0.3728661275831087, 'weighted avg_f1-score': 0.3669319186560566, 'weighted avg_support': 1113.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 3}, {'micro_f1': 0.9184930119505773, 'Loaded_Language_precision': 0.37684943429068757, 'Loaded_Language_recall': 0.3587406793703397, 'Loaded_Language_f1-score': 0.36757215619694406, 'Loaded_Language_support': 1207.0, 'micro avg_precision': 0.37684943429068757, 'micro avg_recall': 0.3587406793703397, 'micro avg_f1-score': 0.36757215619694406, 'micro avg_support': 1207.0, 'macro avg_precision': 0.37684943429068757, 'macro avg_recall': 0.3587406793703397, 'macro avg_f1-score': 0.36757215619694406, 'macro avg_support': 1207.0, 'weighted avg_precision': 0.37684943429068757, 'weighted avg_recall': 0.3587406793703397, 'weighted avg_f1-score': 0.36757215619694406, 'weighted avg_support': 1207.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 4}]}
Best model updated: current epoch macro f1 = 0.36757215619694406
{'micro_f1': 0.9146445209641483, 'Loaded_Language_precision': 0.39338555265448216, 'Loaded_Language_recall': 0.37079573420836753, 'Loaded_Language_f1-score': 0.38175675675675674, 'Loaded_Language_support': 1219.0, 'micro avg_precision': 0.39338555265448216, 'micro avg_recall': 0.37079573420836753, 'micro avg_f1-score': 0.38175675675675674, 'micro avg_support': 1219.0, 'macro avg_precision': 0.39338555265448216, 'macro avg_recall': 0.37079573420836753, 'macro avg_f1-score': 0.38175675675675674, 'macro avg_support': 1219.0, 'weighted avg_precision': 0.39338555265448216, 'weighted avg_recall': 0.37079573420836753, 'weighted avg_f1-score': 0.38175675675675674, 'weighted avg_support': 1219.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 5}
{'results': [{'micro_f1': 0.9014381203159814, 'Loaded_Language_precision': 0.22019147084421237, 'Loaded_Language_recall': 0.20703764320785598, 'Loaded_Language_f1-score': 0.21341206242091948, 'Loaded_Language_support': 1222.0, 'micro avg_precision': 0.22019147084421237, 'micro avg_recall': 0.20703764320785598, 'micro avg_f1-score': 0.21341206242091948, 'micro avg_support': 1222.0, 'macro avg_precision': 0.22019147084421237, 'macro avg_recall': 0.20703764320785598, 'macro avg_f1-score': 0.21341206242091948, 'macro avg_support': 1222.0, 'weighted avg_precision': 0.22019147084421237, 'weighted avg_recall': 0.20703764320785598, 'weighted avg_f1-score': 0.2134120624209195, 'weighted avg_support': 1222.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 0}, {'micro_f1': 0.9154749848085882, 'Loaded_Language_precision': 0.27763272410791995, 'Loaded_Language_recall': 0.3136676499508358, 'Loaded_Language_f1-score': 0.2945521698984303, 'Loaded_Language_support': 1017.0, 'micro avg_precision': 0.27763272410791995, 'micro avg_recall': 0.3136676499508358, 'micro avg_f1-score': 0.2945521698984303, 'micro avg_support': 1017.0, 'macro avg_precision': 0.27763272410791995, 'macro avg_recall': 0.3136676499508358, 'macro avg_f1-score': 0.2945521698984303, 'macro avg_support': 1017.0, 'weighted avg_precision': 0.27763272410791995, 'weighted avg_recall': 0.3136676499508358, 'weighted avg_f1-score': 0.2945521698984303, 'weighted avg_support': 1017.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 1}, {'micro_f1': 0.9165282560259267, 'Loaded_Language_precision': 0.35857267188859876, 'Loaded_Language_recall': 0.35093696763202725, 'Loaded_Language_f1-score': 0.3547137322427895, 'Loaded_Language_support': 1174.0, 'micro avg_precision': 0.35857267188859876, 'micro avg_recall': 0.35093696763202725, 'micro avg_f1-score': 0.3547137322427895, 'micro avg_support': 1174.0, 'macro avg_precision': 0.35857267188859876, 'macro avg_recall': 0.35093696763202725, 'macro avg_f1-score': 0.3547137322427895, 'macro avg_support': 1174.0, 'weighted avg_precision': 0.35857267188859876, 'weighted avg_recall': 0.35093696763202725, 'weighted avg_f1-score': 0.3547137322427895, 'weighted avg_support': 1174.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 2}, {'micro_f1': 0.9172169333603404, 'Loaded_Language_precision': 0.36118363794604, 'Loaded_Language_recall': 0.3728661275831087, 'Loaded_Language_f1-score': 0.3669319186560566, 'Loaded_Language_support': 1113.0, 'micro avg_precision': 0.36118363794604, 'micro avg_recall': 0.3728661275831087, 'micro avg_f1-score': 0.3669319186560566, 'micro avg_support': 1113.0, 'macro avg_precision': 0.36118363794604, 'macro avg_recall': 0.3728661275831087, 'macro avg_f1-score': 0.3669319186560566, 'macro avg_support': 1113.0, 'weighted avg_precision': 0.36118363794604, 'weighted avg_recall': 0.3728661275831087, 'weighted avg_f1-score': 0.3669319186560566, 'weighted avg_support': 1113.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 3}, {'micro_f1': 0.9184930119505773, 'Loaded_Language_precision': 0.37684943429068757, 'Loaded_Language_recall': 0.3587406793703397, 'Loaded_Language_f1-score': 0.36757215619694406, 'Loaded_Language_support': 1207.0, 'micro avg_precision': 0.37684943429068757, 'micro avg_recall': 0.3587406793703397, 'micro avg_f1-score': 0.36757215619694406, 'micro avg_support': 1207.0, 'macro avg_precision': 0.37684943429068757, 'macro avg_recall': 0.3587406793703397, 'macro avg_f1-score': 0.36757215619694406, 'macro avg_support': 1207.0, 'weighted avg_precision': 0.37684943429068757, 'weighted avg_recall': 0.3587406793703397, 'weighted avg_f1-score': 0.36757215619694406, 'weighted avg_support': 1207.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 4}, {'micro_f1': 0.9146445209641483, 'Loaded_Language_precision': 0.39338555265448216, 'Loaded_Language_recall': 0.37079573420836753, 'Loaded_Language_f1-score': 0.38175675675675674, 'Loaded_Language_support': 1219.0, 'micro avg_precision': 0.39338555265448216, 'micro avg_recall': 0.37079573420836753, 'micro avg_f1-score': 0.38175675675675674, 'micro avg_support': 1219.0, 'macro avg_precision': 0.39338555265448216, 'macro avg_recall': 0.37079573420836753, 'macro avg_f1-score': 0.38175675675675674, 'macro avg_support': 1219.0, 'weighted avg_precision': 0.39338555265448216, 'weighted avg_recall': 0.37079573420836753, 'weighted avg_f1-score': 0.38175675675675674, 'weighted avg_support': 1219.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 5}]}
Best model updated: current epoch macro f1 = 0.38175675675675674
{'micro_f1': 0.9185740328134495, 'Loaded_Language_precision': 0.412532637075718, 'Loaded_Language_recall': 0.35033259423503327, 'Loaded_Language_f1-score': 0.37889688249400477, 'Loaded_Language_support': 1353.0, 'micro avg_precision': 0.412532637075718, 'micro avg_recall': 0.35033259423503327, 'micro avg_f1-score': 0.37889688249400477, 'micro avg_support': 1353.0, 'macro avg_precision': 0.412532637075718, 'macro avg_recall': 0.35033259423503327, 'macro avg_f1-score': 0.37889688249400477, 'macro avg_support': 1353.0, 'weighted avg_precision': 0.412532637075718, 'weighted avg_recall': 0.35033259423503327, 'weighted avg_f1-score': 0.3788968824940047, 'weighted avg_support': 1353.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 6}
{'results': [{'micro_f1': 0.9014381203159814, 'Loaded_Language_precision': 0.22019147084421237, 'Loaded_Language_recall': 0.20703764320785598, 'Loaded_Language_f1-score': 0.21341206242091948, 'Loaded_Language_support': 1222.0, 'micro avg_precision': 0.22019147084421237, 'micro avg_recall': 0.20703764320785598, 'micro avg_f1-score': 0.21341206242091948, 'micro avg_support': 1222.0, 'macro avg_precision': 0.22019147084421237, 'macro avg_recall': 0.20703764320785598, 'macro avg_f1-score': 0.21341206242091948, 'macro avg_support': 1222.0, 'weighted avg_precision': 0.22019147084421237, 'weighted avg_recall': 0.20703764320785598, 'weighted avg_f1-score': 0.2134120624209195, 'weighted avg_support': 1222.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 0}, {'micro_f1': 0.9154749848085882, 'Loaded_Language_precision': 0.27763272410791995, 'Loaded_Language_recall': 0.3136676499508358, 'Loaded_Language_f1-score': 0.2945521698984303, 'Loaded_Language_support': 1017.0, 'micro avg_precision': 0.27763272410791995, 'micro avg_recall': 0.3136676499508358, 'micro avg_f1-score': 0.2945521698984303, 'micro avg_support': 1017.0, 'macro avg_precision': 0.27763272410791995, 'macro avg_recall': 0.3136676499508358, 'macro avg_f1-score': 0.2945521698984303, 'macro avg_support': 1017.0, 'weighted avg_precision': 0.27763272410791995, 'weighted avg_recall': 0.3136676499508358, 'weighted avg_f1-score': 0.2945521698984303, 'weighted avg_support': 1017.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 1}, {'micro_f1': 0.9165282560259267, 'Loaded_Language_precision': 0.35857267188859876, 'Loaded_Language_recall': 0.35093696763202725, 'Loaded_Language_f1-score': 0.3547137322427895, 'Loaded_Language_support': 1174.0, 'micro avg_precision': 0.35857267188859876, 'micro avg_recall': 0.35093696763202725, 'micro avg_f1-score': 0.3547137322427895, 'micro avg_support': 1174.0, 'macro avg_precision': 0.35857267188859876, 'macro avg_recall': 0.35093696763202725, 'macro avg_f1-score': 0.3547137322427895, 'macro avg_support': 1174.0, 'weighted avg_precision': 0.35857267188859876, 'weighted avg_recall': 0.35093696763202725, 'weighted avg_f1-score': 0.3547137322427895, 'weighted avg_support': 1174.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 2}, {'micro_f1': 0.9172169333603404, 'Loaded_Language_precision': 0.36118363794604, 'Loaded_Language_recall': 0.3728661275831087, 'Loaded_Language_f1-score': 0.3669319186560566, 'Loaded_Language_support': 1113.0, 'micro avg_precision': 0.36118363794604, 'micro avg_recall': 0.3728661275831087, 'micro avg_f1-score': 0.3669319186560566, 'micro avg_support': 1113.0, 'macro avg_precision': 0.36118363794604, 'macro avg_recall': 0.3728661275831087, 'macro avg_f1-score': 0.3669319186560566, 'macro avg_support': 1113.0, 'weighted avg_precision': 0.36118363794604, 'weighted avg_recall': 0.3728661275831087, 'weighted avg_f1-score': 0.3669319186560566, 'weighted avg_support': 1113.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 3}, {'micro_f1': 0.9184930119505773, 'Loaded_Language_precision': 0.37684943429068757, 'Loaded_Language_recall': 0.3587406793703397, 'Loaded_Language_f1-score': 0.36757215619694406, 'Loaded_Language_support': 1207.0, 'micro avg_precision': 0.37684943429068757, 'micro avg_recall': 0.3587406793703397, 'micro avg_f1-score': 0.36757215619694406, 'micro avg_support': 1207.0, 'macro avg_precision': 0.37684943429068757, 'macro avg_recall': 0.3587406793703397, 'macro avg_f1-score': 0.36757215619694406, 'macro avg_support': 1207.0, 'weighted avg_precision': 0.37684943429068757, 'weighted avg_recall': 0.3587406793703397, 'weighted avg_f1-score': 0.36757215619694406, 'weighted avg_support': 1207.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 4}, {'micro_f1': 0.9146445209641483, 'Loaded_Language_precision': 0.39338555265448216, 'Loaded_Language_recall': 0.37079573420836753, 'Loaded_Language_f1-score': 0.38175675675675674, 'Loaded_Language_support': 1219.0, 'micro avg_precision': 0.39338555265448216, 'micro avg_recall': 0.37079573420836753, 'micro avg_f1-score': 0.38175675675675674, 'micro avg_support': 1219.0, 'macro avg_precision': 0.39338555265448216, 'macro avg_recall': 0.37079573420836753, 'macro avg_f1-score': 0.38175675675675674, 'macro avg_support': 1219.0, 'weighted avg_precision': 0.39338555265448216, 'weighted avg_recall': 0.37079573420836753, 'weighted avg_f1-score': 0.38175675675675674, 'weighted avg_support': 1219.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 5}, {'micro_f1': 0.9185740328134495, 'Loaded_Language_precision': 0.412532637075718, 'Loaded_Language_recall': 0.35033259423503327, 'Loaded_Language_f1-score': 0.37889688249400477, 'Loaded_Language_support': 1353.0, 'micro avg_precision': 0.412532637075718, 'micro avg_recall': 0.35033259423503327, 'micro avg_f1-score': 0.37889688249400477, 'micro avg_support': 1353.0, 'macro avg_precision': 0.412532637075718, 'macro avg_recall': 0.35033259423503327, 'macro avg_f1-score': 0.37889688249400477, 'macro avg_support': 1353.0, 'weighted avg_precision': 0.412532637075718, 'weighted avg_recall': 0.35033259423503327, 'weighted avg_f1-score': 0.3788968824940047, 'weighted avg_support': 1353.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 6}]}
{'micro_f1': 0.920943893052461, 'Loaded_Language_precision': 0.3855526544821584, 'Loaded_Language_recall': 0.41911069063386946, 'Loaded_Language_f1-score': 0.4016319129646419, 'Loaded_Language_support': 1057.0, 'micro avg_precision': 0.3855526544821584, 'micro avg_recall': 0.41911069063386946, 'micro avg_f1-score': 0.4016319129646419, 'micro avg_support': 1057.0, 'macro avg_precision': 0.3855526544821584, 'macro avg_recall': 0.41911069063386946, 'macro avg_f1-score': 0.4016319129646419, 'macro avg_support': 1057.0, 'weighted avg_precision': 0.3855526544821584, 'weighted avg_recall': 0.41911069063386946, 'weighted avg_f1-score': 0.4016319129646419, 'weighted avg_support': 1057.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 7}
{'results': [{'micro_f1': 0.9014381203159814, 'Loaded_Language_precision': 0.22019147084421237, 'Loaded_Language_recall': 0.20703764320785598, 'Loaded_Language_f1-score': 0.21341206242091948, 'Loaded_Language_support': 1222.0, 'micro avg_precision': 0.22019147084421237, 'micro avg_recall': 0.20703764320785598, 'micro avg_f1-score': 0.21341206242091948, 'micro avg_support': 1222.0, 'macro avg_precision': 0.22019147084421237, 'macro avg_recall': 0.20703764320785598, 'macro avg_f1-score': 0.21341206242091948, 'macro avg_support': 1222.0, 'weighted avg_precision': 0.22019147084421237, 'weighted avg_recall': 0.20703764320785598, 'weighted avg_f1-score': 0.2134120624209195, 'weighted avg_support': 1222.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 0}, {'micro_f1': 0.9154749848085882, 'Loaded_Language_precision': 0.27763272410791995, 'Loaded_Language_recall': 0.3136676499508358, 'Loaded_Language_f1-score': 0.2945521698984303, 'Loaded_Language_support': 1017.0, 'micro avg_precision': 0.27763272410791995, 'micro avg_recall': 0.3136676499508358, 'micro avg_f1-score': 0.2945521698984303, 'micro avg_support': 1017.0, 'macro avg_precision': 0.27763272410791995, 'macro avg_recall': 0.3136676499508358, 'macro avg_f1-score': 0.2945521698984303, 'macro avg_support': 1017.0, 'weighted avg_precision': 0.27763272410791995, 'weighted avg_recall': 0.3136676499508358, 'weighted avg_f1-score': 0.2945521698984303, 'weighted avg_support': 1017.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 1}, {'micro_f1': 0.9165282560259267, 'Loaded_Language_precision': 0.35857267188859876, 'Loaded_Language_recall': 0.35093696763202725, 'Loaded_Language_f1-score': 0.3547137322427895, 'Loaded_Language_support': 1174.0, 'micro avg_precision': 0.35857267188859876, 'micro avg_recall': 0.35093696763202725, 'micro avg_f1-score': 0.3547137322427895, 'micro avg_support': 1174.0, 'macro avg_precision': 0.35857267188859876, 'macro avg_recall': 0.35093696763202725, 'macro avg_f1-score': 0.3547137322427895, 'macro avg_support': 1174.0, 'weighted avg_precision': 0.35857267188859876, 'weighted avg_recall': 0.35093696763202725, 'weighted avg_f1-score': 0.3547137322427895, 'weighted avg_support': 1174.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 2}, {'micro_f1': 0.9172169333603404, 'Loaded_Language_precision': 0.36118363794604, 'Loaded_Language_recall': 0.3728661275831087, 'Loaded_Language_f1-score': 0.3669319186560566, 'Loaded_Language_support': 1113.0, 'micro avg_precision': 0.36118363794604, 'micro avg_recall': 0.3728661275831087, 'micro avg_f1-score': 0.3669319186560566, 'micro avg_support': 1113.0, 'macro avg_precision': 0.36118363794604, 'macro avg_recall': 0.3728661275831087, 'macro avg_f1-score': 0.3669319186560566, 'macro avg_support': 1113.0, 'weighted avg_precision': 0.36118363794604, 'weighted avg_recall': 0.3728661275831087, 'weighted avg_f1-score': 0.3669319186560566, 'weighted avg_support': 1113.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 3}, {'micro_f1': 0.9184930119505773, 'Loaded_Language_precision': 0.37684943429068757, 'Loaded_Language_recall': 0.3587406793703397, 'Loaded_Language_f1-score': 0.36757215619694406, 'Loaded_Language_support': 1207.0, 'micro avg_precision': 0.37684943429068757, 'micro avg_recall': 0.3587406793703397, 'micro avg_f1-score': 0.36757215619694406, 'micro avg_support': 1207.0, 'macro avg_precision': 0.37684943429068757, 'macro avg_recall': 0.3587406793703397, 'macro avg_f1-score': 0.36757215619694406, 'macro avg_support': 1207.0, 'weighted avg_precision': 0.37684943429068757, 'weighted avg_recall': 0.3587406793703397, 'weighted avg_f1-score': 0.36757215619694406, 'weighted avg_support': 1207.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 4}, {'micro_f1': 0.9146445209641483, 'Loaded_Language_precision': 0.39338555265448216, 'Loaded_Language_recall': 0.37079573420836753, 'Loaded_Language_f1-score': 0.38175675675675674, 'Loaded_Language_support': 1219.0, 'micro avg_precision': 0.39338555265448216, 'micro avg_recall': 0.37079573420836753, 'micro avg_f1-score': 0.38175675675675674, 'micro avg_support': 1219.0, 'macro avg_precision': 0.39338555265448216, 'macro avg_recall': 0.37079573420836753, 'macro avg_f1-score': 0.38175675675675674, 'macro avg_support': 1219.0, 'weighted avg_precision': 0.39338555265448216, 'weighted avg_recall': 0.37079573420836753, 'weighted avg_f1-score': 0.38175675675675674, 'weighted avg_support': 1219.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 5}, {'micro_f1': 0.9185740328134495, 'Loaded_Language_precision': 0.412532637075718, 'Loaded_Language_recall': 0.35033259423503327, 'Loaded_Language_f1-score': 0.37889688249400477, 'Loaded_Language_support': 1353.0, 'micro avg_precision': 0.412532637075718, 'micro avg_recall': 0.35033259423503327, 'micro avg_f1-score': 0.37889688249400477, 'micro avg_support': 1353.0, 'macro avg_precision': 0.412532637075718, 'macro avg_recall': 0.35033259423503327, 'macro avg_f1-score': 0.37889688249400477, 'macro avg_support': 1353.0, 'weighted avg_precision': 0.412532637075718, 'weighted avg_recall': 0.35033259423503327, 'weighted avg_f1-score': 0.3788968824940047, 'weighted avg_support': 1353.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 6}, {'micro_f1': 0.920943893052461, 'Loaded_Language_precision': 0.3855526544821584, 'Loaded_Language_recall': 0.41911069063386946, 'Loaded_Language_f1-score': 0.4016319129646419, 'Loaded_Language_support': 1057.0, 'micro avg_precision': 0.3855526544821584, 'micro avg_recall': 0.41911069063386946, 'micro avg_f1-score': 0.4016319129646419, 'micro avg_support': 1057.0, 'macro avg_precision': 0.3855526544821584, 'macro avg_recall': 0.41911069063386946, 'macro avg_f1-score': 0.4016319129646419, 'macro avg_support': 1057.0, 'weighted avg_precision': 0.3855526544821584, 'weighted avg_recall': 0.41911069063386946, 'weighted avg_f1-score': 0.4016319129646419, 'weighted avg_support': 1057.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 7}]}
Best model updated: current epoch macro f1 = 0.4016319129646419
{'micro_f1': 0.9199513874822767, 'Loaded_Language_precision': 0.4290687554395126, 'Loaded_Language_recall': 0.3906497622820919, 'Loaded_Language_f1-score': 0.408958938199917, 'Loaded_Language_support': 1262.0, 'micro avg_precision': 0.4290687554395126, 'micro avg_recall': 0.3906497622820919, 'micro avg_f1-score': 0.408958938199917, 'micro avg_support': 1262.0, 'macro avg_precision': 0.4290687554395126, 'macro avg_recall': 0.3906497622820919, 'macro avg_f1-score': 0.408958938199917, 'macro avg_support': 1262.0, 'weighted avg_precision': 0.42906875543951256, 'weighted avg_recall': 0.3906497622820919, 'weighted avg_f1-score': 0.408958938199917, 'weighted avg_support': 1262.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 8}
{'results': [{'micro_f1': 0.9014381203159814, 'Loaded_Language_precision': 0.22019147084421237, 'Loaded_Language_recall': 0.20703764320785598, 'Loaded_Language_f1-score': 0.21341206242091948, 'Loaded_Language_support': 1222.0, 'micro avg_precision': 0.22019147084421237, 'micro avg_recall': 0.20703764320785598, 'micro avg_f1-score': 0.21341206242091948, 'micro avg_support': 1222.0, 'macro avg_precision': 0.22019147084421237, 'macro avg_recall': 0.20703764320785598, 'macro avg_f1-score': 0.21341206242091948, 'macro avg_support': 1222.0, 'weighted avg_precision': 0.22019147084421237, 'weighted avg_recall': 0.20703764320785598, 'weighted avg_f1-score': 0.2134120624209195, 'weighted avg_support': 1222.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 0}, {'micro_f1': 0.9154749848085882, 'Loaded_Language_precision': 0.27763272410791995, 'Loaded_Language_recall': 0.3136676499508358, 'Loaded_Language_f1-score': 0.2945521698984303, 'Loaded_Language_support': 1017.0, 'micro avg_precision': 0.27763272410791995, 'micro avg_recall': 0.3136676499508358, 'micro avg_f1-score': 0.2945521698984303, 'micro avg_support': 1017.0, 'macro avg_precision': 0.27763272410791995, 'macro avg_recall': 0.3136676499508358, 'macro avg_f1-score': 0.2945521698984303, 'macro avg_support': 1017.0, 'weighted avg_precision': 0.27763272410791995, 'weighted avg_recall': 0.3136676499508358, 'weighted avg_f1-score': 0.2945521698984303, 'weighted avg_support': 1017.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 1}, {'micro_f1': 0.9165282560259267, 'Loaded_Language_precision': 0.35857267188859876, 'Loaded_Language_recall': 0.35093696763202725, 'Loaded_Language_f1-score': 0.3547137322427895, 'Loaded_Language_support': 1174.0, 'micro avg_precision': 0.35857267188859876, 'micro avg_recall': 0.35093696763202725, 'micro avg_f1-score': 0.3547137322427895, 'micro avg_support': 1174.0, 'macro avg_precision': 0.35857267188859876, 'macro avg_recall': 0.35093696763202725, 'macro avg_f1-score': 0.3547137322427895, 'macro avg_support': 1174.0, 'weighted avg_precision': 0.35857267188859876, 'weighted avg_recall': 0.35093696763202725, 'weighted avg_f1-score': 0.3547137322427895, 'weighted avg_support': 1174.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 2}, {'micro_f1': 0.9172169333603404, 'Loaded_Language_precision': 0.36118363794604, 'Loaded_Language_recall': 0.3728661275831087, 'Loaded_Language_f1-score': 0.3669319186560566, 'Loaded_Language_support': 1113.0, 'micro avg_precision': 0.36118363794604, 'micro avg_recall': 0.3728661275831087, 'micro avg_f1-score': 0.3669319186560566, 'micro avg_support': 1113.0, 'macro avg_precision': 0.36118363794604, 'macro avg_recall': 0.3728661275831087, 'macro avg_f1-score': 0.3669319186560566, 'macro avg_support': 1113.0, 'weighted avg_precision': 0.36118363794604, 'weighted avg_recall': 0.3728661275831087, 'weighted avg_f1-score': 0.3669319186560566, 'weighted avg_support': 1113.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 3}, {'micro_f1': 0.9184930119505773, 'Loaded_Language_precision': 0.37684943429068757, 'Loaded_Language_recall': 0.3587406793703397, 'Loaded_Language_f1-score': 0.36757215619694406, 'Loaded_Language_support': 1207.0, 'micro avg_precision': 0.37684943429068757, 'micro avg_recall': 0.3587406793703397, 'micro avg_f1-score': 0.36757215619694406, 'micro avg_support': 1207.0, 'macro avg_precision': 0.37684943429068757, 'macro avg_recall': 0.3587406793703397, 'macro avg_f1-score': 0.36757215619694406, 'macro avg_support': 1207.0, 'weighted avg_precision': 0.37684943429068757, 'weighted avg_recall': 0.3587406793703397, 'weighted avg_f1-score': 0.36757215619694406, 'weighted avg_support': 1207.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 4}, {'micro_f1': 0.9146445209641483, 'Loaded_Language_precision': 0.39338555265448216, 'Loaded_Language_recall': 0.37079573420836753, 'Loaded_Language_f1-score': 0.38175675675675674, 'Loaded_Language_support': 1219.0, 'micro avg_precision': 0.39338555265448216, 'micro avg_recall': 0.37079573420836753, 'micro avg_f1-score': 0.38175675675675674, 'micro avg_support': 1219.0, 'macro avg_precision': 0.39338555265448216, 'macro avg_recall': 0.37079573420836753, 'macro avg_f1-score': 0.38175675675675674, 'macro avg_support': 1219.0, 'weighted avg_precision': 0.39338555265448216, 'weighted avg_recall': 0.37079573420836753, 'weighted avg_f1-score': 0.38175675675675674, 'weighted avg_support': 1219.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 5}, {'micro_f1': 0.9185740328134495, 'Loaded_Language_precision': 0.412532637075718, 'Loaded_Language_recall': 0.35033259423503327, 'Loaded_Language_f1-score': 0.37889688249400477, 'Loaded_Language_support': 1353.0, 'micro avg_precision': 0.412532637075718, 'micro avg_recall': 0.35033259423503327, 'micro avg_f1-score': 0.37889688249400477, 'micro avg_support': 1353.0, 'macro avg_precision': 0.412532637075718, 'macro avg_recall': 0.35033259423503327, 'macro avg_f1-score': 0.37889688249400477, 'macro avg_support': 1353.0, 'weighted avg_precision': 0.412532637075718, 'weighted avg_recall': 0.35033259423503327, 'weighted avg_f1-score': 0.3788968824940047, 'weighted avg_support': 1353.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 6}, {'micro_f1': 0.920943893052461, 'Loaded_Language_precision': 0.3855526544821584, 'Loaded_Language_recall': 0.41911069063386946, 'Loaded_Language_f1-score': 0.4016319129646419, 'Loaded_Language_support': 1057.0, 'micro avg_precision': 0.3855526544821584, 'micro avg_recall': 0.41911069063386946, 'micro avg_f1-score': 0.4016319129646419, 'micro avg_support': 1057.0, 'macro avg_precision': 0.3855526544821584, 'macro avg_recall': 0.41911069063386946, 'macro avg_f1-score': 0.4016319129646419, 'macro avg_support': 1057.0, 'weighted avg_precision': 0.3855526544821584, 'weighted avg_recall': 0.41911069063386946, 'weighted avg_f1-score': 0.4016319129646419, 'weighted avg_support': 1057.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 7}, {'micro_f1': 0.9199513874822767, 'Loaded_Language_precision': 0.4290687554395126, 'Loaded_Language_recall': 0.3906497622820919, 'Loaded_Language_f1-score': 0.408958938199917, 'Loaded_Language_support': 1262.0, 'micro avg_precision': 0.4290687554395126, 'micro avg_recall': 0.3906497622820919, 'micro avg_f1-score': 0.408958938199917, 'micro avg_support': 1262.0, 'macro avg_precision': 0.4290687554395126, 'macro avg_recall': 0.3906497622820919, 'macro avg_f1-score': 0.408958938199917, 'macro avg_support': 1262.0, 'weighted avg_precision': 0.42906875543951256, 'weighted avg_recall': 0.3906497622820919, 'weighted avg_f1-score': 0.408958938199917, 'weighted avg_support': 1262.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 8}]}
Best model updated: current epoch macro f1 = 0.408958938199917
{'micro_f1': 0.9208021065424346, 'Loaded_Language_precision': 0.40034812880765885, 'Loaded_Language_recall': 0.40671971706454463, 'Loaded_Language_f1-score': 0.4035087719298246, 'Loaded_Language_support': 1131.0, 'micro avg_precision': 0.40034812880765885, 'micro avg_recall': 0.40671971706454463, 'micro avg_f1-score': 0.4035087719298246, 'micro avg_support': 1131.0, 'macro avg_precision': 0.40034812880765885, 'macro avg_recall': 0.40671971706454463, 'macro avg_f1-score': 0.4035087719298246, 'macro avg_support': 1131.0, 'weighted avg_precision': 0.40034812880765885, 'weighted avg_recall': 0.40671971706454463, 'weighted avg_f1-score': 0.4035087719298246, 'weighted avg_support': 1131.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 9}
{'results': [{'micro_f1': 0.9014381203159814, 'Loaded_Language_precision': 0.22019147084421237, 'Loaded_Language_recall': 0.20703764320785598, 'Loaded_Language_f1-score': 0.21341206242091948, 'Loaded_Language_support': 1222.0, 'micro avg_precision': 0.22019147084421237, 'micro avg_recall': 0.20703764320785598, 'micro avg_f1-score': 0.21341206242091948, 'micro avg_support': 1222.0, 'macro avg_precision': 0.22019147084421237, 'macro avg_recall': 0.20703764320785598, 'macro avg_f1-score': 0.21341206242091948, 'macro avg_support': 1222.0, 'weighted avg_precision': 0.22019147084421237, 'weighted avg_recall': 0.20703764320785598, 'weighted avg_f1-score': 0.2134120624209195, 'weighted avg_support': 1222.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 0}, {'micro_f1': 0.9154749848085882, 'Loaded_Language_precision': 0.27763272410791995, 'Loaded_Language_recall': 0.3136676499508358, 'Loaded_Language_f1-score': 0.2945521698984303, 'Loaded_Language_support': 1017.0, 'micro avg_precision': 0.27763272410791995, 'micro avg_recall': 0.3136676499508358, 'micro avg_f1-score': 0.2945521698984303, 'micro avg_support': 1017.0, 'macro avg_precision': 0.27763272410791995, 'macro avg_recall': 0.3136676499508358, 'macro avg_f1-score': 0.2945521698984303, 'macro avg_support': 1017.0, 'weighted avg_precision': 0.27763272410791995, 'weighted avg_recall': 0.3136676499508358, 'weighted avg_f1-score': 0.2945521698984303, 'weighted avg_support': 1017.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 1}, {'micro_f1': 0.9165282560259267, 'Loaded_Language_precision': 0.35857267188859876, 'Loaded_Language_recall': 0.35093696763202725, 'Loaded_Language_f1-score': 0.3547137322427895, 'Loaded_Language_support': 1174.0, 'micro avg_precision': 0.35857267188859876, 'micro avg_recall': 0.35093696763202725, 'micro avg_f1-score': 0.3547137322427895, 'micro avg_support': 1174.0, 'macro avg_precision': 0.35857267188859876, 'macro avg_recall': 0.35093696763202725, 'macro avg_f1-score': 0.3547137322427895, 'macro avg_support': 1174.0, 'weighted avg_precision': 0.35857267188859876, 'weighted avg_recall': 0.35093696763202725, 'weighted avg_f1-score': 0.3547137322427895, 'weighted avg_support': 1174.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 2}, {'micro_f1': 0.9172169333603404, 'Loaded_Language_precision': 0.36118363794604, 'Loaded_Language_recall': 0.3728661275831087, 'Loaded_Language_f1-score': 0.3669319186560566, 'Loaded_Language_support': 1113.0, 'micro avg_precision': 0.36118363794604, 'micro avg_recall': 0.3728661275831087, 'micro avg_f1-score': 0.3669319186560566, 'micro avg_support': 1113.0, 'macro avg_precision': 0.36118363794604, 'macro avg_recall': 0.3728661275831087, 'macro avg_f1-score': 0.3669319186560566, 'macro avg_support': 1113.0, 'weighted avg_precision': 0.36118363794604, 'weighted avg_recall': 0.3728661275831087, 'weighted avg_f1-score': 0.3669319186560566, 'weighted avg_support': 1113.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 3}, {'micro_f1': 0.9184930119505773, 'Loaded_Language_precision': 0.37684943429068757, 'Loaded_Language_recall': 0.3587406793703397, 'Loaded_Language_f1-score': 0.36757215619694406, 'Loaded_Language_support': 1207.0, 'micro avg_precision': 0.37684943429068757, 'micro avg_recall': 0.3587406793703397, 'micro avg_f1-score': 0.36757215619694406, 'micro avg_support': 1207.0, 'macro avg_precision': 0.37684943429068757, 'macro avg_recall': 0.3587406793703397, 'macro avg_f1-score': 0.36757215619694406, 'macro avg_support': 1207.0, 'weighted avg_precision': 0.37684943429068757, 'weighted avg_recall': 0.3587406793703397, 'weighted avg_f1-score': 0.36757215619694406, 'weighted avg_support': 1207.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 4}, {'micro_f1': 0.9146445209641483, 'Loaded_Language_precision': 0.39338555265448216, 'Loaded_Language_recall': 0.37079573420836753, 'Loaded_Language_f1-score': 0.38175675675675674, 'Loaded_Language_support': 1219.0, 'micro avg_precision': 0.39338555265448216, 'micro avg_recall': 0.37079573420836753, 'micro avg_f1-score': 0.38175675675675674, 'micro avg_support': 1219.0, 'macro avg_precision': 0.39338555265448216, 'macro avg_recall': 0.37079573420836753, 'macro avg_f1-score': 0.38175675675675674, 'macro avg_support': 1219.0, 'weighted avg_precision': 0.39338555265448216, 'weighted avg_recall': 0.37079573420836753, 'weighted avg_f1-score': 0.38175675675675674, 'weighted avg_support': 1219.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 5}, {'micro_f1': 0.9185740328134495, 'Loaded_Language_precision': 0.412532637075718, 'Loaded_Language_recall': 0.35033259423503327, 'Loaded_Language_f1-score': 0.37889688249400477, 'Loaded_Language_support': 1353.0, 'micro avg_precision': 0.412532637075718, 'micro avg_recall': 0.35033259423503327, 'micro avg_f1-score': 0.37889688249400477, 'micro avg_support': 1353.0, 'macro avg_precision': 0.412532637075718, 'macro avg_recall': 0.35033259423503327, 'macro avg_f1-score': 0.37889688249400477, 'macro avg_support': 1353.0, 'weighted avg_precision': 0.412532637075718, 'weighted avg_recall': 0.35033259423503327, 'weighted avg_f1-score': 0.3788968824940047, 'weighted avg_support': 1353.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 6}, {'micro_f1': 0.920943893052461, 'Loaded_Language_precision': 0.3855526544821584, 'Loaded_Language_recall': 0.41911069063386946, 'Loaded_Language_f1-score': 0.4016319129646419, 'Loaded_Language_support': 1057.0, 'micro avg_precision': 0.3855526544821584, 'micro avg_recall': 0.41911069063386946, 'micro avg_f1-score': 0.4016319129646419, 'micro avg_support': 1057.0, 'macro avg_precision': 0.3855526544821584, 'macro avg_recall': 0.41911069063386946, 'macro avg_f1-score': 0.4016319129646419, 'macro avg_support': 1057.0, 'weighted avg_precision': 0.3855526544821584, 'weighted avg_recall': 0.41911069063386946, 'weighted avg_f1-score': 0.4016319129646419, 'weighted avg_support': 1057.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 7}, {'micro_f1': 0.9199513874822767, 'Loaded_Language_precision': 0.4290687554395126, 'Loaded_Language_recall': 0.3906497622820919, 'Loaded_Language_f1-score': 0.408958938199917, 'Loaded_Language_support': 1262.0, 'micro avg_precision': 0.4290687554395126, 'micro avg_recall': 0.3906497622820919, 'micro avg_f1-score': 0.408958938199917, 'micro avg_support': 1262.0, 'macro avg_precision': 0.4290687554395126, 'macro avg_recall': 0.3906497622820919, 'macro avg_f1-score': 0.408958938199917, 'macro avg_support': 1262.0, 'weighted avg_precision': 0.42906875543951256, 'weighted avg_recall': 0.3906497622820919, 'weighted avg_f1-score': 0.408958938199917, 'weighted avg_support': 1262.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 8}, {'micro_f1': 0.9208021065424346, 'Loaded_Language_precision': 0.40034812880765885, 'Loaded_Language_recall': 0.40671971706454463, 'Loaded_Language_f1-score': 0.4035087719298246, 'Loaded_Language_support': 1131.0, 'micro avg_precision': 0.40034812880765885, 'micro avg_recall': 0.40671971706454463, 'micro avg_f1-score': 0.4035087719298246, 'micro avg_support': 1131.0, 'macro avg_precision': 0.40034812880765885, 'macro avg_recall': 0.40671971706454463, 'macro avg_f1-score': 0.4035087719298246, 'macro avg_support': 1131.0, 'weighted avg_precision': 0.40034812880765885, 'weighted avg_recall': 0.40671971706454463, 'weighted avg_f1-score': 0.4035087719298246, 'weighted avg_support': 1131.0, 'O_support': 43747, 'B-Loaded_Language_support': 1149, 'I-Loaded_Language_support': 4474, 'epoch': 9}]}
Saving model to directory: ./models/M2/2024-05-12-17-42-10_aug/mdeberta-v3-base_14_ME10_target=Loaded_Language_SUBSAMPLED_2024-05-12-17-42-10
Training model no. 15 of 23 for (15, 'Repetition') persuasion technique...
{'micro_f1': 0.9099278809268068, 'Repetition_precision': 0.38961038961038963, 'Repetition_recall': 0.32608695652173914, 'Repetition_f1-score': 0.35502958579881655, 'Repetition_support': 184.0, 'micro avg_precision': 0.38961038961038963, 'micro avg_recall': 0.32608695652173914, 'micro avg_f1-score': 0.35502958579881655, 'micro avg_support': 184.0, 'macro avg_precision': 0.38961038961038963, 'macro avg_recall': 0.32608695652173914, 'macro avg_f1-score': 0.35502958579881655, 'macro avg_support': 184.0, 'weighted avg_precision': 0.3896103896103896, 'weighted avg_recall': 0.32608695652173914, 'weighted avg_f1-score': 0.35502958579881655, 'weighted avg_support': 184.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 0}
{'results': [{'micro_f1': 0.9099278809268068, 'Repetition_precision': 0.38961038961038963, 'Repetition_recall': 0.32608695652173914, 'Repetition_f1-score': 0.35502958579881655, 'Repetition_support': 184.0, 'micro avg_precision': 0.38961038961038963, 'micro avg_recall': 0.32608695652173914, 'micro avg_f1-score': 0.35502958579881655, 'micro avg_support': 184.0, 'macro avg_precision': 0.38961038961038963, 'macro avg_recall': 0.32608695652173914, 'macro avg_f1-score': 0.35502958579881655, 'macro avg_support': 184.0, 'weighted avg_precision': 0.3896103896103896, 'weighted avg_recall': 0.32608695652173914, 'weighted avg_f1-score': 0.35502958579881655, 'weighted avg_support': 184.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 0}]}
Best model updated: current epoch macro f1 = 0.35502958579881655
{'micro_f1': 0.9275740371336505, 'Repetition_precision': 0.551948051948052, 'Repetition_recall': 0.5345911949685535, 'Repetition_f1-score': 0.5431309904153354, 'Repetition_support': 159.0, 'micro avg_precision': 0.551948051948052, 'micro avg_recall': 0.5345911949685535, 'micro avg_f1-score': 0.5431309904153354, 'micro avg_support': 159.0, 'macro avg_precision': 0.551948051948052, 'macro avg_recall': 0.5345911949685535, 'macro avg_f1-score': 0.5431309904153354, 'macro avg_support': 159.0, 'weighted avg_precision': 0.551948051948052, 'weighted avg_recall': 0.5345911949685535, 'weighted avg_f1-score': 0.5431309904153354, 'weighted avg_support': 159.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 1}
{'results': [{'micro_f1': 0.9099278809268068, 'Repetition_precision': 0.38961038961038963, 'Repetition_recall': 0.32608695652173914, 'Repetition_f1-score': 0.35502958579881655, 'Repetition_support': 184.0, 'micro avg_precision': 0.38961038961038963, 'micro avg_recall': 0.32608695652173914, 'micro avg_f1-score': 0.35502958579881655, 'micro avg_support': 184.0, 'macro avg_precision': 0.38961038961038963, 'macro avg_recall': 0.32608695652173914, 'macro avg_f1-score': 0.35502958579881655, 'macro avg_support': 184.0, 'weighted avg_precision': 0.3896103896103896, 'weighted avg_recall': 0.32608695652173914, 'weighted avg_f1-score': 0.35502958579881655, 'weighted avg_support': 184.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 0}, {'micro_f1': 0.9275740371336505, 'Repetition_precision': 0.551948051948052, 'Repetition_recall': 0.5345911949685535, 'Repetition_f1-score': 0.5431309904153354, 'Repetition_support': 159.0, 'micro avg_precision': 0.551948051948052, 'micro avg_recall': 0.5345911949685535, 'micro avg_f1-score': 0.5431309904153354, 'micro avg_support': 159.0, 'macro avg_precision': 0.551948051948052, 'macro avg_recall': 0.5345911949685535, 'macro avg_f1-score': 0.5431309904153354, 'macro avg_support': 159.0, 'weighted avg_precision': 0.551948051948052, 'weighted avg_recall': 0.5345911949685535, 'weighted avg_f1-score': 0.5431309904153354, 'weighted avg_support': 159.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 1}]}
Best model updated: current epoch macro f1 = 0.5431309904153354
{'micro_f1': 0.9261930336044192, 'Repetition_precision': 0.6038961038961039, 'Repetition_recall': 0.5344827586206896, 'Repetition_f1-score': 0.5670731707317074, 'Repetition_support': 174.0, 'micro avg_precision': 0.6038961038961039, 'micro avg_recall': 0.5344827586206896, 'micro avg_f1-score': 0.5670731707317074, 'micro avg_support': 174.0, 'macro avg_precision': 0.6038961038961039, 'macro avg_recall': 0.5344827586206896, 'macro avg_f1-score': 0.5670731707317074, 'macro avg_support': 174.0, 'weighted avg_precision': 0.6038961038961039, 'weighted avg_recall': 0.5344827586206896, 'weighted avg_f1-score': 0.5670731707317074, 'weighted avg_support': 174.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 2}
{'results': [{'micro_f1': 0.9099278809268068, 'Repetition_precision': 0.38961038961038963, 'Repetition_recall': 0.32608695652173914, 'Repetition_f1-score': 0.35502958579881655, 'Repetition_support': 184.0, 'micro avg_precision': 0.38961038961038963, 'micro avg_recall': 0.32608695652173914, 'micro avg_f1-score': 0.35502958579881655, 'micro avg_support': 184.0, 'macro avg_precision': 0.38961038961038963, 'macro avg_recall': 0.32608695652173914, 'macro avg_f1-score': 0.35502958579881655, 'macro avg_support': 184.0, 'weighted avg_precision': 0.3896103896103896, 'weighted avg_recall': 0.32608695652173914, 'weighted avg_f1-score': 0.35502958579881655, 'weighted avg_support': 184.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 0}, {'micro_f1': 0.9275740371336505, 'Repetition_precision': 0.551948051948052, 'Repetition_recall': 0.5345911949685535, 'Repetition_f1-score': 0.5431309904153354, 'Repetition_support': 159.0, 'micro avg_precision': 0.551948051948052, 'micro avg_recall': 0.5345911949685535, 'micro avg_f1-score': 0.5431309904153354, 'micro avg_support': 159.0, 'macro avg_precision': 0.551948051948052, 'macro avg_recall': 0.5345911949685535, 'macro avg_f1-score': 0.5431309904153354, 'macro avg_support': 159.0, 'weighted avg_precision': 0.551948051948052, 'weighted avg_recall': 0.5345911949685535, 'weighted avg_f1-score': 0.5431309904153354, 'weighted avg_support': 159.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 1}, {'micro_f1': 0.9261930336044192, 'Repetition_precision': 0.6038961038961039, 'Repetition_recall': 0.5344827586206896, 'Repetition_f1-score': 0.5670731707317074, 'Repetition_support': 174.0, 'micro avg_precision': 0.6038961038961039, 'micro avg_recall': 0.5344827586206896, 'micro avg_f1-score': 0.5670731707317074, 'micro avg_support': 174.0, 'macro avg_precision': 0.6038961038961039, 'macro avg_recall': 0.5344827586206896, 'macro avg_f1-score': 0.5670731707317074, 'macro avg_support': 174.0, 'weighted avg_precision': 0.6038961038961039, 'weighted avg_recall': 0.5344827586206896, 'weighted avg_f1-score': 0.5670731707317074, 'weighted avg_support': 174.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 2}]}
Best model updated: current epoch macro f1 = 0.5670731707317074
{'micro_f1': 0.9281878164799755, 'Repetition_precision': 0.5974025974025974, 'Repetition_recall': 0.5508982035928144, 'Repetition_f1-score': 0.5732087227414331, 'Repetition_support': 167.0, 'micro avg_precision': 0.5974025974025974, 'micro avg_recall': 0.5508982035928144, 'micro avg_f1-score': 0.5732087227414331, 'micro avg_support': 167.0, 'macro avg_precision': 0.5974025974025974, 'macro avg_recall': 0.5508982035928144, 'macro avg_f1-score': 0.5732087227414331, 'macro avg_support': 167.0, 'weighted avg_precision': 0.5974025974025974, 'weighted avg_recall': 0.5508982035928144, 'weighted avg_f1-score': 0.5732087227414331, 'weighted avg_support': 167.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 3}
{'results': [{'micro_f1': 0.9099278809268068, 'Repetition_precision': 0.38961038961038963, 'Repetition_recall': 0.32608695652173914, 'Repetition_f1-score': 0.35502958579881655, 'Repetition_support': 184.0, 'micro avg_precision': 0.38961038961038963, 'micro avg_recall': 0.32608695652173914, 'micro avg_f1-score': 0.35502958579881655, 'micro avg_support': 184.0, 'macro avg_precision': 0.38961038961038963, 'macro avg_recall': 0.32608695652173914, 'macro avg_f1-score': 0.35502958579881655, 'macro avg_support': 184.0, 'weighted avg_precision': 0.3896103896103896, 'weighted avg_recall': 0.32608695652173914, 'weighted avg_f1-score': 0.35502958579881655, 'weighted avg_support': 184.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 0}, {'micro_f1': 0.9275740371336505, 'Repetition_precision': 0.551948051948052, 'Repetition_recall': 0.5345911949685535, 'Repetition_f1-score': 0.5431309904153354, 'Repetition_support': 159.0, 'micro avg_precision': 0.551948051948052, 'micro avg_recall': 0.5345911949685535, 'micro avg_f1-score': 0.5431309904153354, 'micro avg_support': 159.0, 'macro avg_precision': 0.551948051948052, 'macro avg_recall': 0.5345911949685535, 'macro avg_f1-score': 0.5431309904153354, 'macro avg_support': 159.0, 'weighted avg_precision': 0.551948051948052, 'weighted avg_recall': 0.5345911949685535, 'weighted avg_f1-score': 0.5431309904153354, 'weighted avg_support': 159.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 1}, {'micro_f1': 0.9261930336044192, 'Repetition_precision': 0.6038961038961039, 'Repetition_recall': 0.5344827586206896, 'Repetition_f1-score': 0.5670731707317074, 'Repetition_support': 174.0, 'micro avg_precision': 0.6038961038961039, 'micro avg_recall': 0.5344827586206896, 'micro avg_f1-score': 0.5670731707317074, 'micro avg_support': 174.0, 'macro avg_precision': 0.6038961038961039, 'macro avg_recall': 0.5344827586206896, 'macro avg_f1-score': 0.5670731707317074, 'macro avg_support': 174.0, 'weighted avg_precision': 0.6038961038961039, 'weighted avg_recall': 0.5344827586206896, 'weighted avg_f1-score': 0.5670731707317074, 'weighted avg_support': 174.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 2}, {'micro_f1': 0.9281878164799755, 'Repetition_precision': 0.5974025974025974, 'Repetition_recall': 0.5508982035928144, 'Repetition_f1-score': 0.5732087227414331, 'Repetition_support': 167.0, 'micro avg_precision': 0.5974025974025974, 'micro avg_recall': 0.5508982035928144, 'micro avg_f1-score': 0.5732087227414331, 'micro avg_support': 167.0, 'macro avg_precision': 0.5974025974025974, 'macro avg_recall': 0.5508982035928144, 'macro avg_f1-score': 0.5732087227414331, 'macro avg_support': 167.0, 'weighted avg_precision': 0.5974025974025974, 'weighted avg_recall': 0.5508982035928144, 'weighted avg_f1-score': 0.5732087227414331, 'weighted avg_support': 167.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 3}]}
Best model updated: current epoch macro f1 = 0.5732087227414331
{'micro_f1': 0.9189811262851005, 'Repetition_precision': 0.6168831168831169, 'Repetition_recall': 0.6050955414012739, 'Repetition_f1-score': 0.6109324758842444, 'Repetition_support': 157.0, 'micro avg_precision': 0.6168831168831169, 'micro avg_recall': 0.6050955414012739, 'micro avg_f1-score': 0.6109324758842444, 'micro avg_support': 157.0, 'macro avg_precision': 0.6168831168831169, 'macro avg_recall': 0.6050955414012739, 'macro avg_f1-score': 0.6109324758842444, 'macro avg_support': 157.0, 'weighted avg_precision': 0.6168831168831169, 'weighted avg_recall': 0.6050955414012739, 'weighted avg_f1-score': 0.6109324758842444, 'weighted avg_support': 157.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 4}
{'results': [{'micro_f1': 0.9099278809268068, 'Repetition_precision': 0.38961038961038963, 'Repetition_recall': 0.32608695652173914, 'Repetition_f1-score': 0.35502958579881655, 'Repetition_support': 184.0, 'micro avg_precision': 0.38961038961038963, 'micro avg_recall': 0.32608695652173914, 'micro avg_f1-score': 0.35502958579881655, 'micro avg_support': 184.0, 'macro avg_precision': 0.38961038961038963, 'macro avg_recall': 0.32608695652173914, 'macro avg_f1-score': 0.35502958579881655, 'macro avg_support': 184.0, 'weighted avg_precision': 0.3896103896103896, 'weighted avg_recall': 0.32608695652173914, 'weighted avg_f1-score': 0.35502958579881655, 'weighted avg_support': 184.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 0}, {'micro_f1': 0.9275740371336505, 'Repetition_precision': 0.551948051948052, 'Repetition_recall': 0.5345911949685535, 'Repetition_f1-score': 0.5431309904153354, 'Repetition_support': 159.0, 'micro avg_precision': 0.551948051948052, 'micro avg_recall': 0.5345911949685535, 'micro avg_f1-score': 0.5431309904153354, 'micro avg_support': 159.0, 'macro avg_precision': 0.551948051948052, 'macro avg_recall': 0.5345911949685535, 'macro avg_f1-score': 0.5431309904153354, 'macro avg_support': 159.0, 'weighted avg_precision': 0.551948051948052, 'weighted avg_recall': 0.5345911949685535, 'weighted avg_f1-score': 0.5431309904153354, 'weighted avg_support': 159.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 1}, {'micro_f1': 0.9261930336044192, 'Repetition_precision': 0.6038961038961039, 'Repetition_recall': 0.5344827586206896, 'Repetition_f1-score': 0.5670731707317074, 'Repetition_support': 174.0, 'micro avg_precision': 0.6038961038961039, 'micro avg_recall': 0.5344827586206896, 'micro avg_f1-score': 0.5670731707317074, 'micro avg_support': 174.0, 'macro avg_precision': 0.6038961038961039, 'macro avg_recall': 0.5344827586206896, 'macro avg_f1-score': 0.5670731707317074, 'macro avg_support': 174.0, 'weighted avg_precision': 0.6038961038961039, 'weighted avg_recall': 0.5344827586206896, 'weighted avg_f1-score': 0.5670731707317074, 'weighted avg_support': 174.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 2}, {'micro_f1': 0.9281878164799755, 'Repetition_precision': 0.5974025974025974, 'Repetition_recall': 0.5508982035928144, 'Repetition_f1-score': 0.5732087227414331, 'Repetition_support': 167.0, 'micro avg_precision': 0.5974025974025974, 'micro avg_recall': 0.5508982035928144, 'micro avg_f1-score': 0.5732087227414331, 'micro avg_support': 167.0, 'macro avg_precision': 0.5974025974025974, 'macro avg_recall': 0.5508982035928144, 'macro avg_f1-score': 0.5732087227414331, 'macro avg_support': 167.0, 'weighted avg_precision': 0.5974025974025974, 'weighted avg_recall': 0.5508982035928144, 'weighted avg_f1-score': 0.5732087227414331, 'weighted avg_support': 167.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 3}, {'micro_f1': 0.9189811262851005, 'Repetition_precision': 0.6168831168831169, 'Repetition_recall': 0.6050955414012739, 'Repetition_f1-score': 0.6109324758842444, 'Repetition_support': 157.0, 'micro avg_precision': 0.6168831168831169, 'micro avg_recall': 0.6050955414012739, 'micro avg_f1-score': 0.6109324758842444, 'micro avg_support': 157.0, 'macro avg_precision': 0.6168831168831169, 'macro avg_recall': 0.6050955414012739, 'macro avg_f1-score': 0.6109324758842444, 'macro avg_support': 157.0, 'weighted avg_precision': 0.6168831168831169, 'weighted avg_recall': 0.6050955414012739, 'weighted avg_f1-score': 0.6109324758842444, 'weighted avg_support': 157.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 4}]}
Best model updated: current epoch macro f1 = 0.6109324758842444
{'micro_f1': 0.9340187202700628, 'Repetition_precision': 0.6493506493506493, 'Repetition_recall': 0.6329113924050633, 'Repetition_f1-score': 0.6410256410256411, 'Repetition_support': 158.0, 'micro avg_precision': 0.6493506493506493, 'micro avg_recall': 0.6329113924050633, 'micro avg_f1-score': 0.6410256410256411, 'micro avg_support': 158.0, 'macro avg_precision': 0.6493506493506493, 'macro avg_recall': 0.6329113924050633, 'macro avg_f1-score': 0.6410256410256411, 'macro avg_support': 158.0, 'weighted avg_precision': 0.6493506493506493, 'weighted avg_recall': 0.6329113924050633, 'weighted avg_f1-score': 0.6410256410256411, 'weighted avg_support': 158.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 5}
{'results': [{'micro_f1': 0.9099278809268068, 'Repetition_precision': 0.38961038961038963, 'Repetition_recall': 0.32608695652173914, 'Repetition_f1-score': 0.35502958579881655, 'Repetition_support': 184.0, 'micro avg_precision': 0.38961038961038963, 'micro avg_recall': 0.32608695652173914, 'micro avg_f1-score': 0.35502958579881655, 'micro avg_support': 184.0, 'macro avg_precision': 0.38961038961038963, 'macro avg_recall': 0.32608695652173914, 'macro avg_f1-score': 0.35502958579881655, 'macro avg_support': 184.0, 'weighted avg_precision': 0.3896103896103896, 'weighted avg_recall': 0.32608695652173914, 'weighted avg_f1-score': 0.35502958579881655, 'weighted avg_support': 184.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 0}, {'micro_f1': 0.9275740371336505, 'Repetition_precision': 0.551948051948052, 'Repetition_recall': 0.5345911949685535, 'Repetition_f1-score': 0.5431309904153354, 'Repetition_support': 159.0, 'micro avg_precision': 0.551948051948052, 'micro avg_recall': 0.5345911949685535, 'micro avg_f1-score': 0.5431309904153354, 'micro avg_support': 159.0, 'macro avg_precision': 0.551948051948052, 'macro avg_recall': 0.5345911949685535, 'macro avg_f1-score': 0.5431309904153354, 'macro avg_support': 159.0, 'weighted avg_precision': 0.551948051948052, 'weighted avg_recall': 0.5345911949685535, 'weighted avg_f1-score': 0.5431309904153354, 'weighted avg_support': 159.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 1}, {'micro_f1': 0.9261930336044192, 'Repetition_precision': 0.6038961038961039, 'Repetition_recall': 0.5344827586206896, 'Repetition_f1-score': 0.5670731707317074, 'Repetition_support': 174.0, 'micro avg_precision': 0.6038961038961039, 'micro avg_recall': 0.5344827586206896, 'micro avg_f1-score': 0.5670731707317074, 'micro avg_support': 174.0, 'macro avg_precision': 0.6038961038961039, 'macro avg_recall': 0.5344827586206896, 'macro avg_f1-score': 0.5670731707317074, 'macro avg_support': 174.0, 'weighted avg_precision': 0.6038961038961039, 'weighted avg_recall': 0.5344827586206896, 'weighted avg_f1-score': 0.5670731707317074, 'weighted avg_support': 174.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 2}, {'micro_f1': 0.9281878164799755, 'Repetition_precision': 0.5974025974025974, 'Repetition_recall': 0.5508982035928144, 'Repetition_f1-score': 0.5732087227414331, 'Repetition_support': 167.0, 'micro avg_precision': 0.5974025974025974, 'micro avg_recall': 0.5508982035928144, 'micro avg_f1-score': 0.5732087227414331, 'micro avg_support': 167.0, 'macro avg_precision': 0.5974025974025974, 'macro avg_recall': 0.5508982035928144, 'macro avg_f1-score': 0.5732087227414331, 'macro avg_support': 167.0, 'weighted avg_precision': 0.5974025974025974, 'weighted avg_recall': 0.5508982035928144, 'weighted avg_f1-score': 0.5732087227414331, 'weighted avg_support': 167.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 3}, {'micro_f1': 0.9189811262851005, 'Repetition_precision': 0.6168831168831169, 'Repetition_recall': 0.6050955414012739, 'Repetition_f1-score': 0.6109324758842444, 'Repetition_support': 157.0, 'micro avg_precision': 0.6168831168831169, 'micro avg_recall': 0.6050955414012739, 'micro avg_f1-score': 0.6109324758842444, 'micro avg_support': 157.0, 'macro avg_precision': 0.6168831168831169, 'macro avg_recall': 0.6050955414012739, 'macro avg_f1-score': 0.6109324758842444, 'macro avg_support': 157.0, 'weighted avg_precision': 0.6168831168831169, 'weighted avg_recall': 0.6050955414012739, 'weighted avg_f1-score': 0.6109324758842444, 'weighted avg_support': 157.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 4}, {'micro_f1': 0.9340187202700628, 'Repetition_precision': 0.6493506493506493, 'Repetition_recall': 0.6329113924050633, 'Repetition_f1-score': 0.6410256410256411, 'Repetition_support': 158.0, 'micro avg_precision': 0.6493506493506493, 'micro avg_recall': 0.6329113924050633, 'micro avg_f1-score': 0.6410256410256411, 'micro avg_support': 158.0, 'macro avg_precision': 0.6493506493506493, 'macro avg_recall': 0.6329113924050633, 'macro avg_f1-score': 0.6410256410256411, 'macro avg_support': 158.0, 'weighted avg_precision': 0.6493506493506493, 'weighted avg_recall': 0.6329113924050633, 'weighted avg_f1-score': 0.6410256410256411, 'weighted avg_support': 158.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 5}]}
Best model updated: current epoch macro f1 = 0.6410256410256411
{'micro_f1': 0.922356912689888, 'Repetition_precision': 0.6558441558441559, 'Repetition_recall': 0.5804597701149425, 'Repetition_f1-score': 0.6158536585365854, 'Repetition_support': 174.0, 'micro avg_precision': 0.6558441558441559, 'micro avg_recall': 0.5804597701149425, 'micro avg_f1-score': 0.6158536585365854, 'micro avg_support': 174.0, 'macro avg_precision': 0.6558441558441559, 'macro avg_recall': 0.5804597701149425, 'macro avg_f1-score': 0.6158536585365854, 'macro avg_support': 174.0, 'weighted avg_precision': 0.6558441558441559, 'weighted avg_recall': 0.5804597701149425, 'weighted avg_f1-score': 0.6158536585365854, 'weighted avg_support': 174.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 6}
{'results': [{'micro_f1': 0.9099278809268068, 'Repetition_precision': 0.38961038961038963, 'Repetition_recall': 0.32608695652173914, 'Repetition_f1-score': 0.35502958579881655, 'Repetition_support': 184.0, 'micro avg_precision': 0.38961038961038963, 'micro avg_recall': 0.32608695652173914, 'micro avg_f1-score': 0.35502958579881655, 'micro avg_support': 184.0, 'macro avg_precision': 0.38961038961038963, 'macro avg_recall': 0.32608695652173914, 'macro avg_f1-score': 0.35502958579881655, 'macro avg_support': 184.0, 'weighted avg_precision': 0.3896103896103896, 'weighted avg_recall': 0.32608695652173914, 'weighted avg_f1-score': 0.35502958579881655, 'weighted avg_support': 184.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 0}, {'micro_f1': 0.9275740371336505, 'Repetition_precision': 0.551948051948052, 'Repetition_recall': 0.5345911949685535, 'Repetition_f1-score': 0.5431309904153354, 'Repetition_support': 159.0, 'micro avg_precision': 0.551948051948052, 'micro avg_recall': 0.5345911949685535, 'micro avg_f1-score': 0.5431309904153354, 'micro avg_support': 159.0, 'macro avg_precision': 0.551948051948052, 'macro avg_recall': 0.5345911949685535, 'macro avg_f1-score': 0.5431309904153354, 'macro avg_support': 159.0, 'weighted avg_precision': 0.551948051948052, 'weighted avg_recall': 0.5345911949685535, 'weighted avg_f1-score': 0.5431309904153354, 'weighted avg_support': 159.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 1}, {'micro_f1': 0.9261930336044192, 'Repetition_precision': 0.6038961038961039, 'Repetition_recall': 0.5344827586206896, 'Repetition_f1-score': 0.5670731707317074, 'Repetition_support': 174.0, 'micro avg_precision': 0.6038961038961039, 'micro avg_recall': 0.5344827586206896, 'micro avg_f1-score': 0.5670731707317074, 'micro avg_support': 174.0, 'macro avg_precision': 0.6038961038961039, 'macro avg_recall': 0.5344827586206896, 'macro avg_f1-score': 0.5670731707317074, 'macro avg_support': 174.0, 'weighted avg_precision': 0.6038961038961039, 'weighted avg_recall': 0.5344827586206896, 'weighted avg_f1-score': 0.5670731707317074, 'weighted avg_support': 174.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 2}, {'micro_f1': 0.9281878164799755, 'Repetition_precision': 0.5974025974025974, 'Repetition_recall': 0.5508982035928144, 'Repetition_f1-score': 0.5732087227414331, 'Repetition_support': 167.0, 'micro avg_precision': 0.5974025974025974, 'micro avg_recall': 0.5508982035928144, 'micro avg_f1-score': 0.5732087227414331, 'micro avg_support': 167.0, 'macro avg_precision': 0.5974025974025974, 'macro avg_recall': 0.5508982035928144, 'macro avg_f1-score': 0.5732087227414331, 'macro avg_support': 167.0, 'weighted avg_precision': 0.5974025974025974, 'weighted avg_recall': 0.5508982035928144, 'weighted avg_f1-score': 0.5732087227414331, 'weighted avg_support': 167.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 3}, {'micro_f1': 0.9189811262851005, 'Repetition_precision': 0.6168831168831169, 'Repetition_recall': 0.6050955414012739, 'Repetition_f1-score': 0.6109324758842444, 'Repetition_support': 157.0, 'micro avg_precision': 0.6168831168831169, 'micro avg_recall': 0.6050955414012739, 'micro avg_f1-score': 0.6109324758842444, 'micro avg_support': 157.0, 'macro avg_precision': 0.6168831168831169, 'macro avg_recall': 0.6050955414012739, 'macro avg_f1-score': 0.6109324758842444, 'macro avg_support': 157.0, 'weighted avg_precision': 0.6168831168831169, 'weighted avg_recall': 0.6050955414012739, 'weighted avg_f1-score': 0.6109324758842444, 'weighted avg_support': 157.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 4}, {'micro_f1': 0.9340187202700628, 'Repetition_precision': 0.6493506493506493, 'Repetition_recall': 0.6329113924050633, 'Repetition_f1-score': 0.6410256410256411, 'Repetition_support': 158.0, 'micro avg_precision': 0.6493506493506493, 'micro avg_recall': 0.6329113924050633, 'micro avg_f1-score': 0.6410256410256411, 'micro avg_support': 158.0, 'macro avg_precision': 0.6493506493506493, 'macro avg_recall': 0.6329113924050633, 'macro avg_f1-score': 0.6410256410256411, 'macro avg_support': 158.0, 'weighted avg_precision': 0.6493506493506493, 'weighted avg_recall': 0.6329113924050633, 'weighted avg_f1-score': 0.6410256410256411, 'weighted avg_support': 158.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 5}, {'micro_f1': 0.922356912689888, 'Repetition_precision': 0.6558441558441559, 'Repetition_recall': 0.5804597701149425, 'Repetition_f1-score': 0.6158536585365854, 'Repetition_support': 174.0, 'micro avg_precision': 0.6558441558441559, 'micro avg_recall': 0.5804597701149425, 'micro avg_f1-score': 0.6158536585365854, 'micro avg_support': 174.0, 'macro avg_precision': 0.6558441558441559, 'macro avg_recall': 0.5804597701149425, 'macro avg_f1-score': 0.6158536585365854, 'macro avg_support': 174.0, 'weighted avg_precision': 0.6558441558441559, 'weighted avg_recall': 0.5804597701149425, 'weighted avg_f1-score': 0.6158536585365854, 'weighted avg_support': 174.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 6}]}
{'micro_f1': 0.9378548411845942, 'Repetition_precision': 0.6233766233766234, 'Repetition_recall': 0.6808510638297872, 'Repetition_f1-score': 0.6508474576271187, 'Repetition_support': 141.0, 'micro avg_precision': 0.6233766233766234, 'micro avg_recall': 0.6808510638297872, 'micro avg_f1-score': 0.6508474576271187, 'micro avg_support': 141.0, 'macro avg_precision': 0.6233766233766234, 'macro avg_recall': 0.6808510638297872, 'macro avg_f1-score': 0.6508474576271187, 'macro avg_support': 141.0, 'weighted avg_precision': 0.6233766233766234, 'weighted avg_recall': 0.6808510638297872, 'weighted avg_f1-score': 0.6508474576271187, 'weighted avg_support': 141.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 7}
{'results': [{'micro_f1': 0.9099278809268068, 'Repetition_precision': 0.38961038961038963, 'Repetition_recall': 0.32608695652173914, 'Repetition_f1-score': 0.35502958579881655, 'Repetition_support': 184.0, 'micro avg_precision': 0.38961038961038963, 'micro avg_recall': 0.32608695652173914, 'micro avg_f1-score': 0.35502958579881655, 'micro avg_support': 184.0, 'macro avg_precision': 0.38961038961038963, 'macro avg_recall': 0.32608695652173914, 'macro avg_f1-score': 0.35502958579881655, 'macro avg_support': 184.0, 'weighted avg_precision': 0.3896103896103896, 'weighted avg_recall': 0.32608695652173914, 'weighted avg_f1-score': 0.35502958579881655, 'weighted avg_support': 184.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 0}, {'micro_f1': 0.9275740371336505, 'Repetition_precision': 0.551948051948052, 'Repetition_recall': 0.5345911949685535, 'Repetition_f1-score': 0.5431309904153354, 'Repetition_support': 159.0, 'micro avg_precision': 0.551948051948052, 'micro avg_recall': 0.5345911949685535, 'micro avg_f1-score': 0.5431309904153354, 'micro avg_support': 159.0, 'macro avg_precision': 0.551948051948052, 'macro avg_recall': 0.5345911949685535, 'macro avg_f1-score': 0.5431309904153354, 'macro avg_support': 159.0, 'weighted avg_precision': 0.551948051948052, 'weighted avg_recall': 0.5345911949685535, 'weighted avg_f1-score': 0.5431309904153354, 'weighted avg_support': 159.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 1}, {'micro_f1': 0.9261930336044192, 'Repetition_precision': 0.6038961038961039, 'Repetition_recall': 0.5344827586206896, 'Repetition_f1-score': 0.5670731707317074, 'Repetition_support': 174.0, 'micro avg_precision': 0.6038961038961039, 'micro avg_recall': 0.5344827586206896, 'micro avg_f1-score': 0.5670731707317074, 'micro avg_support': 174.0, 'macro avg_precision': 0.6038961038961039, 'macro avg_recall': 0.5344827586206896, 'macro avg_f1-score': 0.5670731707317074, 'macro avg_support': 174.0, 'weighted avg_precision': 0.6038961038961039, 'weighted avg_recall': 0.5344827586206896, 'weighted avg_f1-score': 0.5670731707317074, 'weighted avg_support': 174.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 2}, {'micro_f1': 0.9281878164799755, 'Repetition_precision': 0.5974025974025974, 'Repetition_recall': 0.5508982035928144, 'Repetition_f1-score': 0.5732087227414331, 'Repetition_support': 167.0, 'micro avg_precision': 0.5974025974025974, 'micro avg_recall': 0.5508982035928144, 'micro avg_f1-score': 0.5732087227414331, 'micro avg_support': 167.0, 'macro avg_precision': 0.5974025974025974, 'macro avg_recall': 0.5508982035928144, 'macro avg_f1-score': 0.5732087227414331, 'macro avg_support': 167.0, 'weighted avg_precision': 0.5974025974025974, 'weighted avg_recall': 0.5508982035928144, 'weighted avg_f1-score': 0.5732087227414331, 'weighted avg_support': 167.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 3}, {'micro_f1': 0.9189811262851005, 'Repetition_precision': 0.6168831168831169, 'Repetition_recall': 0.6050955414012739, 'Repetition_f1-score': 0.6109324758842444, 'Repetition_support': 157.0, 'micro avg_precision': 0.6168831168831169, 'micro avg_recall': 0.6050955414012739, 'micro avg_f1-score': 0.6109324758842444, 'micro avg_support': 157.0, 'macro avg_precision': 0.6168831168831169, 'macro avg_recall': 0.6050955414012739, 'macro avg_f1-score': 0.6109324758842444, 'macro avg_support': 157.0, 'weighted avg_precision': 0.6168831168831169, 'weighted avg_recall': 0.6050955414012739, 'weighted avg_f1-score': 0.6109324758842444, 'weighted avg_support': 157.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 4}, {'micro_f1': 0.9340187202700628, 'Repetition_precision': 0.6493506493506493, 'Repetition_recall': 0.6329113924050633, 'Repetition_f1-score': 0.6410256410256411, 'Repetition_support': 158.0, 'micro avg_precision': 0.6493506493506493, 'micro avg_recall': 0.6329113924050633, 'micro avg_f1-score': 0.6410256410256411, 'micro avg_support': 158.0, 'macro avg_precision': 0.6493506493506493, 'macro avg_recall': 0.6329113924050633, 'macro avg_f1-score': 0.6410256410256411, 'macro avg_support': 158.0, 'weighted avg_precision': 0.6493506493506493, 'weighted avg_recall': 0.6329113924050633, 'weighted avg_f1-score': 0.6410256410256411, 'weighted avg_support': 158.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 5}, {'micro_f1': 0.922356912689888, 'Repetition_precision': 0.6558441558441559, 'Repetition_recall': 0.5804597701149425, 'Repetition_f1-score': 0.6158536585365854, 'Repetition_support': 174.0, 'micro avg_precision': 0.6558441558441559, 'micro avg_recall': 0.5804597701149425, 'micro avg_f1-score': 0.6158536585365854, 'micro avg_support': 174.0, 'macro avg_precision': 0.6558441558441559, 'macro avg_recall': 0.5804597701149425, 'macro avg_f1-score': 0.6158536585365854, 'macro avg_support': 174.0, 'weighted avg_precision': 0.6558441558441559, 'weighted avg_recall': 0.5804597701149425, 'weighted avg_f1-score': 0.6158536585365854, 'weighted avg_support': 174.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 6}, {'micro_f1': 0.9378548411845942, 'Repetition_precision': 0.6233766233766234, 'Repetition_recall': 0.6808510638297872, 'Repetition_f1-score': 0.6508474576271187, 'Repetition_support': 141.0, 'micro avg_precision': 0.6233766233766234, 'micro avg_recall': 0.6808510638297872, 'micro avg_f1-score': 0.6508474576271187, 'micro avg_support': 141.0, 'macro avg_precision': 0.6233766233766234, 'macro avg_recall': 0.6808510638297872, 'macro avg_f1-score': 0.6508474576271187, 'macro avg_support': 141.0, 'weighted avg_precision': 0.6233766233766234, 'weighted avg_recall': 0.6808510638297872, 'weighted avg_f1-score': 0.6508474576271187, 'weighted avg_support': 141.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 7}]}
Best model updated: current epoch macro f1 = 0.6508474576271187
{'micro_f1': 0.9286481509897192, 'Repetition_precision': 0.6753246753246753, 'Repetition_recall': 0.5683060109289617, 'Repetition_f1-score': 0.6172106824925816, 'Repetition_support': 183.0, 'micro avg_precision': 0.6753246753246753, 'micro avg_recall': 0.5683060109289617, 'micro avg_f1-score': 0.6172106824925816, 'micro avg_support': 183.0, 'macro avg_precision': 0.6753246753246753, 'macro avg_recall': 0.5683060109289617, 'macro avg_f1-score': 0.6172106824925816, 'macro avg_support': 183.0, 'weighted avg_precision': 0.6753246753246753, 'weighted avg_recall': 0.5683060109289617, 'weighted avg_f1-score': 0.6172106824925816, 'weighted avg_support': 183.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 8}
{'results': [{'micro_f1': 0.9099278809268068, 'Repetition_precision': 0.38961038961038963, 'Repetition_recall': 0.32608695652173914, 'Repetition_f1-score': 0.35502958579881655, 'Repetition_support': 184.0, 'micro avg_precision': 0.38961038961038963, 'micro avg_recall': 0.32608695652173914, 'micro avg_f1-score': 0.35502958579881655, 'micro avg_support': 184.0, 'macro avg_precision': 0.38961038961038963, 'macro avg_recall': 0.32608695652173914, 'macro avg_f1-score': 0.35502958579881655, 'macro avg_support': 184.0, 'weighted avg_precision': 0.3896103896103896, 'weighted avg_recall': 0.32608695652173914, 'weighted avg_f1-score': 0.35502958579881655, 'weighted avg_support': 184.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 0}, {'micro_f1': 0.9275740371336505, 'Repetition_precision': 0.551948051948052, 'Repetition_recall': 0.5345911949685535, 'Repetition_f1-score': 0.5431309904153354, 'Repetition_support': 159.0, 'micro avg_precision': 0.551948051948052, 'micro avg_recall': 0.5345911949685535, 'micro avg_f1-score': 0.5431309904153354, 'micro avg_support': 159.0, 'macro avg_precision': 0.551948051948052, 'macro avg_recall': 0.5345911949685535, 'macro avg_f1-score': 0.5431309904153354, 'macro avg_support': 159.0, 'weighted avg_precision': 0.551948051948052, 'weighted avg_recall': 0.5345911949685535, 'weighted avg_f1-score': 0.5431309904153354, 'weighted avg_support': 159.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 1}, {'micro_f1': 0.9261930336044192, 'Repetition_precision': 0.6038961038961039, 'Repetition_recall': 0.5344827586206896, 'Repetition_f1-score': 0.5670731707317074, 'Repetition_support': 174.0, 'micro avg_precision': 0.6038961038961039, 'micro avg_recall': 0.5344827586206896, 'micro avg_f1-score': 0.5670731707317074, 'micro avg_support': 174.0, 'macro avg_precision': 0.6038961038961039, 'macro avg_recall': 0.5344827586206896, 'macro avg_f1-score': 0.5670731707317074, 'macro avg_support': 174.0, 'weighted avg_precision': 0.6038961038961039, 'weighted avg_recall': 0.5344827586206896, 'weighted avg_f1-score': 0.5670731707317074, 'weighted avg_support': 174.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 2}, {'micro_f1': 0.9281878164799755, 'Repetition_precision': 0.5974025974025974, 'Repetition_recall': 0.5508982035928144, 'Repetition_f1-score': 0.5732087227414331, 'Repetition_support': 167.0, 'micro avg_precision': 0.5974025974025974, 'micro avg_recall': 0.5508982035928144, 'micro avg_f1-score': 0.5732087227414331, 'micro avg_support': 167.0, 'macro avg_precision': 0.5974025974025974, 'macro avg_recall': 0.5508982035928144, 'macro avg_f1-score': 0.5732087227414331, 'macro avg_support': 167.0, 'weighted avg_precision': 0.5974025974025974, 'weighted avg_recall': 0.5508982035928144, 'weighted avg_f1-score': 0.5732087227414331, 'weighted avg_support': 167.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 3}, {'micro_f1': 0.9189811262851005, 'Repetition_precision': 0.6168831168831169, 'Repetition_recall': 0.6050955414012739, 'Repetition_f1-score': 0.6109324758842444, 'Repetition_support': 157.0, 'micro avg_precision': 0.6168831168831169, 'micro avg_recall': 0.6050955414012739, 'micro avg_f1-score': 0.6109324758842444, 'micro avg_support': 157.0, 'macro avg_precision': 0.6168831168831169, 'macro avg_recall': 0.6050955414012739, 'macro avg_f1-score': 0.6109324758842444, 'macro avg_support': 157.0, 'weighted avg_precision': 0.6168831168831169, 'weighted avg_recall': 0.6050955414012739, 'weighted avg_f1-score': 0.6109324758842444, 'weighted avg_support': 157.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 4}, {'micro_f1': 0.9340187202700628, 'Repetition_precision': 0.6493506493506493, 'Repetition_recall': 0.6329113924050633, 'Repetition_f1-score': 0.6410256410256411, 'Repetition_support': 158.0, 'micro avg_precision': 0.6493506493506493, 'micro avg_recall': 0.6329113924050633, 'micro avg_f1-score': 0.6410256410256411, 'micro avg_support': 158.0, 'macro avg_precision': 0.6493506493506493, 'macro avg_recall': 0.6329113924050633, 'macro avg_f1-score': 0.6410256410256411, 'macro avg_support': 158.0, 'weighted avg_precision': 0.6493506493506493, 'weighted avg_recall': 0.6329113924050633, 'weighted avg_f1-score': 0.6410256410256411, 'weighted avg_support': 158.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 5}, {'micro_f1': 0.922356912689888, 'Repetition_precision': 0.6558441558441559, 'Repetition_recall': 0.5804597701149425, 'Repetition_f1-score': 0.6158536585365854, 'Repetition_support': 174.0, 'micro avg_precision': 0.6558441558441559, 'micro avg_recall': 0.5804597701149425, 'micro avg_f1-score': 0.6158536585365854, 'micro avg_support': 174.0, 'macro avg_precision': 0.6558441558441559, 'macro avg_recall': 0.5804597701149425, 'macro avg_f1-score': 0.6158536585365854, 'macro avg_support': 174.0, 'weighted avg_precision': 0.6558441558441559, 'weighted avg_recall': 0.5804597701149425, 'weighted avg_f1-score': 0.6158536585365854, 'weighted avg_support': 174.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 6}, {'micro_f1': 0.9378548411845942, 'Repetition_precision': 0.6233766233766234, 'Repetition_recall': 0.6808510638297872, 'Repetition_f1-score': 0.6508474576271187, 'Repetition_support': 141.0, 'micro avg_precision': 0.6233766233766234, 'micro avg_recall': 0.6808510638297872, 'micro avg_f1-score': 0.6508474576271187, 'micro avg_support': 141.0, 'macro avg_precision': 0.6233766233766234, 'macro avg_recall': 0.6808510638297872, 'macro avg_f1-score': 0.6508474576271187, 'macro avg_support': 141.0, 'weighted avg_precision': 0.6233766233766234, 'weighted avg_recall': 0.6808510638297872, 'weighted avg_f1-score': 0.6508474576271187, 'weighted avg_support': 141.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 7}, {'micro_f1': 0.9286481509897192, 'Repetition_precision': 0.6753246753246753, 'Repetition_recall': 0.5683060109289617, 'Repetition_f1-score': 0.6172106824925816, 'Repetition_support': 183.0, 'micro avg_precision': 0.6753246753246753, 'micro avg_recall': 0.5683060109289617, 'micro avg_f1-score': 0.6172106824925816, 'micro avg_support': 183.0, 'macro avg_precision': 0.6753246753246753, 'macro avg_recall': 0.5683060109289617, 'macro avg_f1-score': 0.6172106824925816, 'macro avg_support': 183.0, 'weighted avg_precision': 0.6753246753246753, 'weighted avg_recall': 0.5683060109289617, 'weighted avg_f1-score': 0.6172106824925816, 'weighted avg_support': 183.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 8}]}
{'micro_f1': 0.9334049409237379, 'Repetition_precision': 0.525974025974026, 'Repetition_recall': 0.6585365853658537, 'Repetition_f1-score': 0.5848375451263539, 'Repetition_support': 123.0, 'micro avg_precision': 0.525974025974026, 'micro avg_recall': 0.6585365853658537, 'micro avg_f1-score': 0.5848375451263539, 'micro avg_support': 123.0, 'macro avg_precision': 0.525974025974026, 'macro avg_recall': 0.6585365853658537, 'macro avg_f1-score': 0.5848375451263539, 'macro avg_support': 123.0, 'weighted avg_precision': 0.525974025974026, 'weighted avg_recall': 0.6585365853658537, 'weighted avg_f1-score': 0.5848375451263539, 'weighted avg_support': 123.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 9}
{'results': [{'micro_f1': 0.9099278809268068, 'Repetition_precision': 0.38961038961038963, 'Repetition_recall': 0.32608695652173914, 'Repetition_f1-score': 0.35502958579881655, 'Repetition_support': 184.0, 'micro avg_precision': 0.38961038961038963, 'micro avg_recall': 0.32608695652173914, 'micro avg_f1-score': 0.35502958579881655, 'micro avg_support': 184.0, 'macro avg_precision': 0.38961038961038963, 'macro avg_recall': 0.32608695652173914, 'macro avg_f1-score': 0.35502958579881655, 'macro avg_support': 184.0, 'weighted avg_precision': 0.3896103896103896, 'weighted avg_recall': 0.32608695652173914, 'weighted avg_f1-score': 0.35502958579881655, 'weighted avg_support': 184.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 0}, {'micro_f1': 0.9275740371336505, 'Repetition_precision': 0.551948051948052, 'Repetition_recall': 0.5345911949685535, 'Repetition_f1-score': 0.5431309904153354, 'Repetition_support': 159.0, 'micro avg_precision': 0.551948051948052, 'micro avg_recall': 0.5345911949685535, 'micro avg_f1-score': 0.5431309904153354, 'micro avg_support': 159.0, 'macro avg_precision': 0.551948051948052, 'macro avg_recall': 0.5345911949685535, 'macro avg_f1-score': 0.5431309904153354, 'macro avg_support': 159.0, 'weighted avg_precision': 0.551948051948052, 'weighted avg_recall': 0.5345911949685535, 'weighted avg_f1-score': 0.5431309904153354, 'weighted avg_support': 159.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 1}, {'micro_f1': 0.9261930336044192, 'Repetition_precision': 0.6038961038961039, 'Repetition_recall': 0.5344827586206896, 'Repetition_f1-score': 0.5670731707317074, 'Repetition_support': 174.0, 'micro avg_precision': 0.6038961038961039, 'micro avg_recall': 0.5344827586206896, 'micro avg_f1-score': 0.5670731707317074, 'micro avg_support': 174.0, 'macro avg_precision': 0.6038961038961039, 'macro avg_recall': 0.5344827586206896, 'macro avg_f1-score': 0.5670731707317074, 'macro avg_support': 174.0, 'weighted avg_precision': 0.6038961038961039, 'weighted avg_recall': 0.5344827586206896, 'weighted avg_f1-score': 0.5670731707317074, 'weighted avg_support': 174.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 2}, {'micro_f1': 0.9281878164799755, 'Repetition_precision': 0.5974025974025974, 'Repetition_recall': 0.5508982035928144, 'Repetition_f1-score': 0.5732087227414331, 'Repetition_support': 167.0, 'micro avg_precision': 0.5974025974025974, 'micro avg_recall': 0.5508982035928144, 'micro avg_f1-score': 0.5732087227414331, 'micro avg_support': 167.0, 'macro avg_precision': 0.5974025974025974, 'macro avg_recall': 0.5508982035928144, 'macro avg_f1-score': 0.5732087227414331, 'macro avg_support': 167.0, 'weighted avg_precision': 0.5974025974025974, 'weighted avg_recall': 0.5508982035928144, 'weighted avg_f1-score': 0.5732087227414331, 'weighted avg_support': 167.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 3}, {'micro_f1': 0.9189811262851005, 'Repetition_precision': 0.6168831168831169, 'Repetition_recall': 0.6050955414012739, 'Repetition_f1-score': 0.6109324758842444, 'Repetition_support': 157.0, 'micro avg_precision': 0.6168831168831169, 'micro avg_recall': 0.6050955414012739, 'micro avg_f1-score': 0.6109324758842444, 'micro avg_support': 157.0, 'macro avg_precision': 0.6168831168831169, 'macro avg_recall': 0.6050955414012739, 'macro avg_f1-score': 0.6109324758842444, 'macro avg_support': 157.0, 'weighted avg_precision': 0.6168831168831169, 'weighted avg_recall': 0.6050955414012739, 'weighted avg_f1-score': 0.6109324758842444, 'weighted avg_support': 157.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 4}, {'micro_f1': 0.9340187202700628, 'Repetition_precision': 0.6493506493506493, 'Repetition_recall': 0.6329113924050633, 'Repetition_f1-score': 0.6410256410256411, 'Repetition_support': 158.0, 'micro avg_precision': 0.6493506493506493, 'micro avg_recall': 0.6329113924050633, 'micro avg_f1-score': 0.6410256410256411, 'micro avg_support': 158.0, 'macro avg_precision': 0.6493506493506493, 'macro avg_recall': 0.6329113924050633, 'macro avg_f1-score': 0.6410256410256411, 'macro avg_support': 158.0, 'weighted avg_precision': 0.6493506493506493, 'weighted avg_recall': 0.6329113924050633, 'weighted avg_f1-score': 0.6410256410256411, 'weighted avg_support': 158.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 5}, {'micro_f1': 0.922356912689888, 'Repetition_precision': 0.6558441558441559, 'Repetition_recall': 0.5804597701149425, 'Repetition_f1-score': 0.6158536585365854, 'Repetition_support': 174.0, 'micro avg_precision': 0.6558441558441559, 'micro avg_recall': 0.5804597701149425, 'micro avg_f1-score': 0.6158536585365854, 'micro avg_support': 174.0, 'macro avg_precision': 0.6558441558441559, 'macro avg_recall': 0.5804597701149425, 'macro avg_f1-score': 0.6158536585365854, 'macro avg_support': 174.0, 'weighted avg_precision': 0.6558441558441559, 'weighted avg_recall': 0.5804597701149425, 'weighted avg_f1-score': 0.6158536585365854, 'weighted avg_support': 174.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 6}, {'micro_f1': 0.9378548411845942, 'Repetition_precision': 0.6233766233766234, 'Repetition_recall': 0.6808510638297872, 'Repetition_f1-score': 0.6508474576271187, 'Repetition_support': 141.0, 'micro avg_precision': 0.6233766233766234, 'micro avg_recall': 0.6808510638297872, 'micro avg_f1-score': 0.6508474576271187, 'micro avg_support': 141.0, 'macro avg_precision': 0.6233766233766234, 'macro avg_recall': 0.6808510638297872, 'macro avg_f1-score': 0.6508474576271187, 'macro avg_support': 141.0, 'weighted avg_precision': 0.6233766233766234, 'weighted avg_recall': 0.6808510638297872, 'weighted avg_f1-score': 0.6508474576271187, 'weighted avg_support': 141.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 7}, {'micro_f1': 0.9286481509897192, 'Repetition_precision': 0.6753246753246753, 'Repetition_recall': 0.5683060109289617, 'Repetition_f1-score': 0.6172106824925816, 'Repetition_support': 183.0, 'micro avg_precision': 0.6753246753246753, 'micro avg_recall': 0.5683060109289617, 'micro avg_f1-score': 0.6172106824925816, 'micro avg_support': 183.0, 'macro avg_precision': 0.6753246753246753, 'macro avg_recall': 0.5683060109289617, 'macro avg_f1-score': 0.6172106824925816, 'macro avg_support': 183.0, 'weighted avg_precision': 0.6753246753246753, 'weighted avg_recall': 0.5683060109289617, 'weighted avg_f1-score': 0.6172106824925816, 'weighted avg_support': 183.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 8}, {'micro_f1': 0.9334049409237379, 'Repetition_precision': 0.525974025974026, 'Repetition_recall': 0.6585365853658537, 'Repetition_f1-score': 0.5848375451263539, 'Repetition_support': 123.0, 'micro avg_precision': 0.525974025974026, 'micro avg_recall': 0.6585365853658537, 'micro avg_f1-score': 0.5848375451263539, 'micro avg_support': 123.0, 'macro avg_precision': 0.525974025974026, 'macro avg_recall': 0.6585365853658537, 'macro avg_f1-score': 0.5848375451263539, 'macro avg_support': 123.0, 'weighted avg_precision': 0.525974025974026, 'weighted avg_recall': 0.6585365853658537, 'weighted avg_f1-score': 0.5848375451263539, 'weighted avg_support': 123.0, 'O_support': 5772, 'B-Repetition_support': 154, 'I-Repetition_support': 591, 'epoch': 9}]}
Early stopping triggered.
Saving model to directory: ./models/M2/2024-05-12-17-42-10_aug/mdeberta-v3-base_15_ME10_target=Repetition_SUBSAMPLED_2024-05-12-17-42-10
Training model no. 16 of 23 for (16, 'Exaggeration-Minimisation') persuasion technique...
{'micro_f1': 0.8287968003555161, 'Exaggeration-Minimisation_precision': 0.19902912621359223, 'Exaggeration-Minimisation_recall': 0.13225806451612904, 'Exaggeration-Minimisation_f1-score': 0.15891472868217055, 'Exaggeration-Minimisation_support': 310.0, 'micro avg_precision': 0.19902912621359223, 'micro avg_recall': 0.13225806451612904, 'micro avg_f1-score': 0.15891472868217055, 'micro avg_support': 310.0, 'macro avg_precision': 0.19902912621359223, 'macro avg_recall': 0.13225806451612904, 'macro avg_f1-score': 0.15891472868217055, 'macro avg_support': 310.0, 'weighted avg_precision': 0.19902912621359223, 'weighted avg_recall': 0.13225806451612904, 'weighted avg_f1-score': 0.15891472868217055, 'weighted avg_support': 310.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 0}
{'results': [{'micro_f1': 0.8287968003555161, 'Exaggeration-Minimisation_precision': 0.19902912621359223, 'Exaggeration-Minimisation_recall': 0.13225806451612904, 'Exaggeration-Minimisation_f1-score': 0.15891472868217055, 'Exaggeration-Minimisation_support': 310.0, 'micro avg_precision': 0.19902912621359223, 'micro avg_recall': 0.13225806451612904, 'micro avg_f1-score': 0.15891472868217055, 'micro avg_support': 310.0, 'macro avg_precision': 0.19902912621359223, 'macro avg_recall': 0.13225806451612904, 'macro avg_f1-score': 0.15891472868217055, 'macro avg_support': 310.0, 'weighted avg_precision': 0.19902912621359223, 'weighted avg_recall': 0.13225806451612904, 'weighted avg_f1-score': 0.15891472868217055, 'weighted avg_support': 310.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 0}]}
Best model updated: current epoch macro f1 = 0.15891472868217055
{'micro_f1': 0.8707921342073103, 'Exaggeration-Minimisation_precision': 0.32038834951456313, 'Exaggeration-Minimisation_recall': 0.28085106382978725, 'Exaggeration-Minimisation_f1-score': 0.29931972789115646, 'Exaggeration-Minimisation_support': 235.0, 'micro avg_precision': 0.32038834951456313, 'micro avg_recall': 0.28085106382978725, 'micro avg_f1-score': 0.29931972789115646, 'micro avg_support': 235.0, 'macro avg_precision': 0.32038834951456313, 'macro avg_recall': 0.28085106382978725, 'macro avg_f1-score': 0.29931972789115646, 'macro avg_support': 235.0, 'weighted avg_precision': 0.32038834951456313, 'weighted avg_recall': 0.28085106382978725, 'weighted avg_f1-score': 0.29931972789115646, 'weighted avg_support': 235.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 1}
{'results': [{'micro_f1': 0.8287968003555161, 'Exaggeration-Minimisation_precision': 0.19902912621359223, 'Exaggeration-Minimisation_recall': 0.13225806451612904, 'Exaggeration-Minimisation_f1-score': 0.15891472868217055, 'Exaggeration-Minimisation_support': 310.0, 'micro avg_precision': 0.19902912621359223, 'micro avg_recall': 0.13225806451612904, 'micro avg_f1-score': 0.15891472868217055, 'micro avg_support': 310.0, 'macro avg_precision': 0.19902912621359223, 'macro avg_recall': 0.13225806451612904, 'macro avg_f1-score': 0.15891472868217055, 'macro avg_support': 310.0, 'weighted avg_precision': 0.19902912621359223, 'weighted avg_recall': 0.13225806451612904, 'weighted avg_f1-score': 0.15891472868217055, 'weighted avg_support': 310.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 0}, {'micro_f1': 0.8707921342073103, 'Exaggeration-Minimisation_precision': 0.32038834951456313, 'Exaggeration-Minimisation_recall': 0.28085106382978725, 'Exaggeration-Minimisation_f1-score': 0.29931972789115646, 'Exaggeration-Minimisation_support': 235.0, 'micro avg_precision': 0.32038834951456313, 'micro avg_recall': 0.28085106382978725, 'micro avg_f1-score': 0.29931972789115646, 'micro avg_support': 235.0, 'macro avg_precision': 0.32038834951456313, 'macro avg_recall': 0.28085106382978725, 'macro avg_f1-score': 0.29931972789115646, 'macro avg_support': 235.0, 'weighted avg_precision': 0.32038834951456313, 'weighted avg_recall': 0.28085106382978725, 'weighted avg_f1-score': 0.29931972789115646, 'weighted avg_support': 235.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 1}]}
Best model updated: current epoch macro f1 = 0.29931972789115646
{'micro_f1': 0.8262415287190312, 'Exaggeration-Minimisation_precision': 0.3640776699029126, 'Exaggeration-Minimisation_recall': 0.24834437086092714, 'Exaggeration-Minimisation_f1-score': 0.2952755905511811, 'Exaggeration-Minimisation_support': 302.0, 'micro avg_precision': 0.3640776699029126, 'micro avg_recall': 0.24834437086092714, 'micro avg_f1-score': 0.2952755905511811, 'micro avg_support': 302.0, 'macro avg_precision': 0.3640776699029126, 'macro avg_recall': 0.24834437086092714, 'macro avg_f1-score': 0.2952755905511811, 'macro avg_support': 302.0, 'weighted avg_precision': 0.3640776699029126, 'weighted avg_recall': 0.24834437086092714, 'weighted avg_f1-score': 0.2952755905511811, 'weighted avg_support': 302.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 2}
{'results': [{'micro_f1': 0.8287968003555161, 'Exaggeration-Minimisation_precision': 0.19902912621359223, 'Exaggeration-Minimisation_recall': 0.13225806451612904, 'Exaggeration-Minimisation_f1-score': 0.15891472868217055, 'Exaggeration-Minimisation_support': 310.0, 'micro avg_precision': 0.19902912621359223, 'micro avg_recall': 0.13225806451612904, 'micro avg_f1-score': 0.15891472868217055, 'micro avg_support': 310.0, 'macro avg_precision': 0.19902912621359223, 'macro avg_recall': 0.13225806451612904, 'macro avg_f1-score': 0.15891472868217055, 'macro avg_support': 310.0, 'weighted avg_precision': 0.19902912621359223, 'weighted avg_recall': 0.13225806451612904, 'weighted avg_f1-score': 0.15891472868217055, 'weighted avg_support': 310.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 0}, {'micro_f1': 0.8707921342073103, 'Exaggeration-Minimisation_precision': 0.32038834951456313, 'Exaggeration-Minimisation_recall': 0.28085106382978725, 'Exaggeration-Minimisation_f1-score': 0.29931972789115646, 'Exaggeration-Minimisation_support': 235.0, 'micro avg_precision': 0.32038834951456313, 'micro avg_recall': 0.28085106382978725, 'micro avg_f1-score': 0.29931972789115646, 'micro avg_support': 235.0, 'macro avg_precision': 0.32038834951456313, 'macro avg_recall': 0.28085106382978725, 'macro avg_f1-score': 0.29931972789115646, 'macro avg_support': 235.0, 'weighted avg_precision': 0.32038834951456313, 'weighted avg_recall': 0.28085106382978725, 'weighted avg_f1-score': 0.29931972789115646, 'weighted avg_support': 235.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 1}, {'micro_f1': 0.8262415287190312, 'Exaggeration-Minimisation_precision': 0.3640776699029126, 'Exaggeration-Minimisation_recall': 0.24834437086092714, 'Exaggeration-Minimisation_f1-score': 0.2952755905511811, 'Exaggeration-Minimisation_support': 302.0, 'micro avg_precision': 0.3640776699029126, 'micro avg_recall': 0.24834437086092714, 'micro avg_f1-score': 0.2952755905511811, 'micro avg_support': 302.0, 'macro avg_precision': 0.3640776699029126, 'macro avg_recall': 0.24834437086092714, 'macro avg_f1-score': 0.2952755905511811, 'macro avg_support': 302.0, 'weighted avg_precision': 0.3640776699029126, 'weighted avg_recall': 0.24834437086092714, 'weighted avg_f1-score': 0.2952755905511811, 'weighted avg_support': 302.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 2}]}
{'micro_f1': 0.8630152205310521, 'Exaggeration-Minimisation_precision': 0.34951456310679613, 'Exaggeration-Minimisation_recall': 0.301255230125523, 'Exaggeration-Minimisation_f1-score': 0.32359550561797756, 'Exaggeration-Minimisation_support': 239.0, 'micro avg_precision': 0.34951456310679613, 'micro avg_recall': 0.301255230125523, 'micro avg_f1-score': 0.32359550561797756, 'micro avg_support': 239.0, 'macro avg_precision': 0.34951456310679613, 'macro avg_recall': 0.301255230125523, 'macro avg_f1-score': 0.32359550561797756, 'macro avg_support': 239.0, 'weighted avg_precision': 0.34951456310679613, 'weighted avg_recall': 0.301255230125523, 'weighted avg_f1-score': 0.32359550561797756, 'weighted avg_support': 239.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 3}
{'results': [{'micro_f1': 0.8287968003555161, 'Exaggeration-Minimisation_precision': 0.19902912621359223, 'Exaggeration-Minimisation_recall': 0.13225806451612904, 'Exaggeration-Minimisation_f1-score': 0.15891472868217055, 'Exaggeration-Minimisation_support': 310.0, 'micro avg_precision': 0.19902912621359223, 'micro avg_recall': 0.13225806451612904, 'micro avg_f1-score': 0.15891472868217055, 'micro avg_support': 310.0, 'macro avg_precision': 0.19902912621359223, 'macro avg_recall': 0.13225806451612904, 'macro avg_f1-score': 0.15891472868217055, 'macro avg_support': 310.0, 'weighted avg_precision': 0.19902912621359223, 'weighted avg_recall': 0.13225806451612904, 'weighted avg_f1-score': 0.15891472868217055, 'weighted avg_support': 310.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 0}, {'micro_f1': 0.8707921342073103, 'Exaggeration-Minimisation_precision': 0.32038834951456313, 'Exaggeration-Minimisation_recall': 0.28085106382978725, 'Exaggeration-Minimisation_f1-score': 0.29931972789115646, 'Exaggeration-Minimisation_support': 235.0, 'micro avg_precision': 0.32038834951456313, 'micro avg_recall': 0.28085106382978725, 'micro avg_f1-score': 0.29931972789115646, 'micro avg_support': 235.0, 'macro avg_precision': 0.32038834951456313, 'macro avg_recall': 0.28085106382978725, 'macro avg_f1-score': 0.29931972789115646, 'macro avg_support': 235.0, 'weighted avg_precision': 0.32038834951456313, 'weighted avg_recall': 0.28085106382978725, 'weighted avg_f1-score': 0.29931972789115646, 'weighted avg_support': 235.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 1}, {'micro_f1': 0.8262415287190312, 'Exaggeration-Minimisation_precision': 0.3640776699029126, 'Exaggeration-Minimisation_recall': 0.24834437086092714, 'Exaggeration-Minimisation_f1-score': 0.2952755905511811, 'Exaggeration-Minimisation_support': 302.0, 'micro avg_precision': 0.3640776699029126, 'micro avg_recall': 0.24834437086092714, 'micro avg_f1-score': 0.2952755905511811, 'micro avg_support': 302.0, 'macro avg_precision': 0.3640776699029126, 'macro avg_recall': 0.24834437086092714, 'macro avg_f1-score': 0.2952755905511811, 'macro avg_support': 302.0, 'weighted avg_precision': 0.3640776699029126, 'weighted avg_recall': 0.24834437086092714, 'weighted avg_f1-score': 0.2952755905511811, 'weighted avg_support': 302.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 2}, {'micro_f1': 0.8630152205310521, 'Exaggeration-Minimisation_precision': 0.34951456310679613, 'Exaggeration-Minimisation_recall': 0.301255230125523, 'Exaggeration-Minimisation_f1-score': 0.32359550561797756, 'Exaggeration-Minimisation_support': 239.0, 'micro avg_precision': 0.34951456310679613, 'micro avg_recall': 0.301255230125523, 'micro avg_f1-score': 0.32359550561797756, 'micro avg_support': 239.0, 'macro avg_precision': 0.34951456310679613, 'macro avg_recall': 0.301255230125523, 'macro avg_f1-score': 0.32359550561797756, 'macro avg_support': 239.0, 'weighted avg_precision': 0.34951456310679613, 'weighted avg_recall': 0.301255230125523, 'weighted avg_f1-score': 0.32359550561797756, 'weighted avg_support': 239.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 3}]}
Best model updated: current epoch macro f1 = 0.32359550561797756
{'micro_f1': 0.8700144428396844, 'Exaggeration-Minimisation_precision': 0.3786407766990291, 'Exaggeration-Minimisation_recall': 0.32231404958677684, 'Exaggeration-Minimisation_f1-score': 0.3482142857142857, 'Exaggeration-Minimisation_support': 242.0, 'micro avg_precision': 0.3786407766990291, 'micro avg_recall': 0.32231404958677684, 'micro avg_f1-score': 0.3482142857142857, 'micro avg_support': 242.0, 'macro avg_precision': 0.3786407766990291, 'macro avg_recall': 0.32231404958677684, 'macro avg_f1-score': 0.3482142857142857, 'macro avg_support': 242.0, 'weighted avg_precision': 0.3786407766990291, 'weighted avg_recall': 0.32231404958677684, 'weighted avg_f1-score': 0.3482142857142857, 'weighted avg_support': 242.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 4}
{'results': [{'micro_f1': 0.8287968003555161, 'Exaggeration-Minimisation_precision': 0.19902912621359223, 'Exaggeration-Minimisation_recall': 0.13225806451612904, 'Exaggeration-Minimisation_f1-score': 0.15891472868217055, 'Exaggeration-Minimisation_support': 310.0, 'micro avg_precision': 0.19902912621359223, 'micro avg_recall': 0.13225806451612904, 'micro avg_f1-score': 0.15891472868217055, 'micro avg_support': 310.0, 'macro avg_precision': 0.19902912621359223, 'macro avg_recall': 0.13225806451612904, 'macro avg_f1-score': 0.15891472868217055, 'macro avg_support': 310.0, 'weighted avg_precision': 0.19902912621359223, 'weighted avg_recall': 0.13225806451612904, 'weighted avg_f1-score': 0.15891472868217055, 'weighted avg_support': 310.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 0}, {'micro_f1': 0.8707921342073103, 'Exaggeration-Minimisation_precision': 0.32038834951456313, 'Exaggeration-Minimisation_recall': 0.28085106382978725, 'Exaggeration-Minimisation_f1-score': 0.29931972789115646, 'Exaggeration-Minimisation_support': 235.0, 'micro avg_precision': 0.32038834951456313, 'micro avg_recall': 0.28085106382978725, 'micro avg_f1-score': 0.29931972789115646, 'micro avg_support': 235.0, 'macro avg_precision': 0.32038834951456313, 'macro avg_recall': 0.28085106382978725, 'macro avg_f1-score': 0.29931972789115646, 'macro avg_support': 235.0, 'weighted avg_precision': 0.32038834951456313, 'weighted avg_recall': 0.28085106382978725, 'weighted avg_f1-score': 0.29931972789115646, 'weighted avg_support': 235.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 1}, {'micro_f1': 0.8262415287190312, 'Exaggeration-Minimisation_precision': 0.3640776699029126, 'Exaggeration-Minimisation_recall': 0.24834437086092714, 'Exaggeration-Minimisation_f1-score': 0.2952755905511811, 'Exaggeration-Minimisation_support': 302.0, 'micro avg_precision': 0.3640776699029126, 'micro avg_recall': 0.24834437086092714, 'micro avg_f1-score': 0.2952755905511811, 'micro avg_support': 302.0, 'macro avg_precision': 0.3640776699029126, 'macro avg_recall': 0.24834437086092714, 'macro avg_f1-score': 0.2952755905511811, 'macro avg_support': 302.0, 'weighted avg_precision': 0.3640776699029126, 'weighted avg_recall': 0.24834437086092714, 'weighted avg_f1-score': 0.2952755905511811, 'weighted avg_support': 302.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 2}, {'micro_f1': 0.8630152205310521, 'Exaggeration-Minimisation_precision': 0.34951456310679613, 'Exaggeration-Minimisation_recall': 0.301255230125523, 'Exaggeration-Minimisation_f1-score': 0.32359550561797756, 'Exaggeration-Minimisation_support': 239.0, 'micro avg_precision': 0.34951456310679613, 'micro avg_recall': 0.301255230125523, 'micro avg_f1-score': 0.32359550561797756, 'micro avg_support': 239.0, 'macro avg_precision': 0.34951456310679613, 'macro avg_recall': 0.301255230125523, 'macro avg_f1-score': 0.32359550561797756, 'macro avg_support': 239.0, 'weighted avg_precision': 0.34951456310679613, 'weighted avg_recall': 0.301255230125523, 'weighted avg_f1-score': 0.32359550561797756, 'weighted avg_support': 239.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 3}, {'micro_f1': 0.8700144428396844, 'Exaggeration-Minimisation_precision': 0.3786407766990291, 'Exaggeration-Minimisation_recall': 0.32231404958677684, 'Exaggeration-Minimisation_f1-score': 0.3482142857142857, 'Exaggeration-Minimisation_support': 242.0, 'micro avg_precision': 0.3786407766990291, 'micro avg_recall': 0.32231404958677684, 'micro avg_f1-score': 0.3482142857142857, 'micro avg_support': 242.0, 'macro avg_precision': 0.3786407766990291, 'macro avg_recall': 0.32231404958677684, 'macro avg_f1-score': 0.3482142857142857, 'macro avg_support': 242.0, 'weighted avg_precision': 0.3786407766990291, 'weighted avg_recall': 0.32231404958677684, 'weighted avg_f1-score': 0.3482142857142857, 'weighted avg_support': 242.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 4}]}
Best model updated: current epoch macro f1 = 0.3482142857142857
{'micro_f1': 0.8575713809576714, 'Exaggeration-Minimisation_precision': 0.3786407766990291, 'Exaggeration-Minimisation_recall': 0.312, 'Exaggeration-Minimisation_f1-score': 0.34210526315789475, 'Exaggeration-Minimisation_support': 250.0, 'micro avg_precision': 0.3786407766990291, 'micro avg_recall': 0.312, 'micro avg_f1-score': 0.34210526315789475, 'micro avg_support': 250.0, 'macro avg_precision': 0.3786407766990291, 'macro avg_recall': 0.312, 'macro avg_f1-score': 0.34210526315789475, 'macro avg_support': 250.0, 'weighted avg_precision': 0.3786407766990291, 'weighted avg_recall': 0.312, 'weighted avg_f1-score': 0.34210526315789475, 'weighted avg_support': 250.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 5}
{'results': [{'micro_f1': 0.8287968003555161, 'Exaggeration-Minimisation_precision': 0.19902912621359223, 'Exaggeration-Minimisation_recall': 0.13225806451612904, 'Exaggeration-Minimisation_f1-score': 0.15891472868217055, 'Exaggeration-Minimisation_support': 310.0, 'micro avg_precision': 0.19902912621359223, 'micro avg_recall': 0.13225806451612904, 'micro avg_f1-score': 0.15891472868217055, 'micro avg_support': 310.0, 'macro avg_precision': 0.19902912621359223, 'macro avg_recall': 0.13225806451612904, 'macro avg_f1-score': 0.15891472868217055, 'macro avg_support': 310.0, 'weighted avg_precision': 0.19902912621359223, 'weighted avg_recall': 0.13225806451612904, 'weighted avg_f1-score': 0.15891472868217055, 'weighted avg_support': 310.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 0}, {'micro_f1': 0.8707921342073103, 'Exaggeration-Minimisation_precision': 0.32038834951456313, 'Exaggeration-Minimisation_recall': 0.28085106382978725, 'Exaggeration-Minimisation_f1-score': 0.29931972789115646, 'Exaggeration-Minimisation_support': 235.0, 'micro avg_precision': 0.32038834951456313, 'micro avg_recall': 0.28085106382978725, 'micro avg_f1-score': 0.29931972789115646, 'micro avg_support': 235.0, 'macro avg_precision': 0.32038834951456313, 'macro avg_recall': 0.28085106382978725, 'macro avg_f1-score': 0.29931972789115646, 'macro avg_support': 235.0, 'weighted avg_precision': 0.32038834951456313, 'weighted avg_recall': 0.28085106382978725, 'weighted avg_f1-score': 0.29931972789115646, 'weighted avg_support': 235.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 1}, {'micro_f1': 0.8262415287190312, 'Exaggeration-Minimisation_precision': 0.3640776699029126, 'Exaggeration-Minimisation_recall': 0.24834437086092714, 'Exaggeration-Minimisation_f1-score': 0.2952755905511811, 'Exaggeration-Minimisation_support': 302.0, 'micro avg_precision': 0.3640776699029126, 'micro avg_recall': 0.24834437086092714, 'micro avg_f1-score': 0.2952755905511811, 'micro avg_support': 302.0, 'macro avg_precision': 0.3640776699029126, 'macro avg_recall': 0.24834437086092714, 'macro avg_f1-score': 0.2952755905511811, 'macro avg_support': 302.0, 'weighted avg_precision': 0.3640776699029126, 'weighted avg_recall': 0.24834437086092714, 'weighted avg_f1-score': 0.2952755905511811, 'weighted avg_support': 302.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 2}, {'micro_f1': 0.8630152205310521, 'Exaggeration-Minimisation_precision': 0.34951456310679613, 'Exaggeration-Minimisation_recall': 0.301255230125523, 'Exaggeration-Minimisation_f1-score': 0.32359550561797756, 'Exaggeration-Minimisation_support': 239.0, 'micro avg_precision': 0.34951456310679613, 'micro avg_recall': 0.301255230125523, 'micro avg_f1-score': 0.32359550561797756, 'micro avg_support': 239.0, 'macro avg_precision': 0.34951456310679613, 'macro avg_recall': 0.301255230125523, 'macro avg_f1-score': 0.32359550561797756, 'macro avg_support': 239.0, 'weighted avg_precision': 0.34951456310679613, 'weighted avg_recall': 0.301255230125523, 'weighted avg_f1-score': 0.32359550561797756, 'weighted avg_support': 239.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 3}, {'micro_f1': 0.8700144428396844, 'Exaggeration-Minimisation_precision': 0.3786407766990291, 'Exaggeration-Minimisation_recall': 0.32231404958677684, 'Exaggeration-Minimisation_f1-score': 0.3482142857142857, 'Exaggeration-Minimisation_support': 242.0, 'micro avg_precision': 0.3786407766990291, 'micro avg_recall': 0.32231404958677684, 'micro avg_f1-score': 0.3482142857142857, 'micro avg_support': 242.0, 'macro avg_precision': 0.3786407766990291, 'macro avg_recall': 0.32231404958677684, 'macro avg_f1-score': 0.3482142857142857, 'macro avg_support': 242.0, 'weighted avg_precision': 0.3786407766990291, 'weighted avg_recall': 0.32231404958677684, 'weighted avg_f1-score': 0.3482142857142857, 'weighted avg_support': 242.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 4}, {'micro_f1': 0.8575713809576714, 'Exaggeration-Minimisation_precision': 0.3786407766990291, 'Exaggeration-Minimisation_recall': 0.312, 'Exaggeration-Minimisation_f1-score': 0.34210526315789475, 'Exaggeration-Minimisation_support': 250.0, 'micro avg_precision': 0.3786407766990291, 'micro avg_recall': 0.312, 'micro avg_f1-score': 0.34210526315789475, 'micro avg_support': 250.0, 'macro avg_precision': 0.3786407766990291, 'macro avg_recall': 0.312, 'macro avg_f1-score': 0.34210526315789475, 'macro avg_support': 250.0, 'weighted avg_precision': 0.3786407766990291, 'weighted avg_recall': 0.312, 'weighted avg_f1-score': 0.34210526315789475, 'weighted avg_support': 250.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 5}]}
{'micro_f1': 0.8639040106654816, 'Exaggeration-Minimisation_precision': 0.42718446601941745, 'Exaggeration-Minimisation_recall': 0.32592592592592595, 'Exaggeration-Minimisation_f1-score': 0.3697478991596639, 'Exaggeration-Minimisation_support': 270.0, 'micro avg_precision': 0.42718446601941745, 'micro avg_recall': 0.32592592592592595, 'micro avg_f1-score': 0.3697478991596639, 'micro avg_support': 270.0, 'macro avg_precision': 0.42718446601941745, 'macro avg_recall': 0.32592592592592595, 'macro avg_f1-score': 0.3697478991596639, 'macro avg_support': 270.0, 'weighted avg_precision': 0.42718446601941745, 'weighted avg_recall': 0.32592592592592595, 'weighted avg_f1-score': 0.3697478991596639, 'weighted avg_support': 270.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 6}
{'results': [{'micro_f1': 0.8287968003555161, 'Exaggeration-Minimisation_precision': 0.19902912621359223, 'Exaggeration-Minimisation_recall': 0.13225806451612904, 'Exaggeration-Minimisation_f1-score': 0.15891472868217055, 'Exaggeration-Minimisation_support': 310.0, 'micro avg_precision': 0.19902912621359223, 'micro avg_recall': 0.13225806451612904, 'micro avg_f1-score': 0.15891472868217055, 'micro avg_support': 310.0, 'macro avg_precision': 0.19902912621359223, 'macro avg_recall': 0.13225806451612904, 'macro avg_f1-score': 0.15891472868217055, 'macro avg_support': 310.0, 'weighted avg_precision': 0.19902912621359223, 'weighted avg_recall': 0.13225806451612904, 'weighted avg_f1-score': 0.15891472868217055, 'weighted avg_support': 310.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 0}, {'micro_f1': 0.8707921342073103, 'Exaggeration-Minimisation_precision': 0.32038834951456313, 'Exaggeration-Minimisation_recall': 0.28085106382978725, 'Exaggeration-Minimisation_f1-score': 0.29931972789115646, 'Exaggeration-Minimisation_support': 235.0, 'micro avg_precision': 0.32038834951456313, 'micro avg_recall': 0.28085106382978725, 'micro avg_f1-score': 0.29931972789115646, 'micro avg_support': 235.0, 'macro avg_precision': 0.32038834951456313, 'macro avg_recall': 0.28085106382978725, 'macro avg_f1-score': 0.29931972789115646, 'macro avg_support': 235.0, 'weighted avg_precision': 0.32038834951456313, 'weighted avg_recall': 0.28085106382978725, 'weighted avg_f1-score': 0.29931972789115646, 'weighted avg_support': 235.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 1}, {'micro_f1': 0.8262415287190312, 'Exaggeration-Minimisation_precision': 0.3640776699029126, 'Exaggeration-Minimisation_recall': 0.24834437086092714, 'Exaggeration-Minimisation_f1-score': 0.2952755905511811, 'Exaggeration-Minimisation_support': 302.0, 'micro avg_precision': 0.3640776699029126, 'micro avg_recall': 0.24834437086092714, 'micro avg_f1-score': 0.2952755905511811, 'micro avg_support': 302.0, 'macro avg_precision': 0.3640776699029126, 'macro avg_recall': 0.24834437086092714, 'macro avg_f1-score': 0.2952755905511811, 'macro avg_support': 302.0, 'weighted avg_precision': 0.3640776699029126, 'weighted avg_recall': 0.24834437086092714, 'weighted avg_f1-score': 0.2952755905511811, 'weighted avg_support': 302.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 2}, {'micro_f1': 0.8630152205310521, 'Exaggeration-Minimisation_precision': 0.34951456310679613, 'Exaggeration-Minimisation_recall': 0.301255230125523, 'Exaggeration-Minimisation_f1-score': 0.32359550561797756, 'Exaggeration-Minimisation_support': 239.0, 'micro avg_precision': 0.34951456310679613, 'micro avg_recall': 0.301255230125523, 'micro avg_f1-score': 0.32359550561797756, 'micro avg_support': 239.0, 'macro avg_precision': 0.34951456310679613, 'macro avg_recall': 0.301255230125523, 'macro avg_f1-score': 0.32359550561797756, 'macro avg_support': 239.0, 'weighted avg_precision': 0.34951456310679613, 'weighted avg_recall': 0.301255230125523, 'weighted avg_f1-score': 0.32359550561797756, 'weighted avg_support': 239.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 3}, {'micro_f1': 0.8700144428396844, 'Exaggeration-Minimisation_precision': 0.3786407766990291, 'Exaggeration-Minimisation_recall': 0.32231404958677684, 'Exaggeration-Minimisation_f1-score': 0.3482142857142857, 'Exaggeration-Minimisation_support': 242.0, 'micro avg_precision': 0.3786407766990291, 'micro avg_recall': 0.32231404958677684, 'micro avg_f1-score': 0.3482142857142857, 'micro avg_support': 242.0, 'macro avg_precision': 0.3786407766990291, 'macro avg_recall': 0.32231404958677684, 'macro avg_f1-score': 0.3482142857142857, 'macro avg_support': 242.0, 'weighted avg_precision': 0.3786407766990291, 'weighted avg_recall': 0.32231404958677684, 'weighted avg_f1-score': 0.3482142857142857, 'weighted avg_support': 242.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 4}, {'micro_f1': 0.8575713809576714, 'Exaggeration-Minimisation_precision': 0.3786407766990291, 'Exaggeration-Minimisation_recall': 0.312, 'Exaggeration-Minimisation_f1-score': 0.34210526315789475, 'Exaggeration-Minimisation_support': 250.0, 'micro avg_precision': 0.3786407766990291, 'micro avg_recall': 0.312, 'micro avg_f1-score': 0.34210526315789475, 'micro avg_support': 250.0, 'macro avg_precision': 0.3786407766990291, 'macro avg_recall': 0.312, 'macro avg_f1-score': 0.34210526315789475, 'macro avg_support': 250.0, 'weighted avg_precision': 0.3786407766990291, 'weighted avg_recall': 0.312, 'weighted avg_f1-score': 0.34210526315789475, 'weighted avg_support': 250.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 5}, {'micro_f1': 0.8639040106654816, 'Exaggeration-Minimisation_precision': 0.42718446601941745, 'Exaggeration-Minimisation_recall': 0.32592592592592595, 'Exaggeration-Minimisation_f1-score': 0.3697478991596639, 'Exaggeration-Minimisation_support': 270.0, 'micro avg_precision': 0.42718446601941745, 'micro avg_recall': 0.32592592592592595, 'micro avg_f1-score': 0.3697478991596639, 'micro avg_support': 270.0, 'macro avg_precision': 0.42718446601941745, 'macro avg_recall': 0.32592592592592595, 'macro avg_f1-score': 0.3697478991596639, 'macro avg_support': 270.0, 'weighted avg_precision': 0.42718446601941745, 'weighted avg_recall': 0.32592592592592595, 'weighted avg_f1-score': 0.3697478991596639, 'weighted avg_support': 270.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 6}]}
Best model updated: current epoch macro f1 = 0.3697478991596639
{'micro_f1': 0.8730141095433842, 'Exaggeration-Minimisation_precision': 0.36893203883495146, 'Exaggeration-Minimisation_recall': 0.34545454545454546, 'Exaggeration-Minimisation_f1-score': 0.3568075117370892, 'Exaggeration-Minimisation_support': 220.0, 'micro avg_precision': 0.36893203883495146, 'micro avg_recall': 0.34545454545454546, 'micro avg_f1-score': 0.3568075117370892, 'micro avg_support': 220.0, 'macro avg_precision': 0.36893203883495146, 'macro avg_recall': 0.34545454545454546, 'macro avg_f1-score': 0.3568075117370892, 'macro avg_support': 220.0, 'weighted avg_precision': 0.36893203883495146, 'weighted avg_recall': 0.34545454545454546, 'weighted avg_f1-score': 0.3568075117370892, 'weighted avg_support': 220.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 7}
{'results': [{'micro_f1': 0.8287968003555161, 'Exaggeration-Minimisation_precision': 0.19902912621359223, 'Exaggeration-Minimisation_recall': 0.13225806451612904, 'Exaggeration-Minimisation_f1-score': 0.15891472868217055, 'Exaggeration-Minimisation_support': 310.0, 'micro avg_precision': 0.19902912621359223, 'micro avg_recall': 0.13225806451612904, 'micro avg_f1-score': 0.15891472868217055, 'micro avg_support': 310.0, 'macro avg_precision': 0.19902912621359223, 'macro avg_recall': 0.13225806451612904, 'macro avg_f1-score': 0.15891472868217055, 'macro avg_support': 310.0, 'weighted avg_precision': 0.19902912621359223, 'weighted avg_recall': 0.13225806451612904, 'weighted avg_f1-score': 0.15891472868217055, 'weighted avg_support': 310.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 0}, {'micro_f1': 0.8707921342073103, 'Exaggeration-Minimisation_precision': 0.32038834951456313, 'Exaggeration-Minimisation_recall': 0.28085106382978725, 'Exaggeration-Minimisation_f1-score': 0.29931972789115646, 'Exaggeration-Minimisation_support': 235.0, 'micro avg_precision': 0.32038834951456313, 'micro avg_recall': 0.28085106382978725, 'micro avg_f1-score': 0.29931972789115646, 'micro avg_support': 235.0, 'macro avg_precision': 0.32038834951456313, 'macro avg_recall': 0.28085106382978725, 'macro avg_f1-score': 0.29931972789115646, 'macro avg_support': 235.0, 'weighted avg_precision': 0.32038834951456313, 'weighted avg_recall': 0.28085106382978725, 'weighted avg_f1-score': 0.29931972789115646, 'weighted avg_support': 235.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 1}, {'micro_f1': 0.8262415287190312, 'Exaggeration-Minimisation_precision': 0.3640776699029126, 'Exaggeration-Minimisation_recall': 0.24834437086092714, 'Exaggeration-Minimisation_f1-score': 0.2952755905511811, 'Exaggeration-Minimisation_support': 302.0, 'micro avg_precision': 0.3640776699029126, 'micro avg_recall': 0.24834437086092714, 'micro avg_f1-score': 0.2952755905511811, 'micro avg_support': 302.0, 'macro avg_precision': 0.3640776699029126, 'macro avg_recall': 0.24834437086092714, 'macro avg_f1-score': 0.2952755905511811, 'macro avg_support': 302.0, 'weighted avg_precision': 0.3640776699029126, 'weighted avg_recall': 0.24834437086092714, 'weighted avg_f1-score': 0.2952755905511811, 'weighted avg_support': 302.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 2}, {'micro_f1': 0.8630152205310521, 'Exaggeration-Minimisation_precision': 0.34951456310679613, 'Exaggeration-Minimisation_recall': 0.301255230125523, 'Exaggeration-Minimisation_f1-score': 0.32359550561797756, 'Exaggeration-Minimisation_support': 239.0, 'micro avg_precision': 0.34951456310679613, 'micro avg_recall': 0.301255230125523, 'micro avg_f1-score': 0.32359550561797756, 'micro avg_support': 239.0, 'macro avg_precision': 0.34951456310679613, 'macro avg_recall': 0.301255230125523, 'macro avg_f1-score': 0.32359550561797756, 'macro avg_support': 239.0, 'weighted avg_precision': 0.34951456310679613, 'weighted avg_recall': 0.301255230125523, 'weighted avg_f1-score': 0.32359550561797756, 'weighted avg_support': 239.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 3}, {'micro_f1': 0.8700144428396844, 'Exaggeration-Minimisation_precision': 0.3786407766990291, 'Exaggeration-Minimisation_recall': 0.32231404958677684, 'Exaggeration-Minimisation_f1-score': 0.3482142857142857, 'Exaggeration-Minimisation_support': 242.0, 'micro avg_precision': 0.3786407766990291, 'micro avg_recall': 0.32231404958677684, 'micro avg_f1-score': 0.3482142857142857, 'micro avg_support': 242.0, 'macro avg_precision': 0.3786407766990291, 'macro avg_recall': 0.32231404958677684, 'macro avg_f1-score': 0.3482142857142857, 'macro avg_support': 242.0, 'weighted avg_precision': 0.3786407766990291, 'weighted avg_recall': 0.32231404958677684, 'weighted avg_f1-score': 0.3482142857142857, 'weighted avg_support': 242.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 4}, {'micro_f1': 0.8575713809576714, 'Exaggeration-Minimisation_precision': 0.3786407766990291, 'Exaggeration-Minimisation_recall': 0.312, 'Exaggeration-Minimisation_f1-score': 0.34210526315789475, 'Exaggeration-Minimisation_support': 250.0, 'micro avg_precision': 0.3786407766990291, 'micro avg_recall': 0.312, 'micro avg_f1-score': 0.34210526315789475, 'micro avg_support': 250.0, 'macro avg_precision': 0.3786407766990291, 'macro avg_recall': 0.312, 'macro avg_f1-score': 0.34210526315789475, 'macro avg_support': 250.0, 'weighted avg_precision': 0.3786407766990291, 'weighted avg_recall': 0.312, 'weighted avg_f1-score': 0.34210526315789475, 'weighted avg_support': 250.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 5}, {'micro_f1': 0.8639040106654816, 'Exaggeration-Minimisation_precision': 0.42718446601941745, 'Exaggeration-Minimisation_recall': 0.32592592592592595, 'Exaggeration-Minimisation_f1-score': 0.3697478991596639, 'Exaggeration-Minimisation_support': 270.0, 'micro avg_precision': 0.42718446601941745, 'micro avg_recall': 0.32592592592592595, 'micro avg_f1-score': 0.3697478991596639, 'micro avg_support': 270.0, 'macro avg_precision': 0.42718446601941745, 'macro avg_recall': 0.32592592592592595, 'macro avg_f1-score': 0.3697478991596639, 'macro avg_support': 270.0, 'weighted avg_precision': 0.42718446601941745, 'weighted avg_recall': 0.32592592592592595, 'weighted avg_f1-score': 0.3697478991596639, 'weighted avg_support': 270.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 6}, {'micro_f1': 0.8730141095433842, 'Exaggeration-Minimisation_precision': 0.36893203883495146, 'Exaggeration-Minimisation_recall': 0.34545454545454546, 'Exaggeration-Minimisation_f1-score': 0.3568075117370892, 'Exaggeration-Minimisation_support': 220.0, 'micro avg_precision': 0.36893203883495146, 'micro avg_recall': 0.34545454545454546, 'micro avg_f1-score': 0.3568075117370892, 'micro avg_support': 220.0, 'macro avg_precision': 0.36893203883495146, 'macro avg_recall': 0.34545454545454546, 'macro avg_f1-score': 0.3568075117370892, 'macro avg_support': 220.0, 'weighted avg_precision': 0.36893203883495146, 'weighted avg_recall': 0.34545454545454546, 'weighted avg_f1-score': 0.3568075117370892, 'weighted avg_support': 220.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 7}]}
{'micro_f1': 0.8720142206421508, 'Exaggeration-Minimisation_precision': 0.3786407766990291, 'Exaggeration-Minimisation_recall': 0.375, 'Exaggeration-Minimisation_f1-score': 0.3768115942028985, 'Exaggeration-Minimisation_support': 208.0, 'micro avg_precision': 0.3786407766990291, 'micro avg_recall': 0.375, 'micro avg_f1-score': 0.3768115942028985, 'micro avg_support': 208.0, 'macro avg_precision': 0.3786407766990291, 'macro avg_recall': 0.375, 'macro avg_f1-score': 0.3768115942028985, 'macro avg_support': 208.0, 'weighted avg_precision': 0.3786407766990291, 'weighted avg_recall': 0.375, 'weighted avg_f1-score': 0.3768115942028985, 'weighted avg_support': 208.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 8}
{'results': [{'micro_f1': 0.8287968003555161, 'Exaggeration-Minimisation_precision': 0.19902912621359223, 'Exaggeration-Minimisation_recall': 0.13225806451612904, 'Exaggeration-Minimisation_f1-score': 0.15891472868217055, 'Exaggeration-Minimisation_support': 310.0, 'micro avg_precision': 0.19902912621359223, 'micro avg_recall': 0.13225806451612904, 'micro avg_f1-score': 0.15891472868217055, 'micro avg_support': 310.0, 'macro avg_precision': 0.19902912621359223, 'macro avg_recall': 0.13225806451612904, 'macro avg_f1-score': 0.15891472868217055, 'macro avg_support': 310.0, 'weighted avg_precision': 0.19902912621359223, 'weighted avg_recall': 0.13225806451612904, 'weighted avg_f1-score': 0.15891472868217055, 'weighted avg_support': 310.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 0}, {'micro_f1': 0.8707921342073103, 'Exaggeration-Minimisation_precision': 0.32038834951456313, 'Exaggeration-Minimisation_recall': 0.28085106382978725, 'Exaggeration-Minimisation_f1-score': 0.29931972789115646, 'Exaggeration-Minimisation_support': 235.0, 'micro avg_precision': 0.32038834951456313, 'micro avg_recall': 0.28085106382978725, 'micro avg_f1-score': 0.29931972789115646, 'micro avg_support': 235.0, 'macro avg_precision': 0.32038834951456313, 'macro avg_recall': 0.28085106382978725, 'macro avg_f1-score': 0.29931972789115646, 'macro avg_support': 235.0, 'weighted avg_precision': 0.32038834951456313, 'weighted avg_recall': 0.28085106382978725, 'weighted avg_f1-score': 0.29931972789115646, 'weighted avg_support': 235.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 1}, {'micro_f1': 0.8262415287190312, 'Exaggeration-Minimisation_precision': 0.3640776699029126, 'Exaggeration-Minimisation_recall': 0.24834437086092714, 'Exaggeration-Minimisation_f1-score': 0.2952755905511811, 'Exaggeration-Minimisation_support': 302.0, 'micro avg_precision': 0.3640776699029126, 'micro avg_recall': 0.24834437086092714, 'micro avg_f1-score': 0.2952755905511811, 'micro avg_support': 302.0, 'macro avg_precision': 0.3640776699029126, 'macro avg_recall': 0.24834437086092714, 'macro avg_f1-score': 0.2952755905511811, 'macro avg_support': 302.0, 'weighted avg_precision': 0.3640776699029126, 'weighted avg_recall': 0.24834437086092714, 'weighted avg_f1-score': 0.2952755905511811, 'weighted avg_support': 302.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 2}, {'micro_f1': 0.8630152205310521, 'Exaggeration-Minimisation_precision': 0.34951456310679613, 'Exaggeration-Minimisation_recall': 0.301255230125523, 'Exaggeration-Minimisation_f1-score': 0.32359550561797756, 'Exaggeration-Minimisation_support': 239.0, 'micro avg_precision': 0.34951456310679613, 'micro avg_recall': 0.301255230125523, 'micro avg_f1-score': 0.32359550561797756, 'micro avg_support': 239.0, 'macro avg_precision': 0.34951456310679613, 'macro avg_recall': 0.301255230125523, 'macro avg_f1-score': 0.32359550561797756, 'macro avg_support': 239.0, 'weighted avg_precision': 0.34951456310679613, 'weighted avg_recall': 0.301255230125523, 'weighted avg_f1-score': 0.32359550561797756, 'weighted avg_support': 239.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 3}, {'micro_f1': 0.8700144428396844, 'Exaggeration-Minimisation_precision': 0.3786407766990291, 'Exaggeration-Minimisation_recall': 0.32231404958677684, 'Exaggeration-Minimisation_f1-score': 0.3482142857142857, 'Exaggeration-Minimisation_support': 242.0, 'micro avg_precision': 0.3786407766990291, 'micro avg_recall': 0.32231404958677684, 'micro avg_f1-score': 0.3482142857142857, 'micro avg_support': 242.0, 'macro avg_precision': 0.3786407766990291, 'macro avg_recall': 0.32231404958677684, 'macro avg_f1-score': 0.3482142857142857, 'macro avg_support': 242.0, 'weighted avg_precision': 0.3786407766990291, 'weighted avg_recall': 0.32231404958677684, 'weighted avg_f1-score': 0.3482142857142857, 'weighted avg_support': 242.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 4}, {'micro_f1': 0.8575713809576714, 'Exaggeration-Minimisation_precision': 0.3786407766990291, 'Exaggeration-Minimisation_recall': 0.312, 'Exaggeration-Minimisation_f1-score': 0.34210526315789475, 'Exaggeration-Minimisation_support': 250.0, 'micro avg_precision': 0.3786407766990291, 'micro avg_recall': 0.312, 'micro avg_f1-score': 0.34210526315789475, 'micro avg_support': 250.0, 'macro avg_precision': 0.3786407766990291, 'macro avg_recall': 0.312, 'macro avg_f1-score': 0.34210526315789475, 'macro avg_support': 250.0, 'weighted avg_precision': 0.3786407766990291, 'weighted avg_recall': 0.312, 'weighted avg_f1-score': 0.34210526315789475, 'weighted avg_support': 250.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 5}, {'micro_f1': 0.8639040106654816, 'Exaggeration-Minimisation_precision': 0.42718446601941745, 'Exaggeration-Minimisation_recall': 0.32592592592592595, 'Exaggeration-Minimisation_f1-score': 0.3697478991596639, 'Exaggeration-Minimisation_support': 270.0, 'micro avg_precision': 0.42718446601941745, 'micro avg_recall': 0.32592592592592595, 'micro avg_f1-score': 0.3697478991596639, 'micro avg_support': 270.0, 'macro avg_precision': 0.42718446601941745, 'macro avg_recall': 0.32592592592592595, 'macro avg_f1-score': 0.3697478991596639, 'macro avg_support': 270.0, 'weighted avg_precision': 0.42718446601941745, 'weighted avg_recall': 0.32592592592592595, 'weighted avg_f1-score': 0.3697478991596639, 'weighted avg_support': 270.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 6}, {'micro_f1': 0.8730141095433842, 'Exaggeration-Minimisation_precision': 0.36893203883495146, 'Exaggeration-Minimisation_recall': 0.34545454545454546, 'Exaggeration-Minimisation_f1-score': 0.3568075117370892, 'Exaggeration-Minimisation_support': 220.0, 'micro avg_precision': 0.36893203883495146, 'micro avg_recall': 0.34545454545454546, 'micro avg_f1-score': 0.3568075117370892, 'micro avg_support': 220.0, 'macro avg_precision': 0.36893203883495146, 'macro avg_recall': 0.34545454545454546, 'macro avg_f1-score': 0.3568075117370892, 'macro avg_support': 220.0, 'weighted avg_precision': 0.36893203883495146, 'weighted avg_recall': 0.34545454545454546, 'weighted avg_f1-score': 0.3568075117370892, 'weighted avg_support': 220.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 7}, {'micro_f1': 0.8720142206421508, 'Exaggeration-Minimisation_precision': 0.3786407766990291, 'Exaggeration-Minimisation_recall': 0.375, 'Exaggeration-Minimisation_f1-score': 0.3768115942028985, 'Exaggeration-Minimisation_support': 208.0, 'micro avg_precision': 0.3786407766990291, 'micro avg_recall': 0.375, 'micro avg_f1-score': 0.3768115942028985, 'micro avg_support': 208.0, 'macro avg_precision': 0.3786407766990291, 'macro avg_recall': 0.375, 'macro avg_f1-score': 0.3768115942028985, 'macro avg_support': 208.0, 'weighted avg_precision': 0.3786407766990291, 'weighted avg_recall': 0.375, 'weighted avg_f1-score': 0.3768115942028985, 'weighted avg_support': 208.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 8}]}
Best model updated: current epoch macro f1 = 0.3768115942028985
{'micro_f1': 0.8707921342073103, 'Exaggeration-Minimisation_precision': 0.45145631067961167, 'Exaggeration-Minimisation_recall': 0.37349397590361444, 'Exaggeration-Minimisation_f1-score': 0.4087912087912088, 'Exaggeration-Minimisation_support': 249.0, 'micro avg_precision': 0.45145631067961167, 'micro avg_recall': 0.37349397590361444, 'micro avg_f1-score': 0.4087912087912088, 'micro avg_support': 249.0, 'macro avg_precision': 0.45145631067961167, 'macro avg_recall': 0.37349397590361444, 'macro avg_f1-score': 0.4087912087912088, 'macro avg_support': 249.0, 'weighted avg_precision': 0.45145631067961167, 'weighted avg_recall': 0.37349397590361444, 'weighted avg_f1-score': 0.4087912087912088, 'weighted avg_support': 249.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 9}
{'results': [{'micro_f1': 0.8287968003555161, 'Exaggeration-Minimisation_precision': 0.19902912621359223, 'Exaggeration-Minimisation_recall': 0.13225806451612904, 'Exaggeration-Minimisation_f1-score': 0.15891472868217055, 'Exaggeration-Minimisation_support': 310.0, 'micro avg_precision': 0.19902912621359223, 'micro avg_recall': 0.13225806451612904, 'micro avg_f1-score': 0.15891472868217055, 'micro avg_support': 310.0, 'macro avg_precision': 0.19902912621359223, 'macro avg_recall': 0.13225806451612904, 'macro avg_f1-score': 0.15891472868217055, 'macro avg_support': 310.0, 'weighted avg_precision': 0.19902912621359223, 'weighted avg_recall': 0.13225806451612904, 'weighted avg_f1-score': 0.15891472868217055, 'weighted avg_support': 310.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 0}, {'micro_f1': 0.8707921342073103, 'Exaggeration-Minimisation_precision': 0.32038834951456313, 'Exaggeration-Minimisation_recall': 0.28085106382978725, 'Exaggeration-Minimisation_f1-score': 0.29931972789115646, 'Exaggeration-Minimisation_support': 235.0, 'micro avg_precision': 0.32038834951456313, 'micro avg_recall': 0.28085106382978725, 'micro avg_f1-score': 0.29931972789115646, 'micro avg_support': 235.0, 'macro avg_precision': 0.32038834951456313, 'macro avg_recall': 0.28085106382978725, 'macro avg_f1-score': 0.29931972789115646, 'macro avg_support': 235.0, 'weighted avg_precision': 0.32038834951456313, 'weighted avg_recall': 0.28085106382978725, 'weighted avg_f1-score': 0.29931972789115646, 'weighted avg_support': 235.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 1}, {'micro_f1': 0.8262415287190312, 'Exaggeration-Minimisation_precision': 0.3640776699029126, 'Exaggeration-Minimisation_recall': 0.24834437086092714, 'Exaggeration-Minimisation_f1-score': 0.2952755905511811, 'Exaggeration-Minimisation_support': 302.0, 'micro avg_precision': 0.3640776699029126, 'micro avg_recall': 0.24834437086092714, 'micro avg_f1-score': 0.2952755905511811, 'micro avg_support': 302.0, 'macro avg_precision': 0.3640776699029126, 'macro avg_recall': 0.24834437086092714, 'macro avg_f1-score': 0.2952755905511811, 'macro avg_support': 302.0, 'weighted avg_precision': 0.3640776699029126, 'weighted avg_recall': 0.24834437086092714, 'weighted avg_f1-score': 0.2952755905511811, 'weighted avg_support': 302.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 2}, {'micro_f1': 0.8630152205310521, 'Exaggeration-Minimisation_precision': 0.34951456310679613, 'Exaggeration-Minimisation_recall': 0.301255230125523, 'Exaggeration-Minimisation_f1-score': 0.32359550561797756, 'Exaggeration-Minimisation_support': 239.0, 'micro avg_precision': 0.34951456310679613, 'micro avg_recall': 0.301255230125523, 'micro avg_f1-score': 0.32359550561797756, 'micro avg_support': 239.0, 'macro avg_precision': 0.34951456310679613, 'macro avg_recall': 0.301255230125523, 'macro avg_f1-score': 0.32359550561797756, 'macro avg_support': 239.0, 'weighted avg_precision': 0.34951456310679613, 'weighted avg_recall': 0.301255230125523, 'weighted avg_f1-score': 0.32359550561797756, 'weighted avg_support': 239.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 3}, {'micro_f1': 0.8700144428396844, 'Exaggeration-Minimisation_precision': 0.3786407766990291, 'Exaggeration-Minimisation_recall': 0.32231404958677684, 'Exaggeration-Minimisation_f1-score': 0.3482142857142857, 'Exaggeration-Minimisation_support': 242.0, 'micro avg_precision': 0.3786407766990291, 'micro avg_recall': 0.32231404958677684, 'micro avg_f1-score': 0.3482142857142857, 'micro avg_support': 242.0, 'macro avg_precision': 0.3786407766990291, 'macro avg_recall': 0.32231404958677684, 'macro avg_f1-score': 0.3482142857142857, 'macro avg_support': 242.0, 'weighted avg_precision': 0.3786407766990291, 'weighted avg_recall': 0.32231404958677684, 'weighted avg_f1-score': 0.3482142857142857, 'weighted avg_support': 242.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 4}, {'micro_f1': 0.8575713809576714, 'Exaggeration-Minimisation_precision': 0.3786407766990291, 'Exaggeration-Minimisation_recall': 0.312, 'Exaggeration-Minimisation_f1-score': 0.34210526315789475, 'Exaggeration-Minimisation_support': 250.0, 'micro avg_precision': 0.3786407766990291, 'micro avg_recall': 0.312, 'micro avg_f1-score': 0.34210526315789475, 'micro avg_support': 250.0, 'macro avg_precision': 0.3786407766990291, 'macro avg_recall': 0.312, 'macro avg_f1-score': 0.34210526315789475, 'macro avg_support': 250.0, 'weighted avg_precision': 0.3786407766990291, 'weighted avg_recall': 0.312, 'weighted avg_f1-score': 0.34210526315789475, 'weighted avg_support': 250.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 5}, {'micro_f1': 0.8639040106654816, 'Exaggeration-Minimisation_precision': 0.42718446601941745, 'Exaggeration-Minimisation_recall': 0.32592592592592595, 'Exaggeration-Minimisation_f1-score': 0.3697478991596639, 'Exaggeration-Minimisation_support': 270.0, 'micro avg_precision': 0.42718446601941745, 'micro avg_recall': 0.32592592592592595, 'micro avg_f1-score': 0.3697478991596639, 'micro avg_support': 270.0, 'macro avg_precision': 0.42718446601941745, 'macro avg_recall': 0.32592592592592595, 'macro avg_f1-score': 0.3697478991596639, 'macro avg_support': 270.0, 'weighted avg_precision': 0.42718446601941745, 'weighted avg_recall': 0.32592592592592595, 'weighted avg_f1-score': 0.3697478991596639, 'weighted avg_support': 270.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 6}, {'micro_f1': 0.8730141095433842, 'Exaggeration-Minimisation_precision': 0.36893203883495146, 'Exaggeration-Minimisation_recall': 0.34545454545454546, 'Exaggeration-Minimisation_f1-score': 0.3568075117370892, 'Exaggeration-Minimisation_support': 220.0, 'micro avg_precision': 0.36893203883495146, 'micro avg_recall': 0.34545454545454546, 'micro avg_f1-score': 0.3568075117370892, 'micro avg_support': 220.0, 'macro avg_precision': 0.36893203883495146, 'macro avg_recall': 0.34545454545454546, 'macro avg_f1-score': 0.3568075117370892, 'macro avg_support': 220.0, 'weighted avg_precision': 0.36893203883495146, 'weighted avg_recall': 0.34545454545454546, 'weighted avg_f1-score': 0.3568075117370892, 'weighted avg_support': 220.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 7}, {'micro_f1': 0.8720142206421508, 'Exaggeration-Minimisation_precision': 0.3786407766990291, 'Exaggeration-Minimisation_recall': 0.375, 'Exaggeration-Minimisation_f1-score': 0.3768115942028985, 'Exaggeration-Minimisation_support': 208.0, 'micro avg_precision': 0.3786407766990291, 'micro avg_recall': 0.375, 'micro avg_f1-score': 0.3768115942028985, 'micro avg_support': 208.0, 'macro avg_precision': 0.3786407766990291, 'macro avg_recall': 0.375, 'macro avg_f1-score': 0.3768115942028985, 'macro avg_support': 208.0, 'weighted avg_precision': 0.3786407766990291, 'weighted avg_recall': 0.375, 'weighted avg_f1-score': 0.3768115942028985, 'weighted avg_support': 208.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 8}, {'micro_f1': 0.8707921342073103, 'Exaggeration-Minimisation_precision': 0.45145631067961167, 'Exaggeration-Minimisation_recall': 0.37349397590361444, 'Exaggeration-Minimisation_f1-score': 0.4087912087912088, 'Exaggeration-Minimisation_support': 249.0, 'micro avg_precision': 0.45145631067961167, 'micro avg_recall': 0.37349397590361444, 'micro avg_f1-score': 0.4087912087912088, 'micro avg_support': 249.0, 'macro avg_precision': 0.45145631067961167, 'macro avg_recall': 0.37349397590361444, 'macro avg_f1-score': 0.4087912087912088, 'macro avg_support': 249.0, 'weighted avg_precision': 0.45145631067961167, 'weighted avg_recall': 0.37349397590361444, 'weighted avg_f1-score': 0.4087912087912088, 'weighted avg_support': 249.0, 'O_support': 6938, 'B-Exaggeration-Minimisation_support': 206, 'I-Exaggeration-Minimisation_support': 1857, 'epoch': 9}]}
Best model updated: current epoch macro f1 = 0.4087912087912088
Saving model to directory: ./models/M2/2024-05-12-17-42-10_aug/mdeberta-v3-base_16_ME10_target=Exaggeration-Minimisation_SUBSAMPLED_2024-05-12-17-42-10
Training model no. 17 of 23 for (17, 'Obfuscation-Vagueness-Confusion') persuasion technique...
{'micro_f1': 0.6223005729396209, 'Obfuscation-Vagueness-Confusion_precision': 0.0, 'Obfuscation-Vagueness-Confusion_recall': 0.0, 'Obfuscation-Vagueness-Confusion_f1-score': 0.0, 'Obfuscation-Vagueness-Confusion_support': 54.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 54.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 54.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 54.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 0}
{'results': [{'micro_f1': 0.6223005729396209, 'Obfuscation-Vagueness-Confusion_precision': 0.0, 'Obfuscation-Vagueness-Confusion_recall': 0.0, 'Obfuscation-Vagueness-Confusion_f1-score': 0.0, 'Obfuscation-Vagueness-Confusion_support': 54.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 54.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 54.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 54.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 0}]}
{'micro_f1': 0.6844424856765094, 'Obfuscation-Vagueness-Confusion_precision': 0.02127659574468085, 'Obfuscation-Vagueness-Confusion_recall': 0.012195121951219513, 'Obfuscation-Vagueness-Confusion_f1-score': 0.015503875968992248, 'Obfuscation-Vagueness-Confusion_support': 82.0, 'micro avg_precision': 0.02127659574468085, 'micro avg_recall': 0.012195121951219513, 'micro avg_f1-score': 0.015503875968992248, 'micro avg_support': 82.0, 'macro avg_precision': 0.02127659574468085, 'macro avg_recall': 0.012195121951219513, 'macro avg_f1-score': 0.015503875968992248, 'macro avg_support': 82.0, 'weighted avg_precision': 0.02127659574468085, 'weighted avg_recall': 0.012195121951219513, 'weighted avg_f1-score': 0.015503875968992248, 'weighted avg_support': 82.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 1}
{'results': [{'micro_f1': 0.6223005729396209, 'Obfuscation-Vagueness-Confusion_precision': 0.0, 'Obfuscation-Vagueness-Confusion_recall': 0.0, 'Obfuscation-Vagueness-Confusion_f1-score': 0.0, 'Obfuscation-Vagueness-Confusion_support': 54.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 54.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 54.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 54.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 0}, {'micro_f1': 0.6844424856765094, 'Obfuscation-Vagueness-Confusion_precision': 0.02127659574468085, 'Obfuscation-Vagueness-Confusion_recall': 0.012195121951219513, 'Obfuscation-Vagueness-Confusion_f1-score': 0.015503875968992248, 'Obfuscation-Vagueness-Confusion_support': 82.0, 'micro avg_precision': 0.02127659574468085, 'micro avg_recall': 0.012195121951219513, 'micro avg_f1-score': 0.015503875968992248, 'micro avg_support': 82.0, 'macro avg_precision': 0.02127659574468085, 'macro avg_recall': 0.012195121951219513, 'macro avg_f1-score': 0.015503875968992248, 'macro avg_support': 82.0, 'weighted avg_precision': 0.02127659574468085, 'weighted avg_recall': 0.012195121951219513, 'weighted avg_f1-score': 0.015503875968992248, 'weighted avg_support': 82.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 1}]}
Best model updated: current epoch macro f1 = 0.015503875968992248
{'micro_f1': 0.6615249008373733, 'Obfuscation-Vagueness-Confusion_precision': 0.10638297872340426, 'Obfuscation-Vagueness-Confusion_recall': 0.037037037037037035, 'Obfuscation-Vagueness-Confusion_f1-score': 0.054945054945054944, 'Obfuscation-Vagueness-Confusion_support': 135.0, 'micro avg_precision': 0.10638297872340426, 'micro avg_recall': 0.037037037037037035, 'micro avg_f1-score': 0.054945054945054944, 'micro avg_support': 135.0, 'macro avg_precision': 0.10638297872340426, 'macro avg_recall': 0.037037037037037035, 'macro avg_f1-score': 0.054945054945054944, 'macro avg_support': 135.0, 'weighted avg_precision': 0.10638297872340426, 'weighted avg_recall': 0.037037037037037035, 'weighted avg_f1-score': 0.054945054945054944, 'weighted avg_support': 135.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 2}
{'results': [{'micro_f1': 0.6223005729396209, 'Obfuscation-Vagueness-Confusion_precision': 0.0, 'Obfuscation-Vagueness-Confusion_recall': 0.0, 'Obfuscation-Vagueness-Confusion_f1-score': 0.0, 'Obfuscation-Vagueness-Confusion_support': 54.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 54.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 54.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 54.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 0}, {'micro_f1': 0.6844424856765094, 'Obfuscation-Vagueness-Confusion_precision': 0.02127659574468085, 'Obfuscation-Vagueness-Confusion_recall': 0.012195121951219513, 'Obfuscation-Vagueness-Confusion_f1-score': 0.015503875968992248, 'Obfuscation-Vagueness-Confusion_support': 82.0, 'micro avg_precision': 0.02127659574468085, 'micro avg_recall': 0.012195121951219513, 'micro avg_f1-score': 0.015503875968992248, 'micro avg_support': 82.0, 'macro avg_precision': 0.02127659574468085, 'macro avg_recall': 0.012195121951219513, 'macro avg_f1-score': 0.015503875968992248, 'macro avg_support': 82.0, 'weighted avg_precision': 0.02127659574468085, 'weighted avg_recall': 0.012195121951219513, 'weighted avg_f1-score': 0.015503875968992248, 'weighted avg_support': 82.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 1}, {'micro_f1': 0.6615249008373733, 'Obfuscation-Vagueness-Confusion_precision': 0.10638297872340426, 'Obfuscation-Vagueness-Confusion_recall': 0.037037037037037035, 'Obfuscation-Vagueness-Confusion_f1-score': 0.054945054945054944, 'Obfuscation-Vagueness-Confusion_support': 135.0, 'micro avg_precision': 0.10638297872340426, 'micro avg_recall': 0.037037037037037035, 'micro avg_f1-score': 0.054945054945054944, 'micro avg_support': 135.0, 'macro avg_precision': 0.10638297872340426, 'macro avg_recall': 0.037037037037037035, 'macro avg_f1-score': 0.054945054945054944, 'macro avg_support': 135.0, 'weighted avg_precision': 0.10638297872340426, 'weighted avg_recall': 0.037037037037037035, 'weighted avg_f1-score': 0.054945054945054944, 'weighted avg_support': 135.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 2}]}
Best model updated: current epoch macro f1 = 0.054945054945054944
{'micro_f1': 0.6910533274570295, 'Obfuscation-Vagueness-Confusion_precision': 0.10638297872340426, 'Obfuscation-Vagueness-Confusion_recall': 0.06097560975609756, 'Obfuscation-Vagueness-Confusion_f1-score': 0.07751937984496125, 'Obfuscation-Vagueness-Confusion_support': 82.0, 'micro avg_precision': 0.10638297872340426, 'micro avg_recall': 0.06097560975609756, 'micro avg_f1-score': 0.07751937984496125, 'micro avg_support': 82.0, 'macro avg_precision': 0.10638297872340426, 'macro avg_recall': 0.06097560975609756, 'macro avg_f1-score': 0.07751937984496125, 'macro avg_support': 82.0, 'weighted avg_precision': 0.10638297872340426, 'weighted avg_recall': 0.06097560975609756, 'weighted avg_f1-score': 0.07751937984496125, 'weighted avg_support': 82.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 3}
{'results': [{'micro_f1': 0.6223005729396209, 'Obfuscation-Vagueness-Confusion_precision': 0.0, 'Obfuscation-Vagueness-Confusion_recall': 0.0, 'Obfuscation-Vagueness-Confusion_f1-score': 0.0, 'Obfuscation-Vagueness-Confusion_support': 54.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 54.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 54.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 54.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 0}, {'micro_f1': 0.6844424856765094, 'Obfuscation-Vagueness-Confusion_precision': 0.02127659574468085, 'Obfuscation-Vagueness-Confusion_recall': 0.012195121951219513, 'Obfuscation-Vagueness-Confusion_f1-score': 0.015503875968992248, 'Obfuscation-Vagueness-Confusion_support': 82.0, 'micro avg_precision': 0.02127659574468085, 'micro avg_recall': 0.012195121951219513, 'micro avg_f1-score': 0.015503875968992248, 'micro avg_support': 82.0, 'macro avg_precision': 0.02127659574468085, 'macro avg_recall': 0.012195121951219513, 'macro avg_f1-score': 0.015503875968992248, 'macro avg_support': 82.0, 'weighted avg_precision': 0.02127659574468085, 'weighted avg_recall': 0.012195121951219513, 'weighted avg_f1-score': 0.015503875968992248, 'weighted avg_support': 82.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 1}, {'micro_f1': 0.6615249008373733, 'Obfuscation-Vagueness-Confusion_precision': 0.10638297872340426, 'Obfuscation-Vagueness-Confusion_recall': 0.037037037037037035, 'Obfuscation-Vagueness-Confusion_f1-score': 0.054945054945054944, 'Obfuscation-Vagueness-Confusion_support': 135.0, 'micro avg_precision': 0.10638297872340426, 'micro avg_recall': 0.037037037037037035, 'micro avg_f1-score': 0.054945054945054944, 'micro avg_support': 135.0, 'macro avg_precision': 0.10638297872340426, 'macro avg_recall': 0.037037037037037035, 'macro avg_f1-score': 0.054945054945054944, 'macro avg_support': 135.0, 'weighted avg_precision': 0.10638297872340426, 'weighted avg_recall': 0.037037037037037035, 'weighted avg_f1-score': 0.054945054945054944, 'weighted avg_support': 135.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 2}, {'micro_f1': 0.6910533274570295, 'Obfuscation-Vagueness-Confusion_precision': 0.10638297872340426, 'Obfuscation-Vagueness-Confusion_recall': 0.06097560975609756, 'Obfuscation-Vagueness-Confusion_f1-score': 0.07751937984496125, 'Obfuscation-Vagueness-Confusion_support': 82.0, 'micro avg_precision': 0.10638297872340426, 'micro avg_recall': 0.06097560975609756, 'micro avg_f1-score': 0.07751937984496125, 'micro avg_support': 82.0, 'macro avg_precision': 0.10638297872340426, 'macro avg_recall': 0.06097560975609756, 'macro avg_f1-score': 0.07751937984496125, 'macro avg_support': 82.0, 'weighted avg_precision': 0.10638297872340426, 'weighted avg_recall': 0.06097560975609756, 'weighted avg_f1-score': 0.07751937984496125, 'weighted avg_support': 82.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 3}]}
Best model updated: current epoch macro f1 = 0.07751937984496125
{'micro_f1': 0.6840017628911415, 'Obfuscation-Vagueness-Confusion_precision': 0.1702127659574468, 'Obfuscation-Vagueness-Confusion_recall': 0.07079646017699115, 'Obfuscation-Vagueness-Confusion_f1-score': 0.1, 'Obfuscation-Vagueness-Confusion_support': 113.0, 'micro avg_precision': 0.1702127659574468, 'micro avg_recall': 0.07079646017699115, 'micro avg_f1-score': 0.1, 'micro avg_support': 113.0, 'macro avg_precision': 0.1702127659574468, 'macro avg_recall': 0.07079646017699115, 'macro avg_f1-score': 0.1, 'macro avg_support': 113.0, 'weighted avg_precision': 0.1702127659574468, 'weighted avg_recall': 0.07079646017699115, 'weighted avg_f1-score': 0.1, 'weighted avg_support': 113.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 4}
{'results': [{'micro_f1': 0.6223005729396209, 'Obfuscation-Vagueness-Confusion_precision': 0.0, 'Obfuscation-Vagueness-Confusion_recall': 0.0, 'Obfuscation-Vagueness-Confusion_f1-score': 0.0, 'Obfuscation-Vagueness-Confusion_support': 54.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 54.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 54.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 54.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 0}, {'micro_f1': 0.6844424856765094, 'Obfuscation-Vagueness-Confusion_precision': 0.02127659574468085, 'Obfuscation-Vagueness-Confusion_recall': 0.012195121951219513, 'Obfuscation-Vagueness-Confusion_f1-score': 0.015503875968992248, 'Obfuscation-Vagueness-Confusion_support': 82.0, 'micro avg_precision': 0.02127659574468085, 'micro avg_recall': 0.012195121951219513, 'micro avg_f1-score': 0.015503875968992248, 'micro avg_support': 82.0, 'macro avg_precision': 0.02127659574468085, 'macro avg_recall': 0.012195121951219513, 'macro avg_f1-score': 0.015503875968992248, 'macro avg_support': 82.0, 'weighted avg_precision': 0.02127659574468085, 'weighted avg_recall': 0.012195121951219513, 'weighted avg_f1-score': 0.015503875968992248, 'weighted avg_support': 82.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 1}, {'micro_f1': 0.6615249008373733, 'Obfuscation-Vagueness-Confusion_precision': 0.10638297872340426, 'Obfuscation-Vagueness-Confusion_recall': 0.037037037037037035, 'Obfuscation-Vagueness-Confusion_f1-score': 0.054945054945054944, 'Obfuscation-Vagueness-Confusion_support': 135.0, 'micro avg_precision': 0.10638297872340426, 'micro avg_recall': 0.037037037037037035, 'micro avg_f1-score': 0.054945054945054944, 'micro avg_support': 135.0, 'macro avg_precision': 0.10638297872340426, 'macro avg_recall': 0.037037037037037035, 'macro avg_f1-score': 0.054945054945054944, 'macro avg_support': 135.0, 'weighted avg_precision': 0.10638297872340426, 'weighted avg_recall': 0.037037037037037035, 'weighted avg_f1-score': 0.054945054945054944, 'weighted avg_support': 135.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 2}, {'micro_f1': 0.6910533274570295, 'Obfuscation-Vagueness-Confusion_precision': 0.10638297872340426, 'Obfuscation-Vagueness-Confusion_recall': 0.06097560975609756, 'Obfuscation-Vagueness-Confusion_f1-score': 0.07751937984496125, 'Obfuscation-Vagueness-Confusion_support': 82.0, 'micro avg_precision': 0.10638297872340426, 'micro avg_recall': 0.06097560975609756, 'micro avg_f1-score': 0.07751937984496125, 'micro avg_support': 82.0, 'macro avg_precision': 0.10638297872340426, 'macro avg_recall': 0.06097560975609756, 'macro avg_f1-score': 0.07751937984496125, 'macro avg_support': 82.0, 'weighted avg_precision': 0.10638297872340426, 'weighted avg_recall': 0.06097560975609756, 'weighted avg_f1-score': 0.07751937984496125, 'weighted avg_support': 82.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 3}, {'micro_f1': 0.6840017628911415, 'Obfuscation-Vagueness-Confusion_precision': 0.1702127659574468, 'Obfuscation-Vagueness-Confusion_recall': 0.07079646017699115, 'Obfuscation-Vagueness-Confusion_f1-score': 0.1, 'Obfuscation-Vagueness-Confusion_support': 113.0, 'micro avg_precision': 0.1702127659574468, 'micro avg_recall': 0.07079646017699115, 'micro avg_f1-score': 0.1, 'micro avg_support': 113.0, 'macro avg_precision': 0.1702127659574468, 'macro avg_recall': 0.07079646017699115, 'macro avg_f1-score': 0.1, 'macro avg_support': 113.0, 'weighted avg_precision': 0.1702127659574468, 'weighted avg_recall': 0.07079646017699115, 'weighted avg_f1-score': 0.1, 'weighted avg_support': 113.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 4}]}
Best model updated: current epoch macro f1 = 0.1
{'micro_f1': 0.7069193477302776, 'Obfuscation-Vagueness-Confusion_precision': 0.10638297872340426, 'Obfuscation-Vagueness-Confusion_recall': 0.05952380952380952, 'Obfuscation-Vagueness-Confusion_f1-score': 0.07633587786259542, 'Obfuscation-Vagueness-Confusion_support': 84.0, 'micro avg_precision': 0.10638297872340426, 'micro avg_recall': 0.05952380952380952, 'micro avg_f1-score': 0.07633587786259542, 'micro avg_support': 84.0, 'macro avg_precision': 0.10638297872340426, 'macro avg_recall': 0.05952380952380952, 'macro avg_f1-score': 0.07633587786259542, 'macro avg_support': 84.0, 'weighted avg_precision': 0.10638297872340427, 'weighted avg_recall': 0.05952380952380952, 'weighted avg_f1-score': 0.07633587786259542, 'weighted avg_support': 84.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 5}
{'results': [{'micro_f1': 0.6223005729396209, 'Obfuscation-Vagueness-Confusion_precision': 0.0, 'Obfuscation-Vagueness-Confusion_recall': 0.0, 'Obfuscation-Vagueness-Confusion_f1-score': 0.0, 'Obfuscation-Vagueness-Confusion_support': 54.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 54.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 54.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 54.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 0}, {'micro_f1': 0.6844424856765094, 'Obfuscation-Vagueness-Confusion_precision': 0.02127659574468085, 'Obfuscation-Vagueness-Confusion_recall': 0.012195121951219513, 'Obfuscation-Vagueness-Confusion_f1-score': 0.015503875968992248, 'Obfuscation-Vagueness-Confusion_support': 82.0, 'micro avg_precision': 0.02127659574468085, 'micro avg_recall': 0.012195121951219513, 'micro avg_f1-score': 0.015503875968992248, 'micro avg_support': 82.0, 'macro avg_precision': 0.02127659574468085, 'macro avg_recall': 0.012195121951219513, 'macro avg_f1-score': 0.015503875968992248, 'macro avg_support': 82.0, 'weighted avg_precision': 0.02127659574468085, 'weighted avg_recall': 0.012195121951219513, 'weighted avg_f1-score': 0.015503875968992248, 'weighted avg_support': 82.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 1}, {'micro_f1': 0.6615249008373733, 'Obfuscation-Vagueness-Confusion_precision': 0.10638297872340426, 'Obfuscation-Vagueness-Confusion_recall': 0.037037037037037035, 'Obfuscation-Vagueness-Confusion_f1-score': 0.054945054945054944, 'Obfuscation-Vagueness-Confusion_support': 135.0, 'micro avg_precision': 0.10638297872340426, 'micro avg_recall': 0.037037037037037035, 'micro avg_f1-score': 0.054945054945054944, 'micro avg_support': 135.0, 'macro avg_precision': 0.10638297872340426, 'macro avg_recall': 0.037037037037037035, 'macro avg_f1-score': 0.054945054945054944, 'macro avg_support': 135.0, 'weighted avg_precision': 0.10638297872340426, 'weighted avg_recall': 0.037037037037037035, 'weighted avg_f1-score': 0.054945054945054944, 'weighted avg_support': 135.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 2}, {'micro_f1': 0.6910533274570295, 'Obfuscation-Vagueness-Confusion_precision': 0.10638297872340426, 'Obfuscation-Vagueness-Confusion_recall': 0.06097560975609756, 'Obfuscation-Vagueness-Confusion_f1-score': 0.07751937984496125, 'Obfuscation-Vagueness-Confusion_support': 82.0, 'micro avg_precision': 0.10638297872340426, 'micro avg_recall': 0.06097560975609756, 'micro avg_f1-score': 0.07751937984496125, 'micro avg_support': 82.0, 'macro avg_precision': 0.10638297872340426, 'macro avg_recall': 0.06097560975609756, 'macro avg_f1-score': 0.07751937984496125, 'macro avg_support': 82.0, 'weighted avg_precision': 0.10638297872340426, 'weighted avg_recall': 0.06097560975609756, 'weighted avg_f1-score': 0.07751937984496125, 'weighted avg_support': 82.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 3}, {'micro_f1': 0.6840017628911415, 'Obfuscation-Vagueness-Confusion_precision': 0.1702127659574468, 'Obfuscation-Vagueness-Confusion_recall': 0.07079646017699115, 'Obfuscation-Vagueness-Confusion_f1-score': 0.1, 'Obfuscation-Vagueness-Confusion_support': 113.0, 'micro avg_precision': 0.1702127659574468, 'micro avg_recall': 0.07079646017699115, 'micro avg_f1-score': 0.1, 'micro avg_support': 113.0, 'macro avg_precision': 0.1702127659574468, 'macro avg_recall': 0.07079646017699115, 'macro avg_f1-score': 0.1, 'macro avg_support': 113.0, 'weighted avg_precision': 0.1702127659574468, 'weighted avg_recall': 0.07079646017699115, 'weighted avg_f1-score': 0.1, 'weighted avg_support': 113.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 4}, {'micro_f1': 0.7069193477302776, 'Obfuscation-Vagueness-Confusion_precision': 0.10638297872340426, 'Obfuscation-Vagueness-Confusion_recall': 0.05952380952380952, 'Obfuscation-Vagueness-Confusion_f1-score': 0.07633587786259542, 'Obfuscation-Vagueness-Confusion_support': 84.0, 'micro avg_precision': 0.10638297872340426, 'micro avg_recall': 0.05952380952380952, 'micro avg_f1-score': 0.07633587786259542, 'micro avg_support': 84.0, 'macro avg_precision': 0.10638297872340426, 'macro avg_recall': 0.05952380952380952, 'macro avg_f1-score': 0.07633587786259542, 'macro avg_support': 84.0, 'weighted avg_precision': 0.10638297872340427, 'weighted avg_recall': 0.05952380952380952, 'weighted avg_f1-score': 0.07633587786259542, 'weighted avg_support': 84.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 5}]}
{'micro_f1': 0.6963420008814456, 'Obfuscation-Vagueness-Confusion_precision': 0.1702127659574468, 'Obfuscation-Vagueness-Confusion_recall': 0.07920792079207921, 'Obfuscation-Vagueness-Confusion_f1-score': 0.10810810810810811, 'Obfuscation-Vagueness-Confusion_support': 101.0, 'micro avg_precision': 0.1702127659574468, 'micro avg_recall': 0.07920792079207921, 'micro avg_f1-score': 0.10810810810810811, 'micro avg_support': 101.0, 'macro avg_precision': 0.1702127659574468, 'macro avg_recall': 0.07920792079207921, 'macro avg_f1-score': 0.10810810810810811, 'macro avg_support': 101.0, 'weighted avg_precision': 0.1702127659574468, 'weighted avg_recall': 0.07920792079207921, 'weighted avg_f1-score': 0.10810810810810811, 'weighted avg_support': 101.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 6}
{'results': [{'micro_f1': 0.6223005729396209, 'Obfuscation-Vagueness-Confusion_precision': 0.0, 'Obfuscation-Vagueness-Confusion_recall': 0.0, 'Obfuscation-Vagueness-Confusion_f1-score': 0.0, 'Obfuscation-Vagueness-Confusion_support': 54.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 54.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 54.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 54.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 0}, {'micro_f1': 0.6844424856765094, 'Obfuscation-Vagueness-Confusion_precision': 0.02127659574468085, 'Obfuscation-Vagueness-Confusion_recall': 0.012195121951219513, 'Obfuscation-Vagueness-Confusion_f1-score': 0.015503875968992248, 'Obfuscation-Vagueness-Confusion_support': 82.0, 'micro avg_precision': 0.02127659574468085, 'micro avg_recall': 0.012195121951219513, 'micro avg_f1-score': 0.015503875968992248, 'micro avg_support': 82.0, 'macro avg_precision': 0.02127659574468085, 'macro avg_recall': 0.012195121951219513, 'macro avg_f1-score': 0.015503875968992248, 'macro avg_support': 82.0, 'weighted avg_precision': 0.02127659574468085, 'weighted avg_recall': 0.012195121951219513, 'weighted avg_f1-score': 0.015503875968992248, 'weighted avg_support': 82.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 1}, {'micro_f1': 0.6615249008373733, 'Obfuscation-Vagueness-Confusion_precision': 0.10638297872340426, 'Obfuscation-Vagueness-Confusion_recall': 0.037037037037037035, 'Obfuscation-Vagueness-Confusion_f1-score': 0.054945054945054944, 'Obfuscation-Vagueness-Confusion_support': 135.0, 'micro avg_precision': 0.10638297872340426, 'micro avg_recall': 0.037037037037037035, 'micro avg_f1-score': 0.054945054945054944, 'micro avg_support': 135.0, 'macro avg_precision': 0.10638297872340426, 'macro avg_recall': 0.037037037037037035, 'macro avg_f1-score': 0.054945054945054944, 'macro avg_support': 135.0, 'weighted avg_precision': 0.10638297872340426, 'weighted avg_recall': 0.037037037037037035, 'weighted avg_f1-score': 0.054945054945054944, 'weighted avg_support': 135.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 2}, {'micro_f1': 0.6910533274570295, 'Obfuscation-Vagueness-Confusion_precision': 0.10638297872340426, 'Obfuscation-Vagueness-Confusion_recall': 0.06097560975609756, 'Obfuscation-Vagueness-Confusion_f1-score': 0.07751937984496125, 'Obfuscation-Vagueness-Confusion_support': 82.0, 'micro avg_precision': 0.10638297872340426, 'micro avg_recall': 0.06097560975609756, 'micro avg_f1-score': 0.07751937984496125, 'micro avg_support': 82.0, 'macro avg_precision': 0.10638297872340426, 'macro avg_recall': 0.06097560975609756, 'macro avg_f1-score': 0.07751937984496125, 'macro avg_support': 82.0, 'weighted avg_precision': 0.10638297872340426, 'weighted avg_recall': 0.06097560975609756, 'weighted avg_f1-score': 0.07751937984496125, 'weighted avg_support': 82.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 3}, {'micro_f1': 0.6840017628911415, 'Obfuscation-Vagueness-Confusion_precision': 0.1702127659574468, 'Obfuscation-Vagueness-Confusion_recall': 0.07079646017699115, 'Obfuscation-Vagueness-Confusion_f1-score': 0.1, 'Obfuscation-Vagueness-Confusion_support': 113.0, 'micro avg_precision': 0.1702127659574468, 'micro avg_recall': 0.07079646017699115, 'micro avg_f1-score': 0.1, 'micro avg_support': 113.0, 'macro avg_precision': 0.1702127659574468, 'macro avg_recall': 0.07079646017699115, 'macro avg_f1-score': 0.1, 'macro avg_support': 113.0, 'weighted avg_precision': 0.1702127659574468, 'weighted avg_recall': 0.07079646017699115, 'weighted avg_f1-score': 0.1, 'weighted avg_support': 113.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 4}, {'micro_f1': 0.7069193477302776, 'Obfuscation-Vagueness-Confusion_precision': 0.10638297872340426, 'Obfuscation-Vagueness-Confusion_recall': 0.05952380952380952, 'Obfuscation-Vagueness-Confusion_f1-score': 0.07633587786259542, 'Obfuscation-Vagueness-Confusion_support': 84.0, 'micro avg_precision': 0.10638297872340426, 'micro avg_recall': 0.05952380952380952, 'micro avg_f1-score': 0.07633587786259542, 'micro avg_support': 84.0, 'macro avg_precision': 0.10638297872340426, 'macro avg_recall': 0.05952380952380952, 'macro avg_f1-score': 0.07633587786259542, 'macro avg_support': 84.0, 'weighted avg_precision': 0.10638297872340427, 'weighted avg_recall': 0.05952380952380952, 'weighted avg_f1-score': 0.07633587786259542, 'weighted avg_support': 84.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 5}, {'micro_f1': 0.6963420008814456, 'Obfuscation-Vagueness-Confusion_precision': 0.1702127659574468, 'Obfuscation-Vagueness-Confusion_recall': 0.07920792079207921, 'Obfuscation-Vagueness-Confusion_f1-score': 0.10810810810810811, 'Obfuscation-Vagueness-Confusion_support': 101.0, 'micro avg_precision': 0.1702127659574468, 'micro avg_recall': 0.07920792079207921, 'micro avg_f1-score': 0.10810810810810811, 'micro avg_support': 101.0, 'macro avg_precision': 0.1702127659574468, 'macro avg_recall': 0.07920792079207921, 'macro avg_f1-score': 0.10810810810810811, 'macro avg_support': 101.0, 'weighted avg_precision': 0.1702127659574468, 'weighted avg_recall': 0.07920792079207921, 'weighted avg_f1-score': 0.10810810810810811, 'weighted avg_support': 101.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 6}]}
Best model updated: current epoch macro f1 = 0.10810810810810811
{'micro_f1': 0.6954605553107096, 'Obfuscation-Vagueness-Confusion_precision': 0.23404255319148937, 'Obfuscation-Vagueness-Confusion_recall': 0.10891089108910891, 'Obfuscation-Vagueness-Confusion_f1-score': 0.14864864864864866, 'Obfuscation-Vagueness-Confusion_support': 101.0, 'micro avg_precision': 0.23404255319148937, 'micro avg_recall': 0.10891089108910891, 'micro avg_f1-score': 0.14864864864864866, 'micro avg_support': 101.0, 'macro avg_precision': 0.23404255319148937, 'macro avg_recall': 0.10891089108910891, 'macro avg_f1-score': 0.14864864864864866, 'macro avg_support': 101.0, 'weighted avg_precision': 0.23404255319148937, 'weighted avg_recall': 0.10891089108910891, 'weighted avg_f1-score': 0.14864864864864866, 'weighted avg_support': 101.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 7}
{'results': [{'micro_f1': 0.6223005729396209, 'Obfuscation-Vagueness-Confusion_precision': 0.0, 'Obfuscation-Vagueness-Confusion_recall': 0.0, 'Obfuscation-Vagueness-Confusion_f1-score': 0.0, 'Obfuscation-Vagueness-Confusion_support': 54.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 54.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 54.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 54.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 0}, {'micro_f1': 0.6844424856765094, 'Obfuscation-Vagueness-Confusion_precision': 0.02127659574468085, 'Obfuscation-Vagueness-Confusion_recall': 0.012195121951219513, 'Obfuscation-Vagueness-Confusion_f1-score': 0.015503875968992248, 'Obfuscation-Vagueness-Confusion_support': 82.0, 'micro avg_precision': 0.02127659574468085, 'micro avg_recall': 0.012195121951219513, 'micro avg_f1-score': 0.015503875968992248, 'micro avg_support': 82.0, 'macro avg_precision': 0.02127659574468085, 'macro avg_recall': 0.012195121951219513, 'macro avg_f1-score': 0.015503875968992248, 'macro avg_support': 82.0, 'weighted avg_precision': 0.02127659574468085, 'weighted avg_recall': 0.012195121951219513, 'weighted avg_f1-score': 0.015503875968992248, 'weighted avg_support': 82.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 1}, {'micro_f1': 0.6615249008373733, 'Obfuscation-Vagueness-Confusion_precision': 0.10638297872340426, 'Obfuscation-Vagueness-Confusion_recall': 0.037037037037037035, 'Obfuscation-Vagueness-Confusion_f1-score': 0.054945054945054944, 'Obfuscation-Vagueness-Confusion_support': 135.0, 'micro avg_precision': 0.10638297872340426, 'micro avg_recall': 0.037037037037037035, 'micro avg_f1-score': 0.054945054945054944, 'micro avg_support': 135.0, 'macro avg_precision': 0.10638297872340426, 'macro avg_recall': 0.037037037037037035, 'macro avg_f1-score': 0.054945054945054944, 'macro avg_support': 135.0, 'weighted avg_precision': 0.10638297872340426, 'weighted avg_recall': 0.037037037037037035, 'weighted avg_f1-score': 0.054945054945054944, 'weighted avg_support': 135.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 2}, {'micro_f1': 0.6910533274570295, 'Obfuscation-Vagueness-Confusion_precision': 0.10638297872340426, 'Obfuscation-Vagueness-Confusion_recall': 0.06097560975609756, 'Obfuscation-Vagueness-Confusion_f1-score': 0.07751937984496125, 'Obfuscation-Vagueness-Confusion_support': 82.0, 'micro avg_precision': 0.10638297872340426, 'micro avg_recall': 0.06097560975609756, 'micro avg_f1-score': 0.07751937984496125, 'micro avg_support': 82.0, 'macro avg_precision': 0.10638297872340426, 'macro avg_recall': 0.06097560975609756, 'macro avg_f1-score': 0.07751937984496125, 'macro avg_support': 82.0, 'weighted avg_precision': 0.10638297872340426, 'weighted avg_recall': 0.06097560975609756, 'weighted avg_f1-score': 0.07751937984496125, 'weighted avg_support': 82.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 3}, {'micro_f1': 0.6840017628911415, 'Obfuscation-Vagueness-Confusion_precision': 0.1702127659574468, 'Obfuscation-Vagueness-Confusion_recall': 0.07079646017699115, 'Obfuscation-Vagueness-Confusion_f1-score': 0.1, 'Obfuscation-Vagueness-Confusion_support': 113.0, 'micro avg_precision': 0.1702127659574468, 'micro avg_recall': 0.07079646017699115, 'micro avg_f1-score': 0.1, 'micro avg_support': 113.0, 'macro avg_precision': 0.1702127659574468, 'macro avg_recall': 0.07079646017699115, 'macro avg_f1-score': 0.1, 'macro avg_support': 113.0, 'weighted avg_precision': 0.1702127659574468, 'weighted avg_recall': 0.07079646017699115, 'weighted avg_f1-score': 0.1, 'weighted avg_support': 113.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 4}, {'micro_f1': 0.7069193477302776, 'Obfuscation-Vagueness-Confusion_precision': 0.10638297872340426, 'Obfuscation-Vagueness-Confusion_recall': 0.05952380952380952, 'Obfuscation-Vagueness-Confusion_f1-score': 0.07633587786259542, 'Obfuscation-Vagueness-Confusion_support': 84.0, 'micro avg_precision': 0.10638297872340426, 'micro avg_recall': 0.05952380952380952, 'micro avg_f1-score': 0.07633587786259542, 'micro avg_support': 84.0, 'macro avg_precision': 0.10638297872340426, 'macro avg_recall': 0.05952380952380952, 'macro avg_f1-score': 0.07633587786259542, 'macro avg_support': 84.0, 'weighted avg_precision': 0.10638297872340427, 'weighted avg_recall': 0.05952380952380952, 'weighted avg_f1-score': 0.07633587786259542, 'weighted avg_support': 84.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 5}, {'micro_f1': 0.6963420008814456, 'Obfuscation-Vagueness-Confusion_precision': 0.1702127659574468, 'Obfuscation-Vagueness-Confusion_recall': 0.07920792079207921, 'Obfuscation-Vagueness-Confusion_f1-score': 0.10810810810810811, 'Obfuscation-Vagueness-Confusion_support': 101.0, 'micro avg_precision': 0.1702127659574468, 'micro avg_recall': 0.07920792079207921, 'micro avg_f1-score': 0.10810810810810811, 'micro avg_support': 101.0, 'macro avg_precision': 0.1702127659574468, 'macro avg_recall': 0.07920792079207921, 'macro avg_f1-score': 0.10810810810810811, 'macro avg_support': 101.0, 'weighted avg_precision': 0.1702127659574468, 'weighted avg_recall': 0.07920792079207921, 'weighted avg_f1-score': 0.10810810810810811, 'weighted avg_support': 101.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 6}, {'micro_f1': 0.6954605553107096, 'Obfuscation-Vagueness-Confusion_precision': 0.23404255319148937, 'Obfuscation-Vagueness-Confusion_recall': 0.10891089108910891, 'Obfuscation-Vagueness-Confusion_f1-score': 0.14864864864864866, 'Obfuscation-Vagueness-Confusion_support': 101.0, 'micro avg_precision': 0.23404255319148937, 'micro avg_recall': 0.10891089108910891, 'micro avg_f1-score': 0.14864864864864866, 'micro avg_support': 101.0, 'macro avg_precision': 0.23404255319148937, 'macro avg_recall': 0.10891089108910891, 'macro avg_f1-score': 0.14864864864864866, 'macro avg_support': 101.0, 'weighted avg_precision': 0.23404255319148937, 'weighted avg_recall': 0.10891089108910891, 'weighted avg_f1-score': 0.14864864864864866, 'weighted avg_support': 101.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 7}]}
Best model updated: current epoch macro f1 = 0.14864864864864866
{'micro_f1': 0.7086822388717496, 'Obfuscation-Vagueness-Confusion_precision': 0.10638297872340426, 'Obfuscation-Vagueness-Confusion_recall': 0.04716981132075472, 'Obfuscation-Vagueness-Confusion_f1-score': 0.06535947712418301, 'Obfuscation-Vagueness-Confusion_support': 106.0, 'micro avg_precision': 0.10638297872340426, 'micro avg_recall': 0.04716981132075472, 'micro avg_f1-score': 0.06535947712418301, 'micro avg_support': 106.0, 'macro avg_precision': 0.10638297872340426, 'macro avg_recall': 0.04716981132075472, 'macro avg_f1-score': 0.06535947712418301, 'macro avg_support': 106.0, 'weighted avg_precision': 0.10638297872340426, 'weighted avg_recall': 0.04716981132075472, 'weighted avg_f1-score': 0.06535947712418301, 'weighted avg_support': 106.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 8}
{'results': [{'micro_f1': 0.6223005729396209, 'Obfuscation-Vagueness-Confusion_precision': 0.0, 'Obfuscation-Vagueness-Confusion_recall': 0.0, 'Obfuscation-Vagueness-Confusion_f1-score': 0.0, 'Obfuscation-Vagueness-Confusion_support': 54.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 54.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 54.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 54.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 0}, {'micro_f1': 0.6844424856765094, 'Obfuscation-Vagueness-Confusion_precision': 0.02127659574468085, 'Obfuscation-Vagueness-Confusion_recall': 0.012195121951219513, 'Obfuscation-Vagueness-Confusion_f1-score': 0.015503875968992248, 'Obfuscation-Vagueness-Confusion_support': 82.0, 'micro avg_precision': 0.02127659574468085, 'micro avg_recall': 0.012195121951219513, 'micro avg_f1-score': 0.015503875968992248, 'micro avg_support': 82.0, 'macro avg_precision': 0.02127659574468085, 'macro avg_recall': 0.012195121951219513, 'macro avg_f1-score': 0.015503875968992248, 'macro avg_support': 82.0, 'weighted avg_precision': 0.02127659574468085, 'weighted avg_recall': 0.012195121951219513, 'weighted avg_f1-score': 0.015503875968992248, 'weighted avg_support': 82.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 1}, {'micro_f1': 0.6615249008373733, 'Obfuscation-Vagueness-Confusion_precision': 0.10638297872340426, 'Obfuscation-Vagueness-Confusion_recall': 0.037037037037037035, 'Obfuscation-Vagueness-Confusion_f1-score': 0.054945054945054944, 'Obfuscation-Vagueness-Confusion_support': 135.0, 'micro avg_precision': 0.10638297872340426, 'micro avg_recall': 0.037037037037037035, 'micro avg_f1-score': 0.054945054945054944, 'micro avg_support': 135.0, 'macro avg_precision': 0.10638297872340426, 'macro avg_recall': 0.037037037037037035, 'macro avg_f1-score': 0.054945054945054944, 'macro avg_support': 135.0, 'weighted avg_precision': 0.10638297872340426, 'weighted avg_recall': 0.037037037037037035, 'weighted avg_f1-score': 0.054945054945054944, 'weighted avg_support': 135.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 2}, {'micro_f1': 0.6910533274570295, 'Obfuscation-Vagueness-Confusion_precision': 0.10638297872340426, 'Obfuscation-Vagueness-Confusion_recall': 0.06097560975609756, 'Obfuscation-Vagueness-Confusion_f1-score': 0.07751937984496125, 'Obfuscation-Vagueness-Confusion_support': 82.0, 'micro avg_precision': 0.10638297872340426, 'micro avg_recall': 0.06097560975609756, 'micro avg_f1-score': 0.07751937984496125, 'micro avg_support': 82.0, 'macro avg_precision': 0.10638297872340426, 'macro avg_recall': 0.06097560975609756, 'macro avg_f1-score': 0.07751937984496125, 'macro avg_support': 82.0, 'weighted avg_precision': 0.10638297872340426, 'weighted avg_recall': 0.06097560975609756, 'weighted avg_f1-score': 0.07751937984496125, 'weighted avg_support': 82.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 3}, {'micro_f1': 0.6840017628911415, 'Obfuscation-Vagueness-Confusion_precision': 0.1702127659574468, 'Obfuscation-Vagueness-Confusion_recall': 0.07079646017699115, 'Obfuscation-Vagueness-Confusion_f1-score': 0.1, 'Obfuscation-Vagueness-Confusion_support': 113.0, 'micro avg_precision': 0.1702127659574468, 'micro avg_recall': 0.07079646017699115, 'micro avg_f1-score': 0.1, 'micro avg_support': 113.0, 'macro avg_precision': 0.1702127659574468, 'macro avg_recall': 0.07079646017699115, 'macro avg_f1-score': 0.1, 'macro avg_support': 113.0, 'weighted avg_precision': 0.1702127659574468, 'weighted avg_recall': 0.07079646017699115, 'weighted avg_f1-score': 0.1, 'weighted avg_support': 113.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 4}, {'micro_f1': 0.7069193477302776, 'Obfuscation-Vagueness-Confusion_precision': 0.10638297872340426, 'Obfuscation-Vagueness-Confusion_recall': 0.05952380952380952, 'Obfuscation-Vagueness-Confusion_f1-score': 0.07633587786259542, 'Obfuscation-Vagueness-Confusion_support': 84.0, 'micro avg_precision': 0.10638297872340426, 'micro avg_recall': 0.05952380952380952, 'micro avg_f1-score': 0.07633587786259542, 'micro avg_support': 84.0, 'macro avg_precision': 0.10638297872340426, 'macro avg_recall': 0.05952380952380952, 'macro avg_f1-score': 0.07633587786259542, 'macro avg_support': 84.0, 'weighted avg_precision': 0.10638297872340427, 'weighted avg_recall': 0.05952380952380952, 'weighted avg_f1-score': 0.07633587786259542, 'weighted avg_support': 84.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 5}, {'micro_f1': 0.6963420008814456, 'Obfuscation-Vagueness-Confusion_precision': 0.1702127659574468, 'Obfuscation-Vagueness-Confusion_recall': 0.07920792079207921, 'Obfuscation-Vagueness-Confusion_f1-score': 0.10810810810810811, 'Obfuscation-Vagueness-Confusion_support': 101.0, 'micro avg_precision': 0.1702127659574468, 'micro avg_recall': 0.07920792079207921, 'micro avg_f1-score': 0.10810810810810811, 'micro avg_support': 101.0, 'macro avg_precision': 0.1702127659574468, 'macro avg_recall': 0.07920792079207921, 'macro avg_f1-score': 0.10810810810810811, 'macro avg_support': 101.0, 'weighted avg_precision': 0.1702127659574468, 'weighted avg_recall': 0.07920792079207921, 'weighted avg_f1-score': 0.10810810810810811, 'weighted avg_support': 101.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 6}, {'micro_f1': 0.6954605553107096, 'Obfuscation-Vagueness-Confusion_precision': 0.23404255319148937, 'Obfuscation-Vagueness-Confusion_recall': 0.10891089108910891, 'Obfuscation-Vagueness-Confusion_f1-score': 0.14864864864864866, 'Obfuscation-Vagueness-Confusion_support': 101.0, 'micro avg_precision': 0.23404255319148937, 'micro avg_recall': 0.10891089108910891, 'micro avg_f1-score': 0.14864864864864866, 'micro avg_support': 101.0, 'macro avg_precision': 0.23404255319148937, 'macro avg_recall': 0.10891089108910891, 'macro avg_f1-score': 0.14864864864864866, 'macro avg_support': 101.0, 'weighted avg_precision': 0.23404255319148937, 'weighted avg_recall': 0.10891089108910891, 'weighted avg_f1-score': 0.14864864864864866, 'weighted avg_support': 101.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 7}, {'micro_f1': 0.7086822388717496, 'Obfuscation-Vagueness-Confusion_precision': 0.10638297872340426, 'Obfuscation-Vagueness-Confusion_recall': 0.04716981132075472, 'Obfuscation-Vagueness-Confusion_f1-score': 0.06535947712418301, 'Obfuscation-Vagueness-Confusion_support': 106.0, 'micro avg_precision': 0.10638297872340426, 'micro avg_recall': 0.04716981132075472, 'micro avg_f1-score': 0.06535947712418301, 'micro avg_support': 106.0, 'macro avg_precision': 0.10638297872340426, 'macro avg_recall': 0.04716981132075472, 'macro avg_f1-score': 0.06535947712418301, 'macro avg_support': 106.0, 'weighted avg_precision': 0.10638297872340426, 'weighted avg_recall': 0.04716981132075472, 'weighted avg_f1-score': 0.06535947712418301, 'weighted avg_support': 106.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 8}]}
{'micro_f1': 0.6994270603790216, 'Obfuscation-Vagueness-Confusion_precision': 0.2127659574468085, 'Obfuscation-Vagueness-Confusion_recall': 0.10416666666666667, 'Obfuscation-Vagueness-Confusion_f1-score': 0.13986013986013987, 'Obfuscation-Vagueness-Confusion_support': 96.0, 'micro avg_precision': 0.2127659574468085, 'micro avg_recall': 0.10416666666666667, 'micro avg_f1-score': 0.13986013986013987, 'micro avg_support': 96.0, 'macro avg_precision': 0.2127659574468085, 'macro avg_recall': 0.10416666666666667, 'macro avg_f1-score': 0.13986013986013987, 'macro avg_support': 96.0, 'weighted avg_precision': 0.2127659574468085, 'weighted avg_recall': 0.10416666666666667, 'weighted avg_f1-score': 0.13986013986013987, 'weighted avg_support': 96.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 9}
{'results': [{'micro_f1': 0.6223005729396209, 'Obfuscation-Vagueness-Confusion_precision': 0.0, 'Obfuscation-Vagueness-Confusion_recall': 0.0, 'Obfuscation-Vagueness-Confusion_f1-score': 0.0, 'Obfuscation-Vagueness-Confusion_support': 54.0, 'micro avg_precision': 0.0, 'micro avg_recall': 0.0, 'micro avg_f1-score': 0.0, 'micro avg_support': 54.0, 'macro avg_precision': 0.0, 'macro avg_recall': 0.0, 'macro avg_f1-score': 0.0, 'macro avg_support': 54.0, 'weighted avg_precision': 0.0, 'weighted avg_recall': 0.0, 'weighted avg_f1-score': 0.0, 'weighted avg_support': 54.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 0}, {'micro_f1': 0.6844424856765094, 'Obfuscation-Vagueness-Confusion_precision': 0.02127659574468085, 'Obfuscation-Vagueness-Confusion_recall': 0.012195121951219513, 'Obfuscation-Vagueness-Confusion_f1-score': 0.015503875968992248, 'Obfuscation-Vagueness-Confusion_support': 82.0, 'micro avg_precision': 0.02127659574468085, 'micro avg_recall': 0.012195121951219513, 'micro avg_f1-score': 0.015503875968992248, 'micro avg_support': 82.0, 'macro avg_precision': 0.02127659574468085, 'macro avg_recall': 0.012195121951219513, 'macro avg_f1-score': 0.015503875968992248, 'macro avg_support': 82.0, 'weighted avg_precision': 0.02127659574468085, 'weighted avg_recall': 0.012195121951219513, 'weighted avg_f1-score': 0.015503875968992248, 'weighted avg_support': 82.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 1}, {'micro_f1': 0.6615249008373733, 'Obfuscation-Vagueness-Confusion_precision': 0.10638297872340426, 'Obfuscation-Vagueness-Confusion_recall': 0.037037037037037035, 'Obfuscation-Vagueness-Confusion_f1-score': 0.054945054945054944, 'Obfuscation-Vagueness-Confusion_support': 135.0, 'micro avg_precision': 0.10638297872340426, 'micro avg_recall': 0.037037037037037035, 'micro avg_f1-score': 0.054945054945054944, 'micro avg_support': 135.0, 'macro avg_precision': 0.10638297872340426, 'macro avg_recall': 0.037037037037037035, 'macro avg_f1-score': 0.054945054945054944, 'macro avg_support': 135.0, 'weighted avg_precision': 0.10638297872340426, 'weighted avg_recall': 0.037037037037037035, 'weighted avg_f1-score': 0.054945054945054944, 'weighted avg_support': 135.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 2}, {'micro_f1': 0.6910533274570295, 'Obfuscation-Vagueness-Confusion_precision': 0.10638297872340426, 'Obfuscation-Vagueness-Confusion_recall': 0.06097560975609756, 'Obfuscation-Vagueness-Confusion_f1-score': 0.07751937984496125, 'Obfuscation-Vagueness-Confusion_support': 82.0, 'micro avg_precision': 0.10638297872340426, 'micro avg_recall': 0.06097560975609756, 'micro avg_f1-score': 0.07751937984496125, 'micro avg_support': 82.0, 'macro avg_precision': 0.10638297872340426, 'macro avg_recall': 0.06097560975609756, 'macro avg_f1-score': 0.07751937984496125, 'macro avg_support': 82.0, 'weighted avg_precision': 0.10638297872340426, 'weighted avg_recall': 0.06097560975609756, 'weighted avg_f1-score': 0.07751937984496125, 'weighted avg_support': 82.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 3}, {'micro_f1': 0.6840017628911415, 'Obfuscation-Vagueness-Confusion_precision': 0.1702127659574468, 'Obfuscation-Vagueness-Confusion_recall': 0.07079646017699115, 'Obfuscation-Vagueness-Confusion_f1-score': 0.1, 'Obfuscation-Vagueness-Confusion_support': 113.0, 'micro avg_precision': 0.1702127659574468, 'micro avg_recall': 0.07079646017699115, 'micro avg_f1-score': 0.1, 'micro avg_support': 113.0, 'macro avg_precision': 0.1702127659574468, 'macro avg_recall': 0.07079646017699115, 'macro avg_f1-score': 0.1, 'macro avg_support': 113.0, 'weighted avg_precision': 0.1702127659574468, 'weighted avg_recall': 0.07079646017699115, 'weighted avg_f1-score': 0.1, 'weighted avg_support': 113.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 4}, {'micro_f1': 0.7069193477302776, 'Obfuscation-Vagueness-Confusion_precision': 0.10638297872340426, 'Obfuscation-Vagueness-Confusion_recall': 0.05952380952380952, 'Obfuscation-Vagueness-Confusion_f1-score': 0.07633587786259542, 'Obfuscation-Vagueness-Confusion_support': 84.0, 'micro avg_precision': 0.10638297872340426, 'micro avg_recall': 0.05952380952380952, 'micro avg_f1-score': 0.07633587786259542, 'micro avg_support': 84.0, 'macro avg_precision': 0.10638297872340426, 'macro avg_recall': 0.05952380952380952, 'macro avg_f1-score': 0.07633587786259542, 'macro avg_support': 84.0, 'weighted avg_precision': 0.10638297872340427, 'weighted avg_recall': 0.05952380952380952, 'weighted avg_f1-score': 0.07633587786259542, 'weighted avg_support': 84.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 5}, {'micro_f1': 0.6963420008814456, 'Obfuscation-Vagueness-Confusion_precision': 0.1702127659574468, 'Obfuscation-Vagueness-Confusion_recall': 0.07920792079207921, 'Obfuscation-Vagueness-Confusion_f1-score': 0.10810810810810811, 'Obfuscation-Vagueness-Confusion_support': 101.0, 'micro avg_precision': 0.1702127659574468, 'micro avg_recall': 0.07920792079207921, 'micro avg_f1-score': 0.10810810810810811, 'micro avg_support': 101.0, 'macro avg_precision': 0.1702127659574468, 'macro avg_recall': 0.07920792079207921, 'macro avg_f1-score': 0.10810810810810811, 'macro avg_support': 101.0, 'weighted avg_precision': 0.1702127659574468, 'weighted avg_recall': 0.07920792079207921, 'weighted avg_f1-score': 0.10810810810810811, 'weighted avg_support': 101.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 6}, {'micro_f1': 0.6954605553107096, 'Obfuscation-Vagueness-Confusion_precision': 0.23404255319148937, 'Obfuscation-Vagueness-Confusion_recall': 0.10891089108910891, 'Obfuscation-Vagueness-Confusion_f1-score': 0.14864864864864866, 'Obfuscation-Vagueness-Confusion_support': 101.0, 'micro avg_precision': 0.23404255319148937, 'micro avg_recall': 0.10891089108910891, 'micro avg_f1-score': 0.14864864864864866, 'micro avg_support': 101.0, 'macro avg_precision': 0.23404255319148937, 'macro avg_recall': 0.10891089108910891, 'macro avg_f1-score': 0.14864864864864866, 'macro avg_support': 101.0, 'weighted avg_precision': 0.23404255319148937, 'weighted avg_recall': 0.10891089108910891, 'weighted avg_f1-score': 0.14864864864864866, 'weighted avg_support': 101.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 7}, {'micro_f1': 0.7086822388717496, 'Obfuscation-Vagueness-Confusion_precision': 0.10638297872340426, 'Obfuscation-Vagueness-Confusion_recall': 0.04716981132075472, 'Obfuscation-Vagueness-Confusion_f1-score': 0.06535947712418301, 'Obfuscation-Vagueness-Confusion_support': 106.0, 'micro avg_precision': 0.10638297872340426, 'micro avg_recall': 0.04716981132075472, 'micro avg_f1-score': 0.06535947712418301, 'micro avg_support': 106.0, 'macro avg_precision': 0.10638297872340426, 'macro avg_recall': 0.04716981132075472, 'macro avg_f1-score': 0.06535947712418301, 'macro avg_support': 106.0, 'weighted avg_precision': 0.10638297872340426, 'weighted avg_recall': 0.04716981132075472, 'weighted avg_f1-score': 0.06535947712418301, 'weighted avg_support': 106.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 8}, {'micro_f1': 0.6994270603790216, 'Obfuscation-Vagueness-Confusion_precision': 0.2127659574468085, 'Obfuscation-Vagueness-Confusion_recall': 0.10416666666666667, 'Obfuscation-Vagueness-Confusion_f1-score': 0.13986013986013987, 'Obfuscation-Vagueness-Confusion_support': 96.0, 'micro avg_precision': 0.2127659574468085, 'micro avg_recall': 0.10416666666666667, 'micro avg_f1-score': 0.13986013986013987, 'micro avg_support': 96.0, 'macro avg_precision': 0.2127659574468085, 'macro avg_recall': 0.10416666666666667, 'macro avg_f1-score': 0.13986013986013987, 'macro avg_support': 96.0, 'weighted avg_precision': 0.2127659574468085, 'weighted avg_recall': 0.10416666666666667, 'weighted avg_f1-score': 0.13986013986013987, 'weighted avg_support': 96.0, 'O_support': 1365, 'B-Obfuscation-Vagueness-Confusion_support': 47, 'I-Obfuscation-Vagueness-Confusion_support': 857, 'epoch': 9}]}
Early stopping triggered.
Saving model to directory: ./models/M2/2024-05-12-17-42-10_aug/mdeberta-v3-base_17_ME10_target=Obfuscation-Vagueness-Confusion_SUBSAMPLED_2024-05-12-17-42-10
Training model no. 18 of 23 for (18, 'Name_Calling-Labeling') persuasion technique...
{'micro_f1': 0.9378114842903575, 'Name_Calling-Labeling_precision': 0.2855392156862745, 'Name_Calling-Labeling_recall': 0.3546423135464231, 'Name_Calling-Labeling_f1-score': 0.3163611676849966, 'Name_Calling-Labeling_support': 657.0, 'micro avg_precision': 0.2855392156862745, 'micro avg_recall': 0.3546423135464231, 'micro avg_f1-score': 0.3163611676849966, 'micro avg_support': 657.0, 'macro avg_precision': 0.2855392156862745, 'macro avg_recall': 0.3546423135464231, 'macro avg_f1-score': 0.3163611676849966, 'macro avg_support': 657.0, 'weighted avg_precision': 0.2855392156862745, 'weighted avg_recall': 0.3546423135464231, 'weighted avg_f1-score': 0.3163611676849966, 'weighted avg_support': 657.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 0}
{'results': [{'micro_f1': 0.9378114842903575, 'Name_Calling-Labeling_precision': 0.2855392156862745, 'Name_Calling-Labeling_recall': 0.3546423135464231, 'Name_Calling-Labeling_f1-score': 0.3163611676849966, 'Name_Calling-Labeling_support': 657.0, 'micro avg_precision': 0.2855392156862745, 'micro avg_recall': 0.3546423135464231, 'micro avg_f1-score': 0.3163611676849966, 'micro avg_support': 657.0, 'macro avg_precision': 0.2855392156862745, 'macro avg_recall': 0.3546423135464231, 'macro avg_f1-score': 0.3163611676849966, 'macro avg_support': 657.0, 'weighted avg_precision': 0.2855392156862745, 'weighted avg_recall': 0.3546423135464231, 'weighted avg_f1-score': 0.3163611676849966, 'weighted avg_support': 657.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 0}]}
Best model updated: current epoch macro f1 = 0.3163611676849966
{'micro_f1': 0.9449311252128153, 'Name_Calling-Labeling_precision': 0.32107843137254904, 'Name_Calling-Labeling_recall': 0.4055727554179567, 'Name_Calling-Labeling_f1-score': 0.3584131326949385, 'Name_Calling-Labeling_support': 646.0, 'micro avg_precision': 0.32107843137254904, 'micro avg_recall': 0.4055727554179567, 'micro avg_f1-score': 0.3584131326949385, 'micro avg_support': 646.0, 'macro avg_precision': 0.32107843137254904, 'macro avg_recall': 0.4055727554179567, 'macro avg_f1-score': 0.3584131326949385, 'macro avg_support': 646.0, 'weighted avg_precision': 0.32107843137254904, 'weighted avg_recall': 0.4055727554179567, 'weighted avg_f1-score': 0.3584131326949385, 'weighted avg_support': 646.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 1}
{'results': [{'micro_f1': 0.9378114842903575, 'Name_Calling-Labeling_precision': 0.2855392156862745, 'Name_Calling-Labeling_recall': 0.3546423135464231, 'Name_Calling-Labeling_f1-score': 0.3163611676849966, 'Name_Calling-Labeling_support': 657.0, 'micro avg_precision': 0.2855392156862745, 'micro avg_recall': 0.3546423135464231, 'micro avg_f1-score': 0.3163611676849966, 'micro avg_support': 657.0, 'macro avg_precision': 0.2855392156862745, 'macro avg_recall': 0.3546423135464231, 'macro avg_f1-score': 0.3163611676849966, 'macro avg_support': 657.0, 'weighted avg_precision': 0.2855392156862745, 'weighted avg_recall': 0.3546423135464231, 'weighted avg_f1-score': 0.3163611676849966, 'weighted avg_support': 657.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 0}, {'micro_f1': 0.9449311252128153, 'Name_Calling-Labeling_precision': 0.32107843137254904, 'Name_Calling-Labeling_recall': 0.4055727554179567, 'Name_Calling-Labeling_f1-score': 0.3584131326949385, 'Name_Calling-Labeling_support': 646.0, 'micro avg_precision': 0.32107843137254904, 'micro avg_recall': 0.4055727554179567, 'micro avg_f1-score': 0.3584131326949385, 'micro avg_support': 646.0, 'macro avg_precision': 0.32107843137254904, 'macro avg_recall': 0.4055727554179567, 'macro avg_f1-score': 0.3584131326949385, 'macro avg_support': 646.0, 'weighted avg_precision': 0.32107843137254904, 'weighted avg_recall': 0.4055727554179567, 'weighted avg_f1-score': 0.3584131326949385, 'weighted avg_support': 646.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 1}]}
Best model updated: current epoch macro f1 = 0.3584131326949385
{'micro_f1': 0.9468503327658258, 'Name_Calling-Labeling_precision': 0.40441176470588236, 'Name_Calling-Labeling_recall': 0.4365079365079365, 'Name_Calling-Labeling_f1-score': 0.41984732824427484, 'Name_Calling-Labeling_support': 756.0, 'micro avg_precision': 0.40441176470588236, 'micro avg_recall': 0.4365079365079365, 'micro avg_f1-score': 0.41984732824427484, 'micro avg_support': 756.0, 'macro avg_precision': 0.40441176470588236, 'macro avg_recall': 0.4365079365079365, 'macro avg_f1-score': 0.41984732824427484, 'macro avg_support': 756.0, 'weighted avg_precision': 0.40441176470588236, 'weighted avg_recall': 0.4365079365079365, 'weighted avg_f1-score': 0.41984732824427484, 'weighted avg_support': 756.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 2}
{'results': [{'micro_f1': 0.9378114842903575, 'Name_Calling-Labeling_precision': 0.2855392156862745, 'Name_Calling-Labeling_recall': 0.3546423135464231, 'Name_Calling-Labeling_f1-score': 0.3163611676849966, 'Name_Calling-Labeling_support': 657.0, 'micro avg_precision': 0.2855392156862745, 'micro avg_recall': 0.3546423135464231, 'micro avg_f1-score': 0.3163611676849966, 'micro avg_support': 657.0, 'macro avg_precision': 0.2855392156862745, 'macro avg_recall': 0.3546423135464231, 'macro avg_f1-score': 0.3163611676849966, 'macro avg_support': 657.0, 'weighted avg_precision': 0.2855392156862745, 'weighted avg_recall': 0.3546423135464231, 'weighted avg_f1-score': 0.3163611676849966, 'weighted avg_support': 657.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 0}, {'micro_f1': 0.9449311252128153, 'Name_Calling-Labeling_precision': 0.32107843137254904, 'Name_Calling-Labeling_recall': 0.4055727554179567, 'Name_Calling-Labeling_f1-score': 0.3584131326949385, 'Name_Calling-Labeling_support': 646.0, 'micro avg_precision': 0.32107843137254904, 'micro avg_recall': 0.4055727554179567, 'micro avg_f1-score': 0.3584131326949385, 'micro avg_support': 646.0, 'macro avg_precision': 0.32107843137254904, 'macro avg_recall': 0.4055727554179567, 'macro avg_f1-score': 0.3584131326949385, 'macro avg_support': 646.0, 'weighted avg_precision': 0.32107843137254904, 'weighted avg_recall': 0.4055727554179567, 'weighted avg_f1-score': 0.3584131326949385, 'weighted avg_support': 646.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 1}, {'micro_f1': 0.9468503327658258, 'Name_Calling-Labeling_precision': 0.40441176470588236, 'Name_Calling-Labeling_recall': 0.4365079365079365, 'Name_Calling-Labeling_f1-score': 0.41984732824427484, 'Name_Calling-Labeling_support': 756.0, 'micro avg_precision': 0.40441176470588236, 'micro avg_recall': 0.4365079365079365, 'micro avg_f1-score': 0.41984732824427484, 'micro avg_support': 756.0, 'macro avg_precision': 0.40441176470588236, 'macro avg_recall': 0.4365079365079365, 'macro avg_f1-score': 0.41984732824427484, 'macro avg_support': 756.0, 'weighted avg_precision': 0.40441176470588236, 'weighted avg_recall': 0.4365079365079365, 'weighted avg_f1-score': 0.41984732824427484, 'weighted avg_support': 756.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 2}]}
Best model updated: current epoch macro f1 = 0.41984732824427484
{'micro_f1': 0.9440643863179075, 'Name_Calling-Labeling_precision': 0.3431372549019608, 'Name_Calling-Labeling_recall': 0.4628099173553719, 'Name_Calling-Labeling_f1-score': 0.3940886699507389, 'Name_Calling-Labeling_support': 605.0, 'micro avg_precision': 0.3431372549019608, 'micro avg_recall': 0.4628099173553719, 'micro avg_f1-score': 0.3940886699507389, 'micro avg_support': 605.0, 'macro avg_precision': 0.3431372549019608, 'macro avg_recall': 0.4628099173553719, 'macro avg_f1-score': 0.3940886699507389, 'macro avg_support': 605.0, 'weighted avg_precision': 0.3431372549019608, 'weighted avg_recall': 0.4628099173553719, 'weighted avg_f1-score': 0.3940886699507389, 'weighted avg_support': 605.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 3}
{'results': [{'micro_f1': 0.9378114842903575, 'Name_Calling-Labeling_precision': 0.2855392156862745, 'Name_Calling-Labeling_recall': 0.3546423135464231, 'Name_Calling-Labeling_f1-score': 0.3163611676849966, 'Name_Calling-Labeling_support': 657.0, 'micro avg_precision': 0.2855392156862745, 'micro avg_recall': 0.3546423135464231, 'micro avg_f1-score': 0.3163611676849966, 'micro avg_support': 657.0, 'macro avg_precision': 0.2855392156862745, 'macro avg_recall': 0.3546423135464231, 'macro avg_f1-score': 0.3163611676849966, 'macro avg_support': 657.0, 'weighted avg_precision': 0.2855392156862745, 'weighted avg_recall': 0.3546423135464231, 'weighted avg_f1-score': 0.3163611676849966, 'weighted avg_support': 657.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 0}, {'micro_f1': 0.9449311252128153, 'Name_Calling-Labeling_precision': 0.32107843137254904, 'Name_Calling-Labeling_recall': 0.4055727554179567, 'Name_Calling-Labeling_f1-score': 0.3584131326949385, 'Name_Calling-Labeling_support': 646.0, 'micro avg_precision': 0.32107843137254904, 'micro avg_recall': 0.4055727554179567, 'micro avg_f1-score': 0.3584131326949385, 'micro avg_support': 646.0, 'macro avg_precision': 0.32107843137254904, 'macro avg_recall': 0.4055727554179567, 'macro avg_f1-score': 0.3584131326949385, 'macro avg_support': 646.0, 'weighted avg_precision': 0.32107843137254904, 'weighted avg_recall': 0.4055727554179567, 'weighted avg_f1-score': 0.3584131326949385, 'weighted avg_support': 646.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 1}, {'micro_f1': 0.9468503327658258, 'Name_Calling-Labeling_precision': 0.40441176470588236, 'Name_Calling-Labeling_recall': 0.4365079365079365, 'Name_Calling-Labeling_f1-score': 0.41984732824427484, 'Name_Calling-Labeling_support': 756.0, 'micro avg_precision': 0.40441176470588236, 'micro avg_recall': 0.4365079365079365, 'micro avg_f1-score': 0.41984732824427484, 'micro avg_support': 756.0, 'macro avg_precision': 0.40441176470588236, 'macro avg_recall': 0.4365079365079365, 'macro avg_f1-score': 0.41984732824427484, 'macro avg_support': 756.0, 'weighted avg_precision': 0.40441176470588236, 'weighted avg_recall': 0.4365079365079365, 'weighted avg_f1-score': 0.41984732824427484, 'weighted avg_support': 756.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 2}, {'micro_f1': 0.9440643863179075, 'Name_Calling-Labeling_precision': 0.3431372549019608, 'Name_Calling-Labeling_recall': 0.4628099173553719, 'Name_Calling-Labeling_f1-score': 0.3940886699507389, 'Name_Calling-Labeling_support': 605.0, 'micro avg_precision': 0.3431372549019608, 'micro avg_recall': 0.4628099173553719, 'micro avg_f1-score': 0.3940886699507389, 'micro avg_support': 605.0, 'macro avg_precision': 0.3431372549019608, 'macro avg_recall': 0.4628099173553719, 'macro avg_f1-score': 0.3940886699507389, 'macro avg_support': 605.0, 'weighted avg_precision': 0.3431372549019608, 'weighted avg_recall': 0.4628099173553719, 'weighted avg_f1-score': 0.3940886699507389, 'weighted avg_support': 605.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 3}]}
{'micro_f1': 0.9473146571738121, 'Name_Calling-Labeling_precision': 0.4497549019607843, 'Name_Calling-Labeling_recall': 0.46455696202531643, 'Name_Calling-Labeling_f1-score': 0.45703611457036114, 'Name_Calling-Labeling_support': 790.0, 'micro avg_precision': 0.4497549019607843, 'micro avg_recall': 0.46455696202531643, 'micro avg_f1-score': 0.45703611457036114, 'micro avg_support': 790.0, 'macro avg_precision': 0.4497549019607843, 'macro avg_recall': 0.46455696202531643, 'macro avg_f1-score': 0.45703611457036114, 'macro avg_support': 790.0, 'weighted avg_precision': 0.4497549019607843, 'weighted avg_recall': 0.46455696202531643, 'weighted avg_f1-score': 0.45703611457036114, 'weighted avg_support': 790.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 4}
{'results': [{'micro_f1': 0.9378114842903575, 'Name_Calling-Labeling_precision': 0.2855392156862745, 'Name_Calling-Labeling_recall': 0.3546423135464231, 'Name_Calling-Labeling_f1-score': 0.3163611676849966, 'Name_Calling-Labeling_support': 657.0, 'micro avg_precision': 0.2855392156862745, 'micro avg_recall': 0.3546423135464231, 'micro avg_f1-score': 0.3163611676849966, 'micro avg_support': 657.0, 'macro avg_precision': 0.2855392156862745, 'macro avg_recall': 0.3546423135464231, 'macro avg_f1-score': 0.3163611676849966, 'macro avg_support': 657.0, 'weighted avg_precision': 0.2855392156862745, 'weighted avg_recall': 0.3546423135464231, 'weighted avg_f1-score': 0.3163611676849966, 'weighted avg_support': 657.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 0}, {'micro_f1': 0.9449311252128153, 'Name_Calling-Labeling_precision': 0.32107843137254904, 'Name_Calling-Labeling_recall': 0.4055727554179567, 'Name_Calling-Labeling_f1-score': 0.3584131326949385, 'Name_Calling-Labeling_support': 646.0, 'micro avg_precision': 0.32107843137254904, 'micro avg_recall': 0.4055727554179567, 'micro avg_f1-score': 0.3584131326949385, 'micro avg_support': 646.0, 'macro avg_precision': 0.32107843137254904, 'macro avg_recall': 0.4055727554179567, 'macro avg_f1-score': 0.3584131326949385, 'macro avg_support': 646.0, 'weighted avg_precision': 0.32107843137254904, 'weighted avg_recall': 0.4055727554179567, 'weighted avg_f1-score': 0.3584131326949385, 'weighted avg_support': 646.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 1}, {'micro_f1': 0.9468503327658258, 'Name_Calling-Labeling_precision': 0.40441176470588236, 'Name_Calling-Labeling_recall': 0.4365079365079365, 'Name_Calling-Labeling_f1-score': 0.41984732824427484, 'Name_Calling-Labeling_support': 756.0, 'micro avg_precision': 0.40441176470588236, 'micro avg_recall': 0.4365079365079365, 'micro avg_f1-score': 0.41984732824427484, 'micro avg_support': 756.0, 'macro avg_precision': 0.40441176470588236, 'macro avg_recall': 0.4365079365079365, 'macro avg_f1-score': 0.41984732824427484, 'macro avg_support': 756.0, 'weighted avg_precision': 0.40441176470588236, 'weighted avg_recall': 0.4365079365079365, 'weighted avg_f1-score': 0.41984732824427484, 'weighted avg_support': 756.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 2}, {'micro_f1': 0.9440643863179075, 'Name_Calling-Labeling_precision': 0.3431372549019608, 'Name_Calling-Labeling_recall': 0.4628099173553719, 'Name_Calling-Labeling_f1-score': 0.3940886699507389, 'Name_Calling-Labeling_support': 605.0, 'micro avg_precision': 0.3431372549019608, 'micro avg_recall': 0.4628099173553719, 'micro avg_f1-score': 0.3940886699507389, 'micro avg_support': 605.0, 'macro avg_precision': 0.3431372549019608, 'macro avg_recall': 0.4628099173553719, 'macro avg_f1-score': 0.3940886699507389, 'macro avg_support': 605.0, 'weighted avg_precision': 0.3431372549019608, 'weighted avg_recall': 0.4628099173553719, 'weighted avg_f1-score': 0.3940886699507389, 'weighted avg_support': 605.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 3}, {'micro_f1': 0.9473146571738121, 'Name_Calling-Labeling_precision': 0.4497549019607843, 'Name_Calling-Labeling_recall': 0.46455696202531643, 'Name_Calling-Labeling_f1-score': 0.45703611457036114, 'Name_Calling-Labeling_support': 790.0, 'micro avg_precision': 0.4497549019607843, 'micro avg_recall': 0.46455696202531643, 'micro avg_f1-score': 0.45703611457036114, 'micro avg_support': 790.0, 'macro avg_precision': 0.4497549019607843, 'macro avg_recall': 0.46455696202531643, 'macro avg_f1-score': 0.45703611457036114, 'macro avg_support': 790.0, 'weighted avg_precision': 0.4497549019607843, 'weighted avg_recall': 0.46455696202531643, 'weighted avg_f1-score': 0.45703611457036114, 'weighted avg_support': 790.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 4}]}
Best model updated: current epoch macro f1 = 0.45703611457036114
{'micro_f1': 0.9456121343445287, 'Name_Calling-Labeling_precision': 0.40931372549019607, 'Name_Calling-Labeling_recall': 0.4677871148459384, 'Name_Calling-Labeling_f1-score': 0.4366013071895425, 'Name_Calling-Labeling_support': 714.0, 'micro avg_precision': 0.40931372549019607, 'micro avg_recall': 0.4677871148459384, 'micro avg_f1-score': 0.4366013071895425, 'micro avg_support': 714.0, 'macro avg_precision': 0.40931372549019607, 'macro avg_recall': 0.4677871148459384, 'macro avg_f1-score': 0.4366013071895425, 'macro avg_support': 714.0, 'weighted avg_precision': 0.40931372549019607, 'weighted avg_recall': 0.4677871148459384, 'weighted avg_f1-score': 0.4366013071895425, 'weighted avg_support': 714.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 5}
{'results': [{'micro_f1': 0.9378114842903575, 'Name_Calling-Labeling_precision': 0.2855392156862745, 'Name_Calling-Labeling_recall': 0.3546423135464231, 'Name_Calling-Labeling_f1-score': 0.3163611676849966, 'Name_Calling-Labeling_support': 657.0, 'micro avg_precision': 0.2855392156862745, 'micro avg_recall': 0.3546423135464231, 'micro avg_f1-score': 0.3163611676849966, 'micro avg_support': 657.0, 'macro avg_precision': 0.2855392156862745, 'macro avg_recall': 0.3546423135464231, 'macro avg_f1-score': 0.3163611676849966, 'macro avg_support': 657.0, 'weighted avg_precision': 0.2855392156862745, 'weighted avg_recall': 0.3546423135464231, 'weighted avg_f1-score': 0.3163611676849966, 'weighted avg_support': 657.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 0}, {'micro_f1': 0.9449311252128153, 'Name_Calling-Labeling_precision': 0.32107843137254904, 'Name_Calling-Labeling_recall': 0.4055727554179567, 'Name_Calling-Labeling_f1-score': 0.3584131326949385, 'Name_Calling-Labeling_support': 646.0, 'micro avg_precision': 0.32107843137254904, 'micro avg_recall': 0.4055727554179567, 'micro avg_f1-score': 0.3584131326949385, 'micro avg_support': 646.0, 'macro avg_precision': 0.32107843137254904, 'macro avg_recall': 0.4055727554179567, 'macro avg_f1-score': 0.3584131326949385, 'macro avg_support': 646.0, 'weighted avg_precision': 0.32107843137254904, 'weighted avg_recall': 0.4055727554179567, 'weighted avg_f1-score': 0.3584131326949385, 'weighted avg_support': 646.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 1}, {'micro_f1': 0.9468503327658258, 'Name_Calling-Labeling_precision': 0.40441176470588236, 'Name_Calling-Labeling_recall': 0.4365079365079365, 'Name_Calling-Labeling_f1-score': 0.41984732824427484, 'Name_Calling-Labeling_support': 756.0, 'micro avg_precision': 0.40441176470588236, 'micro avg_recall': 0.4365079365079365, 'micro avg_f1-score': 0.41984732824427484, 'micro avg_support': 756.0, 'macro avg_precision': 0.40441176470588236, 'macro avg_recall': 0.4365079365079365, 'macro avg_f1-score': 0.41984732824427484, 'macro avg_support': 756.0, 'weighted avg_precision': 0.40441176470588236, 'weighted avg_recall': 0.4365079365079365, 'weighted avg_f1-score': 0.41984732824427484, 'weighted avg_support': 756.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 2}, {'micro_f1': 0.9440643863179075, 'Name_Calling-Labeling_precision': 0.3431372549019608, 'Name_Calling-Labeling_recall': 0.4628099173553719, 'Name_Calling-Labeling_f1-score': 0.3940886699507389, 'Name_Calling-Labeling_support': 605.0, 'micro avg_precision': 0.3431372549019608, 'micro avg_recall': 0.4628099173553719, 'micro avg_f1-score': 0.3940886699507389, 'micro avg_support': 605.0, 'macro avg_precision': 0.3431372549019608, 'macro avg_recall': 0.4628099173553719, 'macro avg_f1-score': 0.3940886699507389, 'macro avg_support': 605.0, 'weighted avg_precision': 0.3431372549019608, 'weighted avg_recall': 0.4628099173553719, 'weighted avg_f1-score': 0.3940886699507389, 'weighted avg_support': 605.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 3}, {'micro_f1': 0.9473146571738121, 'Name_Calling-Labeling_precision': 0.4497549019607843, 'Name_Calling-Labeling_recall': 0.46455696202531643, 'Name_Calling-Labeling_f1-score': 0.45703611457036114, 'Name_Calling-Labeling_support': 790.0, 'micro avg_precision': 0.4497549019607843, 'micro avg_recall': 0.46455696202531643, 'micro avg_f1-score': 0.45703611457036114, 'micro avg_support': 790.0, 'macro avg_precision': 0.4497549019607843, 'macro avg_recall': 0.46455696202531643, 'macro avg_f1-score': 0.45703611457036114, 'macro avg_support': 790.0, 'weighted avg_precision': 0.4497549019607843, 'weighted avg_recall': 0.46455696202531643, 'weighted avg_f1-score': 0.45703611457036114, 'weighted avg_support': 790.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 4}, {'micro_f1': 0.9456121343445287, 'Name_Calling-Labeling_precision': 0.40931372549019607, 'Name_Calling-Labeling_recall': 0.4677871148459384, 'Name_Calling-Labeling_f1-score': 0.4366013071895425, 'Name_Calling-Labeling_support': 714.0, 'micro avg_precision': 0.40931372549019607, 'micro avg_recall': 0.4677871148459384, 'micro avg_f1-score': 0.4366013071895425, 'micro avg_support': 714.0, 'macro avg_precision': 0.40931372549019607, 'macro avg_recall': 0.4677871148459384, 'macro avg_f1-score': 0.4366013071895425, 'macro avg_support': 714.0, 'weighted avg_precision': 0.40931372549019607, 'weighted avg_recall': 0.4677871148459384, 'weighted avg_f1-score': 0.4366013071895425, 'weighted avg_support': 714.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 5}]}
{'micro_f1': 0.9463240984367745, 'Name_Calling-Labeling_precision': 0.41544117647058826, 'Name_Calling-Labeling_recall': 0.5105421686746988, 'Name_Calling-Labeling_f1-score': 0.45810810810810815, 'Name_Calling-Labeling_support': 664.0, 'micro avg_precision': 0.41544117647058826, 'micro avg_recall': 0.5105421686746988, 'micro avg_f1-score': 0.45810810810810815, 'micro avg_support': 664.0, 'macro avg_precision': 0.41544117647058826, 'macro avg_recall': 0.5105421686746988, 'macro avg_f1-score': 0.45810810810810815, 'macro avg_support': 664.0, 'weighted avg_precision': 0.41544117647058826, 'weighted avg_recall': 0.5105421686746988, 'weighted avg_f1-score': 0.4581081081081082, 'weighted avg_support': 664.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 6}
{'results': [{'micro_f1': 0.9378114842903575, 'Name_Calling-Labeling_precision': 0.2855392156862745, 'Name_Calling-Labeling_recall': 0.3546423135464231, 'Name_Calling-Labeling_f1-score': 0.3163611676849966, 'Name_Calling-Labeling_support': 657.0, 'micro avg_precision': 0.2855392156862745, 'micro avg_recall': 0.3546423135464231, 'micro avg_f1-score': 0.3163611676849966, 'micro avg_support': 657.0, 'macro avg_precision': 0.2855392156862745, 'macro avg_recall': 0.3546423135464231, 'macro avg_f1-score': 0.3163611676849966, 'macro avg_support': 657.0, 'weighted avg_precision': 0.2855392156862745, 'weighted avg_recall': 0.3546423135464231, 'weighted avg_f1-score': 0.3163611676849966, 'weighted avg_support': 657.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 0}, {'micro_f1': 0.9449311252128153, 'Name_Calling-Labeling_precision': 0.32107843137254904, 'Name_Calling-Labeling_recall': 0.4055727554179567, 'Name_Calling-Labeling_f1-score': 0.3584131326949385, 'Name_Calling-Labeling_support': 646.0, 'micro avg_precision': 0.32107843137254904, 'micro avg_recall': 0.4055727554179567, 'micro avg_f1-score': 0.3584131326949385, 'micro avg_support': 646.0, 'macro avg_precision': 0.32107843137254904, 'macro avg_recall': 0.4055727554179567, 'macro avg_f1-score': 0.3584131326949385, 'macro avg_support': 646.0, 'weighted avg_precision': 0.32107843137254904, 'weighted avg_recall': 0.4055727554179567, 'weighted avg_f1-score': 0.3584131326949385, 'weighted avg_support': 646.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 1}, {'micro_f1': 0.9468503327658258, 'Name_Calling-Labeling_precision': 0.40441176470588236, 'Name_Calling-Labeling_recall': 0.4365079365079365, 'Name_Calling-Labeling_f1-score': 0.41984732824427484, 'Name_Calling-Labeling_support': 756.0, 'micro avg_precision': 0.40441176470588236, 'micro avg_recall': 0.4365079365079365, 'micro avg_f1-score': 0.41984732824427484, 'micro avg_support': 756.0, 'macro avg_precision': 0.40441176470588236, 'macro avg_recall': 0.4365079365079365, 'macro avg_f1-score': 0.41984732824427484, 'macro avg_support': 756.0, 'weighted avg_precision': 0.40441176470588236, 'weighted avg_recall': 0.4365079365079365, 'weighted avg_f1-score': 0.41984732824427484, 'weighted avg_support': 756.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 2}, {'micro_f1': 0.9440643863179075, 'Name_Calling-Labeling_precision': 0.3431372549019608, 'Name_Calling-Labeling_recall': 0.4628099173553719, 'Name_Calling-Labeling_f1-score': 0.3940886699507389, 'Name_Calling-Labeling_support': 605.0, 'micro avg_precision': 0.3431372549019608, 'micro avg_recall': 0.4628099173553719, 'micro avg_f1-score': 0.3940886699507389, 'micro avg_support': 605.0, 'macro avg_precision': 0.3431372549019608, 'macro avg_recall': 0.4628099173553719, 'macro avg_f1-score': 0.3940886699507389, 'macro avg_support': 605.0, 'weighted avg_precision': 0.3431372549019608, 'weighted avg_recall': 0.4628099173553719, 'weighted avg_f1-score': 0.3940886699507389, 'weighted avg_support': 605.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 3}, {'micro_f1': 0.9473146571738121, 'Name_Calling-Labeling_precision': 0.4497549019607843, 'Name_Calling-Labeling_recall': 0.46455696202531643, 'Name_Calling-Labeling_f1-score': 0.45703611457036114, 'Name_Calling-Labeling_support': 790.0, 'micro avg_precision': 0.4497549019607843, 'micro avg_recall': 0.46455696202531643, 'micro avg_f1-score': 0.45703611457036114, 'micro avg_support': 790.0, 'macro avg_precision': 0.4497549019607843, 'macro avg_recall': 0.46455696202531643, 'macro avg_f1-score': 0.45703611457036114, 'macro avg_support': 790.0, 'weighted avg_precision': 0.4497549019607843, 'weighted avg_recall': 0.46455696202531643, 'weighted avg_f1-score': 0.45703611457036114, 'weighted avg_support': 790.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 4}, {'micro_f1': 0.9456121343445287, 'Name_Calling-Labeling_precision': 0.40931372549019607, 'Name_Calling-Labeling_recall': 0.4677871148459384, 'Name_Calling-Labeling_f1-score': 0.4366013071895425, 'Name_Calling-Labeling_support': 714.0, 'micro avg_precision': 0.40931372549019607, 'micro avg_recall': 0.4677871148459384, 'micro avg_f1-score': 0.4366013071895425, 'micro avg_support': 714.0, 'macro avg_precision': 0.40931372549019607, 'macro avg_recall': 0.4677871148459384, 'macro avg_f1-score': 0.4366013071895425, 'macro avg_support': 714.0, 'weighted avg_precision': 0.40931372549019607, 'weighted avg_recall': 0.4677871148459384, 'weighted avg_f1-score': 0.4366013071895425, 'weighted avg_support': 714.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 5}, {'micro_f1': 0.9463240984367745, 'Name_Calling-Labeling_precision': 0.41544117647058826, 'Name_Calling-Labeling_recall': 0.5105421686746988, 'Name_Calling-Labeling_f1-score': 0.45810810810810815, 'Name_Calling-Labeling_support': 664.0, 'micro avg_precision': 0.41544117647058826, 'micro avg_recall': 0.5105421686746988, 'micro avg_f1-score': 0.45810810810810815, 'micro avg_support': 664.0, 'macro avg_precision': 0.41544117647058826, 'macro avg_recall': 0.5105421686746988, 'macro avg_f1-score': 0.45810810810810815, 'macro avg_support': 664.0, 'weighted avg_precision': 0.41544117647058826, 'weighted avg_recall': 0.5105421686746988, 'weighted avg_f1-score': 0.4581081081081082, 'weighted avg_support': 664.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 6}]}
Best model updated: current epoch macro f1 = 0.45810810810810815
{'micro_f1': 0.9469122426868906, 'Name_Calling-Labeling_precision': 0.49387254901960786, 'Name_Calling-Labeling_recall': 0.4610983981693364, 'Name_Calling-Labeling_f1-score': 0.47692307692307695, 'Name_Calling-Labeling_support': 874.0, 'micro avg_precision': 0.49387254901960786, 'micro avg_recall': 0.4610983981693364, 'micro avg_f1-score': 0.47692307692307695, 'micro avg_support': 874.0, 'macro avg_precision': 0.49387254901960786, 'macro avg_recall': 0.4610983981693364, 'macro avg_f1-score': 0.47692307692307695, 'macro avg_support': 874.0, 'weighted avg_precision': 0.49387254901960786, 'weighted avg_recall': 0.4610983981693364, 'weighted avg_f1-score': 0.47692307692307695, 'weighted avg_support': 874.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 7}
{'results': [{'micro_f1': 0.9378114842903575, 'Name_Calling-Labeling_precision': 0.2855392156862745, 'Name_Calling-Labeling_recall': 0.3546423135464231, 'Name_Calling-Labeling_f1-score': 0.3163611676849966, 'Name_Calling-Labeling_support': 657.0, 'micro avg_precision': 0.2855392156862745, 'micro avg_recall': 0.3546423135464231, 'micro avg_f1-score': 0.3163611676849966, 'micro avg_support': 657.0, 'macro avg_precision': 0.2855392156862745, 'macro avg_recall': 0.3546423135464231, 'macro avg_f1-score': 0.3163611676849966, 'macro avg_support': 657.0, 'weighted avg_precision': 0.2855392156862745, 'weighted avg_recall': 0.3546423135464231, 'weighted avg_f1-score': 0.3163611676849966, 'weighted avg_support': 657.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 0}, {'micro_f1': 0.9449311252128153, 'Name_Calling-Labeling_precision': 0.32107843137254904, 'Name_Calling-Labeling_recall': 0.4055727554179567, 'Name_Calling-Labeling_f1-score': 0.3584131326949385, 'Name_Calling-Labeling_support': 646.0, 'micro avg_precision': 0.32107843137254904, 'micro avg_recall': 0.4055727554179567, 'micro avg_f1-score': 0.3584131326949385, 'micro avg_support': 646.0, 'macro avg_precision': 0.32107843137254904, 'macro avg_recall': 0.4055727554179567, 'macro avg_f1-score': 0.3584131326949385, 'macro avg_support': 646.0, 'weighted avg_precision': 0.32107843137254904, 'weighted avg_recall': 0.4055727554179567, 'weighted avg_f1-score': 0.3584131326949385, 'weighted avg_support': 646.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 1}, {'micro_f1': 0.9468503327658258, 'Name_Calling-Labeling_precision': 0.40441176470588236, 'Name_Calling-Labeling_recall': 0.4365079365079365, 'Name_Calling-Labeling_f1-score': 0.41984732824427484, 'Name_Calling-Labeling_support': 756.0, 'micro avg_precision': 0.40441176470588236, 'micro avg_recall': 0.4365079365079365, 'micro avg_f1-score': 0.41984732824427484, 'micro avg_support': 756.0, 'macro avg_precision': 0.40441176470588236, 'macro avg_recall': 0.4365079365079365, 'macro avg_f1-score': 0.41984732824427484, 'macro avg_support': 756.0, 'weighted avg_precision': 0.40441176470588236, 'weighted avg_recall': 0.4365079365079365, 'weighted avg_f1-score': 0.41984732824427484, 'weighted avg_support': 756.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 2}, {'micro_f1': 0.9440643863179075, 'Name_Calling-Labeling_precision': 0.3431372549019608, 'Name_Calling-Labeling_recall': 0.4628099173553719, 'Name_Calling-Labeling_f1-score': 0.3940886699507389, 'Name_Calling-Labeling_support': 605.0, 'micro avg_precision': 0.3431372549019608, 'micro avg_recall': 0.4628099173553719, 'micro avg_f1-score': 0.3940886699507389, 'micro avg_support': 605.0, 'macro avg_precision': 0.3431372549019608, 'macro avg_recall': 0.4628099173553719, 'macro avg_f1-score': 0.3940886699507389, 'macro avg_support': 605.0, 'weighted avg_precision': 0.3431372549019608, 'weighted avg_recall': 0.4628099173553719, 'weighted avg_f1-score': 0.3940886699507389, 'weighted avg_support': 605.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 3}, {'micro_f1': 0.9473146571738121, 'Name_Calling-Labeling_precision': 0.4497549019607843, 'Name_Calling-Labeling_recall': 0.46455696202531643, 'Name_Calling-Labeling_f1-score': 0.45703611457036114, 'Name_Calling-Labeling_support': 790.0, 'micro avg_precision': 0.4497549019607843, 'micro avg_recall': 0.46455696202531643, 'micro avg_f1-score': 0.45703611457036114, 'micro avg_support': 790.0, 'macro avg_precision': 0.4497549019607843, 'macro avg_recall': 0.46455696202531643, 'macro avg_f1-score': 0.45703611457036114, 'macro avg_support': 790.0, 'weighted avg_precision': 0.4497549019607843, 'weighted avg_recall': 0.46455696202531643, 'weighted avg_f1-score': 0.45703611457036114, 'weighted avg_support': 790.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 4}, {'micro_f1': 0.9456121343445287, 'Name_Calling-Labeling_precision': 0.40931372549019607, 'Name_Calling-Labeling_recall': 0.4677871148459384, 'Name_Calling-Labeling_f1-score': 0.4366013071895425, 'Name_Calling-Labeling_support': 714.0, 'micro avg_precision': 0.40931372549019607, 'micro avg_recall': 0.4677871148459384, 'micro avg_f1-score': 0.4366013071895425, 'micro avg_support': 714.0, 'macro avg_precision': 0.40931372549019607, 'macro avg_recall': 0.4677871148459384, 'macro avg_f1-score': 0.4366013071895425, 'macro avg_support': 714.0, 'weighted avg_precision': 0.40931372549019607, 'weighted avg_recall': 0.4677871148459384, 'weighted avg_f1-score': 0.4366013071895425, 'weighted avg_support': 714.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 5}, {'micro_f1': 0.9463240984367745, 'Name_Calling-Labeling_precision': 0.41544117647058826, 'Name_Calling-Labeling_recall': 0.5105421686746988, 'Name_Calling-Labeling_f1-score': 0.45810810810810815, 'Name_Calling-Labeling_support': 664.0, 'micro avg_precision': 0.41544117647058826, 'micro avg_recall': 0.5105421686746988, 'micro avg_f1-score': 0.45810810810810815, 'micro avg_support': 664.0, 'macro avg_precision': 0.41544117647058826, 'macro avg_recall': 0.5105421686746988, 'macro avg_f1-score': 0.45810810810810815, 'macro avg_support': 664.0, 'weighted avg_precision': 0.41544117647058826, 'weighted avg_recall': 0.5105421686746988, 'weighted avg_f1-score': 0.4581081081081082, 'weighted avg_support': 664.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 6}, {'micro_f1': 0.9469122426868906, 'Name_Calling-Labeling_precision': 0.49387254901960786, 'Name_Calling-Labeling_recall': 0.4610983981693364, 'Name_Calling-Labeling_f1-score': 0.47692307692307695, 'Name_Calling-Labeling_support': 874.0, 'micro avg_precision': 0.49387254901960786, 'micro avg_recall': 0.4610983981693364, 'micro avg_f1-score': 0.47692307692307695, 'micro avg_support': 874.0, 'macro avg_precision': 0.49387254901960786, 'macro avg_recall': 0.4610983981693364, 'macro avg_f1-score': 0.47692307692307695, 'macro avg_support': 874.0, 'weighted avg_precision': 0.49387254901960786, 'weighted avg_recall': 0.4610983981693364, 'weighted avg_f1-score': 0.47692307692307695, 'weighted avg_support': 874.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 7}]}
Best model updated: current epoch macro f1 = 0.47692307692307695
{'micro_f1': 0.9473765670948769, 'Name_Calling-Labeling_precision': 0.4117647058823529, 'Name_Calling-Labeling_recall': 0.5029940119760479, 'Name_Calling-Labeling_f1-score': 0.45283018867924524, 'Name_Calling-Labeling_support': 668.0, 'micro avg_precision': 0.4117647058823529, 'micro avg_recall': 0.5029940119760479, 'micro avg_f1-score': 0.45283018867924524, 'micro avg_support': 668.0, 'macro avg_precision': 0.4117647058823529, 'macro avg_recall': 0.5029940119760479, 'macro avg_f1-score': 0.45283018867924524, 'macro avg_support': 668.0, 'weighted avg_precision': 0.4117647058823529, 'weighted avg_recall': 0.5029940119760479, 'weighted avg_f1-score': 0.4528301886792453, 'weighted avg_support': 668.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 8}
{'results': [{'micro_f1': 0.9378114842903575, 'Name_Calling-Labeling_precision': 0.2855392156862745, 'Name_Calling-Labeling_recall': 0.3546423135464231, 'Name_Calling-Labeling_f1-score': 0.3163611676849966, 'Name_Calling-Labeling_support': 657.0, 'micro avg_precision': 0.2855392156862745, 'micro avg_recall': 0.3546423135464231, 'micro avg_f1-score': 0.3163611676849966, 'micro avg_support': 657.0, 'macro avg_precision': 0.2855392156862745, 'macro avg_recall': 0.3546423135464231, 'macro avg_f1-score': 0.3163611676849966, 'macro avg_support': 657.0, 'weighted avg_precision': 0.2855392156862745, 'weighted avg_recall': 0.3546423135464231, 'weighted avg_f1-score': 0.3163611676849966, 'weighted avg_support': 657.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 0}, {'micro_f1': 0.9449311252128153, 'Name_Calling-Labeling_precision': 0.32107843137254904, 'Name_Calling-Labeling_recall': 0.4055727554179567, 'Name_Calling-Labeling_f1-score': 0.3584131326949385, 'Name_Calling-Labeling_support': 646.0, 'micro avg_precision': 0.32107843137254904, 'micro avg_recall': 0.4055727554179567, 'micro avg_f1-score': 0.3584131326949385, 'micro avg_support': 646.0, 'macro avg_precision': 0.32107843137254904, 'macro avg_recall': 0.4055727554179567, 'macro avg_f1-score': 0.3584131326949385, 'macro avg_support': 646.0, 'weighted avg_precision': 0.32107843137254904, 'weighted avg_recall': 0.4055727554179567, 'weighted avg_f1-score': 0.3584131326949385, 'weighted avg_support': 646.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 1}, {'micro_f1': 0.9468503327658258, 'Name_Calling-Labeling_precision': 0.40441176470588236, 'Name_Calling-Labeling_recall': 0.4365079365079365, 'Name_Calling-Labeling_f1-score': 0.41984732824427484, 'Name_Calling-Labeling_support': 756.0, 'micro avg_precision': 0.40441176470588236, 'micro avg_recall': 0.4365079365079365, 'micro avg_f1-score': 0.41984732824427484, 'micro avg_support': 756.0, 'macro avg_precision': 0.40441176470588236, 'macro avg_recall': 0.4365079365079365, 'macro avg_f1-score': 0.41984732824427484, 'macro avg_support': 756.0, 'weighted avg_precision': 0.40441176470588236, 'weighted avg_recall': 0.4365079365079365, 'weighted avg_f1-score': 0.41984732824427484, 'weighted avg_support': 756.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 2}, {'micro_f1': 0.9440643863179075, 'Name_Calling-Labeling_precision': 0.3431372549019608, 'Name_Calling-Labeling_recall': 0.4628099173553719, 'Name_Calling-Labeling_f1-score': 0.3940886699507389, 'Name_Calling-Labeling_support': 605.0, 'micro avg_precision': 0.3431372549019608, 'micro avg_recall': 0.4628099173553719, 'micro avg_f1-score': 0.3940886699507389, 'micro avg_support': 605.0, 'macro avg_precision': 0.3431372549019608, 'macro avg_recall': 0.4628099173553719, 'macro avg_f1-score': 0.3940886699507389, 'macro avg_support': 605.0, 'weighted avg_precision': 0.3431372549019608, 'weighted avg_recall': 0.4628099173553719, 'weighted avg_f1-score': 0.3940886699507389, 'weighted avg_support': 605.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 3}, {'micro_f1': 0.9473146571738121, 'Name_Calling-Labeling_precision': 0.4497549019607843, 'Name_Calling-Labeling_recall': 0.46455696202531643, 'Name_Calling-Labeling_f1-score': 0.45703611457036114, 'Name_Calling-Labeling_support': 790.0, 'micro avg_precision': 0.4497549019607843, 'micro avg_recall': 0.46455696202531643, 'micro avg_f1-score': 0.45703611457036114, 'micro avg_support': 790.0, 'macro avg_precision': 0.4497549019607843, 'macro avg_recall': 0.46455696202531643, 'macro avg_f1-score': 0.45703611457036114, 'macro avg_support': 790.0, 'weighted avg_precision': 0.4497549019607843, 'weighted avg_recall': 0.46455696202531643, 'weighted avg_f1-score': 0.45703611457036114, 'weighted avg_support': 790.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 4}, {'micro_f1': 0.9456121343445287, 'Name_Calling-Labeling_precision': 0.40931372549019607, 'Name_Calling-Labeling_recall': 0.4677871148459384, 'Name_Calling-Labeling_f1-score': 0.4366013071895425, 'Name_Calling-Labeling_support': 714.0, 'micro avg_precision': 0.40931372549019607, 'micro avg_recall': 0.4677871148459384, 'micro avg_f1-score': 0.4366013071895425, 'micro avg_support': 714.0, 'macro avg_precision': 0.40931372549019607, 'macro avg_recall': 0.4677871148459384, 'macro avg_f1-score': 0.4366013071895425, 'macro avg_support': 714.0, 'weighted avg_precision': 0.40931372549019607, 'weighted avg_recall': 0.4677871148459384, 'weighted avg_f1-score': 0.4366013071895425, 'weighted avg_support': 714.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 5}, {'micro_f1': 0.9463240984367745, 'Name_Calling-Labeling_precision': 0.41544117647058826, 'Name_Calling-Labeling_recall': 0.5105421686746988, 'Name_Calling-Labeling_f1-score': 0.45810810810810815, 'Name_Calling-Labeling_support': 664.0, 'micro avg_precision': 0.41544117647058826, 'micro avg_recall': 0.5105421686746988, 'micro avg_f1-score': 0.45810810810810815, 'micro avg_support': 664.0, 'macro avg_precision': 0.41544117647058826, 'macro avg_recall': 0.5105421686746988, 'macro avg_f1-score': 0.45810810810810815, 'macro avg_support': 664.0, 'weighted avg_precision': 0.41544117647058826, 'weighted avg_recall': 0.5105421686746988, 'weighted avg_f1-score': 0.4581081081081082, 'weighted avg_support': 664.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 6}, {'micro_f1': 0.9469122426868906, 'Name_Calling-Labeling_precision': 0.49387254901960786, 'Name_Calling-Labeling_recall': 0.4610983981693364, 'Name_Calling-Labeling_f1-score': 0.47692307692307695, 'Name_Calling-Labeling_support': 874.0, 'micro avg_precision': 0.49387254901960786, 'micro avg_recall': 0.4610983981693364, 'micro avg_f1-score': 0.47692307692307695, 'micro avg_support': 874.0, 'macro avg_precision': 0.49387254901960786, 'macro avg_recall': 0.4610983981693364, 'macro avg_f1-score': 0.47692307692307695, 'macro avg_support': 874.0, 'weighted avg_precision': 0.49387254901960786, 'weighted avg_recall': 0.4610983981693364, 'weighted avg_f1-score': 0.47692307692307695, 'weighted avg_support': 874.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 7}, {'micro_f1': 0.9473765670948769, 'Name_Calling-Labeling_precision': 0.4117647058823529, 'Name_Calling-Labeling_recall': 0.5029940119760479, 'Name_Calling-Labeling_f1-score': 0.45283018867924524, 'Name_Calling-Labeling_support': 668.0, 'micro avg_precision': 0.4117647058823529, 'micro avg_recall': 0.5029940119760479, 'micro avg_f1-score': 0.45283018867924524, 'micro avg_support': 668.0, 'macro avg_precision': 0.4117647058823529, 'macro avg_recall': 0.5029940119760479, 'macro avg_f1-score': 0.45283018867924524, 'macro avg_support': 668.0, 'weighted avg_precision': 0.4117647058823529, 'weighted avg_recall': 0.5029940119760479, 'weighted avg_f1-score': 0.4528301886792453, 'weighted avg_support': 668.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 8}]}
{'micro_f1': 0.938213898777279, 'Name_Calling-Labeling_precision': 0.4877450980392157, 'Name_Calling-Labeling_recall': 0.42887931034482757, 'Name_Calling-Labeling_f1-score': 0.45642201834862384, 'Name_Calling-Labeling_support': 928.0, 'micro avg_precision': 0.4877450980392157, 'micro avg_recall': 0.42887931034482757, 'micro avg_f1-score': 0.45642201834862384, 'micro avg_support': 928.0, 'macro avg_precision': 0.4877450980392157, 'macro avg_recall': 0.42887931034482757, 'macro avg_f1-score': 0.45642201834862384, 'macro avg_support': 928.0, 'weighted avg_precision': 0.4877450980392157, 'weighted avg_recall': 0.42887931034482757, 'weighted avg_f1-score': 0.45642201834862384, 'weighted avg_support': 928.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 9}
{'results': [{'micro_f1': 0.9378114842903575, 'Name_Calling-Labeling_precision': 0.2855392156862745, 'Name_Calling-Labeling_recall': 0.3546423135464231, 'Name_Calling-Labeling_f1-score': 0.3163611676849966, 'Name_Calling-Labeling_support': 657.0, 'micro avg_precision': 0.2855392156862745, 'micro avg_recall': 0.3546423135464231, 'micro avg_f1-score': 0.3163611676849966, 'micro avg_support': 657.0, 'macro avg_precision': 0.2855392156862745, 'macro avg_recall': 0.3546423135464231, 'macro avg_f1-score': 0.3163611676849966, 'macro avg_support': 657.0, 'weighted avg_precision': 0.2855392156862745, 'weighted avg_recall': 0.3546423135464231, 'weighted avg_f1-score': 0.3163611676849966, 'weighted avg_support': 657.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 0}, {'micro_f1': 0.9449311252128153, 'Name_Calling-Labeling_precision': 0.32107843137254904, 'Name_Calling-Labeling_recall': 0.4055727554179567, 'Name_Calling-Labeling_f1-score': 0.3584131326949385, 'Name_Calling-Labeling_support': 646.0, 'micro avg_precision': 0.32107843137254904, 'micro avg_recall': 0.4055727554179567, 'micro avg_f1-score': 0.3584131326949385, 'micro avg_support': 646.0, 'macro avg_precision': 0.32107843137254904, 'macro avg_recall': 0.4055727554179567, 'macro avg_f1-score': 0.3584131326949385, 'macro avg_support': 646.0, 'weighted avg_precision': 0.32107843137254904, 'weighted avg_recall': 0.4055727554179567, 'weighted avg_f1-score': 0.3584131326949385, 'weighted avg_support': 646.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 1}, {'micro_f1': 0.9468503327658258, 'Name_Calling-Labeling_precision': 0.40441176470588236, 'Name_Calling-Labeling_recall': 0.4365079365079365, 'Name_Calling-Labeling_f1-score': 0.41984732824427484, 'Name_Calling-Labeling_support': 756.0, 'micro avg_precision': 0.40441176470588236, 'micro avg_recall': 0.4365079365079365, 'micro avg_f1-score': 0.41984732824427484, 'micro avg_support': 756.0, 'macro avg_precision': 0.40441176470588236, 'macro avg_recall': 0.4365079365079365, 'macro avg_f1-score': 0.41984732824427484, 'macro avg_support': 756.0, 'weighted avg_precision': 0.40441176470588236, 'weighted avg_recall': 0.4365079365079365, 'weighted avg_f1-score': 0.41984732824427484, 'weighted avg_support': 756.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 2}, {'micro_f1': 0.9440643863179075, 'Name_Calling-Labeling_precision': 0.3431372549019608, 'Name_Calling-Labeling_recall': 0.4628099173553719, 'Name_Calling-Labeling_f1-score': 0.3940886699507389, 'Name_Calling-Labeling_support': 605.0, 'micro avg_precision': 0.3431372549019608, 'micro avg_recall': 0.4628099173553719, 'micro avg_f1-score': 0.3940886699507389, 'micro avg_support': 605.0, 'macro avg_precision': 0.3431372549019608, 'macro avg_recall': 0.4628099173553719, 'macro avg_f1-score': 0.3940886699507389, 'macro avg_support': 605.0, 'weighted avg_precision': 0.3431372549019608, 'weighted avg_recall': 0.4628099173553719, 'weighted avg_f1-score': 0.3940886699507389, 'weighted avg_support': 605.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 3}, {'micro_f1': 0.9473146571738121, 'Name_Calling-Labeling_precision': 0.4497549019607843, 'Name_Calling-Labeling_recall': 0.46455696202531643, 'Name_Calling-Labeling_f1-score': 0.45703611457036114, 'Name_Calling-Labeling_support': 790.0, 'micro avg_precision': 0.4497549019607843, 'micro avg_recall': 0.46455696202531643, 'micro avg_f1-score': 0.45703611457036114, 'micro avg_support': 790.0, 'macro avg_precision': 0.4497549019607843, 'macro avg_recall': 0.46455696202531643, 'macro avg_f1-score': 0.45703611457036114, 'macro avg_support': 790.0, 'weighted avg_precision': 0.4497549019607843, 'weighted avg_recall': 0.46455696202531643, 'weighted avg_f1-score': 0.45703611457036114, 'weighted avg_support': 790.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 4}, {'micro_f1': 0.9456121343445287, 'Name_Calling-Labeling_precision': 0.40931372549019607, 'Name_Calling-Labeling_recall': 0.4677871148459384, 'Name_Calling-Labeling_f1-score': 0.4366013071895425, 'Name_Calling-Labeling_support': 714.0, 'micro avg_precision': 0.40931372549019607, 'micro avg_recall': 0.4677871148459384, 'micro avg_f1-score': 0.4366013071895425, 'micro avg_support': 714.0, 'macro avg_precision': 0.40931372549019607, 'macro avg_recall': 0.4677871148459384, 'macro avg_f1-score': 0.4366013071895425, 'macro avg_support': 714.0, 'weighted avg_precision': 0.40931372549019607, 'weighted avg_recall': 0.4677871148459384, 'weighted avg_f1-score': 0.4366013071895425, 'weighted avg_support': 714.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 5}, {'micro_f1': 0.9463240984367745, 'Name_Calling-Labeling_precision': 0.41544117647058826, 'Name_Calling-Labeling_recall': 0.5105421686746988, 'Name_Calling-Labeling_f1-score': 0.45810810810810815, 'Name_Calling-Labeling_support': 664.0, 'micro avg_precision': 0.41544117647058826, 'micro avg_recall': 0.5105421686746988, 'micro avg_f1-score': 0.45810810810810815, 'micro avg_support': 664.0, 'macro avg_precision': 0.41544117647058826, 'macro avg_recall': 0.5105421686746988, 'macro avg_f1-score': 0.45810810810810815, 'macro avg_support': 664.0, 'weighted avg_precision': 0.41544117647058826, 'weighted avg_recall': 0.5105421686746988, 'weighted avg_f1-score': 0.4581081081081082, 'weighted avg_support': 664.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 6}, {'micro_f1': 0.9469122426868906, 'Name_Calling-Labeling_precision': 0.49387254901960786, 'Name_Calling-Labeling_recall': 0.4610983981693364, 'Name_Calling-Labeling_f1-score': 0.47692307692307695, 'Name_Calling-Labeling_support': 874.0, 'micro avg_precision': 0.49387254901960786, 'micro avg_recall': 0.4610983981693364, 'micro avg_f1-score': 0.47692307692307695, 'micro avg_support': 874.0, 'macro avg_precision': 0.49387254901960786, 'macro avg_recall': 0.4610983981693364, 'macro avg_f1-score': 0.47692307692307695, 'macro avg_support': 874.0, 'weighted avg_precision': 0.49387254901960786, 'weighted avg_recall': 0.4610983981693364, 'weighted avg_f1-score': 0.47692307692307695, 'weighted avg_support': 874.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 7}, {'micro_f1': 0.9473765670948769, 'Name_Calling-Labeling_precision': 0.4117647058823529, 'Name_Calling-Labeling_recall': 0.5029940119760479, 'Name_Calling-Labeling_f1-score': 0.45283018867924524, 'Name_Calling-Labeling_support': 668.0, 'micro avg_precision': 0.4117647058823529, 'micro avg_recall': 0.5029940119760479, 'micro avg_f1-score': 0.45283018867924524, 'micro avg_support': 668.0, 'macro avg_precision': 0.4117647058823529, 'macro avg_recall': 0.5029940119760479, 'macro avg_f1-score': 0.45283018867924524, 'macro avg_support': 668.0, 'weighted avg_precision': 0.4117647058823529, 'weighted avg_recall': 0.5029940119760479, 'weighted avg_f1-score': 0.4528301886792453, 'weighted avg_support': 668.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 8}, {'micro_f1': 0.938213898777279, 'Name_Calling-Labeling_precision': 0.4877450980392157, 'Name_Calling-Labeling_recall': 0.42887931034482757, 'Name_Calling-Labeling_f1-score': 0.45642201834862384, 'Name_Calling-Labeling_support': 928.0, 'micro avg_precision': 0.4877450980392157, 'micro avg_recall': 0.42887931034482757, 'micro avg_f1-score': 0.45642201834862384, 'micro avg_support': 928.0, 'macro avg_precision': 0.4877450980392157, 'macro avg_recall': 0.42887931034482757, 'macro avg_f1-score': 0.45642201834862384, 'macro avg_support': 928.0, 'weighted avg_precision': 0.4877450980392157, 'weighted avg_recall': 0.42887931034482757, 'weighted avg_f1-score': 0.45642201834862384, 'weighted avg_support': 928.0, 'O_support': 29272, 'B-Name_Calling-Labeling_support': 816, 'I-Name_Calling-Labeling_support': 2217, 'epoch': 9}]}
Early stopping triggered.
Saving model to directory: ./models/M2/2024-05-12-17-42-10_aug/mdeberta-v3-base_18_ME10_target=Name_Calling-Labeling_SUBSAMPLED_2024-05-12-17-42-10
Training model no. 19 of 23 for (19, 'Doubt') persuasion technique...
{'micro_f1': 0.7578425595341259, 'Doubt_precision': 0.24651810584958217, 'Doubt_recall': 0.16970278044103548, 'Doubt_f1-score': 0.2010221465076661, 'Doubt_support': 1043.0, 'micro avg_precision': 0.24651810584958217, 'micro avg_recall': 0.16970278044103548, 'micro avg_f1-score': 0.2010221465076661, 'micro avg_support': 1043.0, 'macro avg_precision': 0.24651810584958217, 'macro avg_recall': 0.16970278044103548, 'macro avg_f1-score': 0.2010221465076661, 'macro avg_support': 1043.0, 'weighted avg_precision': 0.24651810584958217, 'weighted avg_recall': 0.16970278044103548, 'weighted avg_f1-score': 0.2010221465076661, 'weighted avg_support': 1043.0, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'O_support': 16422, 'epoch': 0}
{'results': [{'micro_f1': 0.7578425595341259, 'Doubt_precision': 0.24651810584958217, 'Doubt_recall': 0.16970278044103548, 'Doubt_f1-score': 0.2010221465076661, 'Doubt_support': 1043.0, 'micro avg_precision': 0.24651810584958217, 'micro avg_recall': 0.16970278044103548, 'micro avg_f1-score': 0.2010221465076661, 'micro avg_support': 1043.0, 'macro avg_precision': 0.24651810584958217, 'macro avg_recall': 0.16970278044103548, 'macro avg_f1-score': 0.2010221465076661, 'macro avg_support': 1043.0, 'weighted avg_precision': 0.24651810584958217, 'weighted avg_recall': 0.16970278044103548, 'weighted avg_f1-score': 0.2010221465076661, 'weighted avg_support': 1043.0, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'O_support': 16422, 'epoch': 0}]}
Best model updated: current epoch macro f1 = 0.2010221465076661
{'micro_f1': 0.7615515269160109, 'Doubt_precision': 0.24512534818941503, 'Doubt_recall': 0.19555555555555557, 'Doubt_f1-score': 0.21755253399258345, 'Doubt_support': 900.0, 'micro avg_precision': 0.24512534818941503, 'micro avg_recall': 0.19555555555555557, 'micro avg_f1-score': 0.21755253399258345, 'micro avg_support': 900.0, 'macro avg_precision': 0.24512534818941503, 'macro avg_recall': 0.19555555555555557, 'macro avg_f1-score': 0.21755253399258345, 'macro avg_support': 900.0, 'weighted avg_precision': 0.24512534818941503, 'weighted avg_recall': 0.19555555555555557, 'weighted avg_f1-score': 0.21755253399258345, 'weighted avg_support': 900.0, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'O_support': 16422, 'epoch': 1}
{'results': [{'micro_f1': 0.7578425595341259, 'Doubt_precision': 0.24651810584958217, 'Doubt_recall': 0.16970278044103548, 'Doubt_f1-score': 0.2010221465076661, 'Doubt_support': 1043.0, 'micro avg_precision': 0.24651810584958217, 'micro avg_recall': 0.16970278044103548, 'micro avg_f1-score': 0.2010221465076661, 'micro avg_support': 1043.0, 'macro avg_precision': 0.24651810584958217, 'macro avg_recall': 0.16970278044103548, 'macro avg_f1-score': 0.2010221465076661, 'macro avg_support': 1043.0, 'weighted avg_precision': 0.24651810584958217, 'weighted avg_recall': 0.16970278044103548, 'weighted avg_f1-score': 0.2010221465076661, 'weighted avg_support': 1043.0, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'O_support': 16422, 'epoch': 0}, {'micro_f1': 0.7615515269160109, 'Doubt_precision': 0.24512534818941503, 'Doubt_recall': 0.19555555555555557, 'Doubt_f1-score': 0.21755253399258345, 'Doubt_support': 900.0, 'micro avg_precision': 0.24512534818941503, 'micro avg_recall': 0.19555555555555557, 'micro avg_f1-score': 0.21755253399258345, 'micro avg_support': 900.0, 'macro avg_precision': 0.24512534818941503, 'macro avg_recall': 0.19555555555555557, 'macro avg_f1-score': 0.21755253399258345, 'macro avg_support': 900.0, 'weighted avg_precision': 0.24512534818941503, 'weighted avg_recall': 0.19555555555555557, 'weighted avg_f1-score': 0.21755253399258345, 'weighted avg_support': 900.0, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'O_support': 16422, 'epoch': 1}]}
Best model updated: current epoch macro f1 = 0.21755253399258345
{'micro_f1': 0.7633193524905543, 'Doubt_precision': 0.2883008356545961, 'Doubt_recall': 0.21789473684210525, 'Doubt_f1-score': 0.24820143884892082, 'Doubt_support': 950.0, 'micro avg_precision': 0.2883008356545961, 'micro avg_recall': 0.21789473684210525, 'micro avg_f1-score': 0.24820143884892082, 'micro avg_support': 950.0, 'macro avg_precision': 0.2883008356545961, 'macro avg_recall': 0.21789473684210525, 'macro avg_f1-score': 0.24820143884892082, 'macro avg_support': 950.0, 'weighted avg_precision': 0.2883008356545961, 'weighted avg_recall': 0.21789473684210525, 'weighted avg_f1-score': 0.24820143884892085, 'weighted avg_support': 950.0, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'O_support': 16422, 'epoch': 2}
{'results': [{'micro_f1': 0.7578425595341259, 'Doubt_precision': 0.24651810584958217, 'Doubt_recall': 0.16970278044103548, 'Doubt_f1-score': 0.2010221465076661, 'Doubt_support': 1043.0, 'micro avg_precision': 0.24651810584958217, 'micro avg_recall': 0.16970278044103548, 'micro avg_f1-score': 0.2010221465076661, 'micro avg_support': 1043.0, 'macro avg_precision': 0.24651810584958217, 'macro avg_recall': 0.16970278044103548, 'macro avg_f1-score': 0.2010221465076661, 'macro avg_support': 1043.0, 'weighted avg_precision': 0.24651810584958217, 'weighted avg_recall': 0.16970278044103548, 'weighted avg_f1-score': 0.2010221465076661, 'weighted avg_support': 1043.0, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'O_support': 16422, 'epoch': 0}, {'micro_f1': 0.7615515269160109, 'Doubt_precision': 0.24512534818941503, 'Doubt_recall': 0.19555555555555557, 'Doubt_f1-score': 0.21755253399258345, 'Doubt_support': 900.0, 'micro avg_precision': 0.24512534818941503, 'micro avg_recall': 0.19555555555555557, 'micro avg_f1-score': 0.21755253399258345, 'micro avg_support': 900.0, 'macro avg_precision': 0.24512534818941503, 'macro avg_recall': 0.19555555555555557, 'macro avg_f1-score': 0.21755253399258345, 'macro avg_support': 900.0, 'weighted avg_precision': 0.24512534818941503, 'weighted avg_recall': 0.19555555555555557, 'weighted avg_f1-score': 0.21755253399258345, 'weighted avg_support': 900.0, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'O_support': 16422, 'epoch': 1}, {'micro_f1': 0.7633193524905543, 'Doubt_precision': 0.2883008356545961, 'Doubt_recall': 0.21789473684210525, 'Doubt_f1-score': 0.24820143884892082, 'Doubt_support': 950.0, 'micro avg_precision': 0.2883008356545961, 'micro avg_recall': 0.21789473684210525, 'micro avg_f1-score': 0.24820143884892082, 'micro avg_support': 950.0, 'macro avg_precision': 0.2883008356545961, 'macro avg_recall': 0.21789473684210525, 'macro avg_f1-score': 0.24820143884892082, 'macro avg_support': 950.0, 'weighted avg_precision': 0.2883008356545961, 'weighted avg_recall': 0.21789473684210525, 'weighted avg_f1-score': 0.24820143884892085, 'weighted avg_support': 950.0, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'O_support': 16422, 'epoch': 2}]}
Best model updated: current epoch macro f1 = 0.24820143884892082
{'micro_f1': 0.7597837013414676, 'Doubt_precision': 0.2994428969359331, 'Doubt_recall': 0.2817824377457405, 'Doubt_f1-score': 0.29034436191762325, 'Doubt_support': 763.0, 'micro avg_precision': 0.2994428969359331, 'micro avg_recall': 0.2817824377457405, 'micro avg_f1-score': 0.29034436191762325, 'micro avg_support': 763.0, 'macro avg_precision': 0.2994428969359331, 'macro avg_recall': 0.2817824377457405, 'macro avg_f1-score': 0.29034436191762325, 'macro avg_support': 763.0, 'weighted avg_precision': 0.2994428969359331, 'weighted avg_recall': 0.2817824377457405, 'weighted avg_f1-score': 0.29034436191762325, 'weighted avg_support': 763.0, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'O_support': 16422, 'epoch': 3}
{'results': [{'micro_f1': 0.7578425595341259, 'Doubt_precision': 0.24651810584958217, 'Doubt_recall': 0.16970278044103548, 'Doubt_f1-score': 0.2010221465076661, 'Doubt_support': 1043.0, 'micro avg_precision': 0.24651810584958217, 'micro avg_recall': 0.16970278044103548, 'micro avg_f1-score': 0.2010221465076661, 'micro avg_support': 1043.0, 'macro avg_precision': 0.24651810584958217, 'macro avg_recall': 0.16970278044103548, 'macro avg_f1-score': 0.2010221465076661, 'macro avg_support': 1043.0, 'weighted avg_precision': 0.24651810584958217, 'weighted avg_recall': 0.16970278044103548, 'weighted avg_f1-score': 0.2010221465076661, 'weighted avg_support': 1043.0, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'O_support': 16422, 'epoch': 0}, {'micro_f1': 0.7615515269160109, 'Doubt_precision': 0.24512534818941503, 'Doubt_recall': 0.19555555555555557, 'Doubt_f1-score': 0.21755253399258345, 'Doubt_support': 900.0, 'micro avg_precision': 0.24512534818941503, 'micro avg_recall': 0.19555555555555557, 'micro avg_f1-score': 0.21755253399258345, 'micro avg_support': 900.0, 'macro avg_precision': 0.24512534818941503, 'macro avg_recall': 0.19555555555555557, 'macro avg_f1-score': 0.21755253399258345, 'macro avg_support': 900.0, 'weighted avg_precision': 0.24512534818941503, 'weighted avg_recall': 0.19555555555555557, 'weighted avg_f1-score': 0.21755253399258345, 'weighted avg_support': 900.0, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'O_support': 16422, 'epoch': 1}, {'micro_f1': 0.7633193524905543, 'Doubt_precision': 0.2883008356545961, 'Doubt_recall': 0.21789473684210525, 'Doubt_f1-score': 0.24820143884892082, 'Doubt_support': 950.0, 'micro avg_precision': 0.2883008356545961, 'micro avg_recall': 0.21789473684210525, 'micro avg_f1-score': 0.24820143884892082, 'micro avg_support': 950.0, 'macro avg_precision': 0.2883008356545961, 'macro avg_recall': 0.21789473684210525, 'macro avg_f1-score': 0.24820143884892082, 'macro avg_support': 950.0, 'weighted avg_precision': 0.2883008356545961, 'weighted avg_recall': 0.21789473684210525, 'weighted avg_f1-score': 0.24820143884892085, 'weighted avg_support': 950.0, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'O_support': 16422, 'epoch': 2}, {'micro_f1': 0.7597837013414676, 'Doubt_precision': 0.2994428969359331, 'Doubt_recall': 0.2817824377457405, 'Doubt_f1-score': 0.29034436191762325, 'Doubt_support': 763.0, 'micro avg_precision': 0.2994428969359331, 'micro avg_recall': 0.2817824377457405, 'micro avg_f1-score': 0.29034436191762325, 'micro avg_support': 763.0, 'macro avg_precision': 0.2994428969359331, 'macro avg_recall': 0.2817824377457405, 'macro avg_f1-score': 0.29034436191762325, 'macro avg_support': 763.0, 'weighted avg_precision': 0.2994428969359331, 'weighted avg_recall': 0.2817824377457405, 'weighted avg_f1-score': 0.29034436191762325, 'weighted avg_support': 763.0, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'O_support': 16422, 'epoch': 3}]}
Best model updated: current epoch macro f1 = 0.29034436191762325
{'micro_f1': 0.760164997053624, 'Doubt_precision': 0.3802228412256267, 'Doubt_recall': 0.29354838709677417, 'Doubt_f1-score': 0.33131067961165045, 'Doubt_support': 930.0, 'micro avg_precision': 0.3802228412256267, 'micro avg_recall': 0.29354838709677417, 'micro avg_f1-score': 0.33131067961165045, 'micro avg_support': 930.0, 'macro avg_precision': 0.3802228412256267, 'macro avg_recall': 0.29354838709677417, 'macro avg_f1-score': 0.33131067961165045, 'macro avg_support': 930.0, 'weighted avg_precision': 0.3802228412256267, 'weighted avg_recall': 0.29354838709677417, 'weighted avg_f1-score': 0.33131067961165045, 'weighted avg_support': 930.0, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'O_support': 16422, 'epoch': 4}
{'results': [{'micro_f1': 0.7578425595341259, 'Doubt_precision': 0.24651810584958217, 'Doubt_recall': 0.16970278044103548, 'Doubt_f1-score': 0.2010221465076661, 'Doubt_support': 1043.0, 'micro avg_precision': 0.24651810584958217, 'micro avg_recall': 0.16970278044103548, 'micro avg_f1-score': 0.2010221465076661, 'micro avg_support': 1043.0, 'macro avg_precision': 0.24651810584958217, 'macro avg_recall': 0.16970278044103548, 'macro avg_f1-score': 0.2010221465076661, 'macro avg_support': 1043.0, 'weighted avg_precision': 0.24651810584958217, 'weighted avg_recall': 0.16970278044103548, 'weighted avg_f1-score': 0.2010221465076661, 'weighted avg_support': 1043.0, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'O_support': 16422, 'epoch': 0}, {'micro_f1': 0.7615515269160109, 'Doubt_precision': 0.24512534818941503, 'Doubt_recall': 0.19555555555555557, 'Doubt_f1-score': 0.21755253399258345, 'Doubt_support': 900.0, 'micro avg_precision': 0.24512534818941503, 'micro avg_recall': 0.19555555555555557, 'micro avg_f1-score': 0.21755253399258345, 'micro avg_support': 900.0, 'macro avg_precision': 0.24512534818941503, 'macro avg_recall': 0.19555555555555557, 'macro avg_f1-score': 0.21755253399258345, 'macro avg_support': 900.0, 'weighted avg_precision': 0.24512534818941503, 'weighted avg_recall': 0.19555555555555557, 'weighted avg_f1-score': 0.21755253399258345, 'weighted avg_support': 900.0, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'O_support': 16422, 'epoch': 1}, {'micro_f1': 0.7633193524905543, 'Doubt_precision': 0.2883008356545961, 'Doubt_recall': 0.21789473684210525, 'Doubt_f1-score': 0.24820143884892082, 'Doubt_support': 950.0, 'micro avg_precision': 0.2883008356545961, 'micro avg_recall': 0.21789473684210525, 'micro avg_f1-score': 0.24820143884892082, 'micro avg_support': 950.0, 'macro avg_precision': 0.2883008356545961, 'macro avg_recall': 0.21789473684210525, 'macro avg_f1-score': 0.24820143884892082, 'macro avg_support': 950.0, 'weighted avg_precision': 0.2883008356545961, 'weighted avg_recall': 0.21789473684210525, 'weighted avg_f1-score': 0.24820143884892085, 'weighted avg_support': 950.0, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'O_support': 16422, 'epoch': 2}, {'micro_f1': 0.7597837013414676, 'Doubt_precision': 0.2994428969359331, 'Doubt_recall': 0.2817824377457405, 'Doubt_f1-score': 0.29034436191762325, 'Doubt_support': 763.0, 'micro avg_precision': 0.2994428969359331, 'micro avg_recall': 0.2817824377457405, 'micro avg_f1-score': 0.29034436191762325, 'micro avg_support': 763.0, 'macro avg_precision': 0.2994428969359331, 'macro avg_recall': 0.2817824377457405, 'macro avg_f1-score': 0.29034436191762325, 'macro avg_support': 763.0, 'weighted avg_precision': 0.2994428969359331, 'weighted avg_recall': 0.2817824377457405, 'weighted avg_f1-score': 0.29034436191762325, 'weighted avg_support': 763.0, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'O_support': 16422, 'epoch': 3}, {'micro_f1': 0.760164997053624, 'Doubt_precision': 0.3802228412256267, 'Doubt_recall': 0.29354838709677417, 'Doubt_f1-score': 0.33131067961165045, 'Doubt_support': 930.0, 'micro avg_precision': 0.3802228412256267, 'micro avg_recall': 0.29354838709677417, 'micro avg_f1-score': 0.33131067961165045, 'micro avg_support': 930.0, 'macro avg_precision': 0.3802228412256267, 'macro avg_recall': 0.29354838709677417, 'macro avg_f1-score': 0.33131067961165045, 'macro avg_support': 930.0, 'weighted avg_precision': 0.3802228412256267, 'weighted avg_recall': 0.29354838709677417, 'weighted avg_f1-score': 0.33131067961165045, 'weighted avg_support': 930.0, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'O_support': 16422, 'epoch': 4}]}
Best model updated: current epoch macro f1 = 0.33131067961165045
{'micro_f1': 0.7701133488162503, 'Doubt_precision': 0.3635097493036212, 'Doubt_recall': 0.29965556831228474, 'Doubt_f1-score': 0.328508495909377, 'Doubt_support': 871.0, 'micro avg_precision': 0.3635097493036212, 'micro avg_recall': 0.29965556831228474, 'micro avg_f1-score': 0.328508495909377, 'micro avg_support': 871.0, 'macro avg_precision': 0.3635097493036212, 'macro avg_recall': 0.29965556831228474, 'macro avg_f1-score': 0.328508495909377, 'macro avg_support': 871.0, 'weighted avg_precision': 0.36350974930362123, 'weighted avg_recall': 0.29965556831228474, 'weighted avg_f1-score': 0.328508495909377, 'weighted avg_support': 871.0, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'O_support': 16422, 'epoch': 5}
{'results': [{'micro_f1': 0.7578425595341259, 'Doubt_precision': 0.24651810584958217, 'Doubt_recall': 0.16970278044103548, 'Doubt_f1-score': 0.2010221465076661, 'Doubt_support': 1043.0, 'micro avg_precision': 0.24651810584958217, 'micro avg_recall': 0.16970278044103548, 'micro avg_f1-score': 0.2010221465076661, 'micro avg_support': 1043.0, 'macro avg_precision': 0.24651810584958217, 'macro avg_recall': 0.16970278044103548, 'macro avg_f1-score': 0.2010221465076661, 'macro avg_support': 1043.0, 'weighted avg_precision': 0.24651810584958217, 'weighted avg_recall': 0.16970278044103548, 'weighted avg_f1-score': 0.2010221465076661, 'weighted avg_support': 1043.0, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'O_support': 16422, 'epoch': 0}, {'micro_f1': 0.7615515269160109, 'Doubt_precision': 0.24512534818941503, 'Doubt_recall': 0.19555555555555557, 'Doubt_f1-score': 0.21755253399258345, 'Doubt_support': 900.0, 'micro avg_precision': 0.24512534818941503, 'micro avg_recall': 0.19555555555555557, 'micro avg_f1-score': 0.21755253399258345, 'micro avg_support': 900.0, 'macro avg_precision': 0.24512534818941503, 'macro avg_recall': 0.19555555555555557, 'macro avg_f1-score': 0.21755253399258345, 'macro avg_support': 900.0, 'weighted avg_precision': 0.24512534818941503, 'weighted avg_recall': 0.19555555555555557, 'weighted avg_f1-score': 0.21755253399258345, 'weighted avg_support': 900.0, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'O_support': 16422, 'epoch': 1}, {'micro_f1': 0.7633193524905543, 'Doubt_precision': 0.2883008356545961, 'Doubt_recall': 0.21789473684210525, 'Doubt_f1-score': 0.24820143884892082, 'Doubt_support': 950.0, 'micro avg_precision': 0.2883008356545961, 'micro avg_recall': 0.21789473684210525, 'micro avg_f1-score': 0.24820143884892082, 'micro avg_support': 950.0, 'macro avg_precision': 0.2883008356545961, 'macro avg_recall': 0.21789473684210525, 'macro avg_f1-score': 0.24820143884892082, 'macro avg_support': 950.0, 'weighted avg_precision': 0.2883008356545961, 'weighted avg_recall': 0.21789473684210525, 'weighted avg_f1-score': 0.24820143884892085, 'weighted avg_support': 950.0, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'O_support': 16422, 'epoch': 2}, {'micro_f1': 0.7597837013414676, 'Doubt_precision': 0.2994428969359331, 'Doubt_recall': 0.2817824377457405, 'Doubt_f1-score': 0.29034436191762325, 'Doubt_support': 763.0, 'micro avg_precision': 0.2994428969359331, 'micro avg_recall': 0.2817824377457405, 'micro avg_f1-score': 0.29034436191762325, 'micro avg_support': 763.0, 'macro avg_precision': 0.2994428969359331, 'macro avg_recall': 0.2817824377457405, 'macro avg_f1-score': 0.29034436191762325, 'macro avg_support': 763.0, 'weighted avg_precision': 0.2994428969359331, 'weighted avg_recall': 0.2817824377457405, 'weighted avg_f1-score': 0.29034436191762325, 'weighted avg_support': 763.0, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'O_support': 16422, 'epoch': 3}, {'micro_f1': 0.760164997053624, 'Doubt_precision': 0.3802228412256267, 'Doubt_recall': 0.29354838709677417, 'Doubt_f1-score': 0.33131067961165045, 'Doubt_support': 930.0, 'micro avg_precision': 0.3802228412256267, 'micro avg_recall': 0.29354838709677417, 'micro avg_f1-score': 0.33131067961165045, 'micro avg_support': 930.0, 'macro avg_precision': 0.3802228412256267, 'macro avg_recall': 0.29354838709677417, 'macro avg_f1-score': 0.33131067961165045, 'macro avg_support': 930.0, 'weighted avg_precision': 0.3802228412256267, 'weighted avg_recall': 0.29354838709677417, 'weighted avg_f1-score': 0.33131067961165045, 'weighted avg_support': 930.0, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'O_support': 16422, 'epoch': 4}, {'micro_f1': 0.7701133488162503, 'Doubt_precision': 0.3635097493036212, 'Doubt_recall': 0.29965556831228474, 'Doubt_f1-score': 0.328508495909377, 'Doubt_support': 871.0, 'micro avg_precision': 0.3635097493036212, 'micro avg_recall': 0.29965556831228474, 'micro avg_f1-score': 0.328508495909377, 'micro avg_support': 871.0, 'macro avg_precision': 0.3635097493036212, 'macro avg_recall': 0.29965556831228474, 'macro avg_f1-score': 0.328508495909377, 'macro avg_support': 871.0, 'weighted avg_precision': 0.36350974930362123, 'weighted avg_recall': 0.29965556831228474, 'weighted avg_f1-score': 0.328508495909377, 'weighted avg_support': 871.0, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'O_support': 16422, 'epoch': 5}]}
{'micro_f1': 0.7679295642829906, 'Doubt_precision': 0.34818941504178275, 'Doubt_recall': 0.2738225629791895, 'Doubt_f1-score': 0.30656039239730226, 'Doubt_support': 913.0, 'micro avg_precision': 0.34818941504178275, 'micro avg_recall': 0.2738225629791895, 'micro avg_f1-score': 0.30656039239730226, 'micro avg_support': 913.0, 'macro avg_precision': 0.34818941504178275, 'macro avg_recall': 0.2738225629791895, 'macro avg_f1-score': 0.30656039239730226, 'macro avg_support': 913.0, 'weighted avg_precision': 0.34818941504178275, 'weighted avg_recall': 0.2738225629791895, 'weighted avg_f1-score': 0.30656039239730226, 'weighted avg_support': 913.0, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'O_support': 16422, 'epoch': 6}
{'results': [{'micro_f1': 0.7578425595341259, 'Doubt_precision': 0.24651810584958217, 'Doubt_recall': 0.16970278044103548, 'Doubt_f1-score': 0.2010221465076661, 'Doubt_support': 1043.0, 'micro avg_precision': 0.24651810584958217, 'micro avg_recall': 0.16970278044103548, 'micro avg_f1-score': 0.2010221465076661, 'micro avg_support': 1043.0, 'macro avg_precision': 0.24651810584958217, 'macro avg_recall': 0.16970278044103548, 'macro avg_f1-score': 0.2010221465076661, 'macro avg_support': 1043.0, 'weighted avg_precision': 0.24651810584958217, 'weighted avg_recall': 0.16970278044103548, 'weighted avg_f1-score': 0.2010221465076661, 'weighted avg_support': 1043.0, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'O_support': 16422, 'epoch': 0}, {'micro_f1': 0.7615515269160109, 'Doubt_precision': 0.24512534818941503, 'Doubt_recall': 0.19555555555555557, 'Doubt_f1-score': 0.21755253399258345, 'Doubt_support': 900.0, 'micro avg_precision': 0.24512534818941503, 'micro avg_recall': 0.19555555555555557, 'micro avg_f1-score': 0.21755253399258345, 'micro avg_support': 900.0, 'macro avg_precision': 0.24512534818941503, 'macro avg_recall': 0.19555555555555557, 'macro avg_f1-score': 0.21755253399258345, 'macro avg_support': 900.0, 'weighted avg_precision': 0.24512534818941503, 'weighted avg_recall': 0.19555555555555557, 'weighted avg_f1-score': 0.21755253399258345, 'weighted avg_support': 900.0, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'O_support': 16422, 'epoch': 1}, {'micro_f1': 0.7633193524905543, 'Doubt_precision': 0.2883008356545961, 'Doubt_recall': 0.21789473684210525, 'Doubt_f1-score': 0.24820143884892082, 'Doubt_support': 950.0, 'micro avg_precision': 0.2883008356545961, 'micro avg_recall': 0.21789473684210525, 'micro avg_f1-score': 0.24820143884892082, 'micro avg_support': 950.0, 'macro avg_precision': 0.2883008356545961, 'macro avg_recall': 0.21789473684210525, 'macro avg_f1-score': 0.24820143884892082, 'macro avg_support': 950.0, 'weighted avg_precision': 0.2883008356545961, 'weighted avg_recall': 0.21789473684210525, 'weighted avg_f1-score': 0.24820143884892085, 'weighted avg_support': 950.0, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'O_support': 16422, 'epoch': 2}, {'micro_f1': 0.7597837013414676, 'Doubt_precision': 0.2994428969359331, 'Doubt_recall': 0.2817824377457405, 'Doubt_f1-score': 0.29034436191762325, 'Doubt_support': 763.0, 'micro avg_precision': 0.2994428969359331, 'micro avg_recall': 0.2817824377457405, 'micro avg_f1-score': 0.29034436191762325, 'micro avg_support': 763.0, 'macro avg_precision': 0.2994428969359331, 'macro avg_recall': 0.2817824377457405, 'macro avg_f1-score': 0.29034436191762325, 'macro avg_support': 763.0, 'weighted avg_precision': 0.2994428969359331, 'weighted avg_recall': 0.2817824377457405, 'weighted avg_f1-score': 0.29034436191762325, 'weighted avg_support': 763.0, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'O_support': 16422, 'epoch': 3}, {'micro_f1': 0.760164997053624, 'Doubt_precision': 0.3802228412256267, 'Doubt_recall': 0.29354838709677417, 'Doubt_f1-score': 0.33131067961165045, 'Doubt_support': 930.0, 'micro avg_precision': 0.3802228412256267, 'micro avg_recall': 0.29354838709677417, 'micro avg_f1-score': 0.33131067961165045, 'micro avg_support': 930.0, 'macro avg_precision': 0.3802228412256267, 'macro avg_recall': 0.29354838709677417, 'macro avg_f1-score': 0.33131067961165045, 'macro avg_support': 930.0, 'weighted avg_precision': 0.3802228412256267, 'weighted avg_recall': 0.29354838709677417, 'weighted avg_f1-score': 0.33131067961165045, 'weighted avg_support': 930.0, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'O_support': 16422, 'epoch': 4}, {'micro_f1': 0.7701133488162503, 'Doubt_precision': 0.3635097493036212, 'Doubt_recall': 0.29965556831228474, 'Doubt_f1-score': 0.328508495909377, 'Doubt_support': 871.0, 'micro avg_precision': 0.3635097493036212, 'micro avg_recall': 0.29965556831228474, 'micro avg_f1-score': 0.328508495909377, 'micro avg_support': 871.0, 'macro avg_precision': 0.3635097493036212, 'macro avg_recall': 0.29965556831228474, 'macro avg_f1-score': 0.328508495909377, 'macro avg_support': 871.0, 'weighted avg_precision': 0.36350974930362123, 'weighted avg_recall': 0.29965556831228474, 'weighted avg_f1-score': 0.328508495909377, 'weighted avg_support': 871.0, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'O_support': 16422, 'epoch': 5}, {'micro_f1': 0.7679295642829906, 'Doubt_precision': 0.34818941504178275, 'Doubt_recall': 0.2738225629791895, 'Doubt_f1-score': 0.30656039239730226, 'Doubt_support': 913.0, 'micro avg_precision': 0.34818941504178275, 'micro avg_recall': 0.2738225629791895, 'micro avg_f1-score': 0.30656039239730226, 'micro avg_support': 913.0, 'macro avg_precision': 0.34818941504178275, 'macro avg_recall': 0.2738225629791895, 'macro avg_f1-score': 0.30656039239730226, 'macro avg_support': 913.0, 'weighted avg_precision': 0.34818941504178275, 'weighted avg_recall': 0.2738225629791895, 'weighted avg_f1-score': 0.30656039239730226, 'weighted avg_support': 913.0, 'B-Doubt_support': 718, 'I-Doubt_support': 11709, 'O_support': 16422, 'epoch': 6}]}
Early stopping triggered.
Saving model to directory: ./models/M2/2024-05-12-17-42-10_aug/mdeberta-v3-base_19_ME10_target=Doubt_SUBSAMPLED_2024-05-12-17-42-10
Training model no. 20 of 23 for (20, 'Guilt_by_Association') persuasion technique...
{'micro_f1': 0.7140309155766944, 'Guilt_by_Association_precision': 0.023529411764705882, 'Guilt_by_Association_recall': 0.023529411764705882, 'Guilt_by_Association_f1-score': 0.02352941176470588, 'Guilt_by_Association_support': 85.0, 'micro avg_precision': 0.023529411764705882, 'micro avg_recall': 0.023529411764705882, 'micro avg_f1-score': 0.02352941176470588, 'micro avg_support': 85.0, 'macro avg_precision': 0.023529411764705882, 'macro avg_recall': 0.023529411764705882, 'macro avg_f1-score': 0.02352941176470588, 'macro avg_support': 85.0, 'weighted avg_precision': 0.023529411764705882, 'weighted avg_recall': 0.023529411764705882, 'weighted avg_f1-score': 0.02352941176470588, 'weighted avg_support': 85.0, 'O_support': 2009, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 0}
{'results': [{'micro_f1': 0.7140309155766944, 'Guilt_by_Association_precision': 0.023529411764705882, 'Guilt_by_Association_recall': 0.023529411764705882, 'Guilt_by_Association_f1-score': 0.02352941176470588, 'Guilt_by_Association_support': 85.0, 'micro avg_precision': 0.023529411764705882, 'micro avg_recall': 0.023529411764705882, 'micro avg_f1-score': 0.02352941176470588, 'micro avg_support': 85.0, 'macro avg_precision': 0.023529411764705882, 'macro avg_recall': 0.023529411764705882, 'macro avg_f1-score': 0.02352941176470588, 'macro avg_support': 85.0, 'weighted avg_precision': 0.023529411764705882, 'weighted avg_recall': 0.023529411764705882, 'weighted avg_f1-score': 0.02352941176470588, 'weighted avg_support': 85.0, 'O_support': 2009, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 0}]}
Best model updated: current epoch macro f1 = 0.02352941176470588
{'micro_f1': 0.7838882282996433, 'Guilt_by_Association_precision': 0.16470588235294117, 'Guilt_by_Association_recall': 0.10606060606060606, 'Guilt_by_Association_f1-score': 0.12903225806451613, 'Guilt_by_Association_support': 132.0, 'micro avg_precision': 0.16470588235294117, 'micro avg_recall': 0.10606060606060606, 'micro avg_f1-score': 0.12903225806451613, 'micro avg_support': 132.0, 'macro avg_precision': 0.16470588235294117, 'macro avg_recall': 0.10606060606060606, 'macro avg_f1-score': 0.12903225806451613, 'macro avg_support': 132.0, 'weighted avg_precision': 0.16470588235294117, 'weighted avg_recall': 0.10606060606060606, 'weighted avg_f1-score': 0.12903225806451613, 'weighted avg_support': 132.0, 'O_support': 2009, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 1}
{'results': [{'micro_f1': 0.7140309155766944, 'Guilt_by_Association_precision': 0.023529411764705882, 'Guilt_by_Association_recall': 0.023529411764705882, 'Guilt_by_Association_f1-score': 0.02352941176470588, 'Guilt_by_Association_support': 85.0, 'micro avg_precision': 0.023529411764705882, 'micro avg_recall': 0.023529411764705882, 'micro avg_f1-score': 0.02352941176470588, 'micro avg_support': 85.0, 'macro avg_precision': 0.023529411764705882, 'macro avg_recall': 0.023529411764705882, 'macro avg_f1-score': 0.02352941176470588, 'macro avg_support': 85.0, 'weighted avg_precision': 0.023529411764705882, 'weighted avg_recall': 0.023529411764705882, 'weighted avg_f1-score': 0.02352941176470588, 'weighted avg_support': 85.0, 'O_support': 2009, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 0}, {'micro_f1': 0.7838882282996433, 'Guilt_by_Association_precision': 0.16470588235294117, 'Guilt_by_Association_recall': 0.10606060606060606, 'Guilt_by_Association_f1-score': 0.12903225806451613, 'Guilt_by_Association_support': 132.0, 'micro avg_precision': 0.16470588235294117, 'micro avg_recall': 0.10606060606060606, 'micro avg_f1-score': 0.12903225806451613, 'micro avg_support': 132.0, 'macro avg_precision': 0.16470588235294117, 'macro avg_recall': 0.10606060606060606, 'macro avg_f1-score': 0.12903225806451613, 'macro avg_support': 132.0, 'weighted avg_precision': 0.16470588235294117, 'weighted avg_recall': 0.10606060606060606, 'weighted avg_f1-score': 0.12903225806451613, 'weighted avg_support': 132.0, 'O_support': 2009, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 1}]}
Best model updated: current epoch macro f1 = 0.12903225806451613
{'micro_f1': 0.7812128418549347, 'Guilt_by_Association_precision': 0.17647058823529413, 'Guilt_by_Association_recall': 0.13636363636363635, 'Guilt_by_Association_f1-score': 0.15384615384615383, 'Guilt_by_Association_support': 110.0, 'micro avg_precision': 0.17647058823529413, 'micro avg_recall': 0.13636363636363635, 'micro avg_f1-score': 0.15384615384615383, 'micro avg_support': 110.0, 'macro avg_precision': 0.17647058823529413, 'macro avg_recall': 0.13636363636363635, 'macro avg_f1-score': 0.15384615384615383, 'macro avg_support': 110.0, 'weighted avg_precision': 0.17647058823529413, 'weighted avg_recall': 0.13636363636363635, 'weighted avg_f1-score': 0.15384615384615383, 'weighted avg_support': 110.0, 'O_support': 2009, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 2}
{'results': [{'micro_f1': 0.7140309155766944, 'Guilt_by_Association_precision': 0.023529411764705882, 'Guilt_by_Association_recall': 0.023529411764705882, 'Guilt_by_Association_f1-score': 0.02352941176470588, 'Guilt_by_Association_support': 85.0, 'micro avg_precision': 0.023529411764705882, 'micro avg_recall': 0.023529411764705882, 'micro avg_f1-score': 0.02352941176470588, 'micro avg_support': 85.0, 'macro avg_precision': 0.023529411764705882, 'macro avg_recall': 0.023529411764705882, 'macro avg_f1-score': 0.02352941176470588, 'macro avg_support': 85.0, 'weighted avg_precision': 0.023529411764705882, 'weighted avg_recall': 0.023529411764705882, 'weighted avg_f1-score': 0.02352941176470588, 'weighted avg_support': 85.0, 'O_support': 2009, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 0}, {'micro_f1': 0.7838882282996433, 'Guilt_by_Association_precision': 0.16470588235294117, 'Guilt_by_Association_recall': 0.10606060606060606, 'Guilt_by_Association_f1-score': 0.12903225806451613, 'Guilt_by_Association_support': 132.0, 'micro avg_precision': 0.16470588235294117, 'micro avg_recall': 0.10606060606060606, 'micro avg_f1-score': 0.12903225806451613, 'micro avg_support': 132.0, 'macro avg_precision': 0.16470588235294117, 'macro avg_recall': 0.10606060606060606, 'macro avg_f1-score': 0.12903225806451613, 'macro avg_support': 132.0, 'weighted avg_precision': 0.16470588235294117, 'weighted avg_recall': 0.10606060606060606, 'weighted avg_f1-score': 0.12903225806451613, 'weighted avg_support': 132.0, 'O_support': 2009, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 1}, {'micro_f1': 0.7812128418549347, 'Guilt_by_Association_precision': 0.17647058823529413, 'Guilt_by_Association_recall': 0.13636363636363635, 'Guilt_by_Association_f1-score': 0.15384615384615383, 'Guilt_by_Association_support': 110.0, 'micro avg_precision': 0.17647058823529413, 'micro avg_recall': 0.13636363636363635, 'micro avg_f1-score': 0.15384615384615383, 'micro avg_support': 110.0, 'macro avg_precision': 0.17647058823529413, 'macro avg_recall': 0.13636363636363635, 'macro avg_f1-score': 0.15384615384615383, 'macro avg_support': 110.0, 'weighted avg_precision': 0.17647058823529413, 'weighted avg_recall': 0.13636363636363635, 'weighted avg_f1-score': 0.15384615384615383, 'weighted avg_support': 110.0, 'O_support': 2009, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 2}]}
Best model updated: current epoch macro f1 = 0.15384615384615383
{'micro_f1': 0.7853745541022591, 'Guilt_by_Association_precision': 0.21176470588235294, 'Guilt_by_Association_recall': 0.10778443113772455, 'Guilt_by_Association_f1-score': 0.14285714285714285, 'Guilt_by_Association_support': 167.0, 'micro avg_precision': 0.21176470588235294, 'micro avg_recall': 0.10778443113772455, 'micro avg_f1-score': 0.14285714285714285, 'micro avg_support': 167.0, 'macro avg_precision': 0.21176470588235294, 'macro avg_recall': 0.10778443113772455, 'macro avg_f1-score': 0.14285714285714285, 'macro avg_support': 167.0, 'weighted avg_precision': 0.21176470588235297, 'weighted avg_recall': 0.10778443113772455, 'weighted avg_f1-score': 0.14285714285714285, 'weighted avg_support': 167.0, 'O_support': 2009, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 3}
{'results': [{'micro_f1': 0.7140309155766944, 'Guilt_by_Association_precision': 0.023529411764705882, 'Guilt_by_Association_recall': 0.023529411764705882, 'Guilt_by_Association_f1-score': 0.02352941176470588, 'Guilt_by_Association_support': 85.0, 'micro avg_precision': 0.023529411764705882, 'micro avg_recall': 0.023529411764705882, 'micro avg_f1-score': 0.02352941176470588, 'micro avg_support': 85.0, 'macro avg_precision': 0.023529411764705882, 'macro avg_recall': 0.023529411764705882, 'macro avg_f1-score': 0.02352941176470588, 'macro avg_support': 85.0, 'weighted avg_precision': 0.023529411764705882, 'weighted avg_recall': 0.023529411764705882, 'weighted avg_f1-score': 0.02352941176470588, 'weighted avg_support': 85.0, 'O_support': 2009, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 0}, {'micro_f1': 0.7838882282996433, 'Guilt_by_Association_precision': 0.16470588235294117, 'Guilt_by_Association_recall': 0.10606060606060606, 'Guilt_by_Association_f1-score': 0.12903225806451613, 'Guilt_by_Association_support': 132.0, 'micro avg_precision': 0.16470588235294117, 'micro avg_recall': 0.10606060606060606, 'micro avg_f1-score': 0.12903225806451613, 'micro avg_support': 132.0, 'macro avg_precision': 0.16470588235294117, 'macro avg_recall': 0.10606060606060606, 'macro avg_f1-score': 0.12903225806451613, 'macro avg_support': 132.0, 'weighted avg_precision': 0.16470588235294117, 'weighted avg_recall': 0.10606060606060606, 'weighted avg_f1-score': 0.12903225806451613, 'weighted avg_support': 132.0, 'O_support': 2009, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 1}, {'micro_f1': 0.7812128418549347, 'Guilt_by_Association_precision': 0.17647058823529413, 'Guilt_by_Association_recall': 0.13636363636363635, 'Guilt_by_Association_f1-score': 0.15384615384615383, 'Guilt_by_Association_support': 110.0, 'micro avg_precision': 0.17647058823529413, 'micro avg_recall': 0.13636363636363635, 'micro avg_f1-score': 0.15384615384615383, 'micro avg_support': 110.0, 'macro avg_precision': 0.17647058823529413, 'macro avg_recall': 0.13636363636363635, 'macro avg_f1-score': 0.15384615384615383, 'macro avg_support': 110.0, 'weighted avg_precision': 0.17647058823529413, 'weighted avg_recall': 0.13636363636363635, 'weighted avg_f1-score': 0.15384615384615383, 'weighted avg_support': 110.0, 'O_support': 2009, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 2}, {'micro_f1': 0.7853745541022591, 'Guilt_by_Association_precision': 0.21176470588235294, 'Guilt_by_Association_recall': 0.10778443113772455, 'Guilt_by_Association_f1-score': 0.14285714285714285, 'Guilt_by_Association_support': 167.0, 'micro avg_precision': 0.21176470588235294, 'micro avg_recall': 0.10778443113772455, 'micro avg_f1-score': 0.14285714285714285, 'micro avg_support': 167.0, 'macro avg_precision': 0.21176470588235294, 'macro avg_recall': 0.10778443113772455, 'macro avg_f1-score': 0.14285714285714285, 'macro avg_support': 167.0, 'weighted avg_precision': 0.21176470588235297, 'weighted avg_recall': 0.10778443113772455, 'weighted avg_f1-score': 0.14285714285714285, 'weighted avg_support': 167.0, 'O_support': 2009, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 3}]}
{'micro_f1': 0.7874554102259215, 'Guilt_by_Association_precision': 0.2823529411764706, 'Guilt_by_Association_recall': 0.1610738255033557, 'Guilt_by_Association_f1-score': 0.20512820512820512, 'Guilt_by_Association_support': 149.0, 'micro avg_precision': 0.2823529411764706, 'micro avg_recall': 0.1610738255033557, 'micro avg_f1-score': 0.20512820512820512, 'micro avg_support': 149.0, 'macro avg_precision': 0.2823529411764706, 'macro avg_recall': 0.1610738255033557, 'macro avg_f1-score': 0.20512820512820512, 'macro avg_support': 149.0, 'weighted avg_precision': 0.2823529411764706, 'weighted avg_recall': 0.1610738255033557, 'weighted avg_f1-score': 0.20512820512820512, 'weighted avg_support': 149.0, 'O_support': 2009, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 4}
{'results': [{'micro_f1': 0.7140309155766944, 'Guilt_by_Association_precision': 0.023529411764705882, 'Guilt_by_Association_recall': 0.023529411764705882, 'Guilt_by_Association_f1-score': 0.02352941176470588, 'Guilt_by_Association_support': 85.0, 'micro avg_precision': 0.023529411764705882, 'micro avg_recall': 0.023529411764705882, 'micro avg_f1-score': 0.02352941176470588, 'micro avg_support': 85.0, 'macro avg_precision': 0.023529411764705882, 'macro avg_recall': 0.023529411764705882, 'macro avg_f1-score': 0.02352941176470588, 'macro avg_support': 85.0, 'weighted avg_precision': 0.023529411764705882, 'weighted avg_recall': 0.023529411764705882, 'weighted avg_f1-score': 0.02352941176470588, 'weighted avg_support': 85.0, 'O_support': 2009, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 0}, {'micro_f1': 0.7838882282996433, 'Guilt_by_Association_precision': 0.16470588235294117, 'Guilt_by_Association_recall': 0.10606060606060606, 'Guilt_by_Association_f1-score': 0.12903225806451613, 'Guilt_by_Association_support': 132.0, 'micro avg_precision': 0.16470588235294117, 'micro avg_recall': 0.10606060606060606, 'micro avg_f1-score': 0.12903225806451613, 'micro avg_support': 132.0, 'macro avg_precision': 0.16470588235294117, 'macro avg_recall': 0.10606060606060606, 'macro avg_f1-score': 0.12903225806451613, 'macro avg_support': 132.0, 'weighted avg_precision': 0.16470588235294117, 'weighted avg_recall': 0.10606060606060606, 'weighted avg_f1-score': 0.12903225806451613, 'weighted avg_support': 132.0, 'O_support': 2009, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 1}, {'micro_f1': 0.7812128418549347, 'Guilt_by_Association_precision': 0.17647058823529413, 'Guilt_by_Association_recall': 0.13636363636363635, 'Guilt_by_Association_f1-score': 0.15384615384615383, 'Guilt_by_Association_support': 110.0, 'micro avg_precision': 0.17647058823529413, 'micro avg_recall': 0.13636363636363635, 'micro avg_f1-score': 0.15384615384615383, 'micro avg_support': 110.0, 'macro avg_precision': 0.17647058823529413, 'macro avg_recall': 0.13636363636363635, 'macro avg_f1-score': 0.15384615384615383, 'macro avg_support': 110.0, 'weighted avg_precision': 0.17647058823529413, 'weighted avg_recall': 0.13636363636363635, 'weighted avg_f1-score': 0.15384615384615383, 'weighted avg_support': 110.0, 'O_support': 2009, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 2}, {'micro_f1': 0.7853745541022591, 'Guilt_by_Association_precision': 0.21176470588235294, 'Guilt_by_Association_recall': 0.10778443113772455, 'Guilt_by_Association_f1-score': 0.14285714285714285, 'Guilt_by_Association_support': 167.0, 'micro avg_precision': 0.21176470588235294, 'micro avg_recall': 0.10778443113772455, 'micro avg_f1-score': 0.14285714285714285, 'micro avg_support': 167.0, 'macro avg_precision': 0.21176470588235294, 'macro avg_recall': 0.10778443113772455, 'macro avg_f1-score': 0.14285714285714285, 'macro avg_support': 167.0, 'weighted avg_precision': 0.21176470588235297, 'weighted avg_recall': 0.10778443113772455, 'weighted avg_f1-score': 0.14285714285714285, 'weighted avg_support': 167.0, 'O_support': 2009, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 3}, {'micro_f1': 0.7874554102259215, 'Guilt_by_Association_precision': 0.2823529411764706, 'Guilt_by_Association_recall': 0.1610738255033557, 'Guilt_by_Association_f1-score': 0.20512820512820512, 'Guilt_by_Association_support': 149.0, 'micro avg_precision': 0.2823529411764706, 'micro avg_recall': 0.1610738255033557, 'micro avg_f1-score': 0.20512820512820512, 'micro avg_support': 149.0, 'macro avg_precision': 0.2823529411764706, 'macro avg_recall': 0.1610738255033557, 'macro avg_f1-score': 0.20512820512820512, 'macro avg_support': 149.0, 'weighted avg_precision': 0.2823529411764706, 'weighted avg_recall': 0.1610738255033557, 'weighted avg_f1-score': 0.20512820512820512, 'weighted avg_support': 149.0, 'O_support': 2009, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 4}]}
Best model updated: current epoch macro f1 = 0.20512820512820512
{'micro_f1': 0.7853745541022591, 'Guilt_by_Association_precision': 0.25882352941176473, 'Guilt_by_Association_recall': 0.1746031746031746, 'Guilt_by_Association_f1-score': 0.20853080568720378, 'Guilt_by_Association_support': 126.0, 'micro avg_precision': 0.25882352941176473, 'micro avg_recall': 0.1746031746031746, 'micro avg_f1-score': 0.20853080568720378, 'micro avg_support': 126.0, 'macro avg_precision': 0.25882352941176473, 'macro avg_recall': 0.1746031746031746, 'macro avg_f1-score': 0.20853080568720378, 'macro avg_support': 126.0, 'weighted avg_precision': 0.25882352941176473, 'weighted avg_recall': 0.1746031746031746, 'weighted avg_f1-score': 0.20853080568720378, 'weighted avg_support': 126.0, 'O_support': 2009, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 5}
{'results': [{'micro_f1': 0.7140309155766944, 'Guilt_by_Association_precision': 0.023529411764705882, 'Guilt_by_Association_recall': 0.023529411764705882, 'Guilt_by_Association_f1-score': 0.02352941176470588, 'Guilt_by_Association_support': 85.0, 'micro avg_precision': 0.023529411764705882, 'micro avg_recall': 0.023529411764705882, 'micro avg_f1-score': 0.02352941176470588, 'micro avg_support': 85.0, 'macro avg_precision': 0.023529411764705882, 'macro avg_recall': 0.023529411764705882, 'macro avg_f1-score': 0.02352941176470588, 'macro avg_support': 85.0, 'weighted avg_precision': 0.023529411764705882, 'weighted avg_recall': 0.023529411764705882, 'weighted avg_f1-score': 0.02352941176470588, 'weighted avg_support': 85.0, 'O_support': 2009, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 0}, {'micro_f1': 0.7838882282996433, 'Guilt_by_Association_precision': 0.16470588235294117, 'Guilt_by_Association_recall': 0.10606060606060606, 'Guilt_by_Association_f1-score': 0.12903225806451613, 'Guilt_by_Association_support': 132.0, 'micro avg_precision': 0.16470588235294117, 'micro avg_recall': 0.10606060606060606, 'micro avg_f1-score': 0.12903225806451613, 'micro avg_support': 132.0, 'macro avg_precision': 0.16470588235294117, 'macro avg_recall': 0.10606060606060606, 'macro avg_f1-score': 0.12903225806451613, 'macro avg_support': 132.0, 'weighted avg_precision': 0.16470588235294117, 'weighted avg_recall': 0.10606060606060606, 'weighted avg_f1-score': 0.12903225806451613, 'weighted avg_support': 132.0, 'O_support': 2009, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 1}, {'micro_f1': 0.7812128418549347, 'Guilt_by_Association_precision': 0.17647058823529413, 'Guilt_by_Association_recall': 0.13636363636363635, 'Guilt_by_Association_f1-score': 0.15384615384615383, 'Guilt_by_Association_support': 110.0, 'micro avg_precision': 0.17647058823529413, 'micro avg_recall': 0.13636363636363635, 'micro avg_f1-score': 0.15384615384615383, 'micro avg_support': 110.0, 'macro avg_precision': 0.17647058823529413, 'macro avg_recall': 0.13636363636363635, 'macro avg_f1-score': 0.15384615384615383, 'macro avg_support': 110.0, 'weighted avg_precision': 0.17647058823529413, 'weighted avg_recall': 0.13636363636363635, 'weighted avg_f1-score': 0.15384615384615383, 'weighted avg_support': 110.0, 'O_support': 2009, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 2}, {'micro_f1': 0.7853745541022591, 'Guilt_by_Association_precision': 0.21176470588235294, 'Guilt_by_Association_recall': 0.10778443113772455, 'Guilt_by_Association_f1-score': 0.14285714285714285, 'Guilt_by_Association_support': 167.0, 'micro avg_precision': 0.21176470588235294, 'micro avg_recall': 0.10778443113772455, 'micro avg_f1-score': 0.14285714285714285, 'micro avg_support': 167.0, 'macro avg_precision': 0.21176470588235294, 'macro avg_recall': 0.10778443113772455, 'macro avg_f1-score': 0.14285714285714285, 'macro avg_support': 167.0, 'weighted avg_precision': 0.21176470588235297, 'weighted avg_recall': 0.10778443113772455, 'weighted avg_f1-score': 0.14285714285714285, 'weighted avg_support': 167.0, 'O_support': 2009, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 3}, {'micro_f1': 0.7874554102259215, 'Guilt_by_Association_precision': 0.2823529411764706, 'Guilt_by_Association_recall': 0.1610738255033557, 'Guilt_by_Association_f1-score': 0.20512820512820512, 'Guilt_by_Association_support': 149.0, 'micro avg_precision': 0.2823529411764706, 'micro avg_recall': 0.1610738255033557, 'micro avg_f1-score': 0.20512820512820512, 'micro avg_support': 149.0, 'macro avg_precision': 0.2823529411764706, 'macro avg_recall': 0.1610738255033557, 'macro avg_f1-score': 0.20512820512820512, 'macro avg_support': 149.0, 'weighted avg_precision': 0.2823529411764706, 'weighted avg_recall': 0.1610738255033557, 'weighted avg_f1-score': 0.20512820512820512, 'weighted avg_support': 149.0, 'O_support': 2009, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 4}, {'micro_f1': 0.7853745541022591, 'Guilt_by_Association_precision': 0.25882352941176473, 'Guilt_by_Association_recall': 0.1746031746031746, 'Guilt_by_Association_f1-score': 0.20853080568720378, 'Guilt_by_Association_support': 126.0, 'micro avg_precision': 0.25882352941176473, 'micro avg_recall': 0.1746031746031746, 'micro avg_f1-score': 0.20853080568720378, 'micro avg_support': 126.0, 'macro avg_precision': 0.25882352941176473, 'macro avg_recall': 0.1746031746031746, 'macro avg_f1-score': 0.20853080568720378, 'macro avg_support': 126.0, 'weighted avg_precision': 0.25882352941176473, 'weighted avg_recall': 0.1746031746031746, 'weighted avg_f1-score': 0.20853080568720378, 'weighted avg_support': 126.0, 'O_support': 2009, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 5}]}
Best model updated: current epoch macro f1 = 0.20853080568720378
{'micro_f1': 0.8049940546967896, 'Guilt_by_Association_precision': 0.3058823529411765, 'Guilt_by_Association_recall': 0.18181818181818182, 'Guilt_by_Association_f1-score': 0.22807017543859648, 'Guilt_by_Association_support': 143.0, 'micro avg_precision': 0.3058823529411765, 'micro avg_recall': 0.18181818181818182, 'micro avg_f1-score': 0.22807017543859648, 'micro avg_support': 143.0, 'macro avg_precision': 0.3058823529411765, 'macro avg_recall': 0.18181818181818182, 'macro avg_f1-score': 0.22807017543859648, 'macro avg_support': 143.0, 'weighted avg_precision': 0.3058823529411765, 'weighted avg_recall': 0.18181818181818182, 'weighted avg_f1-score': 0.22807017543859645, 'weighted avg_support': 143.0, 'O_support': 2009, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 6}
{'results': [{'micro_f1': 0.7140309155766944, 'Guilt_by_Association_precision': 0.023529411764705882, 'Guilt_by_Association_recall': 0.023529411764705882, 'Guilt_by_Association_f1-score': 0.02352941176470588, 'Guilt_by_Association_support': 85.0, 'micro avg_precision': 0.023529411764705882, 'micro avg_recall': 0.023529411764705882, 'micro avg_f1-score': 0.02352941176470588, 'micro avg_support': 85.0, 'macro avg_precision': 0.023529411764705882, 'macro avg_recall': 0.023529411764705882, 'macro avg_f1-score': 0.02352941176470588, 'macro avg_support': 85.0, 'weighted avg_precision': 0.023529411764705882, 'weighted avg_recall': 0.023529411764705882, 'weighted avg_f1-score': 0.02352941176470588, 'weighted avg_support': 85.0, 'O_support': 2009, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 0}, {'micro_f1': 0.7838882282996433, 'Guilt_by_Association_precision': 0.16470588235294117, 'Guilt_by_Association_recall': 0.10606060606060606, 'Guilt_by_Association_f1-score': 0.12903225806451613, 'Guilt_by_Association_support': 132.0, 'micro avg_precision': 0.16470588235294117, 'micro avg_recall': 0.10606060606060606, 'micro avg_f1-score': 0.12903225806451613, 'micro avg_support': 132.0, 'macro avg_precision': 0.16470588235294117, 'macro avg_recall': 0.10606060606060606, 'macro avg_f1-score': 0.12903225806451613, 'macro avg_support': 132.0, 'weighted avg_precision': 0.16470588235294117, 'weighted avg_recall': 0.10606060606060606, 'weighted avg_f1-score': 0.12903225806451613, 'weighted avg_support': 132.0, 'O_support': 2009, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 1}, {'micro_f1': 0.7812128418549347, 'Guilt_by_Association_precision': 0.17647058823529413, 'Guilt_by_Association_recall': 0.13636363636363635, 'Guilt_by_Association_f1-score': 0.15384615384615383, 'Guilt_by_Association_support': 110.0, 'micro avg_precision': 0.17647058823529413, 'micro avg_recall': 0.13636363636363635, 'micro avg_f1-score': 0.15384615384615383, 'micro avg_support': 110.0, 'macro avg_precision': 0.17647058823529413, 'macro avg_recall': 0.13636363636363635, 'macro avg_f1-score': 0.15384615384615383, 'macro avg_support': 110.0, 'weighted avg_precision': 0.17647058823529413, 'weighted avg_recall': 0.13636363636363635, 'weighted avg_f1-score': 0.15384615384615383, 'weighted avg_support': 110.0, 'O_support': 2009, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 2}, {'micro_f1': 0.7853745541022591, 'Guilt_by_Association_precision': 0.21176470588235294, 'Guilt_by_Association_recall': 0.10778443113772455, 'Guilt_by_Association_f1-score': 0.14285714285714285, 'Guilt_by_Association_support': 167.0, 'micro avg_precision': 0.21176470588235294, 'micro avg_recall': 0.10778443113772455, 'micro avg_f1-score': 0.14285714285714285, 'micro avg_support': 167.0, 'macro avg_precision': 0.21176470588235294, 'macro avg_recall': 0.10778443113772455, 'macro avg_f1-score': 0.14285714285714285, 'macro avg_support': 167.0, 'weighted avg_precision': 0.21176470588235297, 'weighted avg_recall': 0.10778443113772455, 'weighted avg_f1-score': 0.14285714285714285, 'weighted avg_support': 167.0, 'O_support': 2009, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 3}, {'micro_f1': 0.7874554102259215, 'Guilt_by_Association_precision': 0.2823529411764706, 'Guilt_by_Association_recall': 0.1610738255033557, 'Guilt_by_Association_f1-score': 0.20512820512820512, 'Guilt_by_Association_support': 149.0, 'micro avg_precision': 0.2823529411764706, 'micro avg_recall': 0.1610738255033557, 'micro avg_f1-score': 0.20512820512820512, 'micro avg_support': 149.0, 'macro avg_precision': 0.2823529411764706, 'macro avg_recall': 0.1610738255033557, 'macro avg_f1-score': 0.20512820512820512, 'macro avg_support': 149.0, 'weighted avg_precision': 0.2823529411764706, 'weighted avg_recall': 0.1610738255033557, 'weighted avg_f1-score': 0.20512820512820512, 'weighted avg_support': 149.0, 'O_support': 2009, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 4}, {'micro_f1': 0.7853745541022591, 'Guilt_by_Association_precision': 0.25882352941176473, 'Guilt_by_Association_recall': 0.1746031746031746, 'Guilt_by_Association_f1-score': 0.20853080568720378, 'Guilt_by_Association_support': 126.0, 'micro avg_precision': 0.25882352941176473, 'micro avg_recall': 0.1746031746031746, 'micro avg_f1-score': 0.20853080568720378, 'micro avg_support': 126.0, 'macro avg_precision': 0.25882352941176473, 'macro avg_recall': 0.1746031746031746, 'macro avg_f1-score': 0.20853080568720378, 'macro avg_support': 126.0, 'weighted avg_precision': 0.25882352941176473, 'weighted avg_recall': 0.1746031746031746, 'weighted avg_f1-score': 0.20853080568720378, 'weighted avg_support': 126.0, 'O_support': 2009, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 5}, {'micro_f1': 0.8049940546967896, 'Guilt_by_Association_precision': 0.3058823529411765, 'Guilt_by_Association_recall': 0.18181818181818182, 'Guilt_by_Association_f1-score': 0.22807017543859648, 'Guilt_by_Association_support': 143.0, 'micro avg_precision': 0.3058823529411765, 'micro avg_recall': 0.18181818181818182, 'micro avg_f1-score': 0.22807017543859648, 'micro avg_support': 143.0, 'macro avg_precision': 0.3058823529411765, 'macro avg_recall': 0.18181818181818182, 'macro avg_f1-score': 0.22807017543859648, 'macro avg_support': 143.0, 'weighted avg_precision': 0.3058823529411765, 'weighted avg_recall': 0.18181818181818182, 'weighted avg_f1-score': 0.22807017543859645, 'weighted avg_support': 143.0, 'O_support': 2009, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 6}]}
Best model updated: current epoch macro f1 = 0.22807017543859648
{'micro_f1': 0.7987514863258026, 'Guilt_by_Association_precision': 0.2823529411764706, 'Guilt_by_Association_recall': 0.183206106870229, 'Guilt_by_Association_f1-score': 0.22222222222222224, 'Guilt_by_Association_support': 131.0, 'micro avg_precision': 0.2823529411764706, 'micro avg_recall': 0.183206106870229, 'micro avg_f1-score': 0.22222222222222224, 'micro avg_support': 131.0, 'macro avg_precision': 0.2823529411764706, 'macro avg_recall': 0.183206106870229, 'macro avg_f1-score': 0.22222222222222224, 'macro avg_support': 131.0, 'weighted avg_precision': 0.2823529411764706, 'weighted avg_recall': 0.183206106870229, 'weighted avg_f1-score': 0.22222222222222224, 'weighted avg_support': 131.0, 'O_support': 2009, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 7}
{'results': [{'micro_f1': 0.7140309155766944, 'Guilt_by_Association_precision': 0.023529411764705882, 'Guilt_by_Association_recall': 0.023529411764705882, 'Guilt_by_Association_f1-score': 0.02352941176470588, 'Guilt_by_Association_support': 85.0, 'micro avg_precision': 0.023529411764705882, 'micro avg_recall': 0.023529411764705882, 'micro avg_f1-score': 0.02352941176470588, 'micro avg_support': 85.0, 'macro avg_precision': 0.023529411764705882, 'macro avg_recall': 0.023529411764705882, 'macro avg_f1-score': 0.02352941176470588, 'macro avg_support': 85.0, 'weighted avg_precision': 0.023529411764705882, 'weighted avg_recall': 0.023529411764705882, 'weighted avg_f1-score': 0.02352941176470588, 'weighted avg_support': 85.0, 'O_support': 2009, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 0}, {'micro_f1': 0.7838882282996433, 'Guilt_by_Association_precision': 0.16470588235294117, 'Guilt_by_Association_recall': 0.10606060606060606, 'Guilt_by_Association_f1-score': 0.12903225806451613, 'Guilt_by_Association_support': 132.0, 'micro avg_precision': 0.16470588235294117, 'micro avg_recall': 0.10606060606060606, 'micro avg_f1-score': 0.12903225806451613, 'micro avg_support': 132.0, 'macro avg_precision': 0.16470588235294117, 'macro avg_recall': 0.10606060606060606, 'macro avg_f1-score': 0.12903225806451613, 'macro avg_support': 132.0, 'weighted avg_precision': 0.16470588235294117, 'weighted avg_recall': 0.10606060606060606, 'weighted avg_f1-score': 0.12903225806451613, 'weighted avg_support': 132.0, 'O_support': 2009, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 1}, {'micro_f1': 0.7812128418549347, 'Guilt_by_Association_precision': 0.17647058823529413, 'Guilt_by_Association_recall': 0.13636363636363635, 'Guilt_by_Association_f1-score': 0.15384615384615383, 'Guilt_by_Association_support': 110.0, 'micro avg_precision': 0.17647058823529413, 'micro avg_recall': 0.13636363636363635, 'micro avg_f1-score': 0.15384615384615383, 'micro avg_support': 110.0, 'macro avg_precision': 0.17647058823529413, 'macro avg_recall': 0.13636363636363635, 'macro avg_f1-score': 0.15384615384615383, 'macro avg_support': 110.0, 'weighted avg_precision': 0.17647058823529413, 'weighted avg_recall': 0.13636363636363635, 'weighted avg_f1-score': 0.15384615384615383, 'weighted avg_support': 110.0, 'O_support': 2009, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 2}, {'micro_f1': 0.7853745541022591, 'Guilt_by_Association_precision': 0.21176470588235294, 'Guilt_by_Association_recall': 0.10778443113772455, 'Guilt_by_Association_f1-score': 0.14285714285714285, 'Guilt_by_Association_support': 167.0, 'micro avg_precision': 0.21176470588235294, 'micro avg_recall': 0.10778443113772455, 'micro avg_f1-score': 0.14285714285714285, 'micro avg_support': 167.0, 'macro avg_precision': 0.21176470588235294, 'macro avg_recall': 0.10778443113772455, 'macro avg_f1-score': 0.14285714285714285, 'macro avg_support': 167.0, 'weighted avg_precision': 0.21176470588235297, 'weighted avg_recall': 0.10778443113772455, 'weighted avg_f1-score': 0.14285714285714285, 'weighted avg_support': 167.0, 'O_support': 2009, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 3}, {'micro_f1': 0.7874554102259215, 'Guilt_by_Association_precision': 0.2823529411764706, 'Guilt_by_Association_recall': 0.1610738255033557, 'Guilt_by_Association_f1-score': 0.20512820512820512, 'Guilt_by_Association_support': 149.0, 'micro avg_precision': 0.2823529411764706, 'micro avg_recall': 0.1610738255033557, 'micro avg_f1-score': 0.20512820512820512, 'micro avg_support': 149.0, 'macro avg_precision': 0.2823529411764706, 'macro avg_recall': 0.1610738255033557, 'macro avg_f1-score': 0.20512820512820512, 'macro avg_support': 149.0, 'weighted avg_precision': 0.2823529411764706, 'weighted avg_recall': 0.1610738255033557, 'weighted avg_f1-score': 0.20512820512820512, 'weighted avg_support': 149.0, 'O_support': 2009, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 4}, {'micro_f1': 0.7853745541022591, 'Guilt_by_Association_precision': 0.25882352941176473, 'Guilt_by_Association_recall': 0.1746031746031746, 'Guilt_by_Association_f1-score': 0.20853080568720378, 'Guilt_by_Association_support': 126.0, 'micro avg_precision': 0.25882352941176473, 'micro avg_recall': 0.1746031746031746, 'micro avg_f1-score': 0.20853080568720378, 'micro avg_support': 126.0, 'macro avg_precision': 0.25882352941176473, 'macro avg_recall': 0.1746031746031746, 'macro avg_f1-score': 0.20853080568720378, 'macro avg_support': 126.0, 'weighted avg_precision': 0.25882352941176473, 'weighted avg_recall': 0.1746031746031746, 'weighted avg_f1-score': 0.20853080568720378, 'weighted avg_support': 126.0, 'O_support': 2009, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 5}, {'micro_f1': 0.8049940546967896, 'Guilt_by_Association_precision': 0.3058823529411765, 'Guilt_by_Association_recall': 0.18181818181818182, 'Guilt_by_Association_f1-score': 0.22807017543859648, 'Guilt_by_Association_support': 143.0, 'micro avg_precision': 0.3058823529411765, 'micro avg_recall': 0.18181818181818182, 'micro avg_f1-score': 0.22807017543859648, 'micro avg_support': 143.0, 'macro avg_precision': 0.3058823529411765, 'macro avg_recall': 0.18181818181818182, 'macro avg_f1-score': 0.22807017543859648, 'macro avg_support': 143.0, 'weighted avg_precision': 0.3058823529411765, 'weighted avg_recall': 0.18181818181818182, 'weighted avg_f1-score': 0.22807017543859645, 'weighted avg_support': 143.0, 'O_support': 2009, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 6}, {'micro_f1': 0.7987514863258026, 'Guilt_by_Association_precision': 0.2823529411764706, 'Guilt_by_Association_recall': 0.183206106870229, 'Guilt_by_Association_f1-score': 0.22222222222222224, 'Guilt_by_Association_support': 131.0, 'micro avg_precision': 0.2823529411764706, 'micro avg_recall': 0.183206106870229, 'micro avg_f1-score': 0.22222222222222224, 'micro avg_support': 131.0, 'macro avg_precision': 0.2823529411764706, 'macro avg_recall': 0.183206106870229, 'macro avg_f1-score': 0.22222222222222224, 'macro avg_support': 131.0, 'weighted avg_precision': 0.2823529411764706, 'weighted avg_recall': 0.183206106870229, 'weighted avg_f1-score': 0.22222222222222224, 'weighted avg_support': 131.0, 'O_support': 2009, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 7}]}
{'micro_f1': 0.8008323424494649, 'Guilt_by_Association_precision': 0.25882352941176473, 'Guilt_by_Association_recall': 0.1864406779661017, 'Guilt_by_Association_f1-score': 0.21674876847290642, 'Guilt_by_Association_support': 118.0, 'micro avg_precision': 0.25882352941176473, 'micro avg_recall': 0.1864406779661017, 'micro avg_f1-score': 0.21674876847290642, 'micro avg_support': 118.0, 'macro avg_precision': 0.25882352941176473, 'macro avg_recall': 0.1864406779661017, 'macro avg_f1-score': 0.21674876847290642, 'macro avg_support': 118.0, 'weighted avg_precision': 0.25882352941176473, 'weighted avg_recall': 0.1864406779661017, 'weighted avg_f1-score': 0.21674876847290642, 'weighted avg_support': 118.0, 'O_support': 2009, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 8}
{'results': [{'micro_f1': 0.7140309155766944, 'Guilt_by_Association_precision': 0.023529411764705882, 'Guilt_by_Association_recall': 0.023529411764705882, 'Guilt_by_Association_f1-score': 0.02352941176470588, 'Guilt_by_Association_support': 85.0, 'micro avg_precision': 0.023529411764705882, 'micro avg_recall': 0.023529411764705882, 'micro avg_f1-score': 0.02352941176470588, 'micro avg_support': 85.0, 'macro avg_precision': 0.023529411764705882, 'macro avg_recall': 0.023529411764705882, 'macro avg_f1-score': 0.02352941176470588, 'macro avg_support': 85.0, 'weighted avg_precision': 0.023529411764705882, 'weighted avg_recall': 0.023529411764705882, 'weighted avg_f1-score': 0.02352941176470588, 'weighted avg_support': 85.0, 'O_support': 2009, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 0}, {'micro_f1': 0.7838882282996433, 'Guilt_by_Association_precision': 0.16470588235294117, 'Guilt_by_Association_recall': 0.10606060606060606, 'Guilt_by_Association_f1-score': 0.12903225806451613, 'Guilt_by_Association_support': 132.0, 'micro avg_precision': 0.16470588235294117, 'micro avg_recall': 0.10606060606060606, 'micro avg_f1-score': 0.12903225806451613, 'micro avg_support': 132.0, 'macro avg_precision': 0.16470588235294117, 'macro avg_recall': 0.10606060606060606, 'macro avg_f1-score': 0.12903225806451613, 'macro avg_support': 132.0, 'weighted avg_precision': 0.16470588235294117, 'weighted avg_recall': 0.10606060606060606, 'weighted avg_f1-score': 0.12903225806451613, 'weighted avg_support': 132.0, 'O_support': 2009, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 1}, {'micro_f1': 0.7812128418549347, 'Guilt_by_Association_precision': 0.17647058823529413, 'Guilt_by_Association_recall': 0.13636363636363635, 'Guilt_by_Association_f1-score': 0.15384615384615383, 'Guilt_by_Association_support': 110.0, 'micro avg_precision': 0.17647058823529413, 'micro avg_recall': 0.13636363636363635, 'micro avg_f1-score': 0.15384615384615383, 'micro avg_support': 110.0, 'macro avg_precision': 0.17647058823529413, 'macro avg_recall': 0.13636363636363635, 'macro avg_f1-score': 0.15384615384615383, 'macro avg_support': 110.0, 'weighted avg_precision': 0.17647058823529413, 'weighted avg_recall': 0.13636363636363635, 'weighted avg_f1-score': 0.15384615384615383, 'weighted avg_support': 110.0, 'O_support': 2009, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 2}, {'micro_f1': 0.7853745541022591, 'Guilt_by_Association_precision': 0.21176470588235294, 'Guilt_by_Association_recall': 0.10778443113772455, 'Guilt_by_Association_f1-score': 0.14285714285714285, 'Guilt_by_Association_support': 167.0, 'micro avg_precision': 0.21176470588235294, 'micro avg_recall': 0.10778443113772455, 'micro avg_f1-score': 0.14285714285714285, 'micro avg_support': 167.0, 'macro avg_precision': 0.21176470588235294, 'macro avg_recall': 0.10778443113772455, 'macro avg_f1-score': 0.14285714285714285, 'macro avg_support': 167.0, 'weighted avg_precision': 0.21176470588235297, 'weighted avg_recall': 0.10778443113772455, 'weighted avg_f1-score': 0.14285714285714285, 'weighted avg_support': 167.0, 'O_support': 2009, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 3}, {'micro_f1': 0.7874554102259215, 'Guilt_by_Association_precision': 0.2823529411764706, 'Guilt_by_Association_recall': 0.1610738255033557, 'Guilt_by_Association_f1-score': 0.20512820512820512, 'Guilt_by_Association_support': 149.0, 'micro avg_precision': 0.2823529411764706, 'micro avg_recall': 0.1610738255033557, 'micro avg_f1-score': 0.20512820512820512, 'micro avg_support': 149.0, 'macro avg_precision': 0.2823529411764706, 'macro avg_recall': 0.1610738255033557, 'macro avg_f1-score': 0.20512820512820512, 'macro avg_support': 149.0, 'weighted avg_precision': 0.2823529411764706, 'weighted avg_recall': 0.1610738255033557, 'weighted avg_f1-score': 0.20512820512820512, 'weighted avg_support': 149.0, 'O_support': 2009, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 4}, {'micro_f1': 0.7853745541022591, 'Guilt_by_Association_precision': 0.25882352941176473, 'Guilt_by_Association_recall': 0.1746031746031746, 'Guilt_by_Association_f1-score': 0.20853080568720378, 'Guilt_by_Association_support': 126.0, 'micro avg_precision': 0.25882352941176473, 'micro avg_recall': 0.1746031746031746, 'micro avg_f1-score': 0.20853080568720378, 'micro avg_support': 126.0, 'macro avg_precision': 0.25882352941176473, 'macro avg_recall': 0.1746031746031746, 'macro avg_f1-score': 0.20853080568720378, 'macro avg_support': 126.0, 'weighted avg_precision': 0.25882352941176473, 'weighted avg_recall': 0.1746031746031746, 'weighted avg_f1-score': 0.20853080568720378, 'weighted avg_support': 126.0, 'O_support': 2009, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 5}, {'micro_f1': 0.8049940546967896, 'Guilt_by_Association_precision': 0.3058823529411765, 'Guilt_by_Association_recall': 0.18181818181818182, 'Guilt_by_Association_f1-score': 0.22807017543859648, 'Guilt_by_Association_support': 143.0, 'micro avg_precision': 0.3058823529411765, 'micro avg_recall': 0.18181818181818182, 'micro avg_f1-score': 0.22807017543859648, 'micro avg_support': 143.0, 'macro avg_precision': 0.3058823529411765, 'macro avg_recall': 0.18181818181818182, 'macro avg_f1-score': 0.22807017543859648, 'macro avg_support': 143.0, 'weighted avg_precision': 0.3058823529411765, 'weighted avg_recall': 0.18181818181818182, 'weighted avg_f1-score': 0.22807017543859645, 'weighted avg_support': 143.0, 'O_support': 2009, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 6}, {'micro_f1': 0.7987514863258026, 'Guilt_by_Association_precision': 0.2823529411764706, 'Guilt_by_Association_recall': 0.183206106870229, 'Guilt_by_Association_f1-score': 0.22222222222222224, 'Guilt_by_Association_support': 131.0, 'micro avg_precision': 0.2823529411764706, 'micro avg_recall': 0.183206106870229, 'micro avg_f1-score': 0.22222222222222224, 'micro avg_support': 131.0, 'macro avg_precision': 0.2823529411764706, 'macro avg_recall': 0.183206106870229, 'macro avg_f1-score': 0.22222222222222224, 'macro avg_support': 131.0, 'weighted avg_precision': 0.2823529411764706, 'weighted avg_recall': 0.183206106870229, 'weighted avg_f1-score': 0.22222222222222224, 'weighted avg_support': 131.0, 'O_support': 2009, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 7}, {'micro_f1': 0.8008323424494649, 'Guilt_by_Association_precision': 0.25882352941176473, 'Guilt_by_Association_recall': 0.1864406779661017, 'Guilt_by_Association_f1-score': 0.21674876847290642, 'Guilt_by_Association_support': 118.0, 'micro avg_precision': 0.25882352941176473, 'micro avg_recall': 0.1864406779661017, 'micro avg_f1-score': 0.21674876847290642, 'micro avg_support': 118.0, 'macro avg_precision': 0.25882352941176473, 'macro avg_recall': 0.1864406779661017, 'macro avg_f1-score': 0.21674876847290642, 'macro avg_support': 118.0, 'weighted avg_precision': 0.25882352941176473, 'weighted avg_recall': 0.1864406779661017, 'weighted avg_f1-score': 0.21674876847290642, 'weighted avg_support': 118.0, 'O_support': 2009, 'B-Guilt_by_Association_support': 85, 'I-Guilt_by_Association_support': 1270, 'epoch': 8}]}
Early stopping triggered.
Saving model to directory: ./models/M2/2024-05-12-17-42-10_aug/mdeberta-v3-base_20_ME10_target=Guilt_by_Association_SUBSAMPLED_2024-05-12-17-42-10
Training model no. 21 of 23 for (21, 'Appeal_to_Hypocrisy') persuasion technique...
{'micro_f1': 0.7446063064724322, 'Appeal_to_Hypocrisy_precision': 0.19852941176470587, 'Appeal_to_Hypocrisy_recall': 0.1, 'Appeal_to_Hypocrisy_f1-score': 0.1330049261083744, 'Appeal_to_Hypocrisy_support': 270.0, 'micro avg_precision': 0.19852941176470587, 'micro avg_recall': 0.1, 'micro avg_f1-score': 0.1330049261083744, 'micro avg_support': 270.0, 'macro avg_precision': 0.19852941176470587, 'macro avg_recall': 0.1, 'macro avg_f1-score': 0.1330049261083744, 'macro avg_support': 270.0, 'weighted avg_precision': 0.19852941176470587, 'weighted avg_recall': 0.1, 'weighted avg_f1-score': 0.1330049261083744, 'weighted avg_support': 270.0, 'O_support': 2408, 'B-Appeal_to_Hypocrisy_support': 136, 'I-Appeal_to_Hypocrisy_support': 2879, 'epoch': 0}
{'results': [{'micro_f1': 0.7446063064724322, 'Appeal_to_Hypocrisy_precision': 0.19852941176470587, 'Appeal_to_Hypocrisy_recall': 0.1, 'Appeal_to_Hypocrisy_f1-score': 0.1330049261083744, 'Appeal_to_Hypocrisy_support': 270.0, 'micro avg_precision': 0.19852941176470587, 'micro avg_recall': 0.1, 'micro avg_f1-score': 0.1330049261083744, 'micro avg_support': 270.0, 'macro avg_precision': 0.19852941176470587, 'macro avg_recall': 0.1, 'macro avg_f1-score': 0.1330049261083744, 'macro avg_support': 270.0, 'weighted avg_precision': 0.19852941176470587, 'weighted avg_recall': 0.1, 'weighted avg_f1-score': 0.1330049261083744, 'weighted avg_support': 270.0, 'O_support': 2408, 'B-Appeal_to_Hypocrisy_support': 136, 'I-Appeal_to_Hypocrisy_support': 2879, 'epoch': 0}]}
Best model updated: current epoch macro f1 = 0.1330049261083744
{'micro_f1': 0.7759542688548774, 'Appeal_to_Hypocrisy_precision': 0.2647058823529412, 'Appeal_to_Hypocrisy_recall': 0.15126050420168066, 'Appeal_to_Hypocrisy_f1-score': 0.1925133689839572, 'Appeal_to_Hypocrisy_support': 238.0, 'micro avg_precision': 0.2647058823529412, 'micro avg_recall': 0.15126050420168066, 'micro avg_f1-score': 0.1925133689839572, 'micro avg_support': 238.0, 'macro avg_precision': 0.2647058823529412, 'macro avg_recall': 0.15126050420168066, 'macro avg_f1-score': 0.1925133689839572, 'macro avg_support': 238.0, 'weighted avg_precision': 0.2647058823529412, 'weighted avg_recall': 0.15126050420168066, 'weighted avg_f1-score': 0.19251336898395718, 'weighted avg_support': 238.0, 'O_support': 2408, 'B-Appeal_to_Hypocrisy_support': 136, 'I-Appeal_to_Hypocrisy_support': 2879, 'epoch': 1}
{'results': [{'micro_f1': 0.7446063064724322, 'Appeal_to_Hypocrisy_precision': 0.19852941176470587, 'Appeal_to_Hypocrisy_recall': 0.1, 'Appeal_to_Hypocrisy_f1-score': 0.1330049261083744, 'Appeal_to_Hypocrisy_support': 270.0, 'micro avg_precision': 0.19852941176470587, 'micro avg_recall': 0.1, 'micro avg_f1-score': 0.1330049261083744, 'micro avg_support': 270.0, 'macro avg_precision': 0.19852941176470587, 'macro avg_recall': 0.1, 'macro avg_f1-score': 0.1330049261083744, 'macro avg_support': 270.0, 'weighted avg_precision': 0.19852941176470587, 'weighted avg_recall': 0.1, 'weighted avg_f1-score': 0.1330049261083744, 'weighted avg_support': 270.0, 'O_support': 2408, 'B-Appeal_to_Hypocrisy_support': 136, 'I-Appeal_to_Hypocrisy_support': 2879, 'epoch': 0}, {'micro_f1': 0.7759542688548774, 'Appeal_to_Hypocrisy_precision': 0.2647058823529412, 'Appeal_to_Hypocrisy_recall': 0.15126050420168066, 'Appeal_to_Hypocrisy_f1-score': 0.1925133689839572, 'Appeal_to_Hypocrisy_support': 238.0, 'micro avg_precision': 0.2647058823529412, 'micro avg_recall': 0.15126050420168066, 'micro avg_f1-score': 0.1925133689839572, 'micro avg_support': 238.0, 'macro avg_precision': 0.2647058823529412, 'macro avg_recall': 0.15126050420168066, 'macro avg_f1-score': 0.1925133689839572, 'macro avg_support': 238.0, 'weighted avg_precision': 0.2647058823529412, 'weighted avg_recall': 0.15126050420168066, 'weighted avg_f1-score': 0.19251336898395718, 'weighted avg_support': 238.0, 'O_support': 2408, 'B-Appeal_to_Hypocrisy_support': 136, 'I-Appeal_to_Hypocrisy_support': 2879, 'epoch': 1}]}
Best model updated: current epoch macro f1 = 0.1925133689839572
{'micro_f1': 0.7789046653144016, 'Appeal_to_Hypocrisy_precision': 0.27941176470588236, 'Appeal_to_Hypocrisy_recall': 0.17194570135746606, 'Appeal_to_Hypocrisy_f1-score': 0.21288515406162464, 'Appeal_to_Hypocrisy_support': 221.0, 'micro avg_precision': 0.27941176470588236, 'micro avg_recall': 0.17194570135746606, 'micro avg_f1-score': 0.21288515406162464, 'micro avg_support': 221.0, 'macro avg_precision': 0.27941176470588236, 'macro avg_recall': 0.17194570135746606, 'macro avg_f1-score': 0.21288515406162464, 'macro avg_support': 221.0, 'weighted avg_precision': 0.27941176470588236, 'weighted avg_recall': 0.17194570135746606, 'weighted avg_f1-score': 0.21288515406162464, 'weighted avg_support': 221.0, 'O_support': 2408, 'B-Appeal_to_Hypocrisy_support': 136, 'I-Appeal_to_Hypocrisy_support': 2879, 'epoch': 2}
{'results': [{'micro_f1': 0.7446063064724322, 'Appeal_to_Hypocrisy_precision': 0.19852941176470587, 'Appeal_to_Hypocrisy_recall': 0.1, 'Appeal_to_Hypocrisy_f1-score': 0.1330049261083744, 'Appeal_to_Hypocrisy_support': 270.0, 'micro avg_precision': 0.19852941176470587, 'micro avg_recall': 0.1, 'micro avg_f1-score': 0.1330049261083744, 'micro avg_support': 270.0, 'macro avg_precision': 0.19852941176470587, 'macro avg_recall': 0.1, 'macro avg_f1-score': 0.1330049261083744, 'macro avg_support': 270.0, 'weighted avg_precision': 0.19852941176470587, 'weighted avg_recall': 0.1, 'weighted avg_f1-score': 0.1330049261083744, 'weighted avg_support': 270.0, 'O_support': 2408, 'B-Appeal_to_Hypocrisy_support': 136, 'I-Appeal_to_Hypocrisy_support': 2879, 'epoch': 0}, {'micro_f1': 0.7759542688548774, 'Appeal_to_Hypocrisy_precision': 0.2647058823529412, 'Appeal_to_Hypocrisy_recall': 0.15126050420168066, 'Appeal_to_Hypocrisy_f1-score': 0.1925133689839572, 'Appeal_to_Hypocrisy_support': 238.0, 'micro avg_precision': 0.2647058823529412, 'micro avg_recall': 0.15126050420168066, 'micro avg_f1-score': 0.1925133689839572, 'micro avg_support': 238.0, 'macro avg_precision': 0.2647058823529412, 'macro avg_recall': 0.15126050420168066, 'macro avg_f1-score': 0.1925133689839572, 'macro avg_support': 238.0, 'weighted avg_precision': 0.2647058823529412, 'weighted avg_recall': 0.15126050420168066, 'weighted avg_f1-score': 0.19251336898395718, 'weighted avg_support': 238.0, 'O_support': 2408, 'B-Appeal_to_Hypocrisy_support': 136, 'I-Appeal_to_Hypocrisy_support': 2879, 'epoch': 1}, {'micro_f1': 0.7789046653144016, 'Appeal_to_Hypocrisy_precision': 0.27941176470588236, 'Appeal_to_Hypocrisy_recall': 0.17194570135746606, 'Appeal_to_Hypocrisy_f1-score': 0.21288515406162464, 'Appeal_to_Hypocrisy_support': 221.0, 'micro avg_precision': 0.27941176470588236, 'micro avg_recall': 0.17194570135746606, 'micro avg_f1-score': 0.21288515406162464, 'micro avg_support': 221.0, 'macro avg_precision': 0.27941176470588236, 'macro avg_recall': 0.17194570135746606, 'macro avg_f1-score': 0.21288515406162464, 'macro avg_support': 221.0, 'weighted avg_precision': 0.27941176470588236, 'weighted avg_recall': 0.17194570135746606, 'weighted avg_f1-score': 0.21288515406162464, 'weighted avg_support': 221.0, 'O_support': 2408, 'B-Appeal_to_Hypocrisy_support': 136, 'I-Appeal_to_Hypocrisy_support': 2879, 'epoch': 2}]}
Best model updated: current epoch macro f1 = 0.21288515406162464
{'micro_f1': 0.7790890650931219, 'Appeal_to_Hypocrisy_precision': 0.23529411764705882, 'Appeal_to_Hypocrisy_recall': 0.1839080459770115, 'Appeal_to_Hypocrisy_f1-score': 0.2064516129032258, 'Appeal_to_Hypocrisy_support': 174.0, 'micro avg_precision': 0.23529411764705882, 'micro avg_recall': 0.1839080459770115, 'micro avg_f1-score': 0.2064516129032258, 'micro avg_support': 174.0, 'macro avg_precision': 0.23529411764705882, 'macro avg_recall': 0.1839080459770115, 'macro avg_f1-score': 0.2064516129032258, 'macro avg_support': 174.0, 'weighted avg_precision': 0.2352941176470588, 'weighted avg_recall': 0.1839080459770115, 'weighted avg_f1-score': 0.2064516129032258, 'weighted avg_support': 174.0, 'O_support': 2408, 'B-Appeal_to_Hypocrisy_support': 136, 'I-Appeal_to_Hypocrisy_support': 2879, 'epoch': 3}
{'results': [{'micro_f1': 0.7446063064724322, 'Appeal_to_Hypocrisy_precision': 0.19852941176470587, 'Appeal_to_Hypocrisy_recall': 0.1, 'Appeal_to_Hypocrisy_f1-score': 0.1330049261083744, 'Appeal_to_Hypocrisy_support': 270.0, 'micro avg_precision': 0.19852941176470587, 'micro avg_recall': 0.1, 'micro avg_f1-score': 0.1330049261083744, 'micro avg_support': 270.0, 'macro avg_precision': 0.19852941176470587, 'macro avg_recall': 0.1, 'macro avg_f1-score': 0.1330049261083744, 'macro avg_support': 270.0, 'weighted avg_precision': 0.19852941176470587, 'weighted avg_recall': 0.1, 'weighted avg_f1-score': 0.1330049261083744, 'weighted avg_support': 270.0, 'O_support': 2408, 'B-Appeal_to_Hypocrisy_support': 136, 'I-Appeal_to_Hypocrisy_support': 2879, 'epoch': 0}, {'micro_f1': 0.7759542688548774, 'Appeal_to_Hypocrisy_precision': 0.2647058823529412, 'Appeal_to_Hypocrisy_recall': 0.15126050420168066, 'Appeal_to_Hypocrisy_f1-score': 0.1925133689839572, 'Appeal_to_Hypocrisy_support': 238.0, 'micro avg_precision': 0.2647058823529412, 'micro avg_recall': 0.15126050420168066, 'micro avg_f1-score': 0.1925133689839572, 'micro avg_support': 238.0, 'macro avg_precision': 0.2647058823529412, 'macro avg_recall': 0.15126050420168066, 'macro avg_f1-score': 0.1925133689839572, 'macro avg_support': 238.0, 'weighted avg_precision': 0.2647058823529412, 'weighted avg_recall': 0.15126050420168066, 'weighted avg_f1-score': 0.19251336898395718, 'weighted avg_support': 238.0, 'O_support': 2408, 'B-Appeal_to_Hypocrisy_support': 136, 'I-Appeal_to_Hypocrisy_support': 2879, 'epoch': 1}, {'micro_f1': 0.7789046653144016, 'Appeal_to_Hypocrisy_precision': 0.27941176470588236, 'Appeal_to_Hypocrisy_recall': 0.17194570135746606, 'Appeal_to_Hypocrisy_f1-score': 0.21288515406162464, 'Appeal_to_Hypocrisy_support': 221.0, 'micro avg_precision': 0.27941176470588236, 'micro avg_recall': 0.17194570135746606, 'micro avg_f1-score': 0.21288515406162464, 'micro avg_support': 221.0, 'macro avg_precision': 0.27941176470588236, 'macro avg_recall': 0.17194570135746606, 'macro avg_f1-score': 0.21288515406162464, 'macro avg_support': 221.0, 'weighted avg_precision': 0.27941176470588236, 'weighted avg_recall': 0.17194570135746606, 'weighted avg_f1-score': 0.21288515406162464, 'weighted avg_support': 221.0, 'O_support': 2408, 'B-Appeal_to_Hypocrisy_support': 136, 'I-Appeal_to_Hypocrisy_support': 2879, 'epoch': 2}, {'micro_f1': 0.7790890650931219, 'Appeal_to_Hypocrisy_precision': 0.23529411764705882, 'Appeal_to_Hypocrisy_recall': 0.1839080459770115, 'Appeal_to_Hypocrisy_f1-score': 0.2064516129032258, 'Appeal_to_Hypocrisy_support': 174.0, 'micro avg_precision': 0.23529411764705882, 'micro avg_recall': 0.1839080459770115, 'micro avg_f1-score': 0.2064516129032258, 'micro avg_support': 174.0, 'macro avg_precision': 0.23529411764705882, 'macro avg_recall': 0.1839080459770115, 'macro avg_f1-score': 0.2064516129032258, 'macro avg_support': 174.0, 'weighted avg_precision': 0.2352941176470588, 'weighted avg_recall': 0.1839080459770115, 'weighted avg_f1-score': 0.2064516129032258, 'weighted avg_support': 174.0, 'O_support': 2408, 'B-Appeal_to_Hypocrisy_support': 136, 'I-Appeal_to_Hypocrisy_support': 2879, 'epoch': 3}]}
{'micro_f1': 0.7691314770422275, 'Appeal_to_Hypocrisy_precision': 0.23529411764705882, 'Appeal_to_Hypocrisy_recall': 0.17679558011049723, 'Appeal_to_Hypocrisy_f1-score': 0.20189274447949526, 'Appeal_to_Hypocrisy_support': 181.0, 'micro avg_precision': 0.23529411764705882, 'micro avg_recall': 0.17679558011049723, 'micro avg_f1-score': 0.20189274447949526, 'micro avg_support': 181.0, 'macro avg_precision': 0.23529411764705882, 'macro avg_recall': 0.17679558011049723, 'macro avg_f1-score': 0.20189274447949526, 'macro avg_support': 181.0, 'weighted avg_precision': 0.23529411764705882, 'weighted avg_recall': 0.17679558011049723, 'weighted avg_f1-score': 0.20189274447949526, 'weighted avg_support': 181.0, 'O_support': 2408, 'B-Appeal_to_Hypocrisy_support': 136, 'I-Appeal_to_Hypocrisy_support': 2879, 'epoch': 4}
{'results': [{'micro_f1': 0.7446063064724322, 'Appeal_to_Hypocrisy_precision': 0.19852941176470587, 'Appeal_to_Hypocrisy_recall': 0.1, 'Appeal_to_Hypocrisy_f1-score': 0.1330049261083744, 'Appeal_to_Hypocrisy_support': 270.0, 'micro avg_precision': 0.19852941176470587, 'micro avg_recall': 0.1, 'micro avg_f1-score': 0.1330049261083744, 'micro avg_support': 270.0, 'macro avg_precision': 0.19852941176470587, 'macro avg_recall': 0.1, 'macro avg_f1-score': 0.1330049261083744, 'macro avg_support': 270.0, 'weighted avg_precision': 0.19852941176470587, 'weighted avg_recall': 0.1, 'weighted avg_f1-score': 0.1330049261083744, 'weighted avg_support': 270.0, 'O_support': 2408, 'B-Appeal_to_Hypocrisy_support': 136, 'I-Appeal_to_Hypocrisy_support': 2879, 'epoch': 0}, {'micro_f1': 0.7759542688548774, 'Appeal_to_Hypocrisy_precision': 0.2647058823529412, 'Appeal_to_Hypocrisy_recall': 0.15126050420168066, 'Appeal_to_Hypocrisy_f1-score': 0.1925133689839572, 'Appeal_to_Hypocrisy_support': 238.0, 'micro avg_precision': 0.2647058823529412, 'micro avg_recall': 0.15126050420168066, 'micro avg_f1-score': 0.1925133689839572, 'micro avg_support': 238.0, 'macro avg_precision': 0.2647058823529412, 'macro avg_recall': 0.15126050420168066, 'macro avg_f1-score': 0.1925133689839572, 'macro avg_support': 238.0, 'weighted avg_precision': 0.2647058823529412, 'weighted avg_recall': 0.15126050420168066, 'weighted avg_f1-score': 0.19251336898395718, 'weighted avg_support': 238.0, 'O_support': 2408, 'B-Appeal_to_Hypocrisy_support': 136, 'I-Appeal_to_Hypocrisy_support': 2879, 'epoch': 1}, {'micro_f1': 0.7789046653144016, 'Appeal_to_Hypocrisy_precision': 0.27941176470588236, 'Appeal_to_Hypocrisy_recall': 0.17194570135746606, 'Appeal_to_Hypocrisy_f1-score': 0.21288515406162464, 'Appeal_to_Hypocrisy_support': 221.0, 'micro avg_precision': 0.27941176470588236, 'micro avg_recall': 0.17194570135746606, 'micro avg_f1-score': 0.21288515406162464, 'micro avg_support': 221.0, 'macro avg_precision': 0.27941176470588236, 'macro avg_recall': 0.17194570135746606, 'macro avg_f1-score': 0.21288515406162464, 'macro avg_support': 221.0, 'weighted avg_precision': 0.27941176470588236, 'weighted avg_recall': 0.17194570135746606, 'weighted avg_f1-score': 0.21288515406162464, 'weighted avg_support': 221.0, 'O_support': 2408, 'B-Appeal_to_Hypocrisy_support': 136, 'I-Appeal_to_Hypocrisy_support': 2879, 'epoch': 2}, {'micro_f1': 0.7790890650931219, 'Appeal_to_Hypocrisy_precision': 0.23529411764705882, 'Appeal_to_Hypocrisy_recall': 0.1839080459770115, 'Appeal_to_Hypocrisy_f1-score': 0.2064516129032258, 'Appeal_to_Hypocrisy_support': 174.0, 'micro avg_precision': 0.23529411764705882, 'micro avg_recall': 0.1839080459770115, 'micro avg_f1-score': 0.2064516129032258, 'micro avg_support': 174.0, 'macro avg_precision': 0.23529411764705882, 'macro avg_recall': 0.1839080459770115, 'macro avg_f1-score': 0.2064516129032258, 'macro avg_support': 174.0, 'weighted avg_precision': 0.2352941176470588, 'weighted avg_recall': 0.1839080459770115, 'weighted avg_f1-score': 0.2064516129032258, 'weighted avg_support': 174.0, 'O_support': 2408, 'B-Appeal_to_Hypocrisy_support': 136, 'I-Appeal_to_Hypocrisy_support': 2879, 'epoch': 3}, {'micro_f1': 0.7691314770422275, 'Appeal_to_Hypocrisy_precision': 0.23529411764705882, 'Appeal_to_Hypocrisy_recall': 0.17679558011049723, 'Appeal_to_Hypocrisy_f1-score': 0.20189274447949526, 'Appeal_to_Hypocrisy_support': 181.0, 'micro avg_precision': 0.23529411764705882, 'micro avg_recall': 0.17679558011049723, 'micro avg_f1-score': 0.20189274447949526, 'micro avg_support': 181.0, 'macro avg_precision': 0.23529411764705882, 'macro avg_recall': 0.17679558011049723, 'macro avg_f1-score': 0.20189274447949526, 'macro avg_support': 181.0, 'weighted avg_precision': 0.23529411764705882, 'weighted avg_recall': 0.17679558011049723, 'weighted avg_f1-score': 0.20189274447949526, 'weighted avg_support': 181.0, 'O_support': 2408, 'B-Appeal_to_Hypocrisy_support': 136, 'I-Appeal_to_Hypocrisy_support': 2879, 'epoch': 4}]}
Early stopping triggered.
Saving model to directory: ./models/M2/2024-05-12-17-42-10_aug/mdeberta-v3-base_21_ME10_target=Appeal_to_Hypocrisy_SUBSAMPLED_2024-05-12-17-42-10
Training model no. 22 of 23 for (22, 'Questioning_the_Reputation') persuasion technique...
{'micro_f1': 0.7494152267411153, 'Questioning_the_Reputation_precision': 0.2236024844720497, 'Questioning_the_Reputation_recall': 0.11162790697674418, 'Questioning_the_Reputation_f1-score': 0.14891416752843847, 'Questioning_the_Reputation_support': 645.0, 'micro avg_precision': 0.2236024844720497, 'micro avg_recall': 0.11162790697674418, 'micro avg_f1-score': 0.14891416752843847, 'micro avg_support': 645.0, 'macro avg_precision': 0.2236024844720497, 'macro avg_recall': 0.11162790697674418, 'macro avg_f1-score': 0.14891416752843847, 'macro avg_support': 645.0, 'weighted avg_precision': 0.2236024844720497, 'weighted avg_recall': 0.11162790697674418, 'weighted avg_f1-score': 0.14891416752843847, 'weighted avg_support': 645.0, 'O_support': 7710, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 0}
{'results': [{'micro_f1': 0.7494152267411153, 'Questioning_the_Reputation_precision': 0.2236024844720497, 'Questioning_the_Reputation_recall': 0.11162790697674418, 'Questioning_the_Reputation_f1-score': 0.14891416752843847, 'Questioning_the_Reputation_support': 645.0, 'micro avg_precision': 0.2236024844720497, 'micro avg_recall': 0.11162790697674418, 'micro avg_f1-score': 0.14891416752843847, 'micro avg_support': 645.0, 'macro avg_precision': 0.2236024844720497, 'macro avg_recall': 0.11162790697674418, 'macro avg_f1-score': 0.14891416752843847, 'macro avg_support': 645.0, 'weighted avg_precision': 0.2236024844720497, 'weighted avg_recall': 0.11162790697674418, 'weighted avg_f1-score': 0.14891416752843847, 'weighted avg_support': 645.0, 'O_support': 7710, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 0}]}
Best model updated: current epoch macro f1 = 0.14891416752843847
{'micro_f1': 0.7743152493774994, 'Questioning_the_Reputation_precision': 0.18322981366459629, 'Questioning_the_Reputation_recall': 0.11346153846153846, 'Questioning_the_Reputation_f1-score': 0.14014251781472686, 'Questioning_the_Reputation_support': 520.0, 'micro avg_precision': 0.18322981366459629, 'micro avg_recall': 0.11346153846153846, 'micro avg_f1-score': 0.14014251781472686, 'micro avg_support': 520.0, 'macro avg_precision': 0.18322981366459629, 'macro avg_recall': 0.11346153846153846, 'macro avg_f1-score': 0.14014251781472686, 'macro avg_support': 520.0, 'weighted avg_precision': 0.18322981366459629, 'weighted avg_recall': 0.11346153846153846, 'weighted avg_f1-score': 0.14014251781472686, 'weighted avg_support': 520.0, 'O_support': 7710, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 1}
{'results': [{'micro_f1': 0.7494152267411153, 'Questioning_the_Reputation_precision': 0.2236024844720497, 'Questioning_the_Reputation_recall': 0.11162790697674418, 'Questioning_the_Reputation_f1-score': 0.14891416752843847, 'Questioning_the_Reputation_support': 645.0, 'micro avg_precision': 0.2236024844720497, 'micro avg_recall': 0.11162790697674418, 'micro avg_f1-score': 0.14891416752843847, 'micro avg_support': 645.0, 'macro avg_precision': 0.2236024844720497, 'macro avg_recall': 0.11162790697674418, 'macro avg_f1-score': 0.14891416752843847, 'macro avg_support': 645.0, 'weighted avg_precision': 0.2236024844720497, 'weighted avg_recall': 0.11162790697674418, 'weighted avg_f1-score': 0.14891416752843847, 'weighted avg_support': 645.0, 'O_support': 7710, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 0}, {'micro_f1': 0.7743152493774994, 'Questioning_the_Reputation_precision': 0.18322981366459629, 'Questioning_the_Reputation_recall': 0.11346153846153846, 'Questioning_the_Reputation_f1-score': 0.14014251781472686, 'Questioning_the_Reputation_support': 520.0, 'micro avg_precision': 0.18322981366459629, 'micro avg_recall': 0.11346153846153846, 'micro avg_f1-score': 0.14014251781472686, 'micro avg_support': 520.0, 'macro avg_precision': 0.18322981366459629, 'macro avg_recall': 0.11346153846153846, 'macro avg_f1-score': 0.14014251781472686, 'macro avg_support': 520.0, 'weighted avg_precision': 0.18322981366459629, 'weighted avg_recall': 0.11346153846153846, 'weighted avg_f1-score': 0.14014251781472686, 'weighted avg_support': 520.0, 'O_support': 7710, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 1}]}
{'micro_f1': 0.7647325133931939, 'Questioning_the_Reputation_precision': 0.2360248447204969, 'Questioning_the_Reputation_recall': 0.15510204081632653, 'Questioning_the_Reputation_f1-score': 0.187192118226601, 'Questioning_the_Reputation_support': 490.0, 'micro avg_precision': 0.2360248447204969, 'micro avg_recall': 0.15510204081632653, 'micro avg_f1-score': 0.187192118226601, 'micro avg_support': 490.0, 'macro avg_precision': 0.2360248447204969, 'macro avg_recall': 0.15510204081632653, 'macro avg_f1-score': 0.187192118226601, 'macro avg_support': 490.0, 'weighted avg_precision': 0.2360248447204969, 'weighted avg_recall': 0.15510204081632653, 'weighted avg_f1-score': 0.187192118226601, 'weighted avg_support': 490.0, 'O_support': 7710, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 2}
{'results': [{'micro_f1': 0.7494152267411153, 'Questioning_the_Reputation_precision': 0.2236024844720497, 'Questioning_the_Reputation_recall': 0.11162790697674418, 'Questioning_the_Reputation_f1-score': 0.14891416752843847, 'Questioning_the_Reputation_support': 645.0, 'micro avg_precision': 0.2236024844720497, 'micro avg_recall': 0.11162790697674418, 'micro avg_f1-score': 0.14891416752843847, 'micro avg_support': 645.0, 'macro avg_precision': 0.2236024844720497, 'macro avg_recall': 0.11162790697674418, 'macro avg_f1-score': 0.14891416752843847, 'macro avg_support': 645.0, 'weighted avg_precision': 0.2236024844720497, 'weighted avg_recall': 0.11162790697674418, 'weighted avg_f1-score': 0.14891416752843847, 'weighted avg_support': 645.0, 'O_support': 7710, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 0}, {'micro_f1': 0.7743152493774994, 'Questioning_the_Reputation_precision': 0.18322981366459629, 'Questioning_the_Reputation_recall': 0.11346153846153846, 'Questioning_the_Reputation_f1-score': 0.14014251781472686, 'Questioning_the_Reputation_support': 520.0, 'micro avg_precision': 0.18322981366459629, 'micro avg_recall': 0.11346153846153846, 'micro avg_f1-score': 0.14014251781472686, 'micro avg_support': 520.0, 'macro avg_precision': 0.18322981366459629, 'macro avg_recall': 0.11346153846153846, 'macro avg_f1-score': 0.14014251781472686, 'macro avg_support': 520.0, 'weighted avg_precision': 0.18322981366459629, 'weighted avg_recall': 0.11346153846153846, 'weighted avg_f1-score': 0.14014251781472686, 'weighted avg_support': 520.0, 'O_support': 7710, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 1}, {'micro_f1': 0.7647325133931939, 'Questioning_the_Reputation_precision': 0.2360248447204969, 'Questioning_the_Reputation_recall': 0.15510204081632653, 'Questioning_the_Reputation_f1-score': 0.187192118226601, 'Questioning_the_Reputation_support': 490.0, 'micro avg_precision': 0.2360248447204969, 'micro avg_recall': 0.15510204081632653, 'micro avg_f1-score': 0.187192118226601, 'micro avg_support': 490.0, 'macro avg_precision': 0.2360248447204969, 'macro avg_recall': 0.15510204081632653, 'macro avg_f1-score': 0.187192118226601, 'macro avg_support': 490.0, 'weighted avg_precision': 0.2360248447204969, 'weighted avg_recall': 0.15510204081632653, 'weighted avg_f1-score': 0.187192118226601, 'weighted avg_support': 490.0, 'O_support': 7710, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 2}]}
Best model updated: current epoch macro f1 = 0.187192118226601
{'micro_f1': 0.750094318267562, 'Questioning_the_Reputation_precision': 0.2670807453416149, 'Questioning_the_Reputation_recall': 0.16443594646271512, 'Questioning_the_Reputation_f1-score': 0.20355029585798817, 'Questioning_the_Reputation_support': 523.0, 'micro avg_precision': 0.2670807453416149, 'micro avg_recall': 0.16443594646271512, 'micro avg_f1-score': 0.20355029585798817, 'micro avg_support': 523.0, 'macro avg_precision': 0.2670807453416149, 'macro avg_recall': 0.16443594646271512, 'macro avg_f1-score': 0.20355029585798817, 'macro avg_support': 523.0, 'weighted avg_precision': 0.2670807453416149, 'weighted avg_recall': 0.16443594646271512, 'weighted avg_f1-score': 0.20355029585798817, 'weighted avg_support': 523.0, 'O_support': 7710, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 3}
{'results': [{'micro_f1': 0.7494152267411153, 'Questioning_the_Reputation_precision': 0.2236024844720497, 'Questioning_the_Reputation_recall': 0.11162790697674418, 'Questioning_the_Reputation_f1-score': 0.14891416752843847, 'Questioning_the_Reputation_support': 645.0, 'micro avg_precision': 0.2236024844720497, 'micro avg_recall': 0.11162790697674418, 'micro avg_f1-score': 0.14891416752843847, 'micro avg_support': 645.0, 'macro avg_precision': 0.2236024844720497, 'macro avg_recall': 0.11162790697674418, 'macro avg_f1-score': 0.14891416752843847, 'macro avg_support': 645.0, 'weighted avg_precision': 0.2236024844720497, 'weighted avg_recall': 0.11162790697674418, 'weighted avg_f1-score': 0.14891416752843847, 'weighted avg_support': 645.0, 'O_support': 7710, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 0}, {'micro_f1': 0.7743152493774994, 'Questioning_the_Reputation_precision': 0.18322981366459629, 'Questioning_the_Reputation_recall': 0.11346153846153846, 'Questioning_the_Reputation_f1-score': 0.14014251781472686, 'Questioning_the_Reputation_support': 520.0, 'micro avg_precision': 0.18322981366459629, 'micro avg_recall': 0.11346153846153846, 'micro avg_f1-score': 0.14014251781472686, 'micro avg_support': 520.0, 'macro avg_precision': 0.18322981366459629, 'macro avg_recall': 0.11346153846153846, 'macro avg_f1-score': 0.14014251781472686, 'macro avg_support': 520.0, 'weighted avg_precision': 0.18322981366459629, 'weighted avg_recall': 0.11346153846153846, 'weighted avg_f1-score': 0.14014251781472686, 'weighted avg_support': 520.0, 'O_support': 7710, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 1}, {'micro_f1': 0.7647325133931939, 'Questioning_the_Reputation_precision': 0.2360248447204969, 'Questioning_the_Reputation_recall': 0.15510204081632653, 'Questioning_the_Reputation_f1-score': 0.187192118226601, 'Questioning_the_Reputation_support': 490.0, 'micro avg_precision': 0.2360248447204969, 'micro avg_recall': 0.15510204081632653, 'micro avg_f1-score': 0.187192118226601, 'micro avg_support': 490.0, 'macro avg_precision': 0.2360248447204969, 'macro avg_recall': 0.15510204081632653, 'macro avg_f1-score': 0.187192118226601, 'macro avg_support': 490.0, 'weighted avg_precision': 0.2360248447204969, 'weighted avg_recall': 0.15510204081632653, 'weighted avg_f1-score': 0.187192118226601, 'weighted avg_support': 490.0, 'O_support': 7710, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 2}, {'micro_f1': 0.750094318267562, 'Questioning_the_Reputation_precision': 0.2670807453416149, 'Questioning_the_Reputation_recall': 0.16443594646271512, 'Questioning_the_Reputation_f1-score': 0.20355029585798817, 'Questioning_the_Reputation_support': 523.0, 'micro avg_precision': 0.2670807453416149, 'micro avg_recall': 0.16443594646271512, 'micro avg_f1-score': 0.20355029585798817, 'micro avg_support': 523.0, 'macro avg_precision': 0.2670807453416149, 'macro avg_recall': 0.16443594646271512, 'macro avg_f1-score': 0.20355029585798817, 'macro avg_support': 523.0, 'weighted avg_precision': 0.2670807453416149, 'weighted avg_recall': 0.16443594646271512, 'weighted avg_f1-score': 0.20355029585798817, 'weighted avg_support': 523.0, 'O_support': 7710, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 3}]}
Best model updated: current epoch macro f1 = 0.20355029585798817
{'micro_f1': 0.7642043310948464, 'Questioning_the_Reputation_precision': 0.22981366459627328, 'Questioning_the_Reputation_recall': 0.1689497716894977, 'Questioning_the_Reputation_f1-score': 0.19473684210526315, 'Questioning_the_Reputation_support': 438.0, 'micro avg_precision': 0.22981366459627328, 'micro avg_recall': 0.1689497716894977, 'micro avg_f1-score': 0.19473684210526315, 'micro avg_support': 438.0, 'macro avg_precision': 0.22981366459627328, 'macro avg_recall': 0.1689497716894977, 'macro avg_f1-score': 0.19473684210526315, 'macro avg_support': 438.0, 'weighted avg_precision': 0.22981366459627328, 'weighted avg_recall': 0.1689497716894977, 'weighted avg_f1-score': 0.19473684210526315, 'weighted avg_support': 438.0, 'O_support': 7710, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 4}
{'results': [{'micro_f1': 0.7494152267411153, 'Questioning_the_Reputation_precision': 0.2236024844720497, 'Questioning_the_Reputation_recall': 0.11162790697674418, 'Questioning_the_Reputation_f1-score': 0.14891416752843847, 'Questioning_the_Reputation_support': 645.0, 'micro avg_precision': 0.2236024844720497, 'micro avg_recall': 0.11162790697674418, 'micro avg_f1-score': 0.14891416752843847, 'micro avg_support': 645.0, 'macro avg_precision': 0.2236024844720497, 'macro avg_recall': 0.11162790697674418, 'macro avg_f1-score': 0.14891416752843847, 'macro avg_support': 645.0, 'weighted avg_precision': 0.2236024844720497, 'weighted avg_recall': 0.11162790697674418, 'weighted avg_f1-score': 0.14891416752843847, 'weighted avg_support': 645.0, 'O_support': 7710, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 0}, {'micro_f1': 0.7743152493774994, 'Questioning_the_Reputation_precision': 0.18322981366459629, 'Questioning_the_Reputation_recall': 0.11346153846153846, 'Questioning_the_Reputation_f1-score': 0.14014251781472686, 'Questioning_the_Reputation_support': 520.0, 'micro avg_precision': 0.18322981366459629, 'micro avg_recall': 0.11346153846153846, 'micro avg_f1-score': 0.14014251781472686, 'micro avg_support': 520.0, 'macro avg_precision': 0.18322981366459629, 'macro avg_recall': 0.11346153846153846, 'macro avg_f1-score': 0.14014251781472686, 'macro avg_support': 520.0, 'weighted avg_precision': 0.18322981366459629, 'weighted avg_recall': 0.11346153846153846, 'weighted avg_f1-score': 0.14014251781472686, 'weighted avg_support': 520.0, 'O_support': 7710, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 1}, {'micro_f1': 0.7647325133931939, 'Questioning_the_Reputation_precision': 0.2360248447204969, 'Questioning_the_Reputation_recall': 0.15510204081632653, 'Questioning_the_Reputation_f1-score': 0.187192118226601, 'Questioning_the_Reputation_support': 490.0, 'micro avg_precision': 0.2360248447204969, 'micro avg_recall': 0.15510204081632653, 'micro avg_f1-score': 0.187192118226601, 'micro avg_support': 490.0, 'macro avg_precision': 0.2360248447204969, 'macro avg_recall': 0.15510204081632653, 'macro avg_f1-score': 0.187192118226601, 'macro avg_support': 490.0, 'weighted avg_precision': 0.2360248447204969, 'weighted avg_recall': 0.15510204081632653, 'weighted avg_f1-score': 0.187192118226601, 'weighted avg_support': 490.0, 'O_support': 7710, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 2}, {'micro_f1': 0.750094318267562, 'Questioning_the_Reputation_precision': 0.2670807453416149, 'Questioning_the_Reputation_recall': 0.16443594646271512, 'Questioning_the_Reputation_f1-score': 0.20355029585798817, 'Questioning_the_Reputation_support': 523.0, 'micro avg_precision': 0.2670807453416149, 'micro avg_recall': 0.16443594646271512, 'micro avg_f1-score': 0.20355029585798817, 'micro avg_support': 523.0, 'macro avg_precision': 0.2670807453416149, 'macro avg_recall': 0.16443594646271512, 'macro avg_f1-score': 0.20355029585798817, 'macro avg_support': 523.0, 'weighted avg_precision': 0.2670807453416149, 'weighted avg_recall': 0.16443594646271512, 'weighted avg_f1-score': 0.20355029585798817, 'weighted avg_support': 523.0, 'O_support': 7710, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 3}, {'micro_f1': 0.7642043310948464, 'Questioning_the_Reputation_precision': 0.22981366459627328, 'Questioning_the_Reputation_recall': 0.1689497716894977, 'Questioning_the_Reputation_f1-score': 0.19473684210526315, 'Questioning_the_Reputation_support': 438.0, 'micro avg_precision': 0.22981366459627328, 'micro avg_recall': 0.1689497716894977, 'micro avg_f1-score': 0.19473684210526315, 'micro avg_support': 438.0, 'macro avg_precision': 0.22981366459627328, 'macro avg_recall': 0.1689497716894977, 'macro avg_f1-score': 0.19473684210526315, 'macro avg_support': 438.0, 'weighted avg_precision': 0.22981366459627328, 'weighted avg_recall': 0.1689497716894977, 'weighted avg_f1-score': 0.19473684210526315, 'weighted avg_support': 438.0, 'O_support': 7710, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 4}]}
{'micro_f1': 0.7521315928469027, 'Questioning_the_Reputation_precision': 0.2267080745341615, 'Questioning_the_Reputation_recall': 0.18159203980099503, 'Questioning_the_Reputation_f1-score': 0.20165745856353592, 'Questioning_the_Reputation_support': 402.0, 'micro avg_precision': 0.2267080745341615, 'micro avg_recall': 0.18159203980099503, 'micro avg_f1-score': 0.20165745856353592, 'micro avg_support': 402.0, 'macro avg_precision': 0.2267080745341615, 'macro avg_recall': 0.18159203980099503, 'macro avg_f1-score': 0.20165745856353592, 'macro avg_support': 402.0, 'weighted avg_precision': 0.2267080745341615, 'weighted avg_recall': 0.18159203980099503, 'weighted avg_f1-score': 0.20165745856353592, 'weighted avg_support': 402.0, 'O_support': 7710, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 5}
{'results': [{'micro_f1': 0.7494152267411153, 'Questioning_the_Reputation_precision': 0.2236024844720497, 'Questioning_the_Reputation_recall': 0.11162790697674418, 'Questioning_the_Reputation_f1-score': 0.14891416752843847, 'Questioning_the_Reputation_support': 645.0, 'micro avg_precision': 0.2236024844720497, 'micro avg_recall': 0.11162790697674418, 'micro avg_f1-score': 0.14891416752843847, 'micro avg_support': 645.0, 'macro avg_precision': 0.2236024844720497, 'macro avg_recall': 0.11162790697674418, 'macro avg_f1-score': 0.14891416752843847, 'macro avg_support': 645.0, 'weighted avg_precision': 0.2236024844720497, 'weighted avg_recall': 0.11162790697674418, 'weighted avg_f1-score': 0.14891416752843847, 'weighted avg_support': 645.0, 'O_support': 7710, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 0}, {'micro_f1': 0.7743152493774994, 'Questioning_the_Reputation_precision': 0.18322981366459629, 'Questioning_the_Reputation_recall': 0.11346153846153846, 'Questioning_the_Reputation_f1-score': 0.14014251781472686, 'Questioning_the_Reputation_support': 520.0, 'micro avg_precision': 0.18322981366459629, 'micro avg_recall': 0.11346153846153846, 'micro avg_f1-score': 0.14014251781472686, 'micro avg_support': 520.0, 'macro avg_precision': 0.18322981366459629, 'macro avg_recall': 0.11346153846153846, 'macro avg_f1-score': 0.14014251781472686, 'macro avg_support': 520.0, 'weighted avg_precision': 0.18322981366459629, 'weighted avg_recall': 0.11346153846153846, 'weighted avg_f1-score': 0.14014251781472686, 'weighted avg_support': 520.0, 'O_support': 7710, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 1}, {'micro_f1': 0.7647325133931939, 'Questioning_the_Reputation_precision': 0.2360248447204969, 'Questioning_the_Reputation_recall': 0.15510204081632653, 'Questioning_the_Reputation_f1-score': 0.187192118226601, 'Questioning_the_Reputation_support': 490.0, 'micro avg_precision': 0.2360248447204969, 'micro avg_recall': 0.15510204081632653, 'micro avg_f1-score': 0.187192118226601, 'micro avg_support': 490.0, 'macro avg_precision': 0.2360248447204969, 'macro avg_recall': 0.15510204081632653, 'macro avg_f1-score': 0.187192118226601, 'macro avg_support': 490.0, 'weighted avg_precision': 0.2360248447204969, 'weighted avg_recall': 0.15510204081632653, 'weighted avg_f1-score': 0.187192118226601, 'weighted avg_support': 490.0, 'O_support': 7710, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 2}, {'micro_f1': 0.750094318267562, 'Questioning_the_Reputation_precision': 0.2670807453416149, 'Questioning_the_Reputation_recall': 0.16443594646271512, 'Questioning_the_Reputation_f1-score': 0.20355029585798817, 'Questioning_the_Reputation_support': 523.0, 'micro avg_precision': 0.2670807453416149, 'micro avg_recall': 0.16443594646271512, 'micro avg_f1-score': 0.20355029585798817, 'micro avg_support': 523.0, 'macro avg_precision': 0.2670807453416149, 'macro avg_recall': 0.16443594646271512, 'macro avg_f1-score': 0.20355029585798817, 'macro avg_support': 523.0, 'weighted avg_precision': 0.2670807453416149, 'weighted avg_recall': 0.16443594646271512, 'weighted avg_f1-score': 0.20355029585798817, 'weighted avg_support': 523.0, 'O_support': 7710, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 3}, {'micro_f1': 0.7642043310948464, 'Questioning_the_Reputation_precision': 0.22981366459627328, 'Questioning_the_Reputation_recall': 0.1689497716894977, 'Questioning_the_Reputation_f1-score': 0.19473684210526315, 'Questioning_the_Reputation_support': 438.0, 'micro avg_precision': 0.22981366459627328, 'micro avg_recall': 0.1689497716894977, 'micro avg_f1-score': 0.19473684210526315, 'micro avg_support': 438.0, 'macro avg_precision': 0.22981366459627328, 'macro avg_recall': 0.1689497716894977, 'macro avg_f1-score': 0.19473684210526315, 'macro avg_support': 438.0, 'weighted avg_precision': 0.22981366459627328, 'weighted avg_recall': 0.1689497716894977, 'weighted avg_f1-score': 0.19473684210526315, 'weighted avg_support': 438.0, 'O_support': 7710, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 4}, {'micro_f1': 0.7521315928469027, 'Questioning_the_Reputation_precision': 0.2267080745341615, 'Questioning_the_Reputation_recall': 0.18159203980099503, 'Questioning_the_Reputation_f1-score': 0.20165745856353592, 'Questioning_the_Reputation_support': 402.0, 'micro avg_precision': 0.2267080745341615, 'micro avg_recall': 0.18159203980099503, 'micro avg_f1-score': 0.20165745856353592, 'micro avg_support': 402.0, 'macro avg_precision': 0.2267080745341615, 'macro avg_recall': 0.18159203980099503, 'macro avg_f1-score': 0.20165745856353592, 'macro avg_support': 402.0, 'weighted avg_precision': 0.2267080745341615, 'weighted avg_recall': 0.18159203980099503, 'weighted avg_f1-score': 0.20165745856353592, 'weighted avg_support': 402.0, 'O_support': 7710, 'B-Questioning_the_Reputation_support': 322, 'I-Questioning_the_Reputation_support': 5221, 'epoch': 5}]}
Early stopping triggered.
Saving model to directory: ./models/M2/2024-05-12-17-42-10_aug/mdeberta-v3-base_22_ME10_target=Questioning_the_Reputation_SUBSAMPLED_2024-05-12-17-42-10
